[{"content":"Redis学习与实战 缓存穿透 缓存穿透是指客户端请求的数据,Redis和Mysql里面都没有,缓存永远不会生效,如果客户端一直请求相同的id,请求就会一直到达数据库,给数据库上压力了.\n解决方案1:缓存空对象 缓存空对象:如果客户端请求找不到的数据,就把找不到的数据缓存到Redis里,并且设置过期时间,在一定时间内,客户端的空对象请求不会经过Mysql\n缺点:有额外内存消耗,如果管理端新增对象和空对象id相同,可能造成缓存与数据库内容不一致\n解决缓存穿透的业务逻辑: 对应的java逻辑代码: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result getByIdRedis(Long id) { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 解决方案2:布隆过滤 缓存穿透后,穿透的信息进入布隆过滤器,如果再进行查询,先查询布隆过滤器,如果这个id是穿透信息,就直接拒绝查询\n其他解决方案: 做好热点参数的限流\n加强用户权限校验\n缓存雪崩 缓存雪崩是指大量数据同时到期,或者Redis服务直接宕机,大量请求涌入Mysql)\n简单解决办法 把数据存储进Redis的时候直接随机过期时间存储\njava代码如下（其实就是生成随机数) 1 2 3 4 5 private Long cacheAvalanche(){ Random random=new Random(); Long number=random.nextInt(11)+20L; return number; } 其他高级解决方案: Redis集群,分布式部署\n给缓存业务添加降级限流策略,如果redis集体驾崩,就直接拒绝大量请求,防止MySQL数据库压力过大\n给业务添加多级缓存\n缓存击穿 一个热点数据过期,大量线程同时访问,每个线程都选择查询完Redis后查询数据库,导致数据库压力剧增\n解决方案1:互斥锁 使用Redis的setnx作为互斥条件,所有线程同时设置一个键值对,只有一个线程可以设置成功,并且操作数据库,写入缓存,写完后释放锁资源\n1 2 3 4 5 6 7 8 9 10 11 12 13 //设置锁和释放锁的方法 private Boolean setLock(String key){ Boolean flag= stringRedisTemplate.opsForValue().setIfAbsent(key,\u0026#34;1\u0026#34;,10,TimeUnit.SECONDS); if(flag==null){ return false; }else if(flag){ return true; } return false; } private void unLock(String key){ stringRedisTemplate.delete(key); } 互斥锁解决缓存穿透的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result getByIdRedis(Long id) throws InterruptedException { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程休眠对应的时间后重新尝试获取资源(递归) }else { Thread.sleep(50); getByIdRedis(id); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 其中为防止获得锁的线程挂了不会释放锁资源,给锁设置过期时间\n解决方案2:逻辑过期时间 在Redis中存储数据时,多存储一条过期时间,如果过期的话,最快发现的线程会主动申请互斥锁,并且查询数据库,查完后设置过期时间并且写回redis,同时返回给客户端,其他的线程请求完锁后,请求不到就直接返回过期的数据,这种方式可以防止死锁的发生,但是牺牲了一部分redis空间 java代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Override public Result redisLogicExpireTime(Long id){ String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); logger.info(shop); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ RedisData redisData=JSONUtil.toBean(shop,RedisData.class); //判断是否过期 if(redisData.getExpireTime().isAfter(LocalDateTime.now())){ Shop shopRedis= redisData.getData(); System.out.println(shopRedis); logger.info(\u0026#34;查询redis直接输出\u0026#34;); return Result.ok(shopRedis); } } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null\u0026amp;\u0026amp;shop.equals(\u0026#34;\u0026#34;)){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,cacheAvalanche(), TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } RedisData redisData=new RedisData(); redisData.setData(shop1); redisData.setExpireTime(LocalDateTime.now().plusMinutes(cacheAvalanche())); String json= JSON.toJSONString(redisData); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,cacheAvalanche(), TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程直接返回过期的数据 }else { RedisData redisData=new RedisData(); redisData.setData(JSONUtil.toBean(shop,Shop.class)); Shop redis=redisData.getData(); return Result.ok(redis); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 订单秒杀问题 限量限时商品可能会在短时间内面临大量请求,可能会出现超卖的情况\n如果第一次遇到1的时候没来得及写到数据库里,后面的线程查询的时候遇到的还是1,就可以继续执行扣减的操作,导致超卖的情况发生\nJMeter测试结果 200次线程请求直接超卖了9个商品\n解决方案1:乐观锁 • 假设：乐观锁假设冲突发生的概率很小，允许多个事务同时操作数据，但在提交时检查是否有其他事务修改了数据。\n• 实现：通常通过版本号（version）或时间戳（timestamp）实现。在更新数据时，比较当前版本号与数据库中的版本号，如果一致则更新并增加版本号；如果不一致，则说明数据已被其他事务修改，需要重新获取数据并重试。\n• 适用场景：适用于读多写少的场景，或者数据竞争不激烈的情况下。\nJava实现 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .eq(\u0026#34;stock\u0026#34;, seckillVoucher.getStock()) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } 在写入数据库之前,先查询数据库目前的值和之前查询到的是否一样,是否在写入之前被修改了,如果被修改了就不能写入\nJMeter测试结果 可以发现成功率低的可怜,200次请求只抢到了21张票,原因就是每次写入都要查询到之前是否已经写过,请求频率太高,导致不写入的概率也更高,写入越多的情况越不能用乐观锁\n解决方案2:悲观锁 • 假设：悲观锁假设会发生冲突，即多个事务会同时修改同一数据，因此它在操作开始时就锁定数据，防止其他事务修改。\n• 实现：通常通过数据库的锁机制实现，如行锁、表锁等。\n• 适用场景：适用于写操作频繁的场景，或者数据竞争非常激烈的情况下。\n只要在每次写入更新结果之前先查看一下剩余的量是不是大于0就可以了\nJava代码 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } JMeter测试结果 200次请求,只卖出100张,异常比例正确\n单人订单问题 有些商品给购买者限量,比如买火车票或者限定周边,如果一个黄牛用脚本在短时间大量请求,则有可能会多卖\n简单解决\n1 2 3 4 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } JMeter测试结果显示,200个请求同时下单,一共能购买10张票\n解决方案:共享锁 在 Java 中， synchronized是一个关键字，用于控制对共享资源的访问，确保在同一时刻只有一个线程可以访问特定的代码块或方法。这是实现线程同步的一种方式，主要用于解决多线程环境下的并发问题。\n我们可以把订单秒杀的代码先抽离出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Transactional(rollbackFor = Exception.class) public Result createVoucherOrder(Long voucherId) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); voucherOrderMapper.insert(voucherOrder); return Result.ok(voucherOrder.getVoucherId() + \u0026#34;下单成功\u0026#34;); } 如果是对整个函数加锁,也就是在public后面,那么不是同一个用户也会被锁给拦截,性能不高\n或者可以给锁限定userId,如果同一id就被拦截,串行进行\n1 2 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) 这里intern的作用是,toString会导致产生新的字符串对象,字符串对象虽然值是相同的,但是哈希值不一样,被锁认为是不同的对象,这时用intern可以从字符串池里找相同的串,哈希值相同\n锁应当在事务结束之后再释放才行,否则又会产生冲突,事务还没结束,有个线程又进来了,会引发异常,因此应当把锁放到整个方法外面\n1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } JMeter测试结果 200次买票,只买到1次,解决了单人买票的问题\n上述写法依然有问题\nJava魅力时刻 1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } 注意到这里的return createVoucherOrder(voucherId);是目标对象引用的函数，相当于\nreturn this.createVoucherOrder(voucherId);但是只有代理对象才有事务管理的功能,代理对象就是加上@Controller,@Service,@Mapper,@Component,@Bean的对象,这个对象协助目标对象完成工作.\n要想在这个对象里面调用代理对象可以通过如下办法\n1 2 3 4 5 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } AopContext.currentProxy()获取本类的代理对象,然后从Object转成本类的对象,然后调用对应的方法,要在接口里面重新声明这个方法\n同时要引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectjweaver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.22.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在springboot启动类上加注解\n1 @EnableAspectJAutoProxy(exposeProxy = true) 允许SpringIOC容器暴露代理对象,这样我们才能正常获取代理对象\nRedis实现分布式锁 如果现在同时开两个进程,服务器集群部署,由nginx实现负载均衡,实现轮询发送请求,先给8081端口发送,再给8082端口,导致进程内的锁无法和另一个进程的锁联动\n这时可以使用伟大的Redis制作分布式锁来解决这个问题!\n分布式锁的设计 这个锁应当起到互斥作用,很多个线程同时发送过来,只能有一个线程获取锁资源,因此得用setnx.\n在此线程结束运行的时候应当及时释放锁资源,防止服务器资源浪费,及时del key\n如果一个服务器在发送完这个请求后就宕机了,不会执行这个释放锁资源的代码,那么锁资源就不会被释放,导致其他服务器资源浪费.这时候就要给锁设置过期时间,到时间自动释放锁资源\n如果在还没执行expire time的时候服务器就宕机了,那么锁资源一样不会被释放,这时候就得这么写获取锁的语句\n1 set lock thread1 nx ex 10 保持了原子性,让互斥和过期时间一起设置\n同时采用非阻塞的锁,防止很多线程一直等待锁资源释放,尝试一次,如果没获取锁资源就return false,成功就return true\nJava代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { Long threadId = Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId+\u0026#34;\u0026#34;,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } 将分布式锁加入业务逻辑 1 2 3 4 5 6 7 8 9 10 11 12 Long userId =UserHolder.getUser().getId(); SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock=lock.tryLock(1200L); if(!isLock){ return Result.fail(\u0026#34;一人只能买一张票\u0026#34;); } try{ IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); }finally { lock.unlock(); } 分布式锁误删问题: 由于业务阻塞,导致线程1获取锁后没有及时释放锁资源,锁自动释放,线程2请求锁成功,开始执行业务逻辑\n这时候线程1完成业务,执行释放锁的指令,导致业务2的锁被意外删除,以此类推,锁会被意外删除.\n改进办法很简单,只要每次执行删除锁之前先查询锁的线程是否是自己的,是自己的就可以删,不是自己的就跳过.\nJava代码改进 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.UUID; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private static final String ID_PREFIX = UUID.randomUUID().toString(); private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { String threadId =ID_PREFIX+ Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { String UnlockName= stringRedisTemplate.opsForValue().get(LOCK_PREFIX+lockName); String threadId =ID_PREFIX+ Thread.currentThread().getId(); if(threadId.equals(UnlockName)){ stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } } 对程序打断点调试,获取锁后拦截,当我修改这里的ThreadId并且重新放行后,这里的新锁并没有被删掉,解决了误删的问题.\nLua脚本 当我们使用最新的分布式锁的时候,如果在执行finally语句里面的代码时,遭遇JVM进行垃圾回收,这时候会遇到无法战胜的业务阻塞,,代码还是没有做到原子性.如果已经验证完这个线程对应这个锁后突然垃圾回收,那么就会导致del锁这个操作会很危险.\n这时候可以把整个unlock操作用Lua脚本完成\n在Redis客户端使用lua脚本 无参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,\u0026#39;name\u0026#39;,\u0026#39;jack\u0026#39;)\u0026#34; 0 语句的意思是使用脚本,脚本是一个字符串,就是引号里面的,脚本相当于set name jack 0代表没有参数\n有参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,KEYS[1],ARGV[1])\u0026#34; 1 dinglz sb 用KEYS[1]和ARGV[1]作为占位符,后面有一对参数\n使用lua脚本解决删除锁问题 1 2 3 4 5 6 7 8 --查询锁的id local id=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(ARGV[1]==id) then --释放锁 return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) end --不是自己的锁,不用释放锁 return 0 Java代码调用Lua脚本 把lua脚本创建在这个目录下,等下方便读取 重写unlock方法 1 2 3 4 5 6 7 8 9 @Override public void unlock() { List list = new ArrayList(); list.add(LOCK_PREFIX+lockName); stringRedisTemplate.execute( UNLOCK_SCRIPT, list, ID_PREFIX+ Thread.currentThread().getId()); } 向redis传输指令,显示脚本,然后是参数,KEYS[1]参数要用集合封装,第二个参数是线程id也就是ARGV[1]\n同时要配置好脚本\n1 2 3 4 5 6 private static DefaultRedisScript\u0026lt;Long\u0026gt; UNLOCK_SCRIPT; static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unLock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 设置文件位置,然后设置返回格式,返回值为0表示删除锁失败,1表示删除锁成功\nRedisson Redisson是一个封装好的分布式锁工具,这里面的锁是已经写好的,并且比前文介绍的锁多一些功能和奇效\n引入依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置Redisson 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.hmdp.config; import org.redisson.Redisson; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RedissonConfig { @Bean public RedissonClient redisson() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://Yourip:Yourport\u0026#34;).setPassword(\u0026#34;Yourpassword\u0026#34;); return Redisson.create(config); } } @Configuration注解 这里顺带提一嘴Springboot框架面试高频考点,@Configuration是什么,和@Component有啥区别. @Configuration是配置类要添加的注解,它的构成是\n1 2 3 4 5 6 7 8 9 10 11 12 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Component public @interface Configuration { @AliasFor( annotation = Component.class ) String value() default \u0026#34;\u0026#34;; boolean proxyBeanMethods() default true; } 这里面也有@Component,但是它比前者多实现单例模式\n如果你在创建Bean对象的时候一次性创建多个,Spring容器并不会去对象池去找是否有已经创建过的对象,而是直接再创建,这样无法保证单例性\n而如果用@Configuration就可以只创建一次Bean对象\n使用Redisson制作分布式锁 1 2 3 //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); 中间那一行代码就等价于之前写的SimpleRedisLock\nRedisson解决不可重入 不可重入导致死锁 如果一个线程请求锁资源,然后又请求了一次锁资源,第二次请求会失败,因为已经有线程获取过锁,并且就是自身,这导致了这个线程请求不到锁,也释放不了锁,导致了死锁.\n解决方案 于是Redisson改变了锁的结构,让锁的数据结构变为Hash,key存储锁的名称,field存储线程名称,value存储该锁被同一个线程调用了几次,每次调用会给value自增,如果释放锁资源就value自减一次,如果value==0,那么就删除这个锁资源.\nRedisson解决不可重试 不可重试导致大量请求失败 正常线程如果获取锁失败就直接返回false了,或者说一直循环递归等待下去,导致了大量请求无法返回客户需要的内容\n解决方案 1 Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); 注意到我们之前在设置tryLock的时候设置了尝试时间1L,单位是秒.这个意思是我可以总共等待1秒,如果这1秒内获取到锁资源,就返回true,如果没请求到就返回false,当然这个1L可以改为任何数值.\nRedisson的tryLock原码 1 2 3 4 5 6 7 long time = unit.toMillis(waitTime); long current = System.currentTimeMillis(); long threadId = Thread.currentThread().getId(); Long ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { return true; } ttl是剩余等待时间,后面的tryAcquire是看是否获取锁成功,如果获取锁成功就返回null,如果获取成功就返回剩余等待时间.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 else { current = System.currentTimeMillis(); RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } else { boolean var16; try { time -= System.currentTimeMillis() - current; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); boolean var20 = false; return var20; } do { long currentTime = System.currentTimeMillis(); ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { var16 = true; return var16; } time -= System.currentTimeMillis() - currentTime; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); var16 = false; return var16; } currentTime = System.currentTimeMillis(); if (ttl \u0026gt;= 0L \u0026amp;\u0026amp; ttl \u0026lt; time) { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); } else { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(time, TimeUnit.MILLISECONDS); } time -= System.currentTimeMillis() - currentTime; } while(time \u0026gt; 0L); this.acquireFailed(waitTime, unit, threadId); var16 = false; } finally { this.unsubscribe(subscribeFuture, threadId); } return var16; } } 主要看else中的原码,如果获取锁失败,并且要进入等待,RFuture subscribeFuture = this.subscribe(threadId）指的是这个线程订阅了请求的锁的信息,如果锁被释放了,这个线程就会收到信息,这正是观察者模式.但是这个等待并不是无限制的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } 如果时间到达上限了,直接返回false,并且取消订阅.\n如果时间没到上限,就再尝试获取锁,没获取到就继续订阅,因为很多线程同时请求过来,得按顺序获取锁.直到获取到锁或者直接到时间才结束这个循环.\nRedis本地集群部署 只要改一下端口号就能实现本地的Redis集群\n在config文件下修改端口号\n用记事本或者vscode打开都可以,然后按下Ctrl+F搜索6379,下面的端口号改成没设置过的端口号,但也不要跟其他进程冲突了,我这里改为了6381\n然后分别启动Redis就实现Redis集群了\nRedisson实现分布式联锁 1 2 3 4 RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); 使用随机一个redisson客户端来调用它的.getMultiLock方法就可以制作出联锁\n联锁就可以在Redis集群的情况下,所有Redis共有一把锁,以免出现重复申请锁资源的情况\ngetMultiLock会尝试同时获取所有指定的锁，只有当所有锁都成功获取时，才算加锁成功。如果任何一个锁获取失败，它会回滚已经获取的锁，确保加锁操作的原子性。\n通过将多个锁的获取和释放封装在一起，getMultiLock简化了在复杂业务场景下的并发控制逻辑，减少了开发人员在处理多个锁时的错误风险。\n其中redisson.getMultilock使用任意一个对象都可以的原因是,这里是统一新创建\n1 2 3 public RLock getMultiLock(RLock... locks) { return new RedissonMultiLock(locks); } 通过这样制作联锁,可以让每一个Redis都有lock\n异步秒杀问题 将超卖和判重用Redis解决 把卖票过程比喻成厨子做饭,如果饭店只有一个人,那么他自己得招待顾客,还得自己下厨,但是这时候多来了个服务员,服务员负责招待顾客下单,厨子只是来做菜,卖票过程就是用Redis作为先手,把订单都收到手了,交给后端再交给数据库来异步处理这些订单.\nJMeter测试数据时,随着时间请求量会增长,因此可能会面对短时间超高并发,并且现有的代码还有很多查询MySQL的操作,比如:\n查询优惠券剩余数量,查询stock\n顾客是否已经买过一张票,查询是否有这个订单\n于是我们可以通过改变订单流程来解决\n在商家添加优惠券信息的时候就把优惠券的信息和数量同步到Redis\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+voucher.getId()+\u0026#34;:stock\u0026#34;,voucher.getStock().toString()); } 然后在请求到达后端时,先查询Redis,判断优惠券数量是否够,这个用户是否下过单了\nlua脚本 由于一次性操作Redis次数过多,直接使用多条java语句没有原子性,因此要用lua脚本 1 2 3 4 5 6 7 8 9 10 local stock=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(tonumber(stock)\u0026lt;1) then return 1 end local success = redis.call(\u0026#39;SADD\u0026#39;, KEYS[2], ARGV[1]) if(success==0) then return 2 end redis.call(\u0026#39;decr\u0026#39;,KEYS[1]) return 0 由于KEYS传过来时必须得是String类型,而只有number才能比较大小,因此先转化为数字,如果票没了就返回1.\nRedis的set集合 Redis的set集合在插入的时候,要判重,如果重复就不能插入,返回0,如果插入成功就返回1,故可以作为锁.\n多人秒杀的存储效果是这样的\n然后就可以写代码调用脚本了\n1 2 3 4 5 6 7 8 9 10 11 //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } 后端接受到可以下单的信息后制作订单\n1 2 3 4 5 6 7 8 9 Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); 然后把订单数据交给阻塞队列来异步执行,这里要用java自带的阻塞队列,然后多创建一个线程来解决这些下单问题\n1 2 3 4 5 6 7 8 9 //创建阻塞队列 private BlockingQueue\u0026lt;VoucherOrder\u0026gt; queue=new ArrayBlockingQueue\u0026lt;VoucherOrder\u0026gt;(1024*1024); //创建线程池 private static final ExecutorService SECKILL_ORDER_EXECUTOR= Executors.newSingleThreadExecutor( ); //在启动类初始化完就马上把 @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); }着重讲一下\n@PostConstruct 注解：\n当类的实例被创建后，Spring容器会自动调用这个方法。\n通常用于执行一些初始化操作，比如启动线程、加载配置等。\nSECKILL_ORDER_EXECUTOR：\n它的作用是管理线程的生命周期，避免频繁创建和销毁线程的开销。 submit(new VoucherOrderHandler())：\nsubmit方法将一个任务提交到线程池中执行。\nVoucherOrderHandler实现了Runnable接口的类\n这里创建了一个VoucherOrderHandler实例，并将其提交到线程池中，线程池会选择一个空闲线程来执行这个任务。\n这是线程池的任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //给线程池分配任务 private class VoucherOrderHandler implements Runnable{ @Override public void run() { while(true){ try{ VoucherOrder voucherOrder=queue.take(); voucherHandler(voucherOrder); }catch (Exception e){ System.out.println(\u0026#34;订单处理异常\u0026#34;+e.getMessage()); } } } } 在队列中有元素的时候,子线程取出voucherOrder对象,然后解决下单问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private void voucherHandler(VoucherOrder voucherOrder) throws InterruptedException { Long userId=voucherOrder.getUserId(); //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ proxy.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;id为\u0026#34;+userId+\u0026#34;的顾客买到票了\u0026#34;); lock.unlock(); } } 注意到这是个子线程的任务,子线程的任务无法获得代理对象,也就是SpringBoot的IOC容器管理的对象,但是我们需要事务回滚,所以还是得用代理对象,所以只能把代理对象作为私有变量,然后在类的方法中对这个私有代理对象进行赋值\n1 2 3 4 5 6 7 8 private IVoucherOrderService proxy; @Override public Result order(Long voucherId) { ... //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); ... } 然后改进createVoucherOrde方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Transactional(rollbackFor = Exception.class) public void createVoucherOrder(VoucherOrder voucherOrder) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherOrder.getVoucherId(),voucherOrder.getUserId()); if(!list.isEmpty()){ return ; } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherOrder.getVoucherId()) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return ; } voucherOrderMapper.insert(voucherOrder); } 至此,异步下单已经初步完成了.\nJMeter测试 由于要实现多人秒杀,所以就得用多个账户登录来抢票,但是找不到1000个真人来测试,总不能一个一个敲登录来获取token吧,所以可以写一个自动登录1000个账户的测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.hmdp; import com.hmdp.utils.RedisConstants; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.HashMap; import java.util.Map; import java.util.UUID; import java.util.concurrent.TimeUnit; @SpringBootTest public class TokenTest { private static final Integer NUMBER_OF_TOKEN = 1000; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN+1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token= UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY+token,map); System.out.println(token); stringRedisTemplate.expire(token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); } } } 在 Redis里存一份即可,然后把所有的token输出出来,后面拿来给JMeter,这样绕过了拦截器\n把tokens存到txt文件中\n在JMeter里面这样设置一下\n注意那个路径就是txt文件存储位置\n然后改一下登录状态头\n然后就可以开始测试了!\n测试结果:\n1000人抢200张票,只有20%成功率,80%的异常率,测试成功\nRedis实现消息队列 认识消息队列 消息队列（Message Queue，简称MQ）是一种在软件架构中用于实现应用程序之间异步通信的中间件。它允许一个或多个生产者（消息的发送者）将消息发送到队列中，然后由一个或多个消费者（消息的接收者）从队列中读取消息。消息队列的主要作用是解耦、缓冲、异步通信和负载均衡等,可以用来削峰填谷,减轻服务器和数据库的处理压力。 之前有用到spring的阻塞队列,但是这个阻塞队列效果不是很好,如果中途服务挂机了,或者说停机后JVM会强制删除所有内存数据,那么后续请求就无法完成,并且不保留记录.这时候就需要外部的消息队列了,这里先用Redis实现,后面还可以用实现好的消息队列,kafka,RocketMQ\nRedis要求: redis必须达到5版本及其以上,这里使用的是stream数据结构来制作消息队列\nRedis单消费模式 我们可以使用XADD来向消息队列里面加入元素,用XREAD来读取消息队列的元素\n1 XADD users * k2 v2 第一次redis会去查存储空间里面有没有users这个消息队列如果没有就创建\n这个语句的意思是添加名称为users的消息队列,然后*为自动生成id,k2 v2为一个键值对\n添加成功后会返回一个数据\u0026quot;1743079174227-0\u0026quot;这是一个时间戳,用来唯一标识这个队列\n同样的我们可以用XREAD来读取消息队列中的数据\n1 XREAD count 1 streams users 0 这个语句的意思是读消息,一次读一条,读取消息队列users的消息,并且从0开始读\n1 XREAD count 1 block 0 streams users $ 这个语句的意思是读取users的消息,($)读取最新的消息,然后无限阻塞,直到有消息进入队列就读取一条消息.\n这样看上去一个消息队列建好了,但是有bug,如果存储数据时间较长,存储数据没来得及存储完,又传来了一堆新的消息,$只能读取最新的消息,导致中间有很多消息都漏掉了\nRedis消费者组模式 省流版: 消费者组里面有很多消费者,它们是竞争关系,都来争着处理消息,可以解决消息漏处理的问题\n消息表示指的是最后被处理的消息会被打上标签,就像看书有个书签,看完后下次再看就立马知道在哪了\n消息确认就跟TCP三次握手相似,只是没有最后一段客户端向服务端的确认信息,每次处理完信息都会确认一下,并且有个pending-list,如果没处理这个消息就根据这个list继续处理\n创建消费者组 1 XGROUP CREATE users group1 0 这个语句的意思是在users这个消息队列中创建消费者组,如果没有users这个消息队列就会创建失败,这个消费者组的名称为group1,每次从id=0开始读\n通过消费者组读消息队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743074094428-0\u0026#34; 2) 1) \u0026#34;k1\u0026#34; 2) \u0026#34;v1\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743079174227-0\u0026#34; 2) 1) \u0026#34;k2\u0026#34; 2) \u0026#34;v2\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082841091-0\u0026#34; 2) 1) \u0026#34;k3\u0026#34; 2) \u0026#34;v3\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082847320-0\u0026#34; 2) 1) \u0026#34;k4\u0026#34; 2) \u0026#34;v4\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082852967-0\u0026#34; 2) 1) \u0026#34;k5\u0026#34; 2) \u0026#34;v5\u0026#34; 这个语句的含义是通过消费者组进行读取,group的名称是group1(刚刚创建的),消费者名称叫c1(随便取的名字,没有的话会自动创建),每次消费一条信息,阻塞2秒,消息队列名称为users,选择从最早发过来的未读消息开始读,\u0026gt;换成0可以使因为之前处理消息的时候,服务器炸了,重新处理的时候读取pending-list,直接从未处理完成的消息继续处理\n确认信息方法XACK 1 2 XACK users group1 1743074094428-0 1743079320687-0 1743082841091-0 1743082847320-0 (integer) 4 前面是消息队列名称和消费者组名,后面是消息被消费后发出的时间戳\n通过如下语句查询pending-list\n1 2 3 4 5 6 xpending users group1 1) (integer) 1 2) \u0026#34;1743079174227-0\u0026#34; 3) \u0026#34;1743079174227-0\u0026#34; 4) 1) 1) \u0026#34;c1\u0026#34; 2) \u0026#34;1\u0026#34; 通过Redis实现消息队列替代阻塞队列 其实没必要这么实现(绝对不是因为我这边IDEA无法识别我写的函数才不实现的)\n我们可以直接上正经的消息队列\n通过RabbitMQ替代阻塞队列 RabbitMQ是个消息队列,文档非常完整好懂,可以通过文档学习.要使用RabbitMQ要先下载,这里我在ubuntu虚拟机上下载并使用这个消息队列\n在 Ubuntu 上安装 RabbitMQ 通常需要以下步骤：\n1. 更新系统包列表 在安装任何软件之前，建议先更新系统的包列表，以确保安装的软件是最新的版本。运行以下命令：\n1 sudo apt update 2. 安装 Erlang RabbitMQ 是基于 Erlang 编程语言开发的，因此需要先安装 Erlang。可以使用以下命令安装 Erlang：\n1 sudo apt install erlang 3. 添加 RabbitMQ 的官方仓库 为了获取最新版本的 RabbitMQ，建议添加 RabbitMQ 的官方仓库。运行以下命令：\n1 2 3 sudo apt install apt-transport-https wget -O- https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add - echo \u0026#34;deb https://dl.bintray.com/rabbitmq/debian $(lsb_release -sc) main\u0026#34; | sudo tee /etc/apt/sources.list.d/rabbitmq.list 4. 更新包列表 添加完官方仓库后，需要再次更新包列表：\n1 sudo apt update 5. 安装 RabbitMQ Server 现在可以安装 RabbitMQ 了。运行以下命令：\n1 sudo apt install rabbitmq-server 6. 启动和启用 RabbitMQ 服务 安装完成后，RabbitMQ 服务应该会自动启动。可以通过以下命令检查服务状态：\n1 sudo systemctl status rabbitmq-server 如果服务未启动，可以手动启动并设置开机自启：\n1 2 sudo systemctl start rabbitmq-server sudo systemctl enable rabbitmq-server 7. 配置 RabbitMQ（可选） 如果需要进行额外配置，例如设置用户、权限等，可以使用以下命令：\n添加用户：\n1 sudo rabbitmqctl add_user myuser mypassword 设置用户权限：\n1 2 sudo rabbitmqctl set_user_tags myuser administrator sudo rabbitmqctl set_permissions -p / myuser \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; 启用管理插件（用于访问 Web 管理界面，默认端口为 15672）：\n1 sudo rabbitmq-plugins enable rabbitmq_management 正式使用RabbitMQ 按照以上步骤下载完rabbitmq后,我们可以打开网址馆里rabbitmq\nhttp://虚拟机的ip地址:15672\n注! 如果你用的不是docker下载的rabbitmq,那么你虚拟机的ip地址会改变,下次连不上rabbitmq有可能是因为ip地址变了 rabbitmq管理界面长这样\n你可以在主机上打开,也可以在虚拟机上打开,第一次登录只能在虚拟机上打开,因为有默认账号密码.输入账号:guest,密码:guest.然后进去后可以给自己之前用命令行创建的用户改权限\n点击创建的用户,这样修改权限\n这样你就可以用后端语言操控rabbitmq了!\n然后我们就可以打开心爱的IDEA\n引入maven坐标 先引入几个maven坐标\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--rabbitMQ的maven坐标--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 注意:springboot2.0版本只能用这套maven坐标,要用3.0版本maven坐标的话会出bug\n配置rabbitmq 先写好yaml\n然后这样写配置类,把rabbitmq交给IOC容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package com.hmdp.config; import com.hmdp.properties.RabbitMQProperties; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitMQConfig { @Autowired private RabbitMQProperties rabbitMQProperties; @Bean public ConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(rabbitMQProperties.getHost()); connectionFactory.setUsername(rabbitMQProperties.getUsername()); connectionFactory.setPassword(rabbitMQProperties.getPassword()); connectionFactory.setVirtualHost(rabbitMQProperties.getVirtualHost()); connectionFactory.setPort(rabbitMQProperties.getPort()); return connectionFactory; } @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { return new RabbitTemplate(connectionFactory); } @Bean public Queue voucherOrderQueue() { return new Queue(\u0026#34;voucher_order_queue\u0026#34;, true); } } 之前我们用的是阻塞队列,单独为消费者new了个线程来处理消息,现在我们可以创建一个消费者类,并且把对象交给IOC容器,让这个消费者持续处理信息\n消费者类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package com.hmdp.Consumer; import com.hmdp.entity.VoucherOrder; import com.hmdp.service.IVoucherOrderService; import org.redisson.api.RLock; import org.redisson.api.RedissonClient; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import org.springframework.transaction.annotation.Transactional; import javax.annotation.Resource; import java.util.concurrent.TimeUnit; @Component public class VoucherOrderConsumer { @Autowired private IVoucherOrderService voucherOrderService; @Resource private RedissonClient redisson6379; @Resource private RedissonClient redisson6380; @Resource private RedissonClient redisson6381; @Transactional @RabbitListener(queues = \u0026#34;voucher_order_queue\u0026#34;) public void handle(VoucherOrder voucherOrder) throws InterruptedException { //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ voucherOrderService.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;订单处理成功：\u0026#34; + voucherOrder.getId()); lock.unlock(); } } } 然后ServiceImpl类就成为了生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override public Result order(Long voucherId) { //查询优惠券信息 SeckillVoucher seckillVoucher = seckillVoucherMapper.selectById(voucherId); //判断秒杀是否开始 LocalDateTime timeEnd = seckillVoucher.getEndTime(); LocalDateTime timeBegin=seckillVoucher.getBeginTime(); if(timeBegin.isAfter(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动暂未开始\u0026#34;); }else if (timeEnd.isBefore(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动现已结束\u0026#34;); } //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long id=redisId.nextId(\u0026#34;order\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } Long userId= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(id); // 使用 RabbitMQ 发送消息 rabbitTemplate.convertAndSend(\u0026#34;voucher_order_queue\u0026#34;, voucherOrder); //queue.add(voucherOrder); //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); return Result.ok(\u0026#34;下单成功\u0026#34;+id); } 这样我们就使用了rabbitmq作为消息队列完成了异步秒杀.这只是rabbitmq的一点实力,后面我可能会专开一个坑来学rabbitmq\n测试类更新 简单更新了一下测试类 把token一键写入.txt文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Test public void test1() { // 指定文件路径 String filePath = \u0026#34;C:\\\\Users\\\\86180\\\\Desktop\\\\Test\\\\秒杀订单TOKEN数据.txt\u0026#34;; File file = new File(filePath); // 如果文件不存在则创建文件夹和文件 if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } // 如果文件存在，先清空文件内容 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file))) { writer.write(\u0026#34;\u0026#34;); // 清空文件内容 } catch (IOException e) { e.printStackTrace(); } // 写入新的 token 数据 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file, true))) { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN + 1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token = UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY + token, map); stringRedisTemplate.expire(RedisConstants.LOGIN_USER_KEY + token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); // 将 token 写入文件 writer.write(token); writer.newLine(); // 换行 } } catch (IOException e) { e.printStackTrace(); } } 一键刷新测试数据,让我们和JMETER再抢一千次优惠券吧!!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.hmdp; import com.hmdp.mapper.SeckillVoucherMapper; import com.hmdp.service.impl.VoucherOrderServiceImpl; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; @SpringBootTest public class RefreshData { private static final Long VOUCHER_ID=16L; private static final Long STOCK=1000L; @Autowired private VoucherOrderServiceImpl voucherOrderService; @Autowired private SeckillVoucherMapper seckillVoucherMapper; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { //删除所有订单 voucherOrderService.deleteByVoucherId(VOUCHER_ID); //将剩余票数刷新为指定数值 seckillVoucherMapper.updateByVoucherId(VOUCHER_ID,STOCK); //同步修改redis的剩余票数 stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:stock\u0026#34;,STOCK+\u0026#34;\u0026#34;); //删除redis的set stringRedisTemplate.delete(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:set\u0026#34;); } } 点赞功能 问题分析 点赞要求我们第一次点上去是点赞数+1,再点一次是点赞数-1,这完全可以交给数据库去解决,然后就是点赞前五名的人要展示在页面上,这时候可以用到redis的ZSET,排序集合\n业务逻辑: 点赞后,java代码查看是否点赞过,没点赞就点赞数+1,同时记录这个人点赞的时间戳,作为ZSET的排序依据,越早点赞的人越靠前,所有人都加入这个集合,点过赞再点就取消之前点赞,并且从这个集合中remove.查看点赞前五的代码就只用根据时间戳选择前五个用户就好,下面是代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Override //更新点赞 public void updateLike(Long id) { Long userId= UserHolder.getUser().getId(); //获取时间戳 long timestamp = System.currentTimeMillis(); //向ZSET中插入,看是否点过赞了 Boolean success = stringRedisTemplate.opsForZSet().add(RedisConstants.BLOG_LIKED_KEY + id, userId.toString(), timestamp); if(!Boolean.TRUE.equals(success)){ //点过了赞就无法插入,就取消点赞,点赞数减一,从点赞集合中移除用户 boolean success1 =update().setSql(\u0026#34;liked = liked - 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); if(success1) { stringRedisTemplate.opsForZSet().remove(RedisConstants.BLOG_LIKED_KEY + id, userId.toString()); } }else{ //没点过赞就可以插入,点赞数量加一 update().setSql(\u0026#34;liked = liked + 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result selectLike(Long id) { //从ZSET中取最早点赞的5个人 Set\u0026lt;String\u0026gt; ids = stringRedisTemplate.opsForZSet().range(RedisConstants.BLOG_LIKED_KEY + id, 0, 4); if(ids==null||ids.size()==0){ return Result.ok(); } //获取点赞人的Id,然后查表,查到人后返回icon和username List\u0026lt;Long\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); for (String userId : ids) { list.add(Long.parseLong(userId)); } String strId= StrUtil.join(\u0026#34;,\u0026#34;,ids); List\u0026lt;User\u0026gt; users = userService.query() .in(\u0026#34;id\u0026#34;, ids) .last(\u0026#34;order by field(id,\u0026#34;+strId+\u0026#34;)\u0026#34;) .list(); List\u0026lt;UserDTO\u0026gt; userDTOS = new ArrayList\u0026lt;\u0026gt;(); for (User user : users) { UserDTO userDTO = new UserDTO(); //只返回icon,userId和userName,其实userName都可以不传 BeanUtils.copyProperties(user, userDTO); userDTOS.add(userDTO); } return Result.ok(userDTOS); } 关注与互关 关注 关注很好办,只用在数据库的follow表中插入一条数据,谁关注了谁,业务逻辑非常EZ\n查看互关 现在有用户A,B,C.A关注了C,B也关注了C,这时候我们如果是A,我们盒B的账号的时候就能发现,我们共同关注了C,实现这个功能需要两个关注列表取交集,这就可以用到Redis的SET集合了\n在关注好友的时候同时创建集合,集合名就是被关注用户的ID,集合内容就是关注者的ID\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public Result followServer(Long bloggerId, Boolean isFollow) { Long userId= UserHolder.getUser().getId(); if(isFollow){ Follow follow=new Follow(); follow.setUserId(userId); follow.setFollowUserId(bloggerId); follow.setCreateTime(LocalDateTime.now()); followMapper.insert(follow); stringRedisTemplate.opsForSet().add(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;的用户关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); }else if(!isFollow){ followMapper.deleteByUserId(userId,bloggerId); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;取消关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); stringRedisTemplate.opsForSet().remove(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); } return Result.ok(); } 然后我们写查询共同关注者的时候就可以用set的\n下面是redis里实现set的取交集\n1 2 3 4 5 6 7 8 127.0.0.1:6379\u0026gt; SADD key1 a b c d (integer) 4 127.0.0.1:6379\u0026gt; SADD key2 c d e f (integer) 4 127.0.0.1:6379\u0026gt; SADD key3 a c e (integer) 3 127.0.0.1:6379\u0026gt; SINTER key1 key2 key3 1) \u0026#34;c\u0026#34; 在java代码中我们可以这么写,用java中的Set集合接收共同关注者的id\n1 Set\u0026lt;String\u0026gt; intersect = stringRedisTemplate.opsForSet().intersect(RedisConstants.FOLLOW + userId.toString() , RedisConstants.FOLLOW+id.toString()); 然后共同关注就做好了\nfeed流\u0026amp;滚动分页查询 Feed流是一种常见的信息展示方式\nfeed流定义 Feed流是一种基于用户社交关系或兴趣偏好的信息分发机制。它通过动态地向用户推送个性化的内容，让用户在浏览过程中能够快速获取到自己感兴趣的信息。\n核心特点 个性化推荐：Feed流会根据用户的浏览历史、兴趣标签、社交关系等多维度数据，为每个用户量身定制内容。例如，抖音会根据用户点赞、关注、评论等行为，推荐相关的短视频；微博会根据用户的关注列表和兴趣偏好，推送微博动态。\n动态更新：内容会实时更新，用户每次刷新页面或打开应用时，都能看到最新的信息。这种动态性让用户能够及时获取到新鲜的内容，增强了用户的粘性和活跃度。\n分析B站的推送机制 当你特别关注了一个up主,那个up主每次发视频就会私信发送给你,这叫推模式,直接推送给个人\n如果你直接去查看up主的主页,你就能看到他所有的内容,这种叫拉模式,拉取up主的所有内容\n上述两种模式,推模式不适合大V,如果不特别关注就推送,那么网络资源消耗过大.\n这次我要用Redis实现推模式,写一个feed流\n设计思路 我们要实现推流,就要在博主发送blog的时候把信息发到关注他的粉丝账号上,我们先查数据库,找到粉丝id,然后选取Redis数据结构来存储推流信息.\nList和SortedSet都可以来记录有序集合,但是要实现分页滚动查询,还是用ZSET好 我们可以这样写保存blog的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Override public Result saveBlog(Blog blog) { // 获取登录用户 UserDTO user = UserHolder.getUser(); blog.setUserId(user.getId()); // 保存探店博文 boolean saveSuccess = blogService.save(blog); if(!saveSuccess){ return Result.fail(\u0026#34;发布笔记失败\u0026#34;); } List\u0026lt;Long\u0026gt; idList=userMapper.selectByFollower(user.getId()); if(idList!=null\u0026amp;\u0026amp;!idList.isEmpty()){ for(Long id:idList){ stringRedisTemplate.opsForZSet().add(RedisConstants.FEED_KEY + id, blog.getId().toString(), System.currentTimeMillis()); } } // 返回id return Result.ok(blog.getId()); } 存储结果是这样的\n我们以时间戳作为分数,越靠前的blog时间戳大,到时候用户最先看到的就是最新消息\n滚动分页查询 用户每次查询2条记录,记录按照时间戳来排序,第一次查询的最大时间戳为当前时间,要找到最新的消息,后面再查就是上一次查到的最小的时间戳,然后偏移量加一,因为要查询后面两条,偏移量是通过之前重复时间戳数量计算出来的,当很多人同时建立blog时,时间戳可能会一样,这时候就得去重,加上偏移量\n附Java代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result queryBlogByUserId(Long time, Long offset) { Long userId=UserHolder.getUser().getId(); Set\u0026lt;ZSetOperations.TypedTuple\u0026lt;String\u0026gt;\u0026gt; typedTuples; if(offset==0){ typedTuples= stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, System.currentTimeMillis(), offset, 2); }else{ typedTuples = stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, time, offset, 2); } if(typedTuples==null|| typedTuples.isEmpty()){ return Result.fail(\u0026#34;没有文章可以看了捏\u0026#34;); } List\u0026lt;Blog\u0026gt; blogs = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Long\u0026gt; score=new ArrayList\u0026lt;\u0026gt;(); for (ZSetOperations.TypedTuple\u0026lt;String\u0026gt; object : typedTuples) { score.add(Objects.requireNonNull(object.getScore()).longValue()); Blog blog = blogMapper.selectById(Long.parseLong(Objects.requireNonNull(object.getValue()))); blogs.add(blog); } int count=1; Long lastScore=score.get(0); for (int i = 1; i \u0026lt; score.size(); i++) { if(score.get(i)!=lastScore){ count=1; lastScore=score.get(i); }else{ count++; } } ScrollResult scrollResult = new ScrollResult(); scrollResult.setList(blogs); scrollResult.setMinTime(score.get(score.size()-1)); scrollResult.setOffset(count); return Result.ok(scrollResult); } 注意reverseRangeByScoreWithScores函数参数顺序,集合名称,分数最小值,分数最大值,偏移量,查询信息数,这个函数可以同时返回score和value\n最后的效果: Redis-Geo实现搜索附近商户 Redis-Geo可以实现两个经纬度之间的距离测算\n比如我给出一个店铺的经纬度是87.588076 43.841359\n我的坐标是87.5795849 43.81927399\n那我们可以通过redis计算出这两地之间的距离\n1 2 3 4 5 6 7 8 localhost:6379\u0026gt; geoadd g1 87.529252 43.841359 urmuqizhan (integer) 1 localhost:6379\u0026gt; geoadd g1 87.588076 43.8242569 ShenZhenCheng (integer) 1 localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng \u0026#34;5088.3803\u0026#34; localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng km \u0026#34;5.0884\u0026#34; 这里我们通过geoadd语句添加了两地坐标,然后通过geodist计算出了两地之间的距离,如果限定输出格式的话,默认是米,可以限制输出为千米\n软件设计思路 用户要查看周围店铺的时候,我们就要按照距离顺序来给用户推荐,比如美团外卖的最近店铺,用户会给我们自己的坐标,也就是经纬度,我们要做的就是按照他传过来的位置和店铺位置算一个距离数据,然后排序查询后的搜索结果,返回给前端.\n注意到这里面有typeId,表示店铺的类型,比如美食,娱乐等等\n我们要在redis上存储这些店铺的信息,先把经纬度存进去,还有店铺的ID,还有typeId,我们这样可以设计\nshop:geo表示redis数据类型,1表示typeId\n具体实现 当我们把查询到的typeId用来查询所有相关的店铺\n1 2 3 4 5 6 7 GeoResults\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; result = stringRedisTemplate.opsForGeo().search( key, GeoReference.fromCoordinate(x, y), //默认米为单位,5公里 new Distance(5000), RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end) ); 这个函数的参数为,key,用户坐标,查询附近5km的所有店铺,查询到分页表的最后一个下标,因为redis没有设置from 到end的查询方式,所以只能全查了,这样查出来的就按照距离顺序\n这里同时查询出来了距离和店铺的id,我们可以这样取出所有值\n1 2 3 4 5 6 7 8 9 10 11 List\u0026lt;Long\u0026gt; ids=new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Distance\u0026gt; distances=new ArrayList\u0026lt;\u0026gt;(); for (GeoResult\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; r : result) { if (sum\u0026lt;from) { sum++; continue; } RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt; location = r.getContent(); ids.add(Long.valueOf(location.getName())); distances.add(r.getDistance()); } 然后查询数据库,把店铺所有信息和距离返回给前端\n1 2 3 4 5 6 7 for (int i =0;i\u0026lt;ids.size();i++) { Shop shop= shopMapper.selectById(ids.get(i)); shop.setDistance(Double.valueOf(distances.get(i).toString().replaceAll(\u0026#34;[^\\\\d.]\u0026#34;, \u0026#34;\u0026#34;))); if(shop!=null){ shops.add(shop); } } 最后结果就是这样了\n查询的时候是按照距离来搜的,并且附带距离\n","date":"2025-03-16T20:30:40+08:00","permalink":"https://LuciusWan.github.io/p/redis%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E6%88%98/","title":"Redis学习与实战"},{"content":"智识神工实习经历 - 面试话术指南 一、实习整体介绍（30秒版本） \u0026ldquo;我在智识神工实习期间，负责心理医生知识库项目的后端开发。这是一个 AI 驱动的心理健康服务平台，核心功能是让用户可以和 AI 进行心理咨询对话。\n我主要做了几件事：\nAI 大模型集成：用 Spring AI 封装了通义、Ollama 等多个大模型的统一调用接口 RAG 混合检索：基于 ElasticSearch 实现了语义+关键词的混合检索，召回率提升 40% 对话历史优化：用时间游标分页解决了深分页性能问题，百万级数据查询从 2.1 秒降到 0.7 秒 接口限流：用 Redisson + AOP 实现了令牌桶限流，保护 AI 接口 这段实习让我对 RAG 系统、大模型应用开发、性能优化 有了深入的实践经验。\u0026rdquo;\n二、八股文融合速查表 八股知识点 项目中的应用场景 引出话术 ElasticSearch 原理 RAG 混合检索 \u0026ldquo;ES 的倒排索引原理是\u0026hellip;\u0026rdquo; 向量检索 语义匹配 \u0026ldquo;向量相似度计算用的是余弦相似度\u0026hellip;\u0026rdquo; MySQL 深分页 对话历史查询 \u0026ldquo;深分页问题的本质是\u0026hellip;\u0026rdquo; 游标分页 时间游标优化 \u0026ldquo;游标分页避免了 OFFSET 的问题\u0026hellip;\u0026rdquo; 复合索引 查询优化 \u0026ldquo;我建了联合索引\u0026hellip;\u0026rdquo; 令牌桶算法 接口限流 \u0026ldquo;令牌桶和漏桶的区别是\u0026hellip;\u0026rdquo; AOP 原理 限流注解 \u0026ldquo;我用 AOP 实现了声明式限流\u0026hellip;\u0026rdquo; Redis 分布式 Redisson 限流 \u0026ldquo;Redisson 的 RRateLimiter 底层是\u0026hellip;\u0026rdquo; 策略模式 多模型切换 \u0026ldquo;我用策略模式封装了多个大模型\u0026hellip;\u0026rdquo; Rerank 机制 检索结果排序 \u0026ldquo;Rerank 是二次排序，用交叉编码器\u0026hellip;\u0026rdquo; 三、核心亮点一：AI 大模型集成 问题背景 \u0026ldquo;我们的系统需要对接多个大模型：通义千问用于生产环境，Ollama 本地模型用于开发测试。\n问题是：每个模型的 API 格式不一样，如果在业务代码里写一堆 if-else，代码会很乱，而且每次加新模型都要改业务代码。\u0026rdquo;\n技术方案 \u0026ldquo;我用 Spring AI + 策略模式 解决：\n定义统一的 AiModelService 接口 每个模型实现一个策略类 用 Spring 的 Map\u0026lt;String, Interface\u0026gt; 注入自动收集所有实现 业务代码只调用统一接口，根据配置切换模型\u0026rdquo; 🎯 融合八股：策略模式 面试官追问：为什么用策略模式？\n回答：\u0026ldquo;策略模式的核心是把算法封装成独立的类，让它们可以互相替换。好处是：\n开闭原则：加新模型只需新增策略类，不改原有代码 消除 if-else：不用写条件判断 易于测试：每个策略可以独立单元测试\u0026rdquo; 四、核心亮点二：RAG 混合检索 问题背景 \u0026ldquo;心理咨询场景有个特点：用户问题很口语化，比如\u0026rsquo;我最近心情不好\u0026rsquo;，但知识库里是专业术语\u0026rsquo;抑郁情绪\u0026rsquo;。\n纯关键词检索：词不一样，匹配不上 纯向量检索：能匹配语义，但可能召回不相关内容\n所以需要混合检索，结合两者优点。\u0026rdquo;\n技术方案 \u0026ldquo;我设计了三阶段检索架构：\n第一阶段：混合召回\n关键词检索：ES 的 BM25 算法 向量检索：ES 的 kNN 搜索 两路结果合并去重 第二阶段：Rerank 精排\n用交叉编码器对召回结果重新打分 第三阶段：Top-K 截断\n取 Top 5 拼接到 Prompt\u0026rdquo; 效果数据 \u0026ldquo;- 召回率提升 40%\nNDCG 提升 35% 响应时间 \u0026lt; 0.2 秒\u0026rdquo; 🎯 融合八股：ES 倒排索引 面试官追问：ES 检索原理是什么？\n回答：\u0026ldquo;ES 底层用 Lucene，核心是倒排索引。\n传统数据库是正排：文档 ID → 内容 倒排索引反过来：词 → 包含这个词的文档列表\n比如：'抑郁' → [doc1, doc3, doc7]\n搜索时取列表的交集或并集，就能快速找到相关文档。\nBM25 在此基础上计算相关性分数，考虑词频、逆文档频率、文档长度。\u0026rdquo;\n🎯 融合八股：向量检索 面试官追问：向量检索怎么实现？\n回答：\u0026ldquo;核心是把文本转成向量，计算相似度。\nEmbedding：用预训练模型把文本转成 1024 维向量 相似度：余弦相似度 cos(A,B) = A·B / (|A|*|B|) ES kNN：底层用 HNSW 算法，时间复杂度 O(log n)\u0026rdquo;\n🎯 融合八股：Rerank 机制 面试官追问：Rerank 和初次检索的区别？\n回答：\u0026ldquo;初次检索用双塔模型：Query 和 Document 分别编码，快但精度一般。\nRerank 用交叉编码器：Query 和 Document 拼接输入，精度高但慢。\n策略是：双塔快速召回 Top 100，交叉编码器精排出 Top 5。\u0026rdquo;\n五、核心亮点三：对话历史查询优化 问题背景 \u0026ldquo;用户的对话历史会越来越多，产品要求支持分页查看历史记录。\n问题：传统的 LIMIT offset, size 在深分页时性能很差。比如查第 10000 页，MySQL 要先扫描前 10000*20 条记录，再丢弃，非常慢。\n测试数据：百万级数据，查第 5000 页，耗时 2.1 秒，完全不能接受。\u0026rdquo;\n技术方案 \u0026ldquo;我用时间游标分页替代传统分页：\n传统分页：SELECT * FROM chat_history WHERE user_id = ? ORDER BY timestamp DESC LIMIT 100000, 20\n游标分页：SELECT * FROM chat_history WHERE user_id = ? AND timestamp \u0026lt; ? ORDER BY timestamp DESC LIMIT 20\n区别是：游标分页不用 OFFSET，直接从上一页最后一条记录的时间戳开始查，走索引，性能稳定。\u0026rdquo;\n索引设计 \u0026ldquo;我建了复合索引：(user_id, timestamp, session_id)\n为什么这个顺序？\nuser_id 放最前面，因为每次查询都带这个条件 timestamp 放第二，用于游标定位和排序 session_id 放最后，用于覆盖索引，避免回表\u0026rdquo; 效果数据 \u0026ldquo;- 查询性能提升 3 倍\n百万级数据响应时间从 2.1 秒降到 0.7 秒 无论查第几页，性能都稳定\u0026rdquo; 🎯 融合八股：MySQL 深分页问题 面试官追问：深分页为什么慢？\n回答：\u0026ldquo;深分页的本质问题是 OFFSET 需要扫描并丢弃大量数据。\nLIMIT 100000, 20 的执行过程：\n从索引中找到符合条件的记录 扫描前 100020 条 丢弃前 100000 条 返回最后 20 条 OFFSET 越大，扫描的数据越多，性能越差。这是 MySQL 的机制决定的，无法优化。\u0026rdquo;\n🎯 融合八股：游标分页原理 面试官追问：游标分页为什么快？\n回答：\u0026ldquo;游标分页用 WHERE 条件替代 OFFSET。比如上一页最后一条的时间戳是 2024-01-01 12:00:00，下一页查询 WHERE timestamp \u0026lt; '2024-01-01 12:00:00' LIMIT 20。这样 MySQL 直接从索引定位到这个时间点，往前取 20 条，不需要扫描前面的数据。时间复杂度：传统分页 O(offset + limit)，游标分页 O(limit)。\u0026rdquo;\n🎯 融合八股：复合索引最左前缀 面试官追问：为什么索引顺序是 (user_id, timestamp, session_id)？\n回答：\u0026ldquo;遵循最左前缀原则。\n这个索引可以支持：\nWHERE user_id = ? ✅ WHERE user_id = ? AND timestamp \u0026lt; ? ✅ WHERE user_id = ? AND timestamp \u0026lt; ? ORDER BY timestamp ✅ 但不支持：\nWHERE timestamp \u0026lt; ? ❌（没有 user_id） WHERE session_id = ? ❌（跳过了前两列） 我的查询条件是 user_id = ? AND timestamp \u0026lt; ?，正好匹配索引前两列，可以走索引。\u0026rdquo;\n六、核心亮点四：接口限流 问题背景 \u0026ldquo;AI 接口调用大模型，成本很高（按 Token 计费），而且响应慢。如果不限流：\n恶意用户可能刷接口，造成巨额费用 大量请求可能打垮服务\u0026rdquo; 技术方案 \u0026ldquo;我用 Redisson RRateLimiter + Spring AOP 实现了声明式限流，底层用 Redisson 的 RRateLimiter，基于 Redis 实现分布式限流。\u0026rdquo;\n1 2 3 4 @RateLimit(key = \u0026#34;ai:chat\u0026#34;, limit = 10, window = 60) // 每分钟10次 public String chat(String prompt) { return aiService.chat(prompt); } 🎯 融合八股：令牌桶 vs 漏桶 面试官追问：令牌桶和漏桶有什么区别？\n回答：\u0026ldquo;两者都是限流算法，但特性不同：\n漏桶：\n请求进入桶中，以固定速率流出 特点是平滑流量，无论请求多快，处理速度恒定 缺点是无法应对突发流量 令牌桶：\n以固定速率往桶里放令牌，请求需要拿到令牌才能执行 特点是允许突发，桶里有令牌就能立即执行 可以设置桶的容量，控制突发上限 我选令牌桶是因为 AI 接口允许一定的突发，比如用户连续问几个问题。\u0026rdquo;\n🎯 融合八股：Redisson 分布式限流 面试官追问：为什么用 Redisson 而不是本地限流？\n回答：\u0026ldquo;因为我们是分布式部署，多个实例。\n本地限流（如 Guava RateLimiter）只能限制单个实例，3 个实例就是 3 倍的限流额度。\nRedisson RRateLimiter 基于 Redis，所有实例共享同一个限流器，能实现全局限流。\n底层原理是用 Redis 的 Lua 脚本实现令牌桶，保证原子性。\u0026rdquo;\n🎯 融合八股：AOP 实现原理 面试官追问：限流注解是怎么生效的？\n回答：\u0026ldquo;通过 Spring AOP 实现。\n定义 @RateLimit 注解 写一个切面类，用 @Around 拦截带注解的方法 在切面里调用 Redisson 限流器 限流通过则执行原方法，否则抛异常 Spring AOP 底层用动态代理：\n如果目标类实现了接口，用 JDK 动态代理 否则用 CGLIB 生成子类\u0026rdquo; 七、核心亮点五：可观测性建设 问题背景 \u0026ldquo;AI 应用有个特点：大模型是黑盒，出了问题很难排查。比如用户反馈回答不好，我们需要知道：\n检索到了哪些文档？ Prompt 是什么？ 大模型返回了什么？ Token 消耗了多少？\u0026rdquo; 技术方案 \u0026ldquo;我搭建了完整的可观测性体系：\n监控告警：ARMS（阿里云应用监控）\n接口响应时间、错误率 JVM 内存、GC 情况 自定义指标：Prometheus + Grafana\n大模型 Token 用量 检索召回率 限流触发次数 日志追踪：\n每次请求记录完整的 RAG 链路 检索结果、Prompt、响应都落日志\u0026rdquo; 🎯 融合八股：Prometheus 指标类型 面试官追问：Prometheus 有哪些指标类型？\n回答：\u0026ldquo;四种：\nCounter：只增不减的计数器，如请求总数 Gauge：可增可减的仪表盘，如当前连接数 Histogram：直方图，统计分布，如响应时间分布 Summary：摘要，计算分位数，如 P99 响应时间 我用 Counter 统计 Token 用量，用 Histogram 统计响应时间分布。\u0026rdquo;\n八、口语化面试话术（完整版） 公式：业务背景 → 技术选型原因 → 核心难点实现 → 遇到的坑与解决 → 未来优化方向\n【话术一】RAG 混合检索系统 1️⃣ 业务背景（30秒） \u0026ldquo;我们做的是一个心理咨询 AI，用户可以和 AI 聊天，AI 会根据专业知识库给出回答。\n核心问题是检索：用户说\u0026rsquo;我最近心情不好睡不着\u0026rsquo;，但知识库里写的是\u0026rsquo;失眠症状\u0026rsquo;、\u0026lsquo;抑郁情绪\u0026rsquo;这种专业术语。\n如果用传统的关键词搜索，根本搜不到，因为词不一样。但如果纯用向量语义搜索，又可能召回一些不太相关的内容。\n所以我需要设计一个混合检索方案，把关键词匹配和语义匹配结合起来。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我调研了几种方案：\n方案一：纯 ES 关键词检索\n用 BM25 算法匹配关键词 问题是：用户口语化表达和专业术语对不上 方案二：纯向量检索\n用 Embedding 模型把文本转成向量，计算余弦相似度 问题是：可能召回语义相近但实际不相关的内容 方案三：混合检索 + Rerank（我最终选的）\n关键词和向量两路召回，合并结果 用 Rerank 模型二次排序，提高精度 选这个方案是因为它结合了两者的优点：关键词保证精确匹配，向量保证语义理解，Rerank 保证排序质量。\u0026rdquo;\n3️⃣ 核心难点实现（2分钟） \u0026ldquo;整个检索分三个阶段：\n第一阶段：混合召回\n我在 ES 里同时存了原文和向量。查询时并行执行两个搜索：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 // 关键词检索 - BM25 List\u0026lt;Doc\u0026gt; keywordResults = es.search(matchQuery(\u0026#34;content\u0026#34;, query)); // 向量检索 - kNN float[] vector = embeddingModel.embed(query); List\u0026lt;Doc\u0026gt; vectorResults = es.knnSearch(\u0026#34;embedding\u0026#34;, vector, k); // 合并去重 Set\u0026lt;Doc\u0026gt; merged = new LinkedHashSet\u0026lt;\u0026gt;(); merged.addAll(keywordResults); merged.addAll(vectorResults); \u0026ldquo;第二阶段：Rerank 精排\n召回的结果可能有几十条，但给大模型的 context 不能太长。我用交叉编码器重新打分：\u0026rdquo;\n1 2 // Rerank - 交叉编码器 List\u0026lt;Doc\u0026gt; reranked = rerankModel.rerank(query, merged); \u0026ldquo;交叉编码器和双塔模型的区别是：双塔模型分别编码 query 和 doc，交叉编码器把两者拼在一起编码，能捕捉更细粒度的交互，精度更高。\n第三阶段：构建 Prompt\n取 Top 5 的文档，拼接到 Prompt 里：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 你是一个专业的心理咨询师。根据以下参考资料回答用户问题： 【参考资料】 1. {doc1} 2. {doc2} ... 【用户问题】 {query} 4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：向量维度不匹配\n一开始用的 Embedding 模型输出 768 维，后来换了个模型输出 1024 维，ES 里的旧数据就查不了了。\n解决：重新建索引，写了个迁移脚本，把旧数据重新 Embedding 一遍。以后换模型前先评估维度兼容性。\n坑二：Rerank 太慢\n交叉编码器精度高但是慢，100 条文档 Rerank 要 500ms。\n解决：控制召回数量，两路各召回 50 条，去重后大概 70-80 条，Rerank 时间控制在 200ms 以内。\n坑三：ES 向量检索版本问题\nES 7.x 的向量检索是插件形式，不太稳定。\n解决：升级到 ES 8.x，原生支持 kNN 搜索，性能和稳定性都好很多。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. Query 改写：用大模型把用户口语化的问题改写成专业术语，提高关键词召回率 2. 多路召回融合：除了关键词和向量，还可以加知识图谱召回 3. 在线学习：根据用户反馈调整 Rerank 模型的权重\u0026rdquo;\n【话术二】对话历史分页优化 1️⃣ 业务背景（30秒） \u0026ldquo;用户和 AI 的对话历史需要持久化，产品要求支持分页查看历史记录。\n问题是：用户聊得越多，数据越多。有的用户聊了几千条，用传统的 LIMIT offset, size 分页，翻到后面特别慢。\n我测了一下，百万级数据查第 5000 页，要 2.1 秒，用户体验完全不能接受。\u0026rdquo;\n2️⃣ 技术选型原因（30秒） \u0026ldquo;深分页慢的根本原因是 OFFSET 需要扫描并丢弃大量数据。\nLIMIT 100000, 20 实际上要扫描 100020 条，丢弃前 100000 条，只返回最后 20 条。\n解决方案有两种：\n子查询优化：先查出 ID，再根据 ID 查数据。能优化一些，但还是要扫描 游标分页：用 WHERE 条件替代 OFFSET，彻底避免扫描 我选了游标分页，因为它无论查第几页，性能都是恒定的。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;游标分页的核心思想是：记住上一页最后一条记录的位置，下一页从这个位置开始查。\n传统分页：\u0026rdquo;\n1 2 3 4 SELECT * FROM chat_history WHERE user_id = 123 ORDER BY timestamp DESC LIMIT 100000, 20 \u0026ldquo;游标分页：\u0026rdquo;\n1 2 3 4 SELECT * FROM chat_history WHERE user_id = 123 AND timestamp \u0026lt; \u0026#39;2024-01-01 12:00:00\u0026#39; ORDER BY timestamp DESC LIMIT 20 \u0026ldquo;关键是要建好索引：(user_id, timestamp, session_id)\n这个索引可以：\n通过 user_id 快速定位到这个用户的数据 通过 timestamp 快速定位到游标位置 session_id 作为覆盖索引，避免回表\u0026rdquo; 4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：同一时间戳有多条记录\n如果两条记录的 timestamp 完全相同，游标分页可能会漏数据或重复。\n解决：游标改成 (timestamp, id) 组合。先按 timestamp 排序，timestamp 相同时按 id 排序。查询条件改成：\u0026rdquo;\n1 WHERE (timestamp \u0026lt; ?) OR (timestamp = ? AND id \u0026lt; ?) 5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 缓存热点数据：最近的对话记录访问频率高，可以缓存到 Redis 2. 冷热分离：超过 30 天的历史数据迁移到归档表，减少主表数据量 3. ES 检索：如果要支持全文搜索历史记录，可以同步到 ES\u0026rdquo;\n【话术三】接口限流设计 1️⃣ 业务背景（30秒） \u0026ldquo;AI 接口调用大模型，按 Token 计费，成本很高。而且大模型响应慢，如果不限流：\n恶意用户刷接口，一天能刷出几千块的账单 大量请求堆积，正常用户也用不了\u0026rdquo; 2️⃣ 技术选型原因（30秒） \u0026ldquo;限流算法有几种：\n固定窗口：简单但有临界问题 滑动窗口：平滑但内存占用大 漏桶：平滑流量但不能应对突发 令牌桶：允许突发，适合我的场景\n我选令牌桶，因为用户可能连续问几个问题，需要允许一定的突发。\n实现上用 Redisson RRateLimiter，因为我们是分布式部署，需要全局限流。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;我用 AOP 实现了声明式限流：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 自定义注解 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface RateLimit { String key(); int limit(); // 令牌数 int window(); // 时间窗口（秒） } // 切面 @Around(\u0026#34;@annotation(rateLimit)\u0026#34;) public Object around(ProceedingJoinPoint point, RateLimit rateLimit) { String key = buildKey(rateLimit); // 拼接用户ID RRateLimiter limiter = redisson.getRateLimiter(key); // 初始化限流器（只执行一次） limiter.trySetRate(RateType.OVERALL, rateLimit.limit(), rateLimit.window(), RateIntervalUnit.SECONDS); // 尝试获取令牌 if (!limiter.tryAcquire()) { throw new RateLimitException(\u0026#34;操作过于频繁\u0026#34;); } return point.proceed(); } \u0026ldquo;使用时只需要加注解：\u0026rdquo;\n1 2 @RateLimit(key = \u0026#34;ai:chat\u0026#34;, limit = 10, window = 60) public String chat(String prompt) { ... } 4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：限流器初始化重复执行\ntrySetRate 每次请求都调用，虽然 Redisson 内部做了幂等，但还是有性能开销。\n解决：用一个 Set 记录已初始化的 key，只有第一次才调用 trySetRate。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 动态限流：根据系统负载动态调整限流阈值 2. 分级限流：VIP 用户限流阈值更高 3. 熔断降级：大模型响应慢时自动降级，返回缓存的通用回答\u0026rdquo;\n九、常见追问及回答 Q1: 为什么选择 ElasticSearch 而不是专门的向量数据库？ \u0026ldquo;我对比了几个方案：\n方案 优点 缺点 ES 8.x 同时支持关键词和向量，运维成熟 向量检索性能不如专业向量库 Milvus 向量检索性能好 不支持关键词检索，需要两套系统 Pinecone 托管服务，省心 成本高，数据出境问题 我选 ES 是因为：\n我需要混合检索，ES 一套系统搞定 公司已有 ES 集群，运维成本低 我的数据量不大（几十万条），ES 性能够用\u0026rdquo; Q2: Rerank 模型用的是什么？ \u0026ldquo;我用的是 bge-reranker-base，是智源开源的中文 Rerank 模型。\n选它的原因：\n中文效果好，专门针对中文优化 模型不大，推理速度可以接受 开源免费，可以本地部署\u0026rdquo; Q3: 游标分页的缺点是什么？ \u0026ldquo;游标分页有两个限制：\n不能跳页：只能上一页、下一页，不能直接跳到第 100 页 需要稳定的排序字段：如果数据会更新，排序可能变化 对于我的场景，对话历史是按时间顺序的，用户也不需要跳页，所以这两个限制可以接受。\u0026rdquo;\nQ4: 限流被触发后怎么处理？ \u0026ldquo;我做了几层处理：\n友好提示：返回\u0026rsquo;操作过于频繁，请稍后重试\u0026rsquo;，不是冷冰冰的错误码 重试建议：告诉用户多久后可以重试 监控告警：限流触发次数超过阈值时告警，可能是有人在刷接口 日志记录：记录被限流的用户 ID 和 IP，方便排查\u0026rdquo; Q5: 实习期间最大的收获是什么？ \u0026ldquo;最大的收获是学会了从 0 到 1 做一个完整的功能。\n以前在学校做项目，主要是实现功能。实习之后发现，功能只是一部分，还要考虑：\n性能：能不能扛住线上流量 成本：AI 接口调用费用怎么控制 可观测性：出了问题怎么排查 兼容性：新功能上线会不会影响老功能 这些是在实际工作中才能学到的。\u0026rdquo;\n十、面试前 Checklist 必须能脱口而出的 实习 30 秒介绍 RAG 混合检索的三阶段架构 深分页为什么慢，游标分页为什么快 令牌桶和漏桶的区别 为什么用 Redisson 而不是本地限流 召回率提升 40%、NDCG 提升 35% 这些数据 最好能说清楚的 ES 倒排索引原理 BM25 算法 向量检索和余弦相似度 Rerank 交叉编码器 vs 双塔模型 MySQL 复合索引最左前缀原则 AOP 动态代理原理 加分项 遇到的坑和解决方案 未来优化方向 技术选型的对比和权衡 可观测性建设的思路 十一、实习经历软性问题（必问） 这部分问题考察的不是技术，而是你的工作态度、团队协作、抗压能力。即使实际经历不多，也要准备好合理的回答。\nQ1: 实习期间加班多吗？怎么看待加班？ 参考回答：\n\u0026ldquo;实习期间加班不算特别多，但也有过几次。\n印象比较深的一次是 RAG 检索功能要上线前，发现召回率不达标，我主动留下来和 mentor 一起排查问题。最后发现是 Embedding 模型的版本问题，换了模型后效果好了很多。那次大概加班到晚上 10 点多。\n我对加班的看法是：\n如果是因为项目紧急、技术攻关，我觉得是可以接受的，毕竟这也是学习和成长的机会 但如果是因为效率低或者流程问题导致的常态化加班，我觉得应该反思和优化 我会尽量在工作时间内高效完成任务，减少不必要的加班\u0026rdquo; Q2: 你的代码是怎么上线的？经历过完整的上线流程吗？ 参考回答：\n\u0026ldquo;经历过，我们的上线流程大概是这样的：\n1. 开发阶段\n在本地开发，用 Ollama 本地模型测试 写完后提交到 Git，发起 Merge Request 2. Code Review\nmentor 会 review 我的代码，提出修改意见 我印象比较深的是，mentor 指出我的一个 SQL 没有走索引，让我加了复合索引 3. 测试环境\n代码合并到 develop 分支后，自动部署到测试环境 测试同学会做功能测试，我也会自测 4. 预发布环境\n测试通过后，部署到预发布环境 预发布环境连的是生产数据库的从库，可以验证真实数据 5. 生产发布\n一般是晚上低峰期发布 我参与过一次发布，主要是在旁边看 mentor 操作，学习发布流程 发布后会观察监控，确认没有异常 我学到的是：上线不只是把代码部署上去，还要考虑灰度发布、回滚方案、监控告警这些。\u0026rdquo;\nQ3: 和同事/mentor 是怎么协作的？ 参考回答：\n\u0026ldquo;我们团队大概 5-6 个人，我主要和 mentor 还有另一个后端同事协作比较多。\n日常协作方式：\n每天早上有个 15 分钟的站会，同步昨天做了什么、今天计划做什么、有没有阻塞 有问题会先在飞书群里问，复杂的问题会拉个小会讨论 代码通过 GitLab 的 Merge Request 协作，互相 review 印象比较深的一次协作： 做 RAG 混合检索的时候，需要和算法同学配合。他负责调 Rerank 模型，我负责工程实现。我们一起定义了接口格式，他把模型封装成 HTTP 服务，我这边调用。中间遇到过返回格式不一致的问题，我们一起 debug 解决的。\n我学到的是：\n提前对齐接口和预期，能减少很多返工 遇到问题及时沟通，不要自己闷头搞 文档很重要，接口文档、设计文档都要写清楚\u0026rdquo; Q4: 遇到过和同事意见不一致的情况吗？怎么处理的？ 参考回答：\n\u0026ldquo;有过一次。\n背景是：我在做对话历史分页的时候，想用游标分页，但 mentor 一开始建议用传统的 LIMIT OFFSET，因为实现简单。\n我的处理方式：\n我没有直接反驳，而是先写了个测试，用百万级数据测了两种方案的性能 测试结果显示，深分页时传统方案要 2 秒多，游标分页只要 0.7 秒 我把测试结果和分析发给 mentor，说明游标分页虽然实现复杂一点，但性能好很多 mentor 看了数据后同意了我的方案，还夸我做事有理有据 我学到的是：\n意见不一致很正常，关键是用数据和事实说话 不要情绪化，要尊重对方的经验 最终目标是把事情做好，不是证明谁对谁错\u0026rdquo; Q5: 实习期间遇到过什么困难？怎么解决的？ 参考回答：\n\u0026ldquo;遇到过几个困难：\n技术上的困难： 刚开始做 RAG 的时候，对向量检索完全不懂，不知道 Embedding 是什么，kNN 是什么。\n我的解决方式：\n先看了几篇入门文章，了解基本概念 然后看 ES 官方文档，学习怎么用 ES 做向量检索 不懂的地方问 mentor，他给我推荐了几篇论文 最后自己写 demo 验证，边做边学 工作节奏上的困难： 刚开始不太适应，不知道怎么估时间，经常低估任务复杂度，导致 delay。\n我的解决方式：\n后来学会了把大任务拆成小任务，每个小任务单独估时间 估时间的时候会乘以 1.5 的系数，留一些 buffer 如果发现要 delay，提前和 mentor 沟通，而不是等到 deadline 才说 我学到的是：遇到困难很正常，关键是主动学习、主动沟通，不要等着别人来帮你。\u0026rdquo;\nQ6: mentor 对你的评价怎么样？ 参考回答：\n\u0026ldquo;mentor 对我的评价总体是正面的。\n他肯定的地方：\n学习能力强，新技术上手快 做事有责任心，交给我的任务都能按时完成 代码质量不错，review 的时候问题比较少 他给我的建议：\n要更主动地沟通，有问题早点说，不要自己闷头搞 技术深度还要加强，不能只停留在会用的层面，要理解原理 可以多参与技术分享，锻炼表达能力 我的改进： 后来我确实更主动了，每周会主动找 mentor 聊一次，同步进度和问题。技术上也开始看源码、看论文，不只是看教程。\u0026rdquo;\nQ7: 为什么从上一家公司离职/实习结束？ 参考回答：\n\u0026ldquo;主要是因为实习期到了，要回学校准备毕业的事情。\n这段实习我收获很大：\n技术上，学会了 RAG、大模型应用开发、性能优化 工作方式上，学会了怎么和团队协作、怎么做 code review、怎么上线 认知上，知道了企业级开发和学校项目的区别 如果有机会，我还是很愿意继续在这个方向深耕的，所以现在在找相关的工作机会。\u0026rdquo;\nQ8: 实习期间有没有主动做过什么事情？ 参考回答：\n\u0026ldquo;有的，我主动做了几件事：\n1. 写了技术文档 RAG 检索模块做完后，我主动写了一份技术文档，包括架构设计、接口说明、部署方式。后来新来的实习生就是看我的文档上手的。\n2. 优化了一个慢查询 有一次我在看监控的时候，发现有个接口响应时间很长，排查后发现是 SQL 没走索引。我主动提了优化方案，加了索引后响应时间从 2 秒降到了 200ms。\n3. 分享了一次技术 实习快结束的时候，我在组内做了一次技术分享，讲的是游标分页的原理和实践。虽然有点紧张，但反馈还不错。\n我觉得：主动做事不仅能学到更多，也能让 mentor 和团队看到你的价值。\u0026rdquo;\nQ9: 你觉得自己在实习中有什么不足？ 参考回答：\n\u0026ldquo;有几个不足：\n1. 技术深度不够 很多技术只停留在会用的层面，比如 ES 我会用，但底层的 Lucene 原理不太清楚。后来我开始有意识地看源码和论文。\n2. 沟通不够主动 刚开始遇到问题会自己闷头搞很久，后来才学会及时问 mentor。现在我会设一个时间限制，比如一个问题卡了 2 小时还没解决，就去问人。\n3. 全局视角不够 我主要关注自己负责的模块，对整个系统的架构了解不多。后来我会主动看其他模块的代码，了解上下游是怎么配合的。\n我在持续改进，比如现在会定期复盘，看看哪些地方可以做得更好。\u0026rdquo;\nQ10: 你对这份工作有什么期望？ 参考回答：\n\u0026ldquo;我的期望主要有三点：\n1. 技术成长 希望能接触到有挑战的项目，比如高并发、大数据、AI 应用这些方向。我不怕难，怕的是没有成长。\n2. 团队氛围 希望团队氛围是开放的，大家可以互相学习、互相帮助。我在实习的时候很喜欢和 mentor 讨论技术问题，这种感觉很好。\n3. 业务价值 希望做的事情是有价值的，能真正帮助到用户。我在实习的时候做的心理咨询 AI，虽然是 toB 的产品，但想到能帮助到有心理困扰的人，还是很有成就感的。\n总的来说，我希望找一个能让我快速成长、做有价值的事情的平台。\u0026rdquo;\n十二、软性问题回答技巧 回答公式：STAR 法则 S（Situation）：背景是什么 T（Task）：你的任务是什么 A（Action）：你采取了什么行动 R（Result）：结果怎么样 几个原则 诚实但有技巧：不用编造经历，但可以把普通经历讲得有亮点 具体比抽象好：说\u0026quot;我优化了一个 SQL，响应时间从 2 秒降到 200ms\u0026quot;比\u0026quot;我做了性能优化\u0026quot;好 展示成长：即使是不足，也要说你怎么改进的 正面积极：不要抱怨前公司、前同事，即使有不好的经历也要正面表达 避免的雷区 ❌ \u0026ldquo;我没怎么加班\u0026rdquo; → 显得不够投入 ❌ \u0026ldquo;我就是按 mentor 说的做\u0026rdquo; → 显得没有主动性 ❌ \u0026ldquo;前公司/mentor 不好\u0026rdquo; → 显得情商低 ❌ \u0026ldquo;我没遇到什么困难\u0026rdquo; → 显得经历太浅 ❌ \u0026ldquo;我什么都会\u0026rdquo; → 显得不够谦虚 ","date":"2025-11-28T10:18:09+08:00","permalink":"https://LuciusWan.github.io/p/%E5%AE%9E%E4%B9%A0%E7%BB%8F%E5%8E%86%E8%AF%9D%E6%9C%AF/","title":"实习经历话术"},{"content":"高统简答题 1. 什么情况下需要进行估计 f ? 在统计学习中，我们将输入 X 和输出 Y 的关系假设为 Y = f(X) + \\epsilon。我们需要估计 f 通常出于以下两个主要目的：\n预测 (Prediction)：当我们可以很容易获得输入 X，但很难获得输出 Y 时。我们希望通过 \\hat{Y} = \\hat{f}(X) 来预测结果，此时我们只关心预测的准确性，而不太关心 \\hat{f} 的具体形式（它可以是一个黑盒）。\n推断 (Inference)：当我们想理解 X 是如何影响 Y 时。我们需要确切知道 f 的形式，比如哪些特征最重要？它们与 Y 是正相关还是负相关？此时我们不能把 f 当作黑盒。\n2. Y 作为预测，其精确度依赖于哪些量？ 预测的精确度（通常用 E(Y - \\hat{Y})^2 衡量）依赖于两部分误差：\n可约误差 (Reducible Error)：来自于 \\hat{f} 对真实 f 的估计不完美。通过改进模型算法可以减少这部分误差。\n不可约误差 (Irreducible Error)：来自于 \\epsilon（误差项）。因为 Y 本身包含无法通过 X 解释的变异，即使我们完美估计了 f，这部分误差依然存在。\n3. 如何区分推断和预测？ 这是 ISLR 的核心思想之一：\n预测关注的是：给一个新的 X，\\hat{Y} 能有多准？ 我们不在乎模型内部看起来是什么样（哪怕它是复杂的神经网络）。\n推断关注的是：X 和 Y 之间的关系是什么？ 我们需要模型具有可解释性 (Interpretability)。通常，线性模型适合推断，而非线性模型（如 Boosting、SVM）适合预测。\n4. 推断中常用的基本问题有哪些？ 在进行推断时，我们通常问以下三个问题：\n哪些预测变量（predictors, X）与响应变量（response, Y）相关？（特征选择问题）\n预测变量与响应变量之间的关系是什么？（正相关还是负相关？）\n这种关系能够用线性方程总结吗，还是更复杂的非线性关系？\n5. 如何利用均方误差 (MSE) 计算可约误差和不可约误差？ 数学期望形式的分解如下（这是第二章最重要的公式）：\nE(Y - \\hat{Y})^2 = [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon)\n$[f(X) - \\hat{f}(X)]^2$：这是可约误差（即偏差和方差的组合）。\n$Var(\\epsilon)$：这是不可约误差（数据的固有噪声）。\n6. 估计 f 的方法有哪些？ 主要分为两大类：\n参数方法 (Parametric Methods)：\n假设 f 的函数形状（例如：假设它是线性的）。\n利用训练数据拟合参数（例如：最小二乘法）。\n优点：简化问题，需要的样本量较少。\n缺点：如果假设的形状错误，偏差很大。\n非参数方法 (Non-parametric Methods)：\n不假设 f 的明确形状，而是追求尽可能接近数据点（例如：样条、KNN）。\n优点：可以适应各种形状的 f。\n缺点：需要大量的观测数据，且容易过拟合。\n7. 半指导学习 (Semi-supervised Learning) 的适用的数据模型为哪些？ ISLR 对此提及较少，但其定义是：\n适用于只有少量数据有标签 (Y)，但有大量数据只有输入 (X) 而没有标签的情况。这介于监督学习和无监督学习之间。\n8. 模型的拟合效果如何评价（针对回归类模型）？ 最常用的指标是 均方误差 (MSE, Mean Squared Error)：\nMSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2\n我们更关注测试 MSE (Test MSE) 而非训练 MSE，因为我们希望模型在未见数据上表现良好。 9. 描述曲线光滑度 (Smoothness) 的量是什么？ 在统计学习语境下，这通常指的是灵活性 (Flexibility) 或 自由度 (Degrees of Freedom)。\n低自由度（如线性回归）：曲线非常“硬”，是一条直线，不光滑（或者说极其平滑以至于没有波动）。\n高自由度（如 KNN 当 K=1 时）：曲线非常“摆动 (wiggly)”，紧贴每个数据点。\n(注：在平滑样条中，有一个专门的惩罚参数 \\lambda 控制光滑度，\\lambda 越大越光滑/平直)。\n10. 光滑度 (Flexibility) 和偏差、方差的关系？ 这是经典的 偏差-方差权衡 (Bias-Variance Trade-off)：\n光滑度/灵活性 增加（模型变复杂）：\n偏差 (Bias) 降低（模型能更好地拟合真实关系）。\n方差 (Variance) 升高（模型对训练数据的微小变化非常敏感）。\n光滑度/灵活性 降低（模型变简单）：\n偏差 升高。\n方差 降低。\n目标：找到一个中间点，使 Bias^2 + Variance 最小。\n11. 分类模型最常用的估计精度的方法是什么？ 错误率 (Error Rate) 或 误分类率 (Misclassification Rate)：\n\\frac{1}{n} \\sum_{i=1}^{n} I(y_i \\neq \\hat{y}_i)\n即：分类错误的样本数占总样本数的比例。\n12. 贝叶斯错误率 (Bayes Error Rate) 如何计算？ 贝叶斯错误率是理论上最低的可能错误率（类似于回归中的不可约误差）。\n策略：对于给定的 x，将样本分到 Pr(Y=j|X=x) 最大的那一类。\n计算：1 - E(\\max_j Pr(Y=j|X))。\n意思是：1 减去我们在每个点上做出最佳选择时的平均概率。 13. KNN (K-最近邻) 算法的实现步骤？ KNN 是一种非参数方法：\n选定 K 值（例如 K=3）。\n对于一个新的观测点 x_0，在训练数据中找到距离它最近的 K 个点（通常使用欧氏距离）。\n分类决策：这 K 个点中，哪个类别的占比最高（投票），就将 x_0 归为哪一类。\n(注：对于概率，Pr(Y=j|X=x_0) = \\frac{1}{K} \\sum_{i \\in N_0} I(y_i = j))。 第一部分：核心推断与评估 (Inference \u0026amp; Evaluation) 1. 估计参数测量接近程度的常用方法是什么？\n标准误 (Standard Error, SE)。\n它衡量了我们的估计值 \\hat{\\beta} 与真实值 \\beta 之间的平均偏离程度。\n总体均值的标准误 vs 残差的标准误？ 这是一个易混淆点：\n总体均值 \\hat{\\mu} 的标准误：SE(\\hat{\\mu}) = \\frac{\\sigma}{\\sqrt{n}}。衡量的是样本均值估计总体的准确度。\n残差标准误 (RSE, Residual Standard Error)：RSE = \\sqrt{\\frac{RSS}{n-2}}。衡量的是模型预测值偏离真实数据点的平均距离（即 \\epsilon 的标准差估计）。\n3. 置信区间 (Confidence Interval) 如何计算？(95%, 99%)\n通式：\\hat{\\beta}1 \\pm t{\\alpha/2, n-2} \\times SE(\\hat{\\beta}_1)。\n95% 置信区间：大约是 \\hat{\\beta}_1 \\pm 2 \\cdot SE(\\hat{\\beta}_1)。\n这意味着：如果我们重复取样并计算区间，95% 的区间会包含真实的 \\beta_1。\n4. 如何判断预测变量和响应变量之间存在相关性？\n看 p 值 (p-value)。如果 p \u0026lt; 0.05（通常标准），则拒绝原假设 (H_0: \\beta_1 = 0)，认为存在相关性。 判断线性回归拟合质量的标准？ 两个核心指标：\nRSE (残差标准误)：越小越好。衡量绝对误差。\nR^2 (决定系数)：越接近 1 越好。衡量模型解释了数据变异的百分比 (1 - RSS/TSS)。\n6. 为什么有些变量在简单回归中显著，在多元回归中变得不显著？\n这是因为预测变量之间存在相关性 (Collinearity)。\n在简单回归中，X_1 可能只是代理了 X_2 的作用（因为它们相关）。\n在多元回归中，我们控制了 X_2，此时 X_1 纯粹的、额外的贡献可能就为零了。\n第二部分：多元回归与模型选择 (Multiple Regression) 7. 如何判断多个响应变量和预测变量之间有关系？(多元分析)\n这里通常指判断整体模型是否显著，使用 F-统计量 (F-statistic)。\n即使所有单个变量的 p 值都不显著，F 统计量依然可能显著（对抗多重检验问题）。\n8. 如何选择重要的变量？(变量选择方法)\n向前选择 (Forward Selection)：从零开始，逐个加显著变量。\n向后选择 (Backward Selection)：先包含所有变量，逐个剔除不显著的（p值最大）。\n混合选择 (Mixed Selection)：结合上述两者。\n9. 拒绝向后选择 (Backward Selection) 的条件有哪些？\n硬性条件：当样本量 n 小于变量数 p 时 (n \u0026lt; p)，无法使用向后选择（因为无法拟合包含所有变量的初始模型）。此时只能用向前选择。 第三部分：定性变量与模型假设 (Categorical \u0026amp; Assumptions) 10. 哑变量 (Dummy Variables) 和水平数 (Levels) 的关系？什么是基准水平？\n如果一个定性变量有 K 个水平（Level），我们需要创建 K-1 个哑变量。\n基准水平 (Baseline)：就是那个没有对应哑变量的水平。所有的系数 \\beta 都是相对于这个基准水平的差异。\n11. 线性模型的假设有哪些？(经典考题)\n线性 (Linearity)：X 和 Y 是线性关系。\n独立性 (Independence)：误差项 \\epsilon_i 之间互不相关（针对时间序列数据很重要）。\n正态性 (Normality)：误差项服从正态分布。\n同方差性 (Homoscedasticity)：误差项的方差 \\sigma^2 是常数，不随 X 变化。\n12. 线性模型存在的问题？(诊断)\n数据的非线性 (Non-linearity)。\n误差项自相关 (Correlation of error terms)。\n异方差性 (Non-constant variance of error terms)。\n异常值 (Outliers)。\n高杠杆点 (High Leverage points)。\n共线性 (Collinearity)。\n13. 如何去除可加性假设？什么是实验分层原则 (Hierarchy Principle)？\n去除可加性：引入 交互项 (Interaction Term)，例如 X_1 \\times X_2。这意味着 X_1 对 Y 的影响取决于 X_2 的取值。\n分层原则 (Hierarchy Principle)：如果模型中包含了交互项 X_1 \\times X_2，那么必须同时也包含主效应 X_1 和 X_2，即使它们的主效应 p 值不显著。\n14. 如何去除线性假设？\n引入 多项式回归 (Polynomial Regression)，例如加入 X^2, X^3。 第四部分：预测与 KNN (Prediction \u0026amp; KNN) 15. 如何精确地估计某一个预测变量对响应变量的影响？\n使用 置信区间 (Confidence Interval)。它告诉我们 \\hat{f}(x) 的平均值在哪里。 16. 如何判断未来的预测精度呢？\n使用 预测区间 (Prediction Interval)。\n注意：预测区间总是比置信区间宽，因为它不仅要考虑参数估计的不确定性（可约误差），还要包含单个点的随机误差 \\epsilon（不可约误差）。\n17. KNN 回归和分类的具体区别？\nKNN 分类：输出是邻居类别的众数 (Majority Vote)。\nKNN 回归：输出是邻居 Y 值的平均数 (Average)。\n第一部分：逻辑回归 (Logistic Regression) 为什么定性变量的回归问题不能使用线性回归？ 主要有两个原因：\n编码没有自然顺序：如果响应变量 Y 有三个类别（如：狗、猫、鸟），编码为 1, 2, 3。线性回归会假设 1 \u0026lt; 2 \u0026lt; 3 且 (2-1) = (3-2)，这意味着“狗和猫的差距”等于“猫和鸟的差距”，这在逻辑上通常是不成立的。\n概率越界：如果是二分类问题（编码 0 和 1），线性回归预测的 Y 值可能小于 0 或大于 1，这作为“概率”是没有意义的。\n2. 逻辑斯蒂函数表达式以及对数发生比 (Log-odds) 的构造？其含义？\nLogistic 函数（确保输出在 [0,1] 之间）：\np(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n对数发生比 (Log-odds / Logit)：\n\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1 X\n含义：X 每增加一个单位，对数发生比增加 \\beta_1。注意：p(X) 与 X 的关系是非线性的，所以不能简单说概率增加了 \\beta_1。\n3. 估计系数的基本方法？\n最大似然估计 (Maximum Likelihood Estimation, MLE)。\n我们寻找一组 \\beta，使得观测到的数据出现的概率（似然函数）最大化。与之相对，线性回归使用的是最小二乘法 (Least Squares)。\n第二部分：线性判别分析 (LDA) 与 QDA 不使用逻辑斯蒂回归的原因？(即：什么时候 LDA 优于 Logistic？) 这是 ISLR 的经典考点，LDA 在以下情况更好：\n类与类分得特别开：逻辑回归的参数估计会不稳定，而 LDA 很稳定。\n样本量 n 较小 且 X 近似正态分布：LDA 比逻辑回归更稳健。\n多分类问题 (K \u0026gt; 2)：LDA 处理多分类更自然。\n线性判别分析实现的“基本步骤”？\nLDA 的核心是贝叶斯定理：\n假设每一类观测值 f_k(x) 服从正态分布 (Gaussian)。\n假设所有类别的方差 (或协方差矩阵) 相等 (\\sigma_1^2 = \\dots = \\sigma_k^2 = \\sigma^2)。\n利用贝叶斯公式计算后验概率 Pr(Y=k|X=x)。\n将观测分给后验概率（或线性判别分数 \\delta_k(x)）最大的一类。\n6. 贝叶斯分类器的分类结果如何表达？\n它将观测点 x_0 分配给使得 Pr(Y=j|X=x_0) 最大 的那个类别 j。\n这也是理论上错误率最低的分类器。\n7. 为什么 LDA 的灵敏度 (Sensitivity) 这么低？\nLDA 默认使用 0.5 (50%) 作为后验概率的阈值进行分类。\n如果样本严重不平衡（例如：欺诈交易只占 1%），为了最大化整体准确率 (Accuracy)，模型会倾向于把所有人都预测为“正常”。这导致整体准确率很高（99%），但几乎没抓到一个坏人，所以灵敏度 (Sensitivity) 极低。\n解决方法：降低阈值（例如，只要 P(Default|X) \u0026gt; 0.2 就判为违约）。\n8. QDA 在实现过程中和 LDA 存在哪些不同？\n假设不同：LDA 假设所有类别的协方差矩阵相同 (\\Sigma_k = \\Sigma)；QDA 假设每一类有自己的协方差矩阵 (\\Sigma_k)。\n边界形状：LDA 是线性的 (Linear)；QDA 是二次的 (Quadratic)，曲线更弯曲。\n权衡：QDA 灵活性更高（低偏差），但需要估计更多参数（高方差），需要更多的数据。\n第三部分：模型评估 (Evaluation) 灵敏度、特异度、召回率和精确度的计算？ 假设：Positive (P) 是我们要检测的关注类（如患病），Negative (N) 是正常类。\n灵敏度 (Sensitivity) / 召回率 (Recall)：\\frac{TP}{TP + FN} (所有真病人中，抓出来多少？)\n特异度 (Specificity)：\\frac{TN}{TN + FP} (所有健康人中，排除了多少？)\n精确度 (Precision)：\\frac{TP}{TP + FP} (我预测为有病的人里，多少是真的有病？)\n10. 第一类错误和第二类错误的区分？\n第一类错误 (Type I Error)：假阳性 (False Positive)。没病说有病（拒真）。\n第二类错误 (Type II Error)：假阴性 (False Negative)。有病说没病（取伪）。\n11. ROC 图像的基本使用？\n横轴：1 - 特异度 (False Positive Rate)。\n纵轴：灵敏度 (True Positive Rate)。\n用法：ROC 曲线展示了在所有可能的阈值下模型的表现。\nAUC (Area Under Curve)：曲线下的面积。AUC 越大（接近 1），模型越好。AUC = 0.5 相当于瞎猜。\n第四部分：KNN 12. K 近邻算法需要输入的多组参数有哪些？K 值对分类的影响？\n输入参数：\n训练数据 X 和标签 Y。\n测试点 x_0。\nK 值 (邻居数量)。\nK 的影响：\nK 很小 (e.g., K=1)：决策边界非常扭曲、复杂，低偏差，高方差（容易过拟合）。\nK 很大：决策边界接近线性，非常平滑，高偏差，低方差。\n这张图片涉及 ISLR 第五章：重抽样方法 (Resampling Methods)。\n这一章非常重要，因为它是现代统计学习中模型选择 (Model Selection) 和 模型评估 (Model Assessment) 的基石。如果没有交叉验证，我们就无法客观地选择最优模型。\n作为统计学大师，我将为你逐一解答这些问题，重点解释 LOOCV 与 k-fold 的偏差-方差权衡，这是考试必考的难点。\n第一部分：验证集方法 (The Validation Set Approach) 1. 交叉验证常用的误差估计方法？\n对于回归问题：均方误差 (MSE)。\n对于分类问题：误分类率 (Error Rate)。\n验证集方法存在的问题有哪些？ 这是最原始的方法（将数据随机分为 50% 训练，50% 测试），主要有两个大缺陷：\n高方差 (High Variability)：测试误差的估计非常依赖于你是如何分割数据的。换一个随机种子，切分结果不同，评估结果可能波动很大。\n高偏差 (Overestimation of Error)：因为你只用了原本数据的一半 (n/2) 来训练模型。我们知道数据越少模型越差，所以这个方法会高估模型在完整数据集上的错误率。\n第二部分：留一交叉验证 (LOOCV) 3. 留一交叉验证 (LOOCV) 的测试误差估计的均值如何计算？\n步骤：\n总共有 n 个样本。\n拿出第 1 个样本作为测试集，用剩余 n-1 个训练，算 MSE_1。\n拿出第 2 个样本作为测试集，用剩余 n-1 个训练，算 MSE_2。\n\u0026hellip;重复 n 次。\n计算：\n$$CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} MSE_i$$ 大师提示（图里提到的那个线性回归特例）：在线性回归中，LOOCV 其实不需要训练 n 次，只要训练一次就可以算出来：CV_{(n)} = \\frac{1}{n} \\sum (\\frac{y_i - \\hat{y}_i}{1-h_i})^2，其中 h_i 是杠杆值。\n4. 留一交叉验证和验证集方法的比较？\n偏差 (Bias)：LOOCV 更低。因为它用了 n-1 个数据训练（几乎是全部），非常接近在这个数据集上能达到的最好效果。\n随机性：LOOCV 没有随机性（总是切那一个），结果是确定的；验证集方法有随机性。\n第三部分：k 折交叉验证 (k-fold CV) —— 核心考点 5. 使用交叉验证的目的是什么？是对 MSE 的真值感兴趣吗？\n目的：\n模型评估 (Model Assessment)：估计模型在未知数据上的表现。\n模型选择 (Model Selection)：在多个模型（不同灵活性）中选最好的那个。\n关于真值：我们通常不是特别关心 MSE 的绝对真值是多少，而是关心哪个模型的 MSE 最小。我们需要的是 MSE 曲线的最小值位置（用于确定模型复杂度，如 KNN 的 K 值或 Lasso 的 \\lambda）。\nLOOCV 方法和 k 折方法的异同点？如何进行偏差-方差的均衡？(重点!) 这是 ISLR 第五章最深刻的理论部分：\n计算成本：LOOCV 极其昂贵（跑 n 次）；k-fold 便宜（通常 k=5 或 10，只跑 5 或 10 次）。\n偏差 (Bias)：LOOCV 偏差更低。因为它用的训练数据 (n-1) 比 k-fold (n - n/k) 更多，更接近真实分布。\n方差 (Variance)：k-fold 方差更低（这是反直觉的，请仔细看）：\nLOOCV 的 n 个模型是在几乎完全相同的数据上训练的（重叠度极高），导致这 n 个预测结果高度相关。对高度相关的量取平均，方差减少得很少。\nk-fold 的 k 个模型之间重叠度较低，相关性较低。\n结论：k-fold (k=5 or 10) 通常是偏差-方差权衡的最佳选择。它既不会像验证集那样高偏差，也不会像 LOOCV 那样高方差。\n7. 对于分类问题，交叉验证的评判标准是什么？\n依然是 误分类率 (Error Rate)：\n$$CV_k = \\frac{1}{k} \\sum_{i=1}^{k} Err_i$$其中 Err_i 是第 i 折里的错误比例。\n第四部分：实际应用与自助法 (Bootstrap) 8. 使用 KNN 分类器时，使用训练错误率还是交叉验证错误率对 K 值进行选择？为什么？\n必须使用交叉验证错误率 (CV Error)。\n原因：\n训练错误率具有误导性。随着 K 变小（模型变复杂），训练错误率会单调下降直到 0。但这并不代表模型好，而是过拟合。\nCV 错误率会呈现 U 型曲线。它能捕捉到过拟合，帮助我们找到偏差和方差平衡的那个最优 K。\n9. 自助法 (Bootstrap) 适用的条件？\n适用场景：当我们想衡量估计量的不确定性（如标准误 SE、置信区间）时，特别是当这些估计量的理论公式很复杂或不存在时（比如中位数的中位数，或者非线性模型的参数）。\n核心思想：从原始数据集中有放回地 (with replacement) 重复采样，生成多个“假”的数据集，计算参数，然后看这些参数的分布。\n注意：Bootstrap 一般不用于评估模型的预测精度（因为有放回采样导致某些样本出现多次，某些不出现，会造成训练集和测试集重叠，严重低估误差）。\n第一部分：最小二乘法的问题与扩展 (OLS Issues \u0026amp; Extensions) 1. p 和 n 的大小会对最小二乘 (OLS) 的结果产生怎样的影响？最小二乘是如何减小计量方差的？\n影响：\n当 n \\gg p 时：OLS 表现良好，具有低方差和低偏差。\n当 p 接近 n 时：OLS 容易过拟合，方差 (Variance) 剧增。\n当 p \u0026gt; n 时：OLS 无法通过唯一解（方程数少于未知数），方差无穷大。\n如何减小方差：\n通过 约束 (Constraining) 或 收缩 (Shrinking) 估计系数（如 Ridge/Lasso）。\n这会引入少量偏差 (Bias)，但能大幅降低方差，从而降低整体 MSE。\n对线性回归模型的拓展方法有哪些？基本原理是什么？ 主要有三类：\n子集选择 (Subset Selection)：挑出一部分最好的变量来拟合。\n收缩方法 (Shrinkage/Regularization)：保留所有变量，但把系数往 0 压缩（Ridge, Lasso）。\n降维方法 (Dimension Reduction)：将 p 个变量组合成 M 个新变量 (M \u0026lt; p)，然后进行回归（PCR, PLS）。\n第二部分：子集选择 (Subset Selection) 3. 最优子集方法 (Best Subset Selection) 的构建过程是怎样的？\n这是一个穷举过程：\n拟合 M_0 (零模型)。\n对于 k=1, 2, \\dots, p：拟合所有可能的 C_p^k 个模型，挑出 RSS 最小（或 R^2 最大）的那个作为 M_k。\n最后在 M_0, \\dots, M_p 中，利用交叉验证、AIC 或 BIC 选出唯一的最优模型。\n4. 子集选择方法结果的评判标准是什么？\n训练误差不足以作为标准（因为变量越多，训练 RSS 必然越小）。\n间接估算：C_p, AIC, BIC, 调整 R^2 (Adjusted R^2)。这些指标会对变量数量 d 进行惩罚。\n直接估算：验证集误差 (Validation Set Error) 或 交叉验证误差 (Cross-Validation Error)。\n5. 逐步选择 (Stepwise) 相较于最优子集的优点？\n计算效率：最优子集需要拟合 2^p 个模型，当 p\u0026gt;20 时计算量爆炸。逐步选择只需拟合约 p^2 个模型。\n统计稳定性：当 p 很大时，最优子集搜索空间太大，容易在训练数据上过拟合（找到纯粹由噪声构成的“好”模型）。逐步选择搜索空间小，方差更低。\n6. 向前选择和向后选择实现过程？\n向前选择 (Forward)：从空模型开始，每次加一个能使 RSS 下降最多的变量，直到加满。\n向后选择 (Backward)：从全模型开始，每次剔除一个 p 值最大（最不重要）的变量，直到为空。\n7. 为什么向后选择在 n \u0026lt; p 的情况下不成立？\n因为向后选择的第一步是拟合包含所有变量的全模型。\n当 n \u0026lt; p 时，全模型无法拟合（自由度不够，矩阵不可逆），所以无法启动。\n注：向前选择在 n \u0026lt; p 时依然可用。\n8. 最优模型选择的方法有哪些？\nC_p, AIC, BIC（偏向选简单模型）, Adjusted R^2。\n一倍标准误准则 (One-Standard-Error Rule)：在交叉验证中，不一定选误差最小的点，而是选在最小误差的一个标准误范围内，模型最简单（变量最少）的那个点。\n第三部分：正则化/收缩方法 (Ridge \u0026amp; Lasso) —— 核心重难点 9. 岭回归 (Ridge) 中为什么不对 \\beta_0 进行惩罚？\n\\beta_0 是截距项，代表当所有 X=0 时 Y 的平均值。\n如果惩罚 \\beta_0，就会强制回归线经过原点（或接近原点），但这取决于数据的测量单位和位置，没有实际物理意义。我们只希望压缩变量的影响力，不希望改变数据的基准水平。\n10. 为什么在使用岭回归之前需要对数据进行标准化处理？标准化公式？\n原因：岭回归的惩罚项 \\lambda \\sum \\beta_j^2 对变量的尺度 (Scale) 非常敏感。如果 X_1 是“米”，X_2 是“毫米”，X_1 的系数会很大，受到更多惩罚。标准化让所有变量处于公平的起跑线。\n公式：\\tilde{x}{ij} = \\frac{x{ij}}{\\sqrt{\\frac{1}{n} \\sum (x_{ij} - \\bar{x}_j)^2}} （即除以标准差，使其方差为1）。\n11. 为什么岭回归优化了最小二乘的结果？\n偏差-方差权衡 (Bias-Variance Trade-off)：\n随着 \\lambda 增大，岭回归系数减小（偏离真实值），偏差略微增加。\n但同时，模型对训练数据的噪声不再那么敏感，方差大幅下降。\n只要方差下降的幅度超过偏差上升的幅度，整体 MSE 就会下降。\n12. 为什么提出 Lasso 回归？(Lasso vs Ridge)\nRidge 的缺点是：最终模型包含所有 p 个变量（系数趋向于 0 但不等于 0）。这使得模型难以解释。\nLasso 的优点是：它可以将部分系数完全压缩为 0，从而实现变量选择 (Variable Selection)，得到稀疏模型。\n13. 为什么 Lasso 可以将系数估计完全缩为 0？(几何解释)\n几何解释：Lasso 的约束区域是菱形 (Diamond, | \\beta_1 | + | \\beta_2 | \\leq s)，有尖角。RSS 的等高线很容易在尖角处（即坐标轴上）与约束区域相切。在坐标轴上意味着某个 \\beta = 0。\nRidge 的约束区域是圆形 (\\beta_1^2 + \\beta_2^2 \\leq s)，没有尖角，切点几乎不可能刚好在坐标轴上。\n14. 岭回归和 Lasso 回归的不同适用条件？\nLasso：适用于只有少数几个变量真正起作用，其他变量都是噪声的情况（稀疏信号）。\nRidge：适用于大部分变量都对 Y 有贡献，且贡献度差不多大的情况（密集信号）。\n15. 岭回归的贝叶斯解释中对应的密度函数是什么？Lasso 呢？\nRidge：假设系数 \\beta 的先验分布服从 高斯分布 (Normal/Gaussian Distribution)。\nLasso：假设系数 \\beta 的先验分布服从 拉普拉斯分布 (Laplace / Double-Exponential Distribution)（这种分布在 0 处有尖峰）。\n第四部分：降维方法 (Dimension Reduction) 16. 降维方法是如何实现的呢？\n我们不直接用 X_1, \\dots, X_p 回归。\n而是构造 Z_1, \\dots, Z_M (M \u0026lt; p)，其中每个 Z_m 都是原始 X 的线性组合 (\\sum \\phi_{jm} X_j)。\n然后用 Y 对 Z 进行最小二乘回归。\n17. 降维常用的方法有哪些？\n主成分回归 (PCR, Principal Components Regression)：无监督地构造 Z，只看 X 的方差，不看 Y。\n偏最小二乘 (PLS, Partial Least Squares)：有监督地构造 Z，同时利用 X 和 Y 的信息，寻找既能解释 X 变异又能解释 Y 的方向。\n18. 主成分分析法需要进行标准化处理吗？偏最小二乘呢？\n必须标准化。\n如果不标准化，方差大的变量（单位大的变量）会主导主成分的构造，导致降维结果偏向于单位大的变量，而非真正重要的结构。\n第一部分：基础非线性模型 (Polynomials \u0026amp; Step Functions) 非线性回归有哪些类型？ ISLR 第七章主要介绍了以下几种：\n多项式回归 (Polynomial Regression)：引入 X^2, X^3 等。\n阶梯函数 (Step Functions)：将 X 切分为不同的区间，每个区间拟合一个常数。\n回归样条 (Regression Splines)：分段多项式 + 节点约束。\n光滑样条 (Smoothing Splines)：RSS + 平滑惩罚项。\n局部回归 (Local Regression)：只利用邻近点进行加权拟合。\n广义可加模型 (GAMs)：将上述方法扩展到多个预测变量。\n2. 多项式回归最高阶数？为什么这样设置？\n最高阶数：通常不超过 3 或 4 (d=3, 4)。\n原因：\n尾部震荡：高阶多项式在数据的边界（头部和尾部）会产生剧烈的震荡（Runge现象），导致极高的方差。\n解释性差：很难解释 X^8 到底代表什么物理意义。\n第二部分：样条 (Splines) —— 核心考点 3. 三次样条 (Cubic Splines) 的自由度是多少？\n公式：df = 4 + K。\n解释：\n一个没有任何约束的三次多项式有 4 个参数 (\\beta_0, \\beta_1, \\beta_2, \\beta_3)。\n每增加一个节点 (Knot)，为了保持平滑（连续、一阶导连续、二阶导连续），我们实际上增加了一个自由度（或者说截断幂基函数）。\n所以如果有 K 个节点，自由度就是 4+K。\n注意：如果不加截距项，有时会被记为 3+K+1 或直接说用了 K+4 个基函数。\n三次样条函数的基本形式是什么？ 使用截断幂基 (Truncated Power Basis) 表示：\ny_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3 + \\sum_{k=1}^K \\beta_{k+3} h(x_i, \\xi_k) + \\epsilon_i\n其中 h(x, \\xi) 是截断函数：当 x \u0026gt; \\xi 时为 (x - \\xi)^3，否则为 0。这一项确保了在节点 \\xi_k 处的平滑连接。\n5. 为什么使用自然样条 (Natural Spline)？\n问题：普通的三次样条在边界区域（第一个节点之前和最后一个节点之后）方差非常大，预测很不稳定。\n解决：自然样条强制要求函数在边界区域是线性的（二阶导为0）。\n结果：牺牲了一点点偏差，换取了边界区域方差的大幅降低，预测更稳定。\n6. 拟合样条的节点位置如何确定？节点的数量如何确定呢？\n位置 (Location)：\n简单方法：等距分布。\n常用方法：根据分位数分布。数据密集的地方节点多，数据稀疏的地方节点少。\n数量 (Number)：\n使用 交叉验证 (Cross-Validation)。尝试不同的节点数 K，画出 CV 误差曲线，选误差最小的那个。 相较于多项式回归，样条拟合的优点在哪？ 这是一个经典的对比题：\n多项式回归是全局的：为了适应局部的一个弯曲，整个函数（包括远处）都会受到影响并剧烈波动。要增加灵活性必须增加次数 d，导致全局不稳定。\n样条是局部的：它可以保持低阶数（比如 3 阶），通过增加节点 K 来增加灵活性。增加一个节点只会影响该节点附近的拟合，不会导致整个曲线乱动。样条更稳健。\n第三部分：光滑样条 (Smoothing Splines) 如何理解光滑样条中的惩罚项？ 目标函数：\n\\sum_{i=1}^{n} (y_i - g(x_i))^2 + \\lambda \\int g\u0026rsquo;\u0026rsquo;(t)^2 dt\n第一项：拟合程度（RSS）。使曲线靠近数据点。\n第二项 (惩罚项)：光滑程度。g\u0026rsquo;\u0026rsquo;(t) 衡量曲线的曲率（弯曲程度）。\n\\lambda 的作用：\n\\lambda = 0：完全不惩罚，曲线会穿过所有点（过拟合）。\n\\lambda \\to \\infty：惩罚无限大，不允许任何弯曲，结果变成一条直线（最小二乘回归）。\n9. 为什么光滑样条更加注重有效自由度 (df_\\lambda)？\n在光滑样条中，我们不选“节点数量”（实际上它在每个数据点都设了节点，有 n 个节点）。\n我们调节的是 \\lambda。但 \\lambda 是个抽象的数字（比如 0.005），很难直观理解模型的复杂度。\n所以我们将 \\lambda 转换为 有效自由度 (Effective Degrees of Freedom)。比如 df_\\lambda = 8 意味着这个平滑样条的灵活性相当于一个有 8 个参数的多项式。这让我们能直观地量化模型复杂度。\n第四部分：局部回归与 GAM 10. 局部回归 (Local Regression) 的实现步骤？\n选点：对于要预测的目标点 x_0。\n找邻居：找到离 x_0 最近的 k 个点（占据总数据的比例 s）。\n赋权重：离 x_0 越近的点权重越大，远的权重小。\n拟合：利用这些加权的点，拟合一个加权最小二乘回归（通常是线性的）。\n预测：根据拟合出的线计算 \\hat{f}(x_0)。\nGAM 模型 (Generalized Additive Models) 的优缺点？\nGAM 允许我们把非线性结合到多元回归中：Y = \\beta_0 + f_1(X_1) + f_2(X_2) + \\dots + \\epsilon。\n优点：\n非线性：能自动拟合每个变量的非线性关系。\n可加性/可解释性：因为是相加关系，我们可以单独把 f_1(X_1) 画出来，观察 X_1 如何独立影响 Y（控制其他变量不变）。\n缺点：\n忽略交互作用：默认假设变量之间没有交互。如果 X_1 和 X_2 有交互效应，GAM 会漏掉（除非你手动加入交互项 f(X_1, X_2)）。 第一部分：基础决策树 (Decision Trees) 1. 回归树的建立过程？\n采用 自上而下、贪婪 (Greedy) 的递归二叉分裂 (Recursive Binary Splitting)。\n自上而下：从包含所有观测的根节点开始。\n贪婪：在每一步，只考虑当前最好的分裂，不考虑这一步对未来分裂的影响。\n过程：遍历所有预测变量 X_j 和所有可能的切分点 s，找到能使产生的两个区域的 RSS (残差平方和) 最小 的那个切分 (j, s)。\n2. 为什么要引入树的剪枝 (Pruning)？本书采用的哪一种剪枝方式？\n原因：如果不剪枝，树会长得非常茂盛（每个叶子节点甚至只有一个样本），导致过拟合，模型极其复杂，方差极高。\n方法：代价复杂性剪枝 (Cost Complexity Pruning)，也叫最弱连接剪枝 (Weakest Link Pruning)。\n原理：我们在最小化 RSS 的同时，对树的终端节点数量 |T| 进行惩罚。\n$$\\text{Minimize } \\sum_{m=1}^{|T|} \\sum_{i \\in R_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha |T|$$ 3. 代价复杂度剪枝是如何实现的？相关的系数 \\alpha 如何求解？\n\\alpha 是一个调节参数，控制树的复杂度与拟合优度之间的权衡。\n求解 \\alpha：我们无法直接算出最优的 \\alpha，而是使用 K 折交叉验证 (K-fold Cross-Validation)。选取使交叉验证误差最小的那个 \\alpha 值，然后返回对应的那棵子树。\n4. 回归树终端节点的判断条件是什么？\n对于回归树，终端节点（叶子）的预测值是该区域内所有训练观测值的平均值 (Mean)。\n分裂停止条件通常是：节点包含的观测数少于某个阈值（如 5 个），或者 RSS 下降幅度不再显著。\n5. 分类树和回归树的评价标准是什么？\n回归树：RSS (残差平方和)。\n分类树：基尼系数 (Gini Index) 或 交叉熵 (Cross-Entropy)。也可以用分类错误率，但它对树的生长不够敏感。\n6. 基尼系数的大小对分类树的影响？互熵呢？\n这两个指标都是衡量节点纯度 (Node Purity) 的。\n值越小，纯度越高。如果一个节点里的样本全属于同一类，基尼系数和熵都为 0。\n在构建树时，我们总是寻找能让基尼系数或熵下降最多的分裂点。\n第二部分：树的优缺点与对比 7. 线性回归和决策树的适用情况？\n线性回归：适用于真实边界是线性的（Linear）。\n决策树：适用于真实关系高度非线性或复杂的（Complex/Non-linear）。\n(考试技巧：如果问哪个更好，答案永远是“取决于数据特征”。)\n8. 树方法相较于传统方法的优点？\n易于解释：可视化效果好，甚至比线性回归更直观（像人类做决策的过程）。\n处理定性变量：不需要像线性回归那样先生成哑变量 (Dummy Variables)。\n可视化：可以画出漂亮的树图。\n9. 树方法相较于其他回归和分类方法的缺点是什么？\n预测准确性较低：单棵树通常打不过线性回归或样条。\n方差高 (High Variance)：这是最大的痛点。数据稍微改动一点点，生成的树可能完全不同。\n第三部分：装袋法 (Bagging) 与 随机森林 (Random Forest) 10. 装袋法实现的基本原理？定性变量如何处理呢？\n原理：Bootstrap Aggregation。利用 Bootstrap 从原数据集中有放回地抽取 B 个样本集，训练 B 棵树（不剪枝），然后取平均。\n降低方差：平均化多个独立（虽然不是完全独立）的模型可以降低方差。\n定性变量（分类问题）：对于分类，装袋法采用多数投票 (Majority Vote)——所有树中预测最多的那个类别作为最终结果。\n11. 随机森林方法的实现过程？\n随机森林是装袋法的升级版，目的是降低树之间的相关性 (Decorrelate the trees)。\n过程：在构建树的每一步分裂时，只允许从随机抽取的 m 个预测变量中选择（而不是所有 p 个）。\n通常选择 m \\approx \\sqrt{p}。\n这强制让树彼此长得不一样，从而进一步降低方差。\n第四部分：提升法 (Boosting) 12. 应用提升法的回归树的构建过程？\nBoosting 是串行 (Sequential) 的，不是并行的。\n步骤：\n先初始化 f(x) = 0, r_i = y_i。\n拟合一棵树 \\hat{f}^1 到残差 r 上（而不是 Y 上）。\n更新模型：\\hat{f} \\leftarrow \\hat{f} + \\lambda \\hat{f}^1。\n更新残差：r \\leftarrow r - \\lambda \\hat{f}^1。\n重复 B 次。\n核心思想：每棵新树都在修补上一棵树犯的错。\n13. 提升法的三个重要的调整参数？\n树的数量 (B)：Boosting 会过拟合（不像 Bagging），所以 B 不能无限大，需要通过交叉验证选择。\n收缩参数 (\\lambda, Shrinkage/Learning Rate)：控制学习速度。通常很小（0.01 或 0.001）。这意味着我们需要很多棵树来逐步逼近。\n树的深度 (d, Interaction Depth)：控制每棵树的复杂度（交互作用）。通常 d 很小（1 到 4）。如果 d=1，称为树桩 (Stump)。\n14. 提升法应用的函数是什么？\n它应用的是慢速学习 (Slow Learning) 的概念。\n通过将每一步的学习结果乘以 \\lambda，让模型一点一点地从残差中提取信息，而不是一次性拟合所有数据。这使得模型在预测时更稳健。\n第一部分：基础概念与最大间隔分类器 (MMC) 1. 超平面 (Hyperplane) 是如何定义的？\n在 $p$ 维空间中，超平面是一个 $p-1$ 维 的平坦仿射子空间。\n数学定义：满足以下方程的点 $X = (X_1, \\dots, X_p)^T$ 的集合：\n$$\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p = 0$$ 2. 对于分隔超平面，其具有哪些性质？\n它将空间一分为二。\n符号性质：\n如果观测点 $x_i$ 属于第一类 ($y_i = 1$)，则 $f(x_i) \u0026gt; 0$。\n如果观测点 $x_i$ 属于第二类 ($y_i = -1$)，则 $f(x_i) \u0026lt; 0$。\n即 $y_i \\cdot (\\beta_0 + \\beta_1 x_{i1} + \\dots) \u0026gt; 0$ 对所有观测成立。\n3. 如何构造最大分类器 (Maximal Margin Classifier)？即它的约束条件有哪些？\n目标：寻找一个超平面，使得数据点到平面的最小距离（间隔 Margin, $M$）最大化。\n优化问题：\n最大化 $M$。\n约束 1 (单位向量)：$\\sum_{j=1}^{p} \\beta_j^2 = 1$（为了确定系数的尺度）。\n约束 2 (正确分类且在间隔外)：$y_i(\\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}) \\ge M$。\n这意味着所有点不仅要在正确的一侧，而且距离超平面的距离至少为 $M$。\n第二部分：软间隔与支持向量分类器 (SVC) 4. 什么是软间隔 (Soft Margin)？\n背景：现实数据通常是线性不可分的，或者即使分开，受个别噪声点影响，最大间隔会很窄且不稳定。\n定义：我们允许部分观测点违反间隔限制（即落在间隔内部，甚至落在错误的一侧）。这被称为“软”间隔。\n引入松弛变量 (Slack Variables, $\\epsilon_i$) 来量化这种违反程度。\n5. 最大分类器和支持向量分类器 (Support Vector Classifier) 的支持向量相同吗？为什么？\n不相同。\n最大间隔分类器：支持向量仅是那些正好落在间隔边界上的点（数量通常很少）。\n支持向量分类器：支持向量包括：\n正好在间隔边界上的点。\n违反间隔的点（落在间隔内部或错误一侧的点）。\n为什么：因为 SVC 的超平面位置是由这些“难分类”的点决定的，所有违反间隔的点都会对超平面产生影响，所以它们也是支持向量。\n如何区分最大间隔分类器、支持向量分类器以及支持向量机？(核心考点) 这是一个层层递进的关系：\n最大间隔分类器 (MMC)：\n线性边界。\n硬间隔 (Hard Margin)：不允许任何错误，要求数据线性可分。\n支持向量分类器 (SVC)：\n线性边界。\n软间隔 (Soft Margin)：允许部分错误，适用于线性不可分或有噪声的数据。\n支持向量机 (SVM)：\n非线性边界。\n通过核函数 (Kernel) 扩展了 SVC。\n第三部分：支持向量机 (SVM) 与 核函数 7. 对于非线性分类情况，如何利用支持向量机进行分类？\n利用 核技巧 (Kernel Trick)。\n我们不直接在原始空间计算，而是将特征空间升维（例如引入 $X^2, X^3$），在高维空间中寻找线性超平面。\n在计算时，我们不需要真的算出高维坐标，只需计算样本间的内积 $K(x_i, x_i\u0026rsquo;)$。\n常用核函数：多项式核 (Polynomial Kernel) 和 径向基核 (Radial Kernel / RBF)。\n第四部分：多分类与参数 (Multi-class \u0026amp; Cost) 支持向量机如何处理多分类问题？ SVM 本质上是二分类器。处理多分类 ($K\u0026gt;2$) 主要有两种策略：\n一对一 (One-versus-One, OVO)。\n一对多 (One-versus-All, OVA)。\n9. 一对一、一对多分别需要多少模型参与？具体的实现过程是怎样的呢？\n一对一 (One-versus-One)：\n模型数量：$\\binom{K}{2} = \\frac{K(K-1)}{2}$ 个（两两组合）。\n过程：比如有 3 类，我们训练“1 vs 2”、“1 vs 3”、“2 vs 3”。\n预测：将新数据放入所有模型，看哪个类别得票最多。\n一对多 (One-versus-All)：\n模型数量：$K$ 个。\n过程：训练“第 1 类 vs 其他”、“第 2 类 vs 其他”\u0026hellip;\n预测：将新数据放入 $K$ 个模型，计算 $f(x)$ 的值，选取值最大（即距离超平面最远且为正）的那个类别。\n","date":"2025-11-27T21:58:42+08:00","permalink":"https://LuciusWan.github.io/p/%E9%AB%98%E7%BB%9F/","title":"高统"},{"content":"EduAgentX 项目面试话术指南 一、项目整体介绍（30秒版本） \u0026ldquo;我做的是一个智能教育管理系统 EduAgentX，核心功能包括 AI 智能题目生成、高并发抢课系统 和 RAG 知识库检索。技术栈是 Spring Boot 3 + Spring AI + Redis + RocketMQ，同时我还完成了从单体到微服务的架构演进，使用 Spring Cloud Alibaba + Dubbo + Nacos + Higress 网关。项目中我重点解决了三个技术难题：抢课系统的高并发防超卖、AI 工作流的流式输出、以及 热点数据的缓存优化。\u0026rdquo;\n零、八股文融合速查表 八股知识点 项目中的应用场景 引出话术 Redis 单线程模型 Lua 脚本原子性 \u0026ldquo;Lua 能保证原子性是因为 Redis 单线程\u0026hellip;\u0026rdquo; Redis 数据结构 Hash 存储库存/抢课状态 \u0026ldquo;我用 Hash 而不是 String，因为\u0026hellip;\u0026rdquo; Redis 持久化 抢课数据可靠性 \u0026ldquo;我配置了 AOF 持久化，防止宕机丢数据\u0026hellip;\u0026rdquo; 线程池参数 异步工作流执行 \u0026ldquo;我自定义了线程池，核心线程数设置为\u0026hellip;\u0026rdquo; CAS 与原子类 HeavyKeeper 计数器 \u0026ldquo;我用 AtomicInteger 保证计数的线程安全\u0026hellip;\u0026rdquo; ConcurrentHashMap 热点 Key 存储 \u0026ldquo;我用 ConcurrentHashMap 而不是 HashMap\u0026hellip;\u0026rdquo; 阻塞队列 消息缓冲区 \u0026ldquo;我用 ConcurrentLinkedQueue 无锁队列\u0026hellip;\u0026rdquo; AOP 原理 限流切面、性能监控 \u0026ldquo;我用 AOP 实现了限流，原理是动态代理\u0026hellip;\u0026rdquo; Spring 事务 批量写入数据库 \u0026ldquo;我用 TransactionTemplate 编程式事务\u0026hellip;\u0026rdquo; MySQL 索引 抢课记录查询优化 \u0026ldquo;我给 student_id + subject_id 建了联合索引\u0026hellip;\u0026rdquo; MySQL 锁 纯 MySQL 抢课方案 \u0026ldquo;我还实现了一版用悲观锁的方案\u0026hellip;\u0026rdquo; 消息队列 异步削峰 \u0026ldquo;我用 RocketMQ 实现异步，选它是因为\u0026hellip;\u0026rdquo; 设计模式 题目生成模块 \u0026ldquo;我用了策略模式、模板方法、工厂模式\u0026hellip;\u0026rdquo; JVM 内存模型 ThreadLocal 存储 SSE \u0026ldquo;我用 ThreadLocal 存储 Emitter，避免\u0026hellip;\u0026rdquo; 序列化 Redis 序列化配置 \u0026ldquo;我配置了 Jackson 序列化，解决了\u0026hellip;\u0026rdquo; 分布式锁 防止重复抢课 \u0026ldquo;除了 Lua，我还可以用 Redisson 分布式锁\u0026hellip;\u0026rdquo; CAP 理论 缓存一致性策略 \u0026ldquo;我选择了 AP，保证可用性，最终一致\u0026hellip;\u0026rdquo; 限流算法 滑动窗口限流 \u0026ldquo;我实现了滑动窗口限流，用 Redis ZSet\u0026hellip;\u0026rdquo; 二、核心亮点详细话术（融合八股版） 亮点一：高并发抢课系统（Redis + Lua + RocketMQ） 问题背景 \u0026ldquo;在抢课场景下，我们面临的核心问题是 高并发下的库存超卖 和 数据库压力过大。比如一门课只有100个名额，但可能有1000个学生同时点击抢课，如果处理不当就会出现超卖，或者数据库直接被打挂。\u0026rdquo;\n技术方案 \u0026ldquo;我的解决方案分三层：\n第一层：Redis + Lua 脚本保证原子性\n把课程库存预热到 Redis 的 Hash 结构中 使用 Lua 脚本实现原子性的「检查库存 → 扣减库存 → 记录抢课状态」 这样即使万级并发，也不会出现超卖 第二层：RocketMQ 异步削峰\nRedis 操作成功后，不直接写数据库，而是发送消息到 RocketMQ 消费者批量消费（每批1000条或10秒），批量写入 MySQL 这样把瞬时高并发转化为平稳的数据库写入 第三层：失败回滚机制\n如果消息发送失败，立即执行 Redis 回滚脚本 保证 Redis 和最终数据库的数据一致性\u0026rdquo; 代码亮点（可以主动提） \u0026ldquo;Lua 脚本的核心逻辑是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 -- 1. 检查是否已抢课 if redis.call(\u0026#39;HEXISTS\u0026#39;, studentSnatchKey, subjectId) == 1 then return -1 -- 已抢课 end -- 2. 检查并扣减库存（原子操作） local capacity = redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, -1) if capacity \u0026lt; 0 then redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, 1) -- 回滚 return -2 -- 库存不足 end -- 3. 记录抢课状态 redis.call(\u0026#39;HSET\u0026#39;, studentSnatchKey, subjectId, 1) return 1 -- 成功 整个过程在 Redis 单线程中执行，天然保证原子性。\u0026rdquo;\n性能数据 \u0026ldquo;优化后，抢课接口的 QPS 从原来纯 MySQL 的 500 提升到 2000+，响应时间从 200ms 降到 50ms 以内。\u0026rdquo;\n🎯 融合八股：Redis 单线程模型 面试官追问：为什么 Lua 脚本能保证原子性？\n回答：\u0026ldquo;这要从 Redis 的线程模型说起。Redis 6.0 之前是纯单线程模型，所有命令都在一个线程中串行执行。虽然 6.0 引入了 IO 多线程（处理网络读写），但命令执行仍然是单线程的。\nLua 脚本在执行期间，Redis 不会执行其他命令，相当于把多个操作打包成一个原子操作。这和数据库事务不同——数据库是通过锁来保证隔离性，而 Redis 是通过单线程串行执行来保证原子性。\n需要注意 Lua 脚本不能太长，否则会阻塞其他请求。我的脚本只有几行，执行时间在微秒级。\u0026rdquo;\n🎯 融合八股：Redis 数据结构选择 面试官追问：为什么用 Hash 存储库存，而不是 String？\n回答：\u0026ldquo;我用 Hash 有几个考虑：\n内存效率：如果用 String，每个课程一个 Key（如 capacity:1、capacity:2），会有大量的 Key 元数据开销。用 Hash（subject:capacity → {1: 100, 2: 50}），多个字段共享一个 Key 的元数据，内存更省。\n原子操作：HINCRBY 可以原子性地对某个字段加减，配合 Lua 脚本很方便。\n批量操作：HGETALL 可以一次获取所有课程的库存，方便做缓存预热。\nRedis 的 Hash 底层是 ziplist（小数据量）或 hashtable（大数据量），当字段数超过 hash-max-ziplist-entries（默认512）时会转换。我的场景课程数不多，用 ziplist 更省内存。\u0026rdquo;\n🎯 融合八股：消息队列对比 面试官追问：为什么选 RocketMQ 而不是 Kafka？\n回答：\u0026ldquo;我对比了几个主流消息队列：\n特性 RocketMQ Kafka RabbitMQ 吞吐量 10万级 百万级 万级 延迟 ms级 ms级 us级 事务消息 ✅ 支持 ❌ 不支持 ❌ 不支持 延迟消息 ✅ 支持 ❌ 不支持 ✅ 插件支持 消息回溯 ✅ 支持 ✅ 支持 ❌ 不支持 选择 RocketMQ 的原因：\n事务消息：可以保证本地事务和消息发送的一致性 延迟消息：未来可以做延迟退课提醒 消息回溯：出问题时可以重新消费历史消息 阿里生态：和 Spring Cloud Alibaba 集成更好\u0026rdquo; 🎯 融合八股：MySQL 悲观锁 vs 乐观锁 面试官追问：如果不用 Redis，纯 MySQL 怎么实现？\n回答：\u0026ldquo;我其实还实现了一版纯 MySQL 的方案，用的是悲观锁：\n1 2 3 4 -- 悲观锁：SELECT FOR UPDATE SELECT * FROM snatch_subject WHERE subject_id = ? FOR UPDATE; -- 检查库存后更新 UPDATE snatch_subject SET stock_remain = stock_remain - 1 WHERE subject_id = ?; 悲观锁 vs 乐观锁的选择：\n悲观锁：适合写多读少、冲突概率高的场景，但会阻塞其他事务 乐观锁：适合读多写少、冲突概率低的场景，通过版本号实现 抢课场景冲突概率高，所以用悲观锁更合适。但悲观锁的问题是性能差（QPS 只有 500），所以最终选择了 Redis 方案。\u0026rdquo;\n亮点二：AI 工作流引擎（LangGraph4j + SSE 流式输出） 问题背景 \u0026ldquo;AI 生成题目是一个耗时操作，可能需要 10-30 秒。如果用传统的同步请求，用户体验很差，而且容易超时。另外，题目生成涉及多个步骤：知识检索 → 任务拆分 → 题目生成 → 质量检查，需要一个灵活的工作流来编排。\u0026rdquo;\n技术方案 \u0026ldquo;我使用了 LangGraph4j 作为工作流引擎，配合 SSE（Server-Sent Events） 实现流式输出：\n工作流设计：\nRAG 知识检索节点 - 从向量数据库检索相关知识点 任务列表节点 - 根据题目数量创建生成任务队列 题目生成节点 - 调用大模型生成题目 质量检查节点 - 验证题目格式和逻辑 条件路由 - 质检不通过则重新生成，通过则继续下一题 流式输出实现：\n使用 ThreadLocal 存储 SseEmitter，避免序列化问题 工作流异步执行，每个节点完成后实时推送结果 前端通过 EventSource 监听，实时展示生成进度\u0026rdquo; 代码亮点 \u0026ldquo;条件路由的实现是这样的：\n1 2 3 4 5 6 7 .addConditionalEdges(\u0026#34;ques_parse_check_node\u0026#34;, edge_async(this::routeAfterCheck), Map.of( \\\u0026#34;continue_generate\\\u0026#34;, \\\u0026#34;ques_generate_node\\\u0026#34;, // 继续生成下一题 \\\u0026#34;retry_generate\\\u0026#34;, \\\u0026#34;ques_generate_node\\\u0026#34;, // 重新生成当前题 \\\u0026#34;finish\\\u0026#34;, END // 完成 )) 这样就实现了一个带重试机制的循环工作流。\u0026rdquo;\n设计模式应用 \u0026ldquo;在题目生成模块，我还应用了多种设计模式：\n策略模式：不同题型（选择题、填空题、大题）使用不同的生成策略 模板方法模式：题目存储流程统一，但具体存储逻辑由子类实现 工厂模式：根据题型创建对应的生成器 门面模式：AIQuestionFacade 统一对外接口\u0026rdquo; 🎯 融合八股：ThreadLocal 原理与内存泄漏 面试官追问：为什么用 ThreadLocal 存储 SseEmitter？\n回答：\u0026ldquo;因为 SseEmitter 不能序列化，不能放到工作流上下文中传递。我用 ThreadLocal 存储，每个线程有自己的副本。\n1 2 3 4 5 6 7 public static final ThreadLocal\u0026lt;SseEmitter\u0026gt; SSE_EMITTER_HOLDER = new ThreadLocal\u0026lt;\u0026gt;(); // 异步执行前设置 SSE_EMITTER_HOLDER.set(emitter); // 执行完毕后清理（重要！） SSE_EMITTER_HOLDER.remove(); ThreadLocal 原理：每个 Thread 内部有一个 ThreadLocalMap，Key 是 ThreadLocal 对象（弱引用），Value 是存储的值。\n内存泄漏问题：如果不调用 remove()，在线程池场景下，线程会被复用，ThreadLocalMap 中的 Entry 不会被清理，导致内存泄漏。所以我在 finally 块中一定会调用 remove()。\u0026rdquo;\n🎯 融合八股：线程池参数配置 面试官追问：异步执行用的什么线程池？\n回答：\u0026ldquo;我用的是 CompletableFuture.runAsync()，默认使用 ForkJoinPool.commonPool()。但在生产环境，我会自定义线程池：\n1 2 3 4 5 6 7 8 ThreadPoolExecutor executor = new ThreadPoolExecutor( 4, // 核心线程数 = CPU核心数 8, // 最大线程数 = 2 * CPU核心数 60, TimeUnit.SECONDS, // 空闲线程存活时间 new LinkedBlockingQueue\u0026lt;\u0026gt;(1000), // 有界队列，防止OOM new ThreadFactoryBuilder().setNameFormat(\\\u0026#34;ai-workflow-%d\\\u0026#34;).build(), new CallerRunsPolicy() // 拒绝策略：调用者执行 ); 参数设置原则：\nCPU 密集型：核心线程数 = CPU 核心数 IO 密集型：核心线程数 = CPU 核心数 * 2（或更多） AI 生成是 IO 密集型（等待 API 响应），所以可以设置多一些线程 拒绝策略选择：\nAbortPolicy：直接抛异常（默认） CallerRunsPolicy：调用者线程执行（我选这个，保证任务不丢失） DiscardPolicy：静默丢弃 DiscardOldestPolicy：丢弃最老的任务\u0026rdquo; 🎯 融合八股：设计模式详解 面试官追问：能详细说说策略模式怎么用的吗？\n回答：\u0026ldquo;以题目生成为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 1. 策略接口 public interface QuestionGenerator { Question generate(String knowledge, String difficulty); } // 2. 具体策略 @Component(\\\u0026#34;multipleChoice\\\u0026#34;) public class MultipleChoiceGenerator implements QuestionGenerator { ... } @Component(\\\u0026#34;fillBlank\\\u0026#34;) public class FillBlankGenerator implements QuestionGenerator { ... } // 3. 策略选择（配合 Spring 容器） @Resource private Map\u0026lt;String, QuestionGenerator\u0026gt; generatorMap; // Spring 自动注入所有实现 public Question generate(String type, String knowledge) { QuestionGenerator generator = generatorMap.get(type); return generator.generate(knowledge, difficulty); } 策略模式的好处：\n开闭原则：新增题型只需添加新的策略类，不修改原有代码 消除 if-else：避免大量的条件判断 易于测试：每个策略可以独立测试\u0026rdquo; 亮点三：热点数据缓存优化（HeavyKeeper + 二级缓存） 问题背景 \u0026ldquo;在抢课高峰期，某些热门课程会被大量访问，形成热点 Key。如果每次都访问 Redis，会造成 Redis 压力过大，响应时间从正常的 5ms 飙升到 200ms+。\u0026rdquo;\n技术方案 \u0026ldquo;我实现了一套 热点检测 + 二级缓存 的方案：\n热点检测（AsyncHeavyKeeper）：\n使用 HeavyKeeper 算法实时检测 Top K 热点 Key 核心优化：将耗时操作异步化，add() 方法耗时从 5ms 降到 \u0026lt;1ms 使用 ConcurrentLinkedQueue 无锁队列，后台线程批量处理 二级缓存架构：\nL1 缓存：Caffeine 本地缓存，容量 10000，过期时间 60 秒 L2 缓存：Redis 分布式缓存 读操作：先查 L1 → 未命中查 L2 → 写入 L1 写操作：直接写 Redis（保证一致性），不走本地缓存\u0026rdquo; 关键设计决策 \u0026ldquo;这里有一个重要的设计决策：写操作不使用本地缓存。\n原因是：抢课是写操作，需要强一致性。如果用本地缓存，在分布式环境下会出现数据不一致。比如 A 服务器的本地缓存显示还有库存，但实际 Redis 中已经没了。\n所以我的策略是：\n写操作（抢课/退课）：直接走 Redis Lua 脚本 读操作（查询库存/状态）：走二级缓存，提升性能\u0026rdquo; 🎯 融合八股：ConcurrentHashMap 原理 面试官追问：热点 Key 存储为什么用 ConcurrentHashMap？\n回答：\u0026ldquo;因为热点检测是多线程并发访问的场景。\nHashMap 的问题：\n非线程安全，多线程 put 可能导致死循环（JDK7 的头插法）或数据丢失 ConcurrentHashMap 的优势（JDK8+）：\n使用 CAS + synchronized 保证线程安全 锁粒度是单个 Node，而不是整个 Map 读操作完全无锁（volatile 保证可见性） 1 2 3 4 5 6 // 我的代码中 private final ConcurrentHashMap\u0026lt;String, AtomicInteger\u0026gt; hotKeyMap; // computeIfAbsent 是原子操作 AtomicInteger counter = hotKeyMap.computeIfAbsent(key, k -\u0026gt; new AtomicInteger(0)); counter.addAndGet(increment); // AtomicInteger 也是线程安全的 为什么不用 Hashtable？\nHashtable 用 synchronized 锁整个表，性能差 ConcurrentHashMap 锁粒度更细，并发性能更好\u0026rdquo; 🎯 融合八股：CAS 与原子类 面试官追问：AtomicInteger 怎么保证线程安全的？\n回答：\u0026ldquo;AtomicInteger 底层使用 CAS（Compare And Swap） 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // AtomicInteger.addAndGet 的底层实现 public final int addAndGet(int delta) { return U.getAndAddInt(this, VALUE, delta) + delta; } // Unsafe.getAndAddInt public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); // 读取当前值 } while (!compareAndSwapInt(o, offset, v, v + delta)); // CAS 更新 return v; } CAS 原理：比较内存值和预期值，相等则更新，不相等则重试。\nCAS 的问题：\nABA 问题：值从 A→B→A，CAS 认为没变化。解决：AtomicStampedReference（带版本号） 自旋开销：高并发时大量线程自旋，CPU 开销大 只能保证单个变量：多个变量需要用锁 在我的场景中，计数器更新冲突概率不高，CAS 很合适。\u0026rdquo;\n🎯 融合八股：阻塞队列选择 面试官追问：为什么用 ConcurrentLinkedQueue 而不是 LinkedBlockingQueue？\n回答：\u0026ldquo;两者的区别：\n特性 ConcurrentLinkedQueue LinkedBlockingQueue 实现 CAS 无锁 ReentrantLock 加锁 阻塞 非阻塞 支持阻塞 容量 无界 可设置有界 性能 高并发下更好 中等 我选择 ConcurrentLinkedQueue 的原因：\n生产者不阻塞：add() 方法要求极快返回，不能等待 高并发：无锁实现，性能更好 消费者轮询：后台线程用 poll() 非阻塞获取，配合 sleep 避免空转 如果需要阻塞等待，比如生产者-消费者模式，我会用 LinkedBlockingQueue。\u0026rdquo;\n亮点四：微服务架构演进 问题背景 \u0026ldquo;随着业务发展，单体应用出现了几个问题：\nAI 生成任务占用大量资源，影响其他业务 抢课高并发场景无法独立扩展 部署时间长，发布风险高\u0026rdquo; 技术方案 \u0026ldquo;我完成了从单体到微服务的架构演进：\n服务拆分（7个微服务）：\nUser Service - 用户认证 Course Service - 课程管理 Snatch Service - 抢课服务（独立扩展） Question Service - 题目管理 File Service - 文件存储 RAG Service - 知识库检索 AI-Workflow Service - AI 工作流（独立部署，可配 GPU） 技术选型：\n服务注册与配置：Nacos 服务间调用：Dubbo（Triple 协议，性能比 HTTP 高 10 倍） API 网关：Higress（基于 Envoy，支持 Dubbo 协议转换） 消息队列：RocketMQ 分布式事务：Seata（Saga 模式） Session 共享：Spring Session + Redis\u0026rdquo; 为什么选择 Dubbo 而不是 Feign？ \u0026ldquo;主要是性能考虑。Feign 基于 HTTP，每次调用都要经过 HTTP 协议栈，序列化/反序列化开销大。Dubbo 使用 Triple 协议（兼容 gRPC），基于 HTTP/2，支持多路复用，性能是 Feign 的 10 倍以上。\n在抢课这种高并发场景下，服务间调用的性能差异会被放大，所以选择 Dubbo 更合适。\u0026rdquo;\n🎯 融合八股：Spring 事务传播机制 面试官追问：批量写入数据库的事务怎么处理的？\n回答：\u0026ldquo;我用的是 TransactionTemplate 编程式事务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Resource private TransactionTemplate transactionTemplate; private void batchHandleSnatchEvents(List\u0026lt;SnatchEvent\u0026gt; events) { transactionTemplate.execute(status -\u0026gt; { try { // 1. 批量插入抢课记录 snatchMapper.batchInsertSnatch(snatchList); // 2. 批量更新课程容量 snatchSubjectMapper.decrementCapacityBatch(subjectId, count); return true; } catch (Exception e) { status.setRollbackOnly(); // 手动回滚 throw e; } }); } 为什么用编程式事务而不是 @Transactional？\n消费者方法不是 Spring 代理调用，@Transactional 可能失效 编程式事务更灵活，可以精确控制事务边界 事务传播机制（常问）：\nREQUIRED（默认）：有事务就加入，没有就新建 REQUIRES_NEW：总是新建事务，挂起当前事务 NESTED：嵌套事务，可以独立回滚 SUPPORTS：有事务就加入，没有就非事务执行\u0026rdquo; 🎯 融合八股：分布式事务 Seata 面试官追问：跨服务的事务怎么处理？\n回答：\u0026ldquo;我用的是 Seata 的 Saga 模式：\nSeata 的几种模式：\n模式 原理 优点 缺点 AT 自动补偿，基于 undo_log 无侵入 需要数据库支持 TCC Try-Confirm-Cancel 性能好 侵入性强，需要写三个方法 Saga 正向操作 + 补偿操作 长事务友好 最终一致性 XA 两阶段提交 强一致 性能差 我选择 Saga 的原因：\n抢课流程是长事务（Redis → MQ → MySQL） 可以接受最终一致性 补偿逻辑简单（回滚 Redis 操作） Saga 的实现：\n1 2 3 4 5 6 7 // 正向操作 redisService.decrStock(); mqService.sendMessage(); // 补偿操作（失败时调用） redisService.incrStock(); // 回滚库存 ```\u0026#34; 🎯 融合八股：CAP 理论 面试官追问：你的系统是 CP 还是 AP？\n回答：\u0026ldquo;我的系统选择了 AP（可用性 + 分区容错性），牺牲强一致性，保证最终一致性。\nCAP 理论：\nC（Consistency）：所有节点数据一致 A（Availability）：每个请求都能得到响应 P（Partition tolerance）：网络分区时系统仍能工作 分布式系统必须保证 P，所以只能在 C 和 A 之间选择。\n我的选择：\n抢课场景对可用性要求高（用户不能等太久） 可以接受最终一致性（Redis 和 MySQL 短暂不一致） 通过补偿机制保证数据最终一致 如果选择 CP：\n每次抢课都要等 MySQL 写入成功才返回 性能会很差，用户体验不好\u0026rdquo; 三、常见追问及回答 Q1: Redis 和 MySQL 数据一致性怎么保证？ \u0026ldquo;我采用的是 最终一致性 方案：\nRedis 先行：抢课操作先在 Redis 完成，保证高性能 消息队列异步同步：成功后发送 RocketMQ 消息 批量写入 MySQL：消费者批量消费，写入数据库 失败回滚：消息发送失败时，立即回滚 Redis 补偿机制：定时任务对比 Redis 和 MySQL 数据，修复不一致 这样既保证了高性能，又保证了最终数据一致。\u0026rdquo;\nQ2: 如果 RocketMQ 消息丢失怎么办？ \u0026ldquo;我做了多层保障：\n生产者确认：使用同步发送，确保消息到达 Broker 消息持久化：RocketMQ 配置同步刷盘 消费者确认：处理成功后才 ACK，失败会重试 补偿任务：定时任务扫描 Redis 中的抢课记录，对比 MySQL，补偿漏掉的数据 即使极端情况下消息丢失，补偿任务也能保证数据最终一致。\u0026rdquo;\nQ3: Lua 脚本为什么能保证原子性？ \u0026ldquo;Redis 是单线程模型，所有命令都是串行执行的。Lua 脚本在执行期间，不会被其他命令打断，相当于一个原子操作。\n这和数据库的事务不同，数据库事务是通过锁来保证隔离性，而 Redis Lua 是通过单线程串行执行来保证原子性。\n需要注意的是，Lua 脚本不能太长，否则会阻塞其他请求。我的脚本只有几行，执行时间在微秒级。\u0026rdquo;\nQ4: 为什么用 SSE 而不是 WebSocket？ \u0026ldquo;SSE 和 WebSocket 的选择取决于场景：\nSSE：单向通信（服务器 → 客户端），基于 HTTP，实现简单，自动重连 WebSocket：双向通信，需要额外的握手和心跳机制 AI 生成场景是典型的单向推送，用户发起请求后，服务器持续推送生成结果，不需要客户端再发消息。所以 SSE 更合适，实现也更简单。\u0026rdquo;\nQ5: HeavyKeeper 算法原理是什么？ \u0026ldquo;HeavyKeeper 是一种概率数据结构，用于在有限内存下找出 Top K 热点元素。\n核心思想是：\n使用多层 Bucket 数组，每层用不同的 Hash 函数 每个 Bucket 存储一个 Key 的指纹和计数 新元素到来时，如果指纹匹配则计数+1，否则以一定概率衰减原计数 衰减到 0 时，用新元素替换 这样高频元素会稳定占据 Bucket，低频元素会被逐渐淘汰。\n我的优化是把计数更新和清理操作异步化，主线程只做快速的 Bucket 更新，耗时操作放到后台线程。\u0026rdquo;\nQ6: 微服务拆分的原则是什么？ \u0026ldquo;我遵循的原则是：\n业务边界清晰：按领域划分，用户、课程、抢课各自独立 高内聚低耦合：服务内部高内聚，服务间通过接口通信 独立部署：每个服务可以独立部署和扩展 数据独立：每个服务有自己的数据库，避免跨库查询 渐进式拆分：先拆独立性高的服务（用户、文件），再拆有依赖的服务 比如抢课服务，它是高并发场景，需要独立扩展，所以单独拆出来。AI 服务是计算密集型，可能需要 GPU，也单独拆出来。\u0026rdquo;\n四、项目难点与解决方案总结 难点 问题描述 解决方案 效果 高并发超卖 1000人同时抢100个名额 Redis Lua 原子操作 零超卖 数据库压力 瞬时高并发写入 RocketMQ 异步削峰 数据库 QPS 降低 90% AI 生成超时 生成耗时 10-30 秒 SSE 流式输出 + 异步工作流 用户实时看到进度 热点 Key Redis 响应从 5ms 飙到 200ms HeavyKeeper + 二级缓存 响应稳定在 10ms 单体瓶颈 无法独立扩展 微服务拆分 抢课服务可独立扩容 五、面试加分项 1. 主动提及的技术深度 \u0026ldquo;我还研究了Redis 的 IO 多线程优化，在 Redis 6.0+ 可以配置 io-threads 提升性能\u0026rdquo; \u0026ldquo;Lua 脚本我做了优化，把多次 Redis 操作合并，减少网络往返\u0026rdquo; \u0026ldquo;消息队列我对比了 RocketMQ 和 Kafka，选择 RocketMQ 是因为它支持事务消息和延迟消息\u0026rdquo; 2. 可以展示的监控意识 \u0026ldquo;我在关键路径加了性能监控切面，记录每个方法的执行时间\u0026rdquo; \u0026ldquo;Redis 慢查询我配置了告警，超过 50ms 就会记录日志\u0026rdquo; \u0026ldquo;消息队列的消费延迟我也做了监控，防止消息堆积\u0026rdquo; 3. 可以提及的扩展思考 \u0026ldquo;如果并发量再大 10 倍，我会考虑 Redis Cluster 分片\u0026rdquo; \u0026ldquo;如果要支持秒杀场景，可以加入令牌桶限流\u0026rdquo; \u0026ldquo;未来可以考虑用 Serverless 部署 AI 服务，按需扩缩容\u0026rdquo; 六、更多八股融合场景 🎯 AOP 原理（限流切面） 项目应用：我用 AOP 实现了接口限流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Aspect @Component public class RateLimitAspect { @Around(\u0026#34;@annotation(rateLimit)\u0026#34;) public Object around(ProceedingJoinPoint point, RateLimit rateLimit) { // 滑动窗口限流（Redis ZSet 实现） Long remaining = redisTemplate.execute(RATE_LIMIT_SCRIPT, ...); if (remaining \u0026lt; 0) { throw new BusinessException(\u0026#34;操作过于频繁\u0026#34;); } return point.proceed(); } } AOP 原理：\nSpring AOP 基于动态代理实现 JDK 动态代理：目标类实现接口时使用，基于反射 CGLIB 代理：目标类没有接口时使用，基于字节码生成子类 @Around 的执行顺序：\n1 2 3 4 5 6 @Around 前置逻辑 → @Before → 目标方法 → @AfterReturning / @AfterThrowing → @Around 后置逻辑 → @After 🎯 限流算法（滑动窗口） 项目应用：我实现了滑动窗口限流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- Redis ZSet 实现滑动窗口 local key = KEYS[1] local window = ARGV[1] -- 窗口大小（秒） local limit = ARGV[2] -- 限制次数 local now = ARGV[3] -- 当前时间戳 -- 移除窗口外的请求 redis.call(\u0026#39;ZREMRANGEBYSCORE\u0026#39;, key, 0, now - window * 1000) -- 统计窗口内的请求数 local count = redis.call(\u0026#39;ZCARD\u0026#39;, key) if count \u0026lt; limit then redis.call(\u0026#39;ZADD\u0026#39;, key, now, now) -- 记录本次请求 return limit - count - 1 -- 返回剩余次数 else return -1 -- 限流 end 常见限流算法对比：\n算法 原理 优点 缺点 固定窗口 固定时间段计数 简单 临界问题（窗口边界突发） 滑动窗口 滑动时间段计数 平滑 内存占用大 漏桶 固定速率流出 平滑流量 无法应对突发 令牌桶 固定速率生成令牌 允许突发 实现复杂 我选择滑动窗口是因为它能平滑限流，避免固定窗口的临界问题。\n🎯 MySQL 索引优化 项目应用：抢课记录查询优化\n1 2 3 4 5 -- 查询某学生是否抢过某课程 SELECT * FROM snatch WHERE student_id = ? AND subject_id = ?; -- 我建了联合索引 CREATE INDEX idx_student_subject ON snatch(student_id, subject_id); 索引原理（B+ 树）：\n非叶子节点只存索引，叶子节点存数据 叶子节点用链表连接，支持范围查询 树高一般 3-4 层，查询复杂度 O(log n) 联合索引的最左前缀原则：\n(student_id, subject_id) 索引可以支持： WHERE student_id = ? ✅ WHERE student_id = ? AND subject_id = ? ✅ WHERE subject_id = ? ❌（不走索引） 索引失效场景：\n对索引列使用函数：WHERE YEAR(create_time) = 2024 隐式类型转换：WHERE student_id = '123'（student_id 是 int） LIKE 左模糊：WHERE name LIKE '%张' OR 条件：WHERE student_id = 1 OR name = '张三' 🎯 Redis 序列化问题 项目应用：我配置了两个 RedisTemplate\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 1. 通用 RedisTemplate（Jackson 序列化） @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate() { template.setValueSerializer(new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(...)); return template; } // 2. Lua 专用 RedisTemplate（String 序列化） @Bean public RedisTemplate\u0026lt;String, String\u0026gt; luaRedisTemplate() { template.setValueSerializer(new StringRedisSerializer()); return template; } 为什么要两个？\nJackson 序列化会在值前面加类型信息，Lua 脚本处理不了 Lua 脚本需要纯字符串，所以用 StringRedisSerializer 常见序列化方式：\nJdkSerializationRedisSerializer：Java 原生序列化，可读性差 StringRedisSerializer：字符串，简单但只能存字符串 Jackson2JsonRedisSerializer：JSON，可读性好，需要配置类型信息 GenericJackson2JsonRedisSerializer：JSON + 类型信息，通用性好 🎯 Spring Bean 生命周期 项目应用：消费者启动和关闭\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Component public class SnatchEventConsumer { @PostConstruct // Bean 初始化后执行 public void start() { // 启动消费线程 new Thread(this::consumeLoop).start(); } @PreDestroy // Bean 销毁前执行 public void shutdown() { // 优雅关闭：处理完剩余消息 flushBatch(); scheduler.shutdown(); } } Bean 生命周期：\n实例化（new） 属性注入（@Autowired） Aware 接口回调（BeanNameAware、ApplicationContextAware） BeanPostProcessor.postProcessBeforeInitialization @PostConstruct InitializingBean.afterPropertiesSet init-method BeanPostProcessor.postProcessAfterInitialization 使用中\u0026hellip; @PreDestroy DisposableBean.destroy destroy-method 🎯 JVM 内存模型与可见性 项目应用：后台线程的停止标志\n1 2 3 4 5 6 7 8 9 10 11 12 13 private final AtomicBoolean running = new AtomicBoolean(true); // 后台线程 private void processQueue() { while (running.get()) { // 需要保证可见性 // 处理逻辑 } } // 关闭方法 public void shutdown() { running.set(false); // 其他线程能立即看到 } 为什么用 AtomicBoolean 而不是普通 boolean？\n普通 boolean 没有可见性保证，其他线程可能看不到修改 AtomicBoolean 底层用 volatile，保证可见性 volatile 的作用：\n可见性：一个线程修改后，其他线程立即可见 禁止指令重排序：防止编译器和 CPU 优化导致的乱序 volatile 不能保证原子性：\ncount++ 不是原子操作（读-改-写） 需要原子性用 AtomicInteger 或 synchronized 七、一句话总结 \u0026ldquo;这个项目让我深入理解了 高并发系统设计（Redis + Lua + MQ）、AI 应用开发（LangGraph4j + RAG + SSE）、以及 微服务架构演进（Spring Cloud Alibaba + Dubbo）。最大的收获是学会了如何在 性能、一致性、可用性 之间做权衡。\u0026rdquo;\n八、面试话术模板 开场白 \u0026ldquo;我做的是一个智能教育管理系统，主要有三个技术亮点：高并发抢课、AI 工作流、微服务架构。您想先听哪个？\u0026rdquo;\n引出八股的过渡句 \u0026ldquo;说到这个，其实涉及到 Redis 的单线程模型\u0026hellip;\u0026rdquo; \u0026ldquo;这里我用了 ConcurrentHashMap，它的原理是\u0026hellip;\u0026rdquo; \u0026ldquo;为了保证线程安全，我用了 AtomicInteger，它底层是 CAS\u0026hellip;\u0026rdquo; \u0026ldquo;事务这块我用的是编程式事务，因为 @Transactional 有个坑\u0026hellip;\u0026rdquo; 展示深度的句式 \u0026ldquo;我还对比了几种方案\u0026hellip;\u0026rdquo; \u0026ldquo;这里有个细节需要注意\u0026hellip;\u0026rdquo; \u0026ldquo;我踩过一个坑是\u0026hellip;\u0026rdquo; \u0026ldquo;如果并发量再大 10 倍，我会考虑\u0026hellip;\u0026rdquo; 结束语 \u0026ldquo;这个项目让我对高并发和分布式有了更深的理解，也让我养成了从性能、一致性、可用性多角度思考问题的习惯。\u0026rdquo;\n九、口语化面试话术（完整版） 公式：业务背景 → 技术选型原因 → 核心难点实现（手撕逻辑） → 遇到的坑与解决 → 未来优化方向\n【话术一】高并发抢课系统 1️⃣ 业务背景（30秒） \u0026ldquo;我们这个系统有一个抢课功能，就是学生选课的时候，热门课程可能几百上千人同时抢。\n核心问题有两个：\n第一是超卖，比如课程只有100个名额，结果抢了120个人，这肯定不行 第二是数据库扛不住，如果每个请求都直接打到MySQL，瞬时1000个并发，数据库直接就挂了 所以我需要设计一个既能防超卖、又能扛住高并发的方案。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我调研了几种方案：\n方案一：纯MySQL + 悲观锁\n用 SELECT FOR UPDATE 锁住库存记录 问题是性能太差，测下来只有500 QPS，而且锁竞争严重 方案二：MySQL + 乐观锁\n用版本号控制，UPDATE ... WHERE version = ? 问题是高并发下大量重试，成功率低 方案三：Redis + Lua + 消息队列（我最终选的）\nRedis 单线程，天然防并发问题 Lua 脚本保证原子性，不会超卖 消息队列异步写数据库，削峰填谷 选 Redis 的核心原因是：它的单线程模型天然保证了操作的原子性，不需要加锁就能防止并发问题。\u0026rdquo;\n3️⃣ 核心难点实现（2分钟，可手撕） \u0026ldquo;核心就是这个 Lua 脚本，我给您讲一下逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 第一步：检查这个学生是不是已经抢过了 local hasSnatch = redis.call(\u0026#39;HEXISTS\u0026#39;, studentKey, subjectId) if hasSnatch == 1 then return -1 -- 已经抢过，直接返回 end -- 第二步：扣减库存（原子操作） local newCapacity = redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, -1) if newCapacity \u0026lt; 0 then -- 库存不够，要回滚 redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, 1) return -2 -- 库存不足 end -- 第三步：记录抢课状态 redis.call(\u0026#39;HSET\u0026#39;, studentKey, subjectId, 1) return 1 -- 成功 为什么能防超卖？\n关键在于 Redis 是单线程执行命令的。这个 Lua 脚本在执行期间，不会有其他命令插进来。所以「检查库存 → 扣减库存 → 记录状态」这三步是一个原子操作，不可能出现两个人同时扣减最后一个库存的情况。\n数据怎么落库？\nRedis 操作成功后，我不是直接写 MySQL，而是发一条消息到 RocketMQ。消费者那边批量消费，比如攒够1000条或者等10秒，然后批量 INSERT。这样数据库的压力就从瞬时1000 QPS 变成了平稳的每秒几十次批量写入。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;我踩过几个坑：\n坑一：Redis 序列化问题\n一开始我用 Jackson 序列化，结果 Lua 脚本执行报错。因为 Jackson 会在值前面加类型信息，Lua 处理不了。\n解决：我配了两个 RedisTemplate，一个用 Jackson 给业务用，一个用纯 String 序列化专门给 Lua 脚本用。\n坑二：消息发送失败数据不一致\nRedis 扣减成功了，但是消息发送失败了，这时候 Redis 和 MySQL 数据就不一致了。\n解决：我加了回滚机制。消息发送失败时，立即执行一个回滚的 Lua 脚本，把库存加回去，把抢课状态删掉。\n坑三：热点 Key 导致 Redis 响应变慢\n压测的时候发现，热门课程的 Key 被大量访问，Redis 响应时间从5ms飙到200ms。\n解决：我实现了一个热点检测 + 本地缓存的方案。用 HeavyKeeper 算法检测热点 Key，检测到之后把数据缓存到本地 Caffeine，减少 Redis 访问。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;如果并发量再大10倍，我会考虑：\nRedis Cluster 分片：把不同课程的库存分散到不同节点，避免单点瓶颈 令牌桶预热：抢课开始前，先发放令牌，没有令牌的请求直接拒绝，减少无效请求 本地预扣减：在应用层先做一次本地库存预扣减，过滤掉大部分请求，只有预扣减成功的才去访问 Redis\u0026rdquo; 【话术二】AI 智能题目生成 1️⃣ 业务背景（30秒） \u0026ldquo;我们系统有一个 AI 出题功能，老师输入知识点和题目数量，系统自动生成选择题、填空题、大题。\n核心问题：\nAI 生成很慢，一道题可能要5-10秒，生成10道题就要1-2分钟 如果用传统的同步请求，用户要等很久，体验很差，而且容易超时 生成的题目质量参差不齐，需要有质检和重试机制\u0026rdquo; 2️⃣ 技术选型原因（1分钟） \u0026ldquo;我选了 LangGraph4j + SSE 流式输出 的方案：\n为什么用 LangGraph4j？\n它是一个工作流引擎，可以把复杂的 AI 任务拆成多个节点 支持条件路由，比如质检不通过可以自动重试 节点之间可以传递上下文，方便管理状态 为什么用 SSE 而不是 WebSocket？\nSSE 是单向通信，服务器推送给客户端，正好符合我的场景 基于 HTTP，实现简单，不需要额外的握手和心跳 自动重连，断了会自己连回来 为什么不用轮询？\n轮询会产生大量无效请求 实时性差，用户体验不好\u0026rdquo; 3️⃣ 核心难点实现（2分钟） \u0026ldquo;我设计了一个四节点的工作流：\n1 2 3 开始 → RAG知识检索 → 任务拆分 → 题目生成 → 质量检查 → 结束 ↑ ↓ ←← 重试 ←←← 节点一：RAG 知识检索\n根据老师输入的知识点，从向量数据库检索相关的教学文档 这样生成的题目更贴合教材内容 节点二：任务拆分\n把「生成10道选择题」拆成10个独立的任务 每个任务生成一道题 节点三：题目生成\n调用大模型，传入知识点和检索到的文档 生成题目、选项、答案、解析 节点四：质量检查\n检查 JSON 格式是否正确 检查选项数量是否符合要求 检查答案是否在选项中 条件路由的实现：\n1 2 3 4 5 6 7 .addConditionalEdges(\u0026#34;质检节点\u0026#34;, edge_async(this::routeAfterCheck), Map.of( \u0026#34;continue\u0026#34;, \u0026#34;生成节点\u0026#34;, // 质检通过，继续下一题 \u0026#34;retry\u0026#34;, \u0026#34;生成节点\u0026#34;, // 质检失败，重新生成 \u0026#34;finish\u0026#34;, END // 全部完成 )) SSE 流式输出：\n每生成一道题，就立即推送给前端，用户可以实时看到进度。我用 ThreadLocal 存储 SseEmitter，避免序列化问题。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：ThreadLocal 内存泄漏\n一开始我忘了清理 ThreadLocal，结果在线程池场景下，线程被复用，ThreadLocal 里的对象一直不释放，内存越来越大。\n解决：在 finally 块里一定要调用 remove()。\n坑二：异步线程拿不到 ThreadLocal\n工作流是异步执行的，但是异步线程和主线程不是同一个，拿不到主线程的 ThreadLocal。\n解决：在异步任务开始时，重新 set 一次 SseEmitter。\n坑三：大模型返回格式不稳定\n有时候大模型返回的 JSON 格式不对，解析失败。\n解决：我在 prompt 里加了严格的格式要求，并且在质检节点做了格式校验，不通过就重试，最多重试3次。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 并行生成：现在是串行生成10道题，可以改成并行，开10个线程同时生成 2. 缓存相似题目：如果知识点相似，可以从缓存里取，不用每次都调大模型 3. 模型微调：用我们自己的题库数据微调模型，提高生成质量\u0026rdquo;\n【话术三】微服务架构演进 1️⃣ 业务背景（30秒） \u0026ldquo;项目一开始是单体架构，后来遇到了几个问题：\n资源竞争：AI 生成任务很吃 CPU 和内存，一跑起来其他接口都变慢了 无法独立扩展：抢课高峰期，只有抢课模块需要扩容，但单体架构只能整体扩容，浪费资源 发布风险高：改一行代码要重新部署整个应用，万一出问题影响所有功能 所以我决定做微服务拆分。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我选的是 Spring Cloud Alibaba + Dubbo + Nacos + Higress 这套：\n为什么选 Dubbo 而不是 Feign？\nFeign 基于 HTTP，每次调用都要经过完整的 HTTP 协议栈，开销大 Dubbo 用的是 Triple 协议，基于 HTTP/2，支持多路复用，性能是 Feign 的10倍 在抢课这种高并发场景，服务间调用的性能差异会被放大 为什么选 Nacos？\n同时支持服务注册和配置中心，不用部署两套 和 Spring Cloud Alibaba 生态集成好 性能比 Eureka 和 Consul 都好 为什么选 Higress 网关？\n基于 Envoy，性能很高 原生支持 Dubbo 协议转换，外部 HTTP 请求可以直接转成 Dubbo 调用 和 Nacos 无缝集成\u0026rdquo; 3️⃣ 核心难点实现（1分钟） \u0026ldquo;我拆成了7个服务：\n服务 职责 为什么单独拆 User 用户认证 基础服务，被所有服务依赖 Course 课程管理 业务独立 Snatch 抢课 高并发，需要独立扩展 Question 题目管理 业务独立 File 文件存储 IO 密集，独立部署 RAG 知识库检索 向量计算，资源隔离 AI-Workflow AI 工作流 CPU 密集，可能要 GPU 服务间调用：用 Dubbo RPC，定义了统一的接口模块 EduAgentX-Client，所有服务都依赖它。\nSession 共享：用 Spring Session + Redis，所有服务共享同一个 Session 存储。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：循环依赖\nCourse 服务要调用 User 服务获取教师信息，User 服务又要调用 Course 服务获取用户的课程列表，形成了循环依赖。\n解决：重新梳理服务边界，把「用户的课程列表」这个功能放到 Course 服务，User 服务只负责用户基本信息。\n坑二：分布式事务\n抢课成功后要同时更新 Redis、发消息、写数据库，跨了多个服务。\n解决：用 Seata 的 Saga 模式，定义正向操作和补偿操作。失败时自动执行补偿，保证最终一致性。\n坑三：服务调用超时\nAI 服务生成题目很慢，默认的 Dubbo 超时时间是3秒，经常超时。\n解决：针对 AI 服务单独配置超时时间为60秒，其他服务保持3秒。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 服务网格：引入 Istio，把服务治理下沉到基础设施层 2. 容器化：用 Kubernetes 部署，实现自动扩缩容 3. Serverless：AI 服务可以用 Serverless 部署，按调用量付费，降低成本\u0026rdquo;\n【话术四】热点缓存优化 1️⃣ 业务背景（30秒） \u0026ldquo;压测的时候发现一个问题：热门课程被大量访问，Redis 响应时间从正常的5ms飙升到200ms，严重影响了抢课接口的性能。\n分析原因是：所有请求都打到 Redis 的同一个 Key 上，形成了热点 Key，Redis 单线程处理不过来。\u0026rdquo;\n2️⃣ 技术选型原因（30秒） \u0026ldquo;我的方案是 热点检测 + 本地缓存：\n用 HeavyKeeper 算法 实时检测哪些 Key 是热点 检测到热点后，把数据缓存到本地 Caffeine 后续请求先查本地缓存，命中就不用访问 Redis 了 为什么用 HeavyKeeper？因为它是概率数据结构，内存占用小，可以在有限内存下找出 Top K 热点元素。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;HeavyKeeper 的原理是：\n维护一个多层的 Bucket 数组 每个 Bucket 存一个 Key 的指纹和计数 新请求来了，如果指纹匹配就计数+1 如果不匹配，以一定概率衰减原来的计数 衰减到0就用新 Key 替换 我做的优化：\n原始实现的 add() 方法要5ms，太慢了。我改成了异步版本：\n1 2 3 4 5 6 7 8 9 10 11 public AddResult add(String key, int increment) { // 1. 快速更新 Bucket（分段锁，\u0026lt;1ms） int maxCount = updateBuckets(key, increment); // 2. 如果是热点，放入队列（不阻塞） if (maxCount \u0026gt;= threshold) { updateQueue.offer(new UpdateTask(key, maxCount)); } return result; } 耗时操作（清理过期数据、统计 Top K）都放到后台线程异步处理，主线程只做快速的计数更新。优化后 add() 耗时从5ms降到了0.1ms。\u0026rdquo;\n4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：本地缓存数据不一致\n本地缓存和 Redis 数据可能不一致，比如 A 服务器的本地缓存显示还有库存，但 Redis 里已经没了。\n解决：我的策略是写操作不走本地缓存。抢课、退课这种写操作，直接走 Redis Lua 脚本。本地缓存只用于读操作（查询库存、查询状态），而且设置了60秒过期时间，保证最终一致性。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 多级缓存：可以再加一层进程内缓存，形成 L1（进程内）→ L2（本地 Caffeine）→ L3（Redis）的三级缓存 2. 缓存预热：抢课开始前，提前把热门课程的数据加载到本地缓存 3. Redis Cluster：如果热点 Key 太多，可以用 Redis Cluster 分散到多个节点\u0026rdquo;\n十、万能应对话术 当面试官问「还有什么要补充的吗」 \u0026ldquo;我想补充一点，这个项目让我最大的收获不是学会了某个技术，而是学会了怎么做技术选型。\n比如抢课系统，我一开始想用分布式锁，后来发现 Lua 脚本更简单高效；消息队列我对比了 Kafka 和 RocketMQ，最后选了 RocketMQ 因为它支持事务消息。\n我觉得做技术选型最重要的是理解每个方案的优缺点和适用场景，而不是盲目追求新技术。\u0026rdquo;\n当面试官问「这个项目有什么不足」 \u0026ldquo;有几个地方我觉得可以做得更好：\n监控不够完善：目前只有基础的日志，缺少完整的链路追踪和性能监控大盘 测试覆盖率不够：单元测试写得比较少，主要靠手工测试 文档不够完善：接口文档有，但是架构设计文档和运维文档比较欠缺 如果有机会重新做，我会在项目初期就把这些基础设施搭建好。\u0026rdquo;\n当面试官问「你在团队中的角色」 \u0026ldquo;我是这个项目的主要开发者，负责核心模块的设计和实现：\n抢课系统的高并发方案是我设计的 AI 工作流引擎是我从零搭建的 微服务拆分的架构设计也是我主导的 遇到技术难题时，我会先自己调研，然后和团队讨论，最后形成方案文档，评审通过后再实施。\u0026rdquo;\n当面试官深挖某个技术细节你不太确定时 \u0026ldquo;这个细节我不太确定，但是我的理解是\u0026hellip;（说你的理解）。回去之后我会再深入研究一下，确认一下是不是这样。\u0026rdquo;\n千万不要：\n瞎编一个答案 说「我不知道」然后沉默 十一、面试前 Checklist 必须能脱口而出的 项目30秒介绍 三个核心亮点的业务背景 Lua 脚本的核心逻辑（能手写） 为什么选 Redis 不选 MySQL 为什么选 RocketMQ 不选 Kafka 为什么选 Dubbo 不选 Feign ThreadLocal 内存泄漏怎么解决 分布式事务用的什么方案 最好能说清楚的 Redis 单线程模型 ConcurrentHashMap 原理 线程池参数怎么配置 AOP 的实现原理 Spring 事务传播机制 CAP 理论，你的系统是 CP 还是 AP 加分项 性能优化的具体数据（QPS 从多少到多少） 踩过的坑和解决方案 未来的优化方向 对比过哪些技术方案 ","date":"2025-11-27T20:08:45+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E8%AF%9D%E6%9C%AF/","title":"面试话术"},{"content":"面试八股/场景2.0 介绍一下RDB和AOF Redis 是一个基于内存的数据库，为了防止服务器宕机导致数据丢失，Redis 提供了两种主要的持久化机制：RDB (Redis Database) 和 AOF (Append Only File)。\n这两者分别代表了两种不同的思路：快照（Snapshotting） 和 日志（Logging）。\n1. RDB (Redis Database) —— 快照模式 RDB 是 Redis 默认的持久化方式。它会在指定的时间间隔内，将内存中的数据集快照写入磁盘。\n工作原理 触发方式： 可以通过配置文件（如 save 900 1，表示900秒内有1个key变动则触发）自动触发，也可以手动执行 SAVE 或 BGSAVE 命令。\n核心流程（BGSAVE）：\nRedis 主进程 fork 一个子进程。\n子进程共享主进程的内存数据（利用操作系统的 Copy-on-Write / 写时复制 技术）。\n子进程将数据写入到一个临时的 RDB 文件中。\n写入完成后，用新文件替换旧的 RDB 文件。\n✅ 优点 恢复速度快： RDB 是一个紧凑的二进制文件，非常适合用于灾难恢复和备份。Redis 加载 RDB 文件恢复数据的速度远快于 AOF。\n文件体积小： 相比 AOF，RDB 文件更小，节省磁盘空间。\n性能影响小： 父进程在 fork 子进程后继续处理请求，持久化工作由子进程完成，最大化了 Redis 的性能。\n❌ 缺点 数据丢失风险较高： RDB 是间隔执行的（例如每5分钟一次）。如果 Redis 在两次快照之间宕机，这期间产生的数据将会丢失。\n大数据集下的停顿： 当数据集非常大（如几十 GB）时，fork 子进程的操作可能会比较耗时，导致 Redis 主进程出现毫秒级甚至秒级的阻塞。\n2. AOF (Append Only File) —— 日志模式 AOF 记录了服务器接收到的每一个写操作（查询操作不记录）。服务器启动时，通过重新执行这些命令来还原数据。\n工作原理 命令追加： 所有的写命令会先追加到 AOF 缓冲区。\n同步策略（fsync）： 根据配置将缓冲区内容同步到磁盘：\nappendfsync always：每次写操作都同步（最安全，但性能最差）。\nappendfsync everysec：每秒同步一次（默认推荐，兼顾性能与安全）。\nappendfsync no：由操作系统决定何时同步（性能最好，但不可控）。\nAOF 重写（Rewrite）： 随着时间推移，AOF 文件会越来越大（例如：SET a 1, SET a 2 其实最终只是 a=2）。Redis 会在后台对 AOF 文件进行重写，只保留恢复当前数据所需的最小命令集。\n✅ 优点 数据安全性高： 使用 everysec 策略，最坏情况下也只会丢失 1 秒的数据。\n可读性强： AOF 文件是纯文本格式，如果误执行了 FLUSHALL，只要 AOF 文件未被重写，可以手动删掉文件末尾的该命令来挽救数据。\n❌ 缺点 文件体积大： 记录所有写命令，导致 AOF 文件通常比 RDB 文件大得多。\n恢复速度慢： 恢复数据时需要“重放”所有命令，速度比加载 RDB 二进制快照要慢。\n写性能稍低： 根据 fsync 策略，AOF 对写性能有一定影响（通常 everysec 影响很小）。\n3. RDB vs AOF 核心对比 特性 RDB (快照) AOF (日志) 数据安全性 较低 (可能丢失最后几分钟数据) 高 (默认通常只丢1秒) 恢复速度 非常快 较慢 (需重放命令) 文件体积 小 (二进制压缩) 大 (文本记录) 资源消耗 CPU 高 (Fork 过程), I/O 低 CPU 低, I/O 高 (持续追加) 启动优先级 低 (若开启 AOF，优先加载 AOF) 高 (因为数据更全) Redis 是一个基于内存的数据库，为了防止服务器宕机导致数据丢失，Redis 提供了两种主要的持久化机制：RDB (Redis Database) 和 AOF (Append Only File)。\n这两者分别代表了两种不同的思路：快照（Snapshotting） 和 日志（Logging）。\n以下是两者的详细对比与解析：\n1. RDB (Redis Database) —— 快照模式 RDB 是 Redis 默认的持久化方式。它会在指定的时间间隔内，将内存中的数据集快照写入磁盘。\n工作原理 触发方式： 可以通过配置文件（如 save 900 1，表示900秒内有1个key变动则触发）自动触发，也可以手动执行 SAVE 或 BGSAVE 命令。\n核心流程（BGSAVE）：\nRedis 主进程 fork 一个子进程。\n子进程共享主进程的内存数据（利用操作系统的 Copy-on-Write / 写时复制 技术）。\n子进程将数据写入到一个临时的 RDB 文件中。\n写入完成后，用新文件替换旧的 RDB 文件。\n✅ 优点 恢复速度快： RDB 是一个紧凑的二进制文件，非常适合用于灾难恢复和备份。Redis 加载 RDB 文件恢复数据的速度远快于 AOF。\n文件体积小： 相比 AOF，RDB 文件更小，节省磁盘空间。\n性能影响小： 父进程在 fork 子进程后继续处理请求，持久化工作由子进程完成，最大化了 Redis 的性能。\n❌ 缺点 数据丢失风险较高： RDB 是间隔执行的（例如每5分钟一次）。如果 Redis 在两次快照之间宕机，这期间产生的数据将会丢失。\n大数据集下的停顿： 当数据集非常大（如几十 GB）时，fork 子进程的操作可能会比较耗时，导致 Redis 主进程出现毫秒级甚至秒级的阻塞。\n2. AOF (Append Only File) —— 日志模式 AOF 记录了服务器接收到的每一个写操作（查询操作不记录）。服务器启动时，通过重新执行这些命令来还原数据。\n工作原理 命令追加： 所有的写命令会先追加到 AOF 缓冲区。\n同步策略（fsync）： 根据配置将缓冲区内容同步到磁盘：\nappendfsync always：每次写操作都同步（最安全，但性能最差）。\nappendfsync everysec：每秒同步一次（默认推荐，兼顾性能与安全）。\nappendfsync no：由操作系统决定何时同步（性能最好，但不可控）。\nAOF 重写（Rewrite）： 随着时间推移，AOF 文件会越来越大（例如：SET a 1, SET a 2 其实最终只是 a=2）。Redis 会在后台对 AOF 文件进行重写，只保留恢复当前数据所需的最小命令集。\n✅ 优点 数据安全性高： 使用 everysec 策略，最坏情况下也只会丢失 1 秒的数据。\n可读性强： AOF 文件是纯文本格式，如果误执行了 FLUSHALL，只要 AOF 文件未被重写，可以手动删掉文件末尾的该命令来挽救数据。\n❌ 缺点 文件体积大： 记录所有写命令，导致 AOF 文件通常比 RDB 文件大得多。\n恢复速度慢： 恢复数据时需要“重放”所有命令，速度比加载 RDB 二进制快照要慢。\n写性能稍低： 根据 fsync 策略，AOF 对写性能有一定影响（通常 everysec 影响很小）。\n3. RDB vs AOF 核心对比 特性 RDB (快照) AOF (日志) 数据安全性 较低 (可能丢失最后几分钟数据) 高 (默认通常只丢1秒) 恢复速度 非常快 较慢 (需重放命令) 文件体积 小 (二进制压缩) 大 (文本记录) 资源消耗 CPU 高 (Fork 过程), I/O 低 CPU 低, I/O 高 (持续追加) 启动优先级 低 (若开启 AOF，优先加载 AOF) 高 (因为数据更全) 4. 最佳实践：混合持久化 (Redis 4.0+) 在 Redis 4.0 之前，通常建议同时开启 RDB（做备份）和 AOF（保数据）。\nRedis 4.0 引入了混合持久化（Hybrid Persistence）：\n这是目前的推荐配置。它结合了 RDB 和 AOF 的优点：\n机制： 在进行 AOF 重写时，Redis 会将当前内存的数据以 RDB 格式 写入 AOF 文件的开头，随后的增量写操作继续以 AOF 文本格式 追加到文件末尾。\n结果： AOF 文件前半部分是 RDB（加载快、体积小），后半部分是增量日志（数据全）。\n效果： 既保证了快速启动（加载 RDB 部分），又保证了数据不丢失（加载 AOF 增量部分）。\n进程和线程的区别 用一句话概括：进程是资源分配的最小单位，线程是 CPU 调度的最小单位。\n核心区别详解 1. 资源的拥有权（Resource Ownership） 进程： 拥有独立的内存空间（代码段、数据段、堆等）和系统资源（文件描述符等）。不同进程之间的资源是隔离的。\n线程： 线程本身不拥有系统资源，只拥有很少的运行中必不可少的资源（如程序计数器、栈、寄存器）。同一进程内的所有线程共享该进程的内存空间（堆、全局变量）和文件资源。\n2. 调度与开销（Overhead \u0026amp; Switching） 进程： 切换成本高。当操作系统切换进程时，需要保存当前进程的上下文（内存页表、CPU 状态等）并加载新进程的上下文，这会导致 CPU 缓存失效，开销较大。\n线程： 切换成本低。同一进程内的线程切换，不需要切换内存页表，只需要保存和恢复少量的寄存器内容和栈信息，速度很快。\n3. 通信方式（Communication） 进程间通信 (IPC)： 困难。因为内存隔离，进程间需要通过特殊机制通信，如：管道 (Pipe)、消息队列、共享内存、信号量、Socket 等。\n线程间通信： 容易。因为共享内存（堆），线程之间可以直接读写同一变量来进行通信。\n注意： 虽然通信容易，但带来了**线程安全（同步）**问题，需要使用锁（Lock）或 CAS 等机制来防止数据错乱。 4. 健壮性与隔离性（Stability） 进程： 健壮性强。一个进程崩溃通常不会影响其他进程（因为内存是隔离的）。例如：Chrome 浏览器的一个标签页（进程）崩了，通常不会导致整个浏览器崩溃。\n线程： 健壮性弱。一个线程出现致命错误（如非法内存访问），可能会导致整个进程崩溃，进而导致该进程内的所有线程都挂掉。\n对比总结表 维度 进程 (Process) 线程 (Thread) 本质 资源分配的最小单位 CPU 调度的最小单位 内存空间 独立（互不干扰） 共享（同一进程内） 切换开销 大 (涉及虚拟内存、页表切换) 小 (不涉及内存地址空间切换) 通信难度 难 (IPC：管道、Socket等) 易 (直接读写共享变量) 稳定性 进程间隔离，一个崩了不影响其他 一个线程崩了可能搞挂整个进程 并发性 也可以并发，但资源消耗大 并发性高，资源消耗小 Redis的内存淘汰机制 当 Redis 的内存使用量达到在 redis.conf 中配置的 maxmemory 上限时，为了能继续接收新的写入请求，Redis 必须根据配置的策略删除一部分数据。这就是 Redis 的内存淘汰机制。\nRedis 提供了 8 种 淘汰策略（Redis 4.0 之后），我们可以从**“淘汰范围”和“淘汰算法”**两个维度来理解。\n1. 两个核心维度 在记忆这些策略之前，先理解两个概念，这样就不需要死记硬背了：\n淘汰范围（也就是“去哪里选”）：\nallkeys：从所有键中筛选（不管有没有设置过期时间）。通常用于把 Redis 当纯缓存用的场景。\nvolatile：只从**设置了过期时间（TTL）**的键中筛选。通常用于把 Redis 当数据库用，同时又想缓存一部分临时数据的场景。\n淘汰算法（也就是“怎么选”）：\nLRU (Least Recently Used)：最近最少使用。\nLFU (Least Frequently Used)：最不经常使用（Redis 4.0+）。\nRandom：随机。\nTTL：快过期的。\nRedis 的 LRU 是真的 LRU 吗？ 不是。 Redis 使用的是近似 LRU 算法（Approximated LRU）。\n原因： 严格的 LRU 需要维护一个巨大的双向链表，每访问一次 key 就要移动节点，这非常消耗内存且影响性能。\n实现： Redis 采用随机采样的方式。当需要淘汰时，它随机抽取 N 个 key（默认 5 个，由 maxmemory-samples 配置），然后淘汰这 N 个里面最久没被访问的那一个。\n效果： 虽然是近似的，但在 Redis 3.0 优化后，效果已经非常接近严格 LRU 了。\nRedis的各种淘汰策略 策略前缀 策略后缀 (算法) 含义 适用场景 noeviction - 不淘汰，写请求报错 纯数据存储，数据不能丢 allkeys -lru 所有Key + 最近最少使用 通用缓存 (推荐) allkeys -lfu 所有Key + 最不经常使用 即使最近被访问过，总体访问频率低也被淘汰 allkeys -random 所有Key + 随机 极少使用 volatile -lru 过期Key + 最近最少使用 混合存储，只淘汰缓存部分 volatile -lfu 过期Key + 最不经常使用 同上 volatile -random 过期Key + 随机 极少使用 volatile -ttl 过期Key + 剩余时间最短 让快过期的先走 Java的双亲委派模型是什么？ 双亲委派模型（Parent Delegation Model） 是 Java 类加载机制的核心设计思想。\n虽然名字听起来有点高大上（甚至有点拗口），但它的核心逻辑非常简单，用一句话概括就是：“这也是为了你好：有事儿先找你爹，你爹搞不定你再自己来。”\n下面我从结构、流程、作用和例外四个方面为你拆解。\n1. 谁是“双亲”？（类加载器的层级） 在 Java 中，类加载器（ClassLoader）是有层级关系的。并不是真的有两个亲戚（“双亲”这个翻译其实有点误导，它指的是 Parent，即父级）。\n主要的类加载器有三层：\n启动类加载器 (Bootstrap ClassLoader)\n地位： 老祖宗，最顶层。\n职责： 负责加载 Java 的核心类库（如 java.lang.String, rt.jar 等）。它是用 C++ 写的，在 Java 代码里拿不到它的引用（也就是 null）。\n它负责加载 Java 运行时环境（JRE）中最核心的库。这些类位于 $JAVA_HOME/jre/lib 目录下，通常打包在 rt.jar (Runtime Jar) 中。\n💡 具体例子： 只要是 java.* 开头的几乎都是它加载的。\n基础类型包装类： java.lang.Integer, java.lang.Double, java.lang.String\n集合框架： java.util.ArrayList, java.util.HashMap, java.util.HashSet\nIO 流： java.io.File, java.io.FileInputStream\n并发包： java.util.concurrent.ConcurrentHashMap\n线程： java.lang.Thread\n🧐 现象： 如果你在代码里打印 String.class.getClassLoader()，你会得到 null。这不是因为没加载，而是因为 Bootstrap 是用 C++ 写的，Java 代码无法获取它的引用。\n扩展类加载器 (Extension ClassLoader)\n地位： 中间层。\n职责： 负责加载 Java 的扩展库（JAVA_HOME/lib/ext 目录下的 jar 包）。\n它负责加载 $JAVA_HOME/jre/lib/ext 目录下的类库，或者被 java.ext.dirs 系统变量所指定的路径。它是对 Java 核心功能的补充。\n💡 具体例子： 这些类通常平时用得少一点，多涉及一些加密、特殊网络协议或 XML 解析等。\n加密库： com.sun.crypto.provider.SunJCE (Java 加密扩展，做 AES/DES 加密时会用到)\nDNS 相关： sun.net.spi.nameservice.dns.DNSNameService (某些 JDK 版本下的 DNS 解析服务)\nJavaScript 引擎： jdk.nashorn.api.scripting.NashornScriptEngine (Java 8 中内置的 JS 引擎)\n应用程序类加载器 (Application ClassLoader)\n地位： 最底层（系统默认）。\n职责： 负责加载我们自己写的代码（ClassPath 下的类）和第三方 Jar 包。\n这是我们接触最多的加载器。它负责加载 CLASSPATH 环境变量或系统属性 java.class.path 指定的类库。\n💡 具体例子： 凡是你自己在工程里写的，或者在 pom.xml / build.gradle 里引用的，都归它管。\n你写的业务代码：\ncom.example.project.UserController\ncom.example.project.MyUtils\n你的 Main 启动类\n第三方开源框架（Maven 依赖）：\nSpring 全家桶： org.springframework.boot.SpringApplication, org.springframework.context.ApplicationContext\n数据库驱动： com.mysql.cj.jdbc.Driver (注意：虽然 Driver 接口是核心的，但 MySQL 的实现类是 App 加载的)\n中间件客户端： org.apache.rocketmq.client.producer.DefaultMQProducer (RocketMQ), com.alibaba.dubbo.config.ApplicationConfig (Dubbo)\n工具类： com.alibaba.fastjson.JSON, org.apache.commons.lang3.StringUtils\n此外，还可以有自定义类加载器 (Custom ClassLoader)，挂在应用程序类加载器下面。\n2. 委派流程（怎么工作？） 当一个类加载器收到了类加载的请求时，它不会自己立即去加载，而是遵循以下步骤：\n向上委托： 它会把这个请求委托给父类加载器去执行。\n层层传递： 父类加载器如果还有父类，就继续向上委托，直到传到最顶层的 Bootstrap ClassLoader。\n向下尝试：\nBootstrap 尝试加载，如果找到了（比如是 String），就直接返回。\n如果 Bootstrap 没找到（也就是它管辖的范围里没有这个类），就告诉子类（Extension）：“我搞不定，你来吧”。\nExtension 尝试加载，如果没找到，再往下交给 Application。\nApplication 尝试加载，如果也没找到，就会抛出 ClassNotFoundException。\n3. 为什么要这么设计？（核心作用） 双亲委派模型主要解决了两个大问题：\n✅ 1. 安全性 (Security) —— 防止核心 API 被篡改 假设黑客写了一个恶意的类，名字也叫 java.lang.String，并且放在了你的 ClassPath 下。 如果没有双亲委派，系统就会加载这个恶意的 String 类，你的密码、数据全都会被黑客截获。 有了双亲委派： 系统在加载 String 时，会一直往上找，最终由 Bootstrap ClassLoader 加载了 JDK 自带的那个正版 String。黑客写的那个类永远没有机会被加载。\n✅ 2. 避免重复加载 (Uniqueness) Java 类在内存中的唯一性是由 “类加载器 + 类全名” 共同决定的。 如果同一个 System 类被两个不同的加载器各加载了一次，JVM 会认为它们是两个完全不同的类，这会导致类型转换异常，系统会乱套。 双亲委派保证了核心类永远只由顶层的加载器加载一次。\n4. 什么时候需要打破双亲委派？ 虽然双亲委派很好，但在某些特殊场景下，它反而成了阻碍，我们需要“打破”它（即：不让父类先加载，而是自己先加载，或者绕过父类）。\n经典案例：\nTomcat (Web 容器)：\nTomcat 上可能部署了两个 Web 应用，一个用 Spring 4，一个用 Spring 5。\n如果用默认的双亲委派，Spring 类库只能加载一份，会导致冲突。\n解决： Tomcat 自定义了类加载器，优先加载 Web 应用自己 WEB-INF/lib 下的类，打破了“向上委托”的规则（先自己找，找不到再问爸爸）。\nJDBC (SPI 机制)：\nJava 核心包提供了 java.sql.Driver 接口（在 Bootstrap 层加载）。\n但是具体的实现（如 MySQL 驱动）是第三方厂商提供的（在 ClassPath 下，由 App 层加载）。\n这里出现了一个悖论：Bootstrap 层的代码需要去调用 App 层的代码。父加载器是看不到子加载器的类的。\n解决： 使用 线程上下文类加载器 (Thread Context ClassLoader)，让父级加载器“走后门”拿到子级加载器去加载类。\nHashMap与ConcurentHashMap的区别 HashMap 和 ConcurrentHashMap (CHM) 的核心区别在于：线程安全性和底层实现机制\n简单来说：\nHashMap 是非线程安全的，性能极高，适合单线程。\nConcurrentHashMap 是线程安全的，高并发下性能依然优秀，适合多线程。\n核心区别详解 ① 线程安全性 (Thread Safety) HashMap:\n不安全。 如果多个线程同时写入 HashMap，可能会导致数据覆盖（Data Race）。\n严重问题： 在 JDK 1.7 中，多线程并发扩容（Resize）时甚至会导致链表成环，造成 Infinite Loop（死循环），CPU 飙升 100%。虽然 JDK 1.8 修复了死循环问题，但依然会有数据丢失风险。\nConcurrentHashMap:\n安全。 它是专门为并发设计的。内部使用了非常精妙的锁机制和 CAS 操作，保证了多线程下的数据一致性。 ② 锁的粒度 (Locking Granularity) —— 性能的关键 HashMap: 没有锁。\nHashtable (反面教材): 使用 synchronized 锁住整个 Map（一把大锁）。只要有一个线程在写，其他线程无论是读还是写都得排队，效率极低。\nConcurrentHashMap:\nJDK 1.7: 使用 分段锁 (Segment Locking)。将数据分成一段一段（默认 16 段），每次只锁住被修改的那一段。\nJDK 1.8 (优化): 抛弃了分段锁，采用 CAS + synchronized。锁的粒度更细，只锁住哈希桶的头节点。这意味着只要两个线程操作的 Key 不在同一个桶（Hash冲突），它们就可以完全并行，互不干扰！\n能用无锁（CAS）解决的就用无锁，解决不了的再用锁（synchronized），而且锁本身也做了巨大的优化\n1. CAS (Compare And Swap) —— 冲锋在前的“轻骑兵” CAS 是一种乐观锁机制。它的核心思想是：“我认为没人跟我抢，所以我直接尝试更新。如果真的有人抢（比较失败），我再重试或放弃。”\n在 JDK 1.8 的 CHM 中，CAS 主要用于无竞争场景和状态设置，它的速度非常快，因为它直接对应 CPU 的一条原子指令（cmpxchg）。\nCAS 在哪里用？ 插入新节点（最关键的路径）： 当 put 一个数据时，如果计算出的 Hash 槽位（Bucket）是空的（没有发生哈希冲突），CHM 不会加锁，而是直接用 CAS 尝试把新节点放入该位置。\n代码逻辑： casTabAt(tab, i, null, new Node(...))\n优势： 这种情况在哈希散列良好的情况下非常常见，完全避免了加锁的开销。\n初始化数组： 在 initTable 方法中，通过 CAS 修改 sizeCtl 变量（将其设为 -1），来抢占“初始化数组”的权利。只有一个线程能 CAS 成功，其他的线程会 yield 让出 CPU。\n计数更新： 在 addCount 方法中，利用类似 LongAdder 的机制（Cells 数组），通过 CAS 累加元素的数量。\nCAS 的潜在问题： ABA 问题：（虽然在 CHM 的节点插入中通常不涉及，但在其他并发场景需注意）。\n自旋开销： 如果竞争太激烈，CAS 一直失败重试（自旋），会白白浪费 CPU 资源。\n2. Synchronized —— 坐镇后方的“重装卫士” 在 JDK 1.6 之前，synchronized 是重量级锁，性能很差。但在 JDK 1.8 中，它是经过武装牙齿的“新式重甲”。\nSynchronized 在哪里用？ 仅在发生哈希冲突时使用。\n当 put 数据时，如果发现目标槽位已经有节点了（Hash 冲突），CAS 就搞不定了（因为要操作链表或红黑树，涉及多个指针的变动，CAS 很难保证原子性）。 此时，CHM 会用 synchronized 锁住该槽位的头节点。\n底层实现深度对比 (JDK 1.7 vs JDK 1.8) 这是面试中最能体现深度的部分，重点关注 ConcurrentHashMap 的演进。\nHashMap JDK 1.7: 数组 + 链表。\nJDK 1.8: 数组 + 链表 + 红黑树。当链表长度 \u0026gt; 8 且数组长度 \u0026gt; 64 时，链表会转为红黑树，将查询复杂度从 $O(n)$ 优化到 $O(\\log n)$。\nConcurrentHashMap (进化史) 特性 JDK 1.7 (分段锁) JDK 1.8 (CAS + Synchronized) 核心结构 Segment 数组 + HashEntry 数组 + 链表 Node 数组 + 链表 + 红黑树 锁机制 ReentrantLock (Segment 继承自它) CAS (乐观锁) + synchronized 锁粒度 粗。锁住一个 Segment (默认含多个 Hash 桶) 细。只锁住当前 Hash 桶的头节点 并发度 受限于 Segment 个数 (默认 16) 理论上等于 Hash 桶的数量 (数组长度) 读操作 volatile 保证可见性，无锁 volatile 保证可见性，无锁 JDK 1.8 为什么要放弃分段锁？\n内存占用： 每个 Segment 都要继承 ReentrantLock，通过 AQS 维护队列，内存开销大。\n锁粒度不够细： 即使分了 16 段，依然可能存在多个线程竞争同一个段的情况。\n效率提升： JDK 1.6 之后 JVM 对 synchronized 做了大量优化（偏向锁、轻量级锁），在低竞争下性能已经非常好了，没必要维护复杂的 ReentrantLock。\n3. 总结对比表 维度 HashMap ConcurrentHashMap 线程安全 ❌ 否 ✅ 是 Null Key/Value ✅ 允许 ❌ 不允许 原理 (JDK8) 数组 + 链表 + 红黑树 数组 + 链表 + 红黑树 + CAS + synchronized 扩容机制 新建数组 -\u0026gt; 迁移数据 能够支持多线程并发协助扩容 (这是 CHM 1.8 的黑科技) 应用场景 局部变量、单线程环境 全局缓存、高并发环境 为什么要用synchronized去处理hash冲突 CAS 的“射程”只有 1 个变量 (One Word) 这是核心原因。 CAS 只能保证对“内存中某一个地址”的更新是原子的。\n没有冲突时（put 到空槽位）： 只需要把 Node 放入数组的 tab[i] 位置。这就只涉及一个变量（数组的一个坑位）的修改。\nCAS(tab, i, null, newNode) -\u0026gt; 搞得定！ ✅ 有冲突时（链表/红黑树）： 这就不是改一个变量的事了，这是一个复合操作（Compound Operation）。\n场景一：链表追加 你需要先遍历链表找到最后一个节点 Tail，然后把 Tail.next 指向 NewNode。 看似只改了 Tail.next 一个变量，但在并发环境下，你必须保证从你找到 Tail 到你修改 Tail 的这段时间里，Tail 没有被别人删掉，也没有别人在后面先插了一脚。如果要用 CAS 解决这个问题，必须极其复杂的自旋重试，代码复杂度指数级上升。\n场景二：红黑树旋转 (最致命的) 红黑树插入节点后，为了保持平衡，可能需要变色和旋转。 一次旋转（左旋/右旋）往往涉及到 3 到 5 个指针的同时修改（父节点指向子节点、子节点指向孙节点、父节点指向新的子节点\u0026hellip;）。 CAS 一次只能改 1 个指针，无法同时原子性地修改 3 个指针。 如果你用 3 次 CAS 分别去改，那在第 1 次和第 2 次之间，树的结构是断裂的。其他线程读到这个断裂的树，程序直接崩了。\n结论： synchronized 锁住的是**“一段代码逻辑”（原子性范围大），而 CAS 锁住的是“一个变量”**（原子性范围小）。处理复杂数据结构变动，必须用大范围的锁。\nRedis挂了RocketMQ挂了都怎么处理 Redis 挂了怎么处理？ Redis 挂了，最大的风险是大量流量瞬间击穿缓存，直接打到数据库（MySQL），导致数据库宕机，引发“缓存雪崩”。\n1. 架构层面（事前：别让它挂） 生产环境绝对不能用单机版（Standalone）Redis。\n哨兵模式 (Sentinel)： 此时如果主节点挂了，哨兵会自动选举一个从节点变成主节点。业务层感知很小。\n集群模式 (Cluster)： 数据分片。某一个分片的主节点挂了，该分片的从节点上位。\n2. 应用层面（事中：挂了怎么办） 这是开发最需要关心的。如果 Redis 真的全挂了，代码必须有降级策略。\n方案 A：二级缓存（本地缓存）兜底\n策略： 请求先查 Redis -\u0026gt; Redis 挂了/没数据 -\u0026gt; 查本地缓存 (如 Caffeine/Guava) -\u0026gt; 本地也没 -\u0026gt; 查数据库。\n作用： 本地缓存虽然容量小，但能扛住短期的高热点流量，给数据库争取喘息时间。\n方案 B：熔断与限流（Circuit Breaker \u0026amp; Rate Limiting）\n工具： Sentinel (阿里), Hystrix, Resilience4j。\n逻辑： 当监测到访问 Redis 的异常率飙升（比如连接超时），直接熔断 Redis 调用。\n后续： 请求不再去连 Redis（防止卡死线程），而是直接限流访问数据库。比如平时 10000 QPS，Redis 挂了，限制只有 200 QPS 能打到数据库，剩下的请求直接报错或返回默认值。\n目的： 保住数据库！ 只要数据库还活着，服务就还有救；数据库挂了，整个系统就完了。\n方案 C：服务降级\n如果是非核心业务（比如“猜你喜欢”、“热搜榜”），Redis 挂了直接返回空数据或静态的默认数据，不要去查数据库。 3. 关于分布式锁 如果你的系统依赖 Redis 做分布式锁（Redisson），Redis 挂了会导致锁失效或无法加锁。\n处理： 这种情况下通常需要业务报错（Fail Fast），或者降级为数据库乐观锁（Version字段），但并发性能会大打折扣。\nMQ (消息队列) 挂了怎么处理？ MQ (如 RocketMQ, Kafka, RabbitMQ) 挂了，最大的风险是上下游解耦失败，导致核心链路断开（如下单成功了，但扣库存/发积分的消息发不出去了），或者数据丢失。\n1. 架构层面（事前：别让它挂） 集群部署： 无论是 Kafka 还是 RocketMQ，都是主从/多副本机制。\n多机房/多Broker： 确保一个 Broker 挂了，Producer 可以自动重连到其他 Broker 发送消息。\n2. 应用层面（事中：生产者发不出去怎么办？） 这是最关键的。如果 MQ 彻底连不上了，生产者（Producer）必须有备选方案。\n方案 A：本地消息表（Local Message Table）—— 最稳妥方案\n原理： 既然 MQ 连不上，那就把消息写到本地数据库的一张表里（和业务数据在同一个事务中）。\n流程：\n开启数据库事务。\n执行业务 SQL（如下单）。\n执行插入 SQL：INSERT INTO local_msg_table ... status='PENDING'。\n提交事务。\n恢复： 启动一个定时任务（Timer），轮询这张本地消息表，把状态是 \u0026lsquo;PENDING\u0026rsquo; 的消息尝试重新发给 MQ。一旦发送成功，从表中删除或更新状态。\n方案 B：写入本地磁盘/文件\n原理： 如果数据库压力也很大，可以将消息内容追加写入服务器的本地日志文件。\n恢复： 后续写个脚本读取日志文件，重新灌入 MQ。\n方案 C：同步直连（极端降级）\n如果业务允许，当 MQ 挂了，消费者（Consumer）提供一个 HTTP/RPC 接口。生产者发现 MQ 发送失败，直接调用消费者的 RPC 接口（将异步变同步）。\n缺点： 失去了削峰填谷的作用，消费者可能扛不住压力。\n3. 应用层面（事中：消费者收不到怎么办？） 积压处理： MQ 挂了期间，消息无法消费。等 MQ 恢复后，可能会有海量消息涌入。\n策略： 消费者需要评估是否增加线程数，或者临时起一套只负责“搬运”的消费者，把消息快速落库，然后再慢慢处理，防止消费者被压垮。\n介绍TiDB的计算与存储分离，和MySQL的区别是什么 一句话概括：TiDB 把“处理 SQL 的脑子”和“存数据的肚子”彻底分开了，中间通过网络（RPC）通信。\n一、 TiDB 的计算与存储分离架构 TiDB 的架构主要由三大组件组成，完美体现了这种分离：\n1. 计算层：TiDB Server（无状态的“大脑”） 职责： 负责接收客户端的 SQL 请求，进行 SQL 解析、语法检查、制定查询计划（Optimizer）、生成执行器。\n特点： 它是无状态的（Stateless）。 它不存储任何实际的数据。\n扩展性： 如果你发现 SQL 解析慢了，或者并发连接数太高了，只需要加几台 TiDB Server 机器就行，完全不需要进行数据迁移。\n2. 存储层：TiKV（分布式的“肚子”） 职责： 负责存储真正的数据。底层是一个巨大的、分布式的、有序的 Key-Value Map。\n实现： 内部使用 RocksDB 存储引擎。数据被切分成很多个 Region（默认 96MB），通过 Raft 协议（类似 Paxos）保证多副本一致性。\n扩展性： 如果你发现硬盘满了，或者磁盘 I/O 扛不住了，只需要加几台 TiKV 机器，数据会自动均衡过去。\n3. 调度层：PD (Placement Driver)（“总指挥”） 职责： 存储元数据（哪个 Key 在哪个 TiKV 上），负责给 TiDB Server 提供路由信息，同时指挥 TiKV 进行数据搬迁和负载均衡。 二、 TiDB 与 MySQL 的核心区别 我们将传统 MySQL（单机或主从架构）与 TiDB 进行深度对比：\n维度 MySQL (传统架构) TiDB (存算分离架构) 架构模式 紧耦合 (Monolithic) 松耦合 (Microservices-like) 进程结构 SQL 解析器和 InnoDB 引擎在同一个进程 (mysqld) 中。 SQL 解析在 TiDB 进程，数据存储在 TiKV 进程，通常部署在不同机器上。 通信方式 内存函数调用 (Function Call)，极快。 网络 RPC 调用 (gRPC)，有网络延迟开销。 扩展能力 (Scaling) 垂直扩展 (Vertical)：买更好的 CPU/内存。\n分库分表：需要中间件，运维极其痛苦。 水平扩展 (Horizontal)：计算不足加 TiDB，存储不足加 TiKV，完全透明，业务无感知。 查询执行 数据在哪，计算就在哪。 分布式计算：TiDB 生成计划，分发给多个 TiKV 并行处理。 事务限制 受限于单机内存和磁盘，大事务容易导致主从延迟。 基于 Percolator 模型 (Google) 的两阶段提交 (2PC)，支持跨行跨表分布式事务。 高可用 需依赖 MHA/Orchestrator，主从切换可能丢数据或需人工介入。 基于 Raft 协议，自动选主，强一致性，RPO = 0（数据不丢）。 为什么lua脚本能保证原子性？ 简单直接的答案是：因为 Redis 的主工作线程是单线程的，且 Lua 脚本在执行时是“排他”的。\n我们可以把 Redis 想象成一个只开了一个窗口的办事大厅，而 Lua 脚本就是一份必须一次性办完的复杂文件。\n以下是深度的技术原理拆解，帮助你在面试中不仅能答对，还能答出深度：\n1. 核心机制：单线程 + 独占模式 Redis 的核心命令执行器是单线程的（Event Loop）。\n普通命令（如 SET/GET）： Redis 会从队列里一个个取出来执行。A 客户端发一个 SET，B 客户端发一个 GET，它们是排队轮流执行的。\nLua 脚本（EVAL）： 当 Redis 读到 EVAL 命令（执行 Lua 脚本）时，它会进入一种独占模式。\nRedis 会暂停处理所有其他客户端发来的请求。\n它把整个 Lua 脚本作为一个整体交给 Lua 解释器执行。\n只有当脚本执行结束（或者超时），Redis 才会恢复去处理请求队列里排队的下一个命令。\n结论： 在 Lua 脚本执行期间，绝对不会有其他客户端的命令插队。这就从物理上保证了脚本内的操作是不可分割的（Indivisible），也就是原子性。\n面试高阶陷阱：此“原子性”非彼“原子性” 这是面试官最喜欢挖的坑，一定要主动指出来：\nRedis Lua 脚本的“原子性”是指“隔离性 (Isolation)”，而不是数据库事务中的“原子性 (Atomicity，要么全做要么全不做)”。\nSQL 事务： 如果中间报错，会回滚 (Rollback)，像什么都没发生过一样。\nRedis Lua： 如果脚本里有 3 条命令，执行到第 2 条报错了：\n第 1 条已经生效的数据不会回滚！\n第 2 条报错停止。\n第 3 条不会执行。\n脚本结束。\n面试话术：\n“Redis 的 Lua 脚本保证的是执行过程不被其他客户端打断，保证了操作的原子隔离性。但是，Redis 不支持回滚 (Rollback)。如果脚本内部逻辑抛出错误，之前执行成功的写操作是无法撤销的。所以在编写 Lua 脚本时，必须保证代码逻辑的健壮性。”\n我的简历中使用了 Redisson 的 RRateLimiter ，这个组件的底层就是纯 Lua 脚本实现的。\n可以这样举例：\n“比如我在项目中使用的令牌桶限流。\n我需要查询当前令牌够不够（GET）。\n如果够，我就要扣减一个令牌（DECR）。\n这两个操作如果分开执行，在高并发下会出现‘超卖’（两个线程同时看到令牌剩余 1 个，结果都扣减了，变成 -1）。 而 Redisson 将这两个动作封装在一个 Lua 脚本里发给 Redis，因为 Lua 的原子性，这两个动作瞬间完成，中间没缝隙，绝对不会出现超卖。”\n为什么这比 Redis原生事务更强？ Redis 原生事务（MULTI/EXEC）存在一个痛点：CAS (Check-And-Set) 问题。\nRedis 事务流程： 你必须先 GET 一个值到客户端，判断一下（Check），然后再发 SET 命令（Set）。\n竞态条件： 在你 GET 之后、SET 之前，因为网络延迟，另一个客户端可能修改了这个值。虽然 WATCH 可以监控变化并取消事务，但这意味着你需要写重试逻辑，高并发下失败率极高。\nLua 的优势： 逻辑直接在服务端运行。GET 和 SET 之间没有网络通信延迟，且中间没有其他命令插入。你可以放心地读取一个值，修改它，再写回去，完全不用担心期间被别人改了。\n介绍一下虚拟内存 虚拟内存 (Virtual Memory)，一言以蔽之，是操作系统对所有进程撒的一个弥天大谎。\n它给每个进程（比如你的 Java 程序）营造了一个美丽的幻觉：\n“兄弟，这整个电脑的内存全是你的！是连续的！是独占的！你想怎么用怎么用，不用管别人。”\n但实际上，物理内存（RAM）可能早就被碎尸万段，甚至塞满了，部分数据都被赶到硬盘上去了。\n在很久以前（DOS 时代），确实没有虚拟内存。程序直接操作物理地址。 这会导致三个严重问题：\n打架（地址冲突）：\nQQ 说：“我要住 101 号房间。”\n微信说：“我也要住 101 号房间。”\n崩了。程序员必须小心翼翼地规划，谁用哪块地。\n偷窥（不安全）：\nQQ 住 101，微信住 102。\n微信稍微伸个头，就能看到 QQ 在 101 房间里的隐私（读取内存数据）。恶意程序可以随意修改操作系统的核心数据。\n不够用（内存不足）：\n你有 4GB 内存，GTA5 游戏要 8GB。直接报错退出，玩不了。 二、 虚拟内存的机制（怎么圆这个谎？） 为了解决上面的问题，操作系统引入了中间商。\n1. 核心道具：页表 (Page Table) \u0026amp; MMU 虚拟地址 (Virtual Address)：进程手里拿到的房卡号（比如 0x001）。这是假的。\n物理地址 (Physical Address)：内存条上真正的存储单元地址（比如 0x8F3）。这是真的。\n映射表 (Page Table)：记录“假房号”对应“真房号”的小本本。\nMMU (Memory Management Unit)：CPU 里专门负责查表的一个硬件单元。\n2. 工作流程 当你的 Java 程序执行指令 int a = 10 (假设要把 10 写到地址 0x001)：\n进程发出指令：“我要往 0x001 写数据！”（这是虚拟地址）。\nMMU 拦截：“稍等，我查一下表。”\nMMU 查页表发现：进程 A 的 0x001 对应物理内存的 0x8F3。 硬件执行：CPU 把数据写到了物理内存的 0x8F3。\n妙在哪里？\nQQ 往 0x001 写数据 -\u0026gt; 映射到物理地址 0x800。\n微信 往 0x001 写数据 -\u0026gt; 映射到物理地址 0x900。\n虽然他们用的虚拟地址一样，但物理上完全隔离，互不干扰！\n缺页中断 (Page Fault) —— “空手套白狼” 这是虚拟内存最骚的操作。 你的 Java 程序申请了 1GB 内存（比如 new byte[1024*1024*1024]）。 操作系统直接答应：“好，给你 1GB！”（虚拟内存里划给你了）。 但实际上，物理内存里 1KB 都没给你分配。\n当你真正开始写数据时：\nCPU 拿着虚拟地址去查表。\nMMU 发现：“夷？这个页在物理内存里不存在（Valid 位是 0）。”\n触发 缺页中断 (Page Fault)。\n操作系统内核醒来：“哎呀，这小子来真的了。”\n操作系统赶紧找一块空闲的物理内存，分配给这个页，更新映射表。\n让 CPU 重新执行刚才的写入指令。\n这就是为什么 Java 启动时申请大内存很快，但实际占用（RES）是随着运行慢慢涨上去的。\n交换 (Swap) —— 硬盘来凑数 如果物理内存真满了（比如开了几十个 Chrome 标签页），怎么办？\n动作：操作系统会把那些很久没用的页（冷数据），从物理内存里踢出来，写到硬盘上（Swap 分区 / pagefile.sys）。\n腾地：物理内存腾出来了，给当前急用的程序用。\n换回：当你突然切回那个很久没用的 Chrome 标签页，操作系统会再触发缺页中断，把硬盘里的数据读回物理内存（这时候你会感觉电脑卡了一下，硬盘灯狂闪）。\n操作系统中有很多内存淘汰策略，比如LRU，LFU，CLOCK，增强CLOCK等\n进程切换和线程切换的区别? 1.进程切换:进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大。 2.线程切换:线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小。\n线程切换为什么比进程切换快，节省了什么资源? 线程切换比进程切换快是因为线程共享同一进程的地址空间和资源，线程切换时只需切换堆栈和程序计数器等少量信息，而不需要切换地址空间，避免了进程切换时需要切换内存映射表等大量资源的开销，从而节省了时间和系统资源。\nJNI 是什么？ 它在 Java 编程中是一个非常重要的机制，主要用于解决 Java 应用程序需要与本地代码（Native Code）交互的问题。\nJNI 的核心概念与作用 1. 核心定义 JNI 是一套编程接口，它允许运行在 Java 虚拟机（JVM） 上的 Java 代码与用其他语言（如 C、C++ 等）编写的本地应用程序和库进行交互。\n2. 主要作用 调用本地库 (Calling Native Libraries): 允许 Java 程序调用操作系统底层功能、硬件设备驱动程序，或者使用已经存在的、用 C/C++ 等语言编写的高性能库。\n提高性能 (Performance Enhancement): 对于对性能要求极高或需要直接操作硬件的代码块，可以将其用 C/C++ 实现，并通过 JNI 在 Java 中调用，以提升执行效率。\n复用现有代码 (Reusing Existing Code): 允许开发者在 Java 项目中重用大量的现有 C/C++ 代码库，而无需将其完全重写成 Java。\nJNI 的缺点 虽然 JNI 很强大，但它也有一些缺点：\n失去跨平台性： 一旦使用 JNI，你的 Java 程序就依赖于特定的本地库文件，从而失去了 Java “一次编译，到处运行” 的跨平台优势。\n开发复杂性： JNI 的开发过程比纯 Java 复杂，需要处理 C/C++ 代码、头文件生成、本地内存管理和垃圾回收的交互等问题。\n安全和稳定性风险： 本地代码不受 JVM 内存管理和安全机制的保护。如果本地代码有内存泄漏或越界访问等错误，可能导致整个 JVM 崩溃。\nSpringBoot程序的JDBC连接到了MySQL，用的是UDS，请问流程是什么 场景准备 主角 A (Spring Boot)：位于 Linux 系统的一个进程（假设 PID=100）。\n主角 B (MySQL)：位于 Linux 系统的另一个进程（假设 PID=200）。\n秘密通道 (UDS 文件)：MySQL 在启动时，会在硬盘上创建一个特殊文件，通常位于 /var/lib/mysql/mysql.sock（这个路径在 my.cnf 里配置）。\n配置上的不同（这是关键第一步）： 平时你连数据库，URL 写的是 jdbc:mysql://127.0.0.1:3306/...。 用 UDS 时，你的 JDBC URL 会变得很奇怪，大概长这样（取决于具体的驱动实现，通常需要引入 junixsocket 等库配合）：\nProperties\n1 2 # 意思就是：别走 TCP 了，帮我去连这个文件！ jdbc:mysql:///?socketFactory=org.newsclub.net.mysql.AFUNIXDatabaseSocketFactory\u0026amp;socket=/var/lib/mysql/mysql.sock 二、 详细连接流程（从发起请求到拿到数据） 假设你的 Controller 收到一个请求，要查 SELECT * FROM users。\n第一阶段：建立连接（握手） Java 发起系统调用：\nSpring Boot (JDBC 驱动) 解析 URL，发现要用 UDS。\n它不再调用 TCP 的 connect(ip, port)，而是调用针对文件的系统调用 socket(AF_UNIX, ...) 和 connect(\u0026quot;/var/lib/mysql/mysql.sock\u0026quot;)。\n操作系统（内核）介入：\n内核看到 Java 想连 /var/lib/mysql/mysql.sock。\n权限检查：内核检查运行 Java 进程的用户（比如 app_user）有没有对这个 sock 文件的读写权限。如果没有，直接报错 Permission denied。\n查找绑定：内核查看记录表，发现这个 sock 文件正被 PID=200 (MySQL) 监听（Listen）着。\n建立通道：\n内核在内存里，直接在 PID=100 (Java) 和 PID=200 (MySQL) 之间搭了一根“虚拟管子”。\n分配句柄：\n给 Java 进程发一个文件句柄（FD），比如 FD=8。\n给 MySQL 进程发一个文件句柄（FD），比如 FD=12。\n此时，连接建立完成。不需要 TCP 的三次握手（SYN, SYN-ACK, ACK），只有文件系统的查找开销。\n第二阶段：发送 SQL（写数据） Java 写数据：\nSpring Boot 把 SQL 语句 SELECT * FROM users 转成字节流。\n调用系统调用 write(FD=8, \u0026quot;SELECT...\u0026quot;)。\n内核搬运（最快的部分）：\n没有协议栈：内核不需要给数据包加 TCP 头、IP 头、不需要算校验和，也不需要路由查找。\n直接拷贝：内核直接把 Java 进程 发送缓冲区 里的数据，拷贝到 MySQL 进程的 接收缓冲区 里。\nMySQL 那个监听的 FD=12 变得“可读”。\nMySQL 读数据：\nMySQL 被唤醒，调用 read(FD=12)，拿到了 SQL 语句。 第三阶段：返回结果（读数据） MySQL 处理：\nMySQL 解析 SQL，查自己的 B+ 树，找到了 10 条用户数据。 MySQL 写回：\nMySQL 调用 write(FD=12, [用户数据])。 内核再次搬运：\n内核把数据直接从 MySQL 的内存搬运到 Java 的内存缓冲区。 Java 拿到结果：\nSpring Boot 从 read(FD=8) 中苏醒，拿到 ResultSet，封装成对象返回给 Controller。 如果用 TCP (127.0.0.1) 流程有啥区别？ 为了让你更直观地看到 UDS 省了啥，我们看看普通的 Localhost TCP 连接多了哪些步骤：\n打包：Java 把 SQL 加上 TCP 头（源端口、目标端口）、IP 头（源IP 127.0.0.1、目标IP 127.0.0.1）。\n计算：CPU 计算 TCP 校验和。\n路由：内核网络层查路由表，发现是回环地址（Loopback）。\n伪装发送：数据包虽然不出网卡，但要在内核的协议栈里走一圈“虚拟出网再入网”的流程（MTU检查、防火墙规则检查 iptables 等）。\n拆包：MySQL 端收到后，去掉 IP 头、去掉 TCP 头，校验数据的完整性。\n总结差异：\nTCP 方式：就像你写了一封信，虽然寄给同一个办公室的同事，但你还是把它扔进了楼下的邮局信箱。邮局（内核网络栈）盖戳、分拣、再投递回同一个办公室。\nUDS 方式：你直接站起来，把信放在了同事的桌子上。\nRedis把数据从内核内存区拷贝到用户内存的过程 详细流程图解（从 Socket 到 Redis） 假设一个客户端发来了 GET user:1。\n第一步：数据到达内核 网卡接收到光信号/电信号，转成数据包。\nDMA (直接内存访问) 把数据包拷贝到内核的内存（Socket 接收缓冲区）。\n内核检查这根 Socket 对应的句柄（FD），发现 Redis 之前通过 epoll_ctl 关注了它的“可读事件”。\n内核动作：把这个 FD 加入到 就绪链表 (Ready List) 中。\n第二步：Redis 醒来 Redis 主线程一直在跑一个死循环（aeMain）。\n循环里调用了 epoll_wait。\n刚才数据一到，epoll_wait 立刻返回，告诉 Redis：“嘿，FD=5 是可读的！”\n第三步：读取与执行 Redis 根据 FD=5，找到对应的处理函数（通常是 readQueryFromClient）。\n系统调用 read：把数据从内核搬运到 Redis 的用户态 Buffer。\n协议解析：解析 RESP 协议，知道你要执行 GET。\n查字典：在内存的 HashMap 里找到 user:1 的值。\n准备回复：把结果写入到客户端对象的发送缓冲区。\n第四步：回复客户端 如果发送缓冲区很小，Redis 直接当场就调用 write 发回去了。\n如果发送缓冲区满了（或者内核的写缓冲区满了），Redis 会向 epoll 注册一个 “写事件”。\n等下次内核告诉 Redis “这个 Socket 可以写了”，Redis 再继续把剩下的数据发完。\n操作系统的IO多路复用select，poll，epoll poll和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。\nepoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过epoll_ctl0 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是O(logn)。而 select/poll 内核里没有类似 epol 红黑树这种保存所有待检测的 socket 的数据结构，所以select/pol 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。\nepoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait0 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。\n我们来看一个最经典的场景：Redis 怎么把数据发给客户端？ 假设 Redis 要发送字符串 \u0026quot;Hello\u0026quot;。\n1. 物理位置 字符串 \u0026ldquo;Hello\u0026rdquo;：一开始在 Redis 的用户内存里。\nSocket 对象：在操作系统的内核内存里。\n2. 发送过程 (write) Redis 调用 write(fd, \u0026quot;Hello\u0026quot;) 系统调用。\n步骤 A：跨界拷贝（CPU Copy） CPU 暂停 Redis 的用户态运行，切换到内核态。 CPU 把 \u0026ldquo;Hello\u0026rdquo; 从 Redis 的用户内存 复制到 Socket 的发送缓冲区（内核内存）。 注意：这时候数据其实还在内存里，没出去呢！\n步骤 B：DMA 拷贝 操作系统看“发送缓冲区”里有货了，就命令 网卡（硬件）： “喂，把这块内存里的数据拿走发出去。” 网卡的 DMA 控制器直接把数据从内核内存搬运到网卡硬件上，然后变成电信号发走。\n3. 接收过程 (read) 客户端发来了一条命令 \u0026quot;GET\u0026quot;。\n步骤 A：硬件接收 网卡收到电信号，转成数据包，通过 DMA 搬运到 Socket 的接收缓冲区（内核内存）。 此时，Redis 还不知道数据来了。\n步骤 B：通知与唤醒 (Epoll) 内核发现这个 Socket 的接收缓冲区有数据了，于是通过 Epoll 告诉 Redis：“FD=5 有读事件了！”\n步骤 C：跨界拷贝（CPU Copy） Redis 醒来，调用 read(fd)。 CPU 把数据从 Socket 的接收缓冲区（内核内存） 复制到 Redis 的用户内存。 现在，Redis 终于可以在自己的变量里看到 \u0026quot;GET\u0026quot; 这三个字母了。\n内核内存和Socket是什么？ 内核内存 (Kernel Memory) —— “皇宫禁地” 在 Linux 操作系统中，物理内存（RAM）被逻辑上划分为两块：\n用户空间 (User Space)：\n谁在住？ 你的 Java 程序、Chrome 浏览器、QQ 等所有应用程序。\n地位：平民百姓。权力有限，想干大事（读硬盘、发网络包）必须打报告（系统调用）。\n特点：如果你的 Java 程序崩了，只是这块地盘乱了，不会影响整个电脑。\n内核空间 (Kernel Space) / 内核内存：\n谁在住？ 操作系统内核（Linux Kernel）、硬件驱动程序。\n地位：皇宫禁地（VIP）。拥有最高权限，可以随意操作 CPU、硬盘、网卡。\n特点：Socket 就存放在这里！ 还有页表、进程表等核心数据。如果这里崩了，电脑直接蓝屏或重启。\n为什么要有“内核内存”？ 主要是为了安全和隔离。防止你写了一个只有 bug 的代码，直接把操作系统的核心数据给改了，导致系统瘫痪。\nSocket 是什么？—— “插座与缓冲区” “Socket” 翻译过来叫“插座”或“套接字”。 但这个翻译太抽象了。在内核内存的视角里，Socket 到底是什么？\n本质上，Socket 就是内核内存里的两个缓冲区（Buffer）结构体。\n当你用 Java new Socket() 创建一个连接时，内核会在内核内存里划出一小块地盘，专门维护这个连接。这块地盘里主要包含两部分：\n接收缓冲区 (Recv Buffer)：\n像一个收件箱。\n网卡收到网线传来的数据，会先扔进这个箱子，等着你的 Java 程序来取。\n发送缓冲区 (Send Buffer)：\n像一个发件箱。\n你的 Java 程序想发数据，先把数据扔进这个箱子，然后由操作系统择机发给网卡。\n传统的Java17，是用户级线程和内核级线程一对一处理 在 Java 19（虚拟线程/协程）普及之前，Java 17 及更早版本，采用的确实是经典的 1:1 线程模型。\n这意味着：每一个 Java 线程（User Thread），在底层都死死绑定着一个操作系统的内核线程（Kernel Thread）。\n一、 核心关系：傀儡与真身 在 1:1 模型中，Java 线程和内核线程的关系，就像是 “皮影戏的傀儡” 和 “幕后的操纵者”。\nJava 线程 (User Thread)：\n这是你在代码里 new Thread() 创建出来的对象。\n它只是一个傀儡（皮影）。它有名字、有属性（ID、Priority），但它自己是没有生命的，动不起来。\n它生活在 JVM 的堆内存 里（用户态）。\n内核线程 (Kernel Thread / KLT)：\n这是操作系统（Linux/Windows）真正创建出来的工人。\n它是幕后的操纵者。只有它才能被 CPU 调度，只有它才有资格进 CPU 干活。\n它生活在 内核空间 里。\n所谓 1:1 映射：就是当你调用 thread.start() 时，JVM 会通过系统调用（System Call），向操作系统申请一个内核线程，然后把这个 Java 线程对象和那个内核线程**“绑死”**在一起。此后，这个 Java 线程的一举一动，其实都是那个内核线程在干活。\n二、 它们怎么“通信”？（控制权传递） 你问的“通信”，其实不是像发微信那样发消息，而是指令下达和状态同步。这一切都是通过 JNI (Java Native Interface) 和 系统调用 (System Call) 完成的。\n我们可以把这想象成牵线的过程。\n1. 启动指令：start() Java 层：你喊了一句 t1.start()。\n通信过程：\nJava 方法调用 private native void start0()。\n这就触碰到了 JVM 的 C++ 代码。\nJVM 向操作系统发起系统调用：clone() (Linux) 或 CreateThread (Windows)。\n操作系统：收到请求，创建一个真正的内核线程。\n绑定：JVM 把这个内核线程的 ID 记在 Java 线程对象里（建立了 1:1 关系）。\n2. 行为控制：sleep() / yield() / park() 场景：你在 Java 代码里写了 Thread.sleep(1000)。\n通信过程：\nJava 线程（傀儡）说：“我要睡一秒。”\nJVM 识别到这是个 Native 方法。\nJVM 发起系统调用，告诉内核：“喂，把你手里控制这个 Java 线程的那个内核线程挂起（Suspend）1秒。”\n操作系统：把对应的内核线程从 CPU 上也就是“运行队列”里拿下来，扔到“等待队列”里。\n结果：Java 线程看起来停了，其实是背后的内核线程停了。\n3. 阻塞同步：IO 操作 场景：你读取文件 fis.read()。\n通信过程：\nJava 代码执行到读取指令。\n因为读取硬盘是特权操作，Java 线程自己干不了，必须陷入内核态。\n对应的内核线程发起 IO 请求，然后被操作系统阻塞（因为它要等硬盘转圈圈）。\n反馈：内核线程不动了，Java 线程的状态也就变成了 BLOCKED 或 RUNNABLE (但在等待 syscall 返回)。\n三、 它们怎么调度？（谁说了算？） 这是最关键的：JVM 完全不管调度！JVM 是没有资格分配 CPU 时间片的。\n在 1:1 模型下，Java 线程的调度完全交给操作系统的调度器（Scheduler）。\n1. 调度者：OS 调度器（比如 Linux 的 CFS） JVM 就像一个劳务派遣公司，它把人（线程）招进来，交给政府（OS）去管理。至于谁先干活、谁后干活、干多久，全看政府的心情。\n2. 调度方式：抢占式 (Preemptive) 操作系统是个独裁者，它采用**“抢占式”**调度。\n时间片（Time Slice）：\nOS 给每个内核线程分配一小段 CPU 时间（比如 10ms - 100ms）。\n时间一到，CPU 内部的时钟中断响铃。\nOS 强行把当前线程踢下来（哪怕你代码还没跑完），换下一个线程上。\n上下文切换 (Context Switch) —— 昂贵的代价： 这就是 1:1 模型最大的痛点。当 OS 决定切换线程时：\n保存现场：把当前内核线程的寄存器值、程序计数器（跑到哪一行了）全部存回内存。\n刷新缓存：因为换人了，CPU L1/L2 缓存里的数据大部分都废了，需要重新加载。\n恢复现场：把下一个要运行的内核线程的信息读进寄存器。\n3. Java 优先级的尴尬 Java 里有 Thread.setPriority(1-10)。\n现实：这玩意儿基本是个心理安慰。\n原因：Java 的优先级只是给 OS 一个“建议”。由于不同操作系统对优先级的定义不同（Linux 甚至可能忽略它），JVM 传过去之后，OS 可能会说：“好的我知道了，但我还是按我的规则办。”\nsynchronized的底层原理 第一层：数据结构层 —— Mark Word 的比特位舞步 在 64 位 JVM 中，对象头（Object Header）里的 Mark Word 是 8 个字节（64 bit）。synchronized 的所有状态流转，本质上就是在修改这 64 个 bit。\n我们需要关注最后 2 位（锁标志位）和倒数第 3 位（偏向锁位）：\n锁状态 25 bit (未使用) 31 bit (HashCode) 1 bit (未用) 4 bit (分代年龄) 1 bit (偏向锁位) 2 bit (锁标志位) 无锁 \u0026hellip; HashCode 0 age 0 01 偏向锁 ThreadID (54bit) Epoch (2bit) \u0026hellip; age 1 01 轻量级锁 指向栈中 Lock Record 的指针 (62bit) \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 00 重量级锁 指向互斥量（Monitor）的指针 (62bit) \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 10 GC 标记 \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 11 底层细节：\n当锁是 轻量级锁 (00) 时，前 62 位不再存 HashCode，而是存一个内存地址指针，指向持有锁线程的栈帧。\n当锁是 重量级锁 (10) 时，前 62 位指向堆内存中 C++ 定义的 ObjectMonitor 对象。\n第二层：栈帧层 —— Lock Record (锁记录) 在轻量级锁阶段，JVM 并不想直接请求操作系统，它玩了一个“偷梁换柱”的把戏。\n开辟空间：当代码进入 synchronized 块，如果当前是无锁状态，JVM 会在当前线程的栈帧中创建一个名为 Lock Record 的空间。\nDisplaced Mark Word：JVM 把对象头里原本的 Mark Word 拷贝一份到这个 Lock Record 中（为了保存原本的 HashCode 和分代年龄，等锁释放了还得还回去）。\nCAS 争抢：JVM 尝试用 CAS (Compare And Swap) 指令，将对象头里的 Mark Word 替换为指向 Lock Record 的指针。\n成功：对象头变成了“指针 + 00”，代表抢锁成功。\n失败：说明有竞争，或者已经锁了。JVM 会检查对象头的指针是不是指向我自己的栈？如果是，说明是重入锁，只需在栈里再放一个空的 Lock Record 记录重入次数即可。\n第三层：JVM 实现层 —— C++ 里的 ObjectMonitor 当竞争升级为重量级锁，JVM 会去堆中申请一个 C++ 对象：ObjectMonitor。\n在 OpenJDK 的 HotSpot 源码中 (src/share/vm/runtime/objectMonitor.hpp)，它的核心结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 class ObjectMonitor { ... void * volatile _owner; // 指向当前持有锁的线程 (The King) volatile jlong _recursions; // 锁的重入次数 volatile int _count; // 抢锁计数器 // 核心等待队列 ObjectWaiter * volatile _cxq; // (Contention Queue) 竞争队列，单向链表 ObjectWaiter * volatile _EntryList; // 等待队列，双向链表 (阻塞状态的线程) ObjectWaiter * volatile _WaitSet; // 等待集合 (调用wait()后的线程) ... } 底层竞争流程（硬核版）：\nCAS 抢占：线程尝试通过 CAS 将 _owner 指针指向自己。成功则执行。\n自旋失败，入队：如果抢不到，线程被封装成 ObjectWaiter 对象。\n进入 cxq：线程首先通过 CAS 尝试把节点插入 _cxq 队列的头部（LIFO 策略，为了减少尾部维护开销）。\nOnDeck 机制：JVM 不会把所有人都唤醒，而是通过策略挑选一个继承人（Heir），称为 OnDeck，只有这个线程会去竞争锁，避免“惊群效应”。\n第四层：操作系统与硬件层 —— Futex 与 内存屏障 这是最底下的地基，也是为什么重量级锁慢的原因。\n1. 操作系统：Mutex 与 Futex 当线程在 ObjectMonitor 里抢不到锁，需要“阻塞（Block）”时，JVM 会调用操作系统的内核函数。\nLinux 环境下：\n早期：直接用 pthread_mutex_lock，这需要从用户态（User Mode）切换到内核态（Kernel Mode）。这个切换涉及到保存 CPU 寄存器上下文、刷新 CPU 缓存（L1/L2 Cache 失效）等，开销极大。\n现代优化 (Futex)：Linux 提供了 futex (Fast Userspace muTEX)。\n它先在用户态尝试通过 CAS 修改一个整数。\n只有当 CAS 失败（确实有竞争），才会调用系统调用（System Call）陷入内核态去执行 sem_wait 让线程挂起。\npark()：Java 中的 LockSupport.park() 底层就是调用了 futex 相关的系统调用。\n2. CPU 硬件：内存语义 (JMM) synchronized 不仅仅是锁，它还保证了 内存可见性。\nLock (monitorenter)：\n底层会插入一个 LoadBarrier（或类似的刷新指令）。\n强制让当前线程的工作内存（CPU Cache）失效，必须从主内存重新读取变量。\nUnlock (monitorexit)：\n底层会插入一个 StoreBarrier（写屏障）。\n强制将工作内存中的最新修改立即刷新回主内存，确保别的线程能看到。\n确保每次都能读到业务的最新的缓存信息，比如剩余票数还剩1个，把之前获取锁之前获取到的2给删了，重新更新为最新值，然后在把剩余票数变为0个。\n总结：一条线程的“黑化”之路 如果一个 Java 线程去抢 synchronized：\nCPU 指令层：先尝试 CAS 修改对象头。\n栈帧层：如果失败，检查是否是自己锁的（重入），或者尝试把 Mark Word 复制到自己栈帧（轻量级锁）。\nC++ 对象层：还失败？去堆里找 ObjectMonitor，把自己包装成 ObjectWaiter 节点，拼命往 _cxq 队列头挤。\nOS 内核层：挤不进去？调用 futex 系统调用，请求操作系统把自己挂起（Sleep），交出 CPU 时间片，从用户态跌落内核态，等待被唤醒。\n介绍一下Java里的volatile volatile 是 Java 虚拟机（JVM）提供的一种轻量级的同步机制。在并发编程中，它通常被用来修饰变量。\n理解 volatile，核心要抓住这三大特性：可见性、有序性，以及它不保证原子性。\n以下是详细的拆解：\n1. 核心特性 A. 保证可见性 (Visibility) 这是 volatile 最主要的作用。\n问题背景： 在 Java 内存模型 (JMM) 中，每个线程都有自己的工作内存 (Working Memory，对应 CPU 缓存)，变量存储在主内存 (Main Memory) 中。线程操作变量时，会先将变量从主内存拷贝到自己的工作内存中。如果线程 A 修改了变量，线程 B 可能还在读取自己缓存中的旧值，导致数据不一致。\nvolatile 的作用：\n当一个线程修改了 volatile 变量的值，新值会立即刷新到主内存。\n同时，会强制让其他线程工作内存中该变量的缓存失效。\n当其他线程需要读取该变量时，必须重新从主内存读取最新值。\nB. 禁止指令重排序 (Ordering) 问题背景： 为了提高性能，编译器和处理器通常会对指令进行重排序（即代码执行顺序可能与编写顺序不同），只要不影响单线程下的结果即可。但在多线程环境下，重排序可能导致严重的逻辑错误（例如：对象初始化了一半就被另一个线程使用了）。\nvolatile 的作用： JVM 会通过插入内存屏障 (Memory Barrier) 来禁止特定类型的指令重排序，从而保证有序性。\n经典案例： 单例模式的“双重检查锁”（Double-Checked Locking）。如果不加 volatile，可能导致拿到一个未完全初始化的对象。 C. 不保证原子性 (No Atomicity) 这是面试和开发中最大的坑。\n现象： volatile 不能替代 synchronized 或 Lock。\n例子： 对一个 volatile int count 执行 count++ 操作。\ncount++ 包含三个步骤：读值 -\u0026gt; 加 1 -\u0026gt; 写回。\n如果两个线程同时读到了 100，都加 1，然后都写回 101。最终结果是 101，而不是期望的 102。\n结论： 对于复合操作（Read-Modify-Write），volatile 无法保证线程安全。\n3. 什么时候使用 volatile？ 由于 volatile 比 synchronized 开销小（因为它不会引起线程上下文切换），在满足以下两个条件时，推荐使用：\n对变量的写操作不依赖于当前值（例如：不是 i++，而是 flag = true）。\n该变量没有包含在具有其他变量的不变式中。\n常见场景 1：状态标记量 (Flag) 用于控制线程停止或状态切换。\n1 2 3 4 5 6 7 8 9 10 11 volatile boolean shutdownRequested; public void shutdown() { shutdownRequested = true; } public void doWork() { while (!shutdownRequested) { // 执行业务逻辑 } } 常见场景 2：单例模式 (Double-Checked Locking) 这是 volatile 防重排最经典的应用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Singleton { // 必须加 volatile，防止指令重排导致 instance 指向未初始化的内存 private volatile static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); // new 操作并非原子，分为3步： // 1. 分配内存 // 2. 初始化对象 // 3. 将 instance 指向内存地址 // 若发生重排(1-\u0026gt;3-\u0026gt;2)，其他线程可能拿到非空的但未初始化的对象。 } } } return instance; } } 4. 总结：volatile vs synchronized 特性 volatile synchronized 可见性 保证 保证 有序性 保证 保证 原子性 不保证 保证 线程阻塞 不会阻塞线程 会阻塞线程 适用范围 仅变量 方法、代码块 性能 较高 (轻量级) 较低 (重量级，尽管已有优化) 一句话总结： volatile 是 Java 提供的轻量级同步机制，它主要用于保证多线程下的变量可见性和禁止指令重排，但它不能保证原子性，因此不能完全替代锁。\n它保证的“顺序”：禁止内部瞎优化（指令重排） CPU 和编译器为了快，有时候会把你写的代码顺序打乱（只要单线程下逻辑通顺就行）。\nVolatile 的作用： 告诉 CPU，“这行代码很关键，别给我乱动位置”。\n例子：\n你写的是：步骤1 -\u0026gt; 步骤2 -\u0026gt; volatile写\nCPU 不允许优化成：volatile写 -\u0026gt; 步骤1 -\u0026gt; 步骤2\n这就是你说的“保证代码执行顺序不改变”。\n2. 它无法改变的“并发”：无法阻止外部线程的“插队” 这正是你后半句说的重点。volatile 不是锁。\n没有排他性： 它不能像 synchronized 那样让线程排队（Serial Execution）。\n现象： 线程 A 和线程 B 可以同时去修改这个 volatile 变量。\n后果： 如果操作不是原子的（比如 i++），大家还是会“撞车”。\n讲解Java的ThreadLocal ThreadLocal 是 Java 中一个非常重要且高频面试的并发工具类。它的核心思想是 “空间换时间”，为每个线程提供独立的变量副本，从而实现线程隔离。\n以下我将从核心概念、应用场景、底层原理（源码级别）、内存泄漏问题以及最佳实践五个维度为你详细讲解。\n1. 核心概念 ThreadLocal（线程局部变量）提供了线程本地变量。当你在代码中创建一个 ThreadLocal 变量时，访问这个变量的每个线程都会拥有一个独立的、自己的本地副本。\n它的作用： 它是为了解决多线程并发访问共享变量时的线程安全问题，但它不是通过加锁（synchronized）来实现的，而是通过让每个线程自己玩自己的，互不干扰。\n比喻：\nsynchronized 就像只有一个厕所，大家需要排队（锁），同一时间只能一个人用。\nThreadLocal 就像给每个人发了一个专用的移动厕所，大家互不影响，不需要排队。\n2. 核心应用场景 ThreadLocal 主要有两个经典的使用场景：\n线程隔离（每个线程需要一个独享的对象）：\n典型案例： SimpleDateFormat。它是线程不安全的，如果把它定义为 static 并在多线程中共用，会报错。\n解法： 使用 ThreadLocal 为每个线程创建一个单独的 SimpleDateFormat 副本。\n案例： 数据库连接（Connection）、Session 管理。\n上下文传递（跨方法传递参数）：\n场景： 在一个 Web 请求中，从 Controller -\u0026gt; Service -\u0026gt; DAO，我们需要传递用户信息（User ID）。\n问题： 如果每个方法都加一个 userId 参数，代码会非常臃肿。\n解法： 在拦截器处将 User ID 存入 ThreadLocal，后续任何地方都可以直接取出来使用，无需层层传参。\n3. 底层原理（重点：ThreadLocalMap） 这是理解 ThreadLocal 的关键。很多人误以为 ThreadLocal 内部维护了一个 Map，Key 是线程，Value 是值。其实恰恰相反。\n3.1 真实的存储结构 Thread 类中： 每个 Thread 对象内部维护了一个成员变量 threadLocals。\nJava\n1 2 // Thread.java 源码片段 ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap： 这是一个类似于 HashMap 的结构，但它是 ThreadLocal 的静态内部类。\nKey 和 Value：\nKey： 是当前的 ThreadLocal 对象实例本身（而且是弱引用，WeakReference）。\nValue： 是我们 set 进去的具体值。\n3.2 引用关系图 1 2 3 4 5 6 Thread (当前线程) └── threadLocals (ThreadLocalMap) └── Entry[] (数组) └── Entry (继承自 WeakReference) ├── Key (弱引用) ──\u0026gt; ThreadLocal 实例 └── Value (强引用) ──\u0026gt; 具体对象 (如 Connection) 结论： 数据其实是存放在线程对象（Thread）自己的堆内存里的，ThreadLocal 仅仅是一个访问入口（Key）。\n3.3 Hash 冲突解决 与 HashMap 使用链表法/红黑树不同，ThreadLocalMap 使用的是 线性探测法 (Linear Probing)。\n如果计算出的槽位（slot）已经被占用了，它就往后找下一个空位存放。\n这也意味着 ThreadLocal 不适合存储极其大量的数据，否则检索效率会下降。\n4. 著名的内存泄漏问题 这是 ThreadLocal 最致命的坑，也是面试必问点。\n4.1 为什么会泄漏？ ThreadLocalMap 的 Entry 对 Key（ThreadLocal） 是弱引用，但对 Value 是强引用。\nKey 被回收： 如果外界没有 ThreadLocal 的强引用了，在下一次 GC 时，Key 会被回收，Entry 中的 Key 变成了 null。\nValue 还在： 但是，Value 是强引用，只要 Current Thread 还在运行（比如线程池中的核心线程，生命周期很长），这个 Value 就会一直存在于内存中，无法被回收。\n结果： 出现了一条 Current Thread -\u0026gt; ThreadLocalMap -\u0026gt; Entry -\u0026gt; Value 的强引用链，导致 Value 占用的内存无法释放，形成内存泄漏。\n4.2 各种补救措施（探测式清理） Java 的设计者也想到了这点。ThreadLocalMap 在调用 set()、get()、remove() 方法时，会顺便检查 Key 为 null 的 Entry，并将对应的 Value 清除。\n4.3 终极解决方案 必须在使用完后，手动调用 remove() 方法。\n5. 最佳实践代码示例 无论是在 Spring 的拦截器中，还是日常开发，请务必遵循 try-finally 模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class UserContext { // 1. 定义 ThreadLocal，通常建议配合 static final 修饰 private static final ThreadLocal\u0026lt;UserInfo\u0026gt; userHolder = new ThreadLocal\u0026lt;\u0026gt;(); // 2. 设置值 public static void setUser(UserInfo user) { userHolder.set(user); } // 3. 获取值 public static UserInfo getUser() { return userHolder.get(); } // 4. 清除值 (至关重要) public static void remove() { userHolder.remove(); } } // 业务使用伪代码 public void doBusiness() { try { UserContext.setUser(new UserInfo(\u0026#34;Gemini\u0026#34;, 1)); // 执行业务逻辑... serviceLayer.process(); } finally { // 5. 必须在 finally 中清除，防止内存泄漏和线程复用导致的数据污染 UserContext.remove(); } } 6. 父子线程传递 (InheritableThreadLocal) 普通的 ThreadLocal 无法在子线程中获取父线程设置的值。如果需要传递，可以使用 InheritableThreadLocal。\n原理： 在创建子线程（Thread 构造函数）时，会自动把父线程的 inheritableThreadLocals Map 中的数据复制一份给子线程。\n注意： 仅限创建时复制，后续父线程修改，子线程不可见（拷贝的是引用）。\n总结 用途： 线程隔离（每个线程一份）和 上下文传递（透传参数）。\n原理： 每个 Thread 内部维护一个 ThreadLocalMap，Key 是 ThreadLocal 实例本身。\n坑：\n内存泄漏： 弱引用 Key 导致 Value 滞留。\n数据污染： 线程池复用线程时，如果没清理，下一个任务会读到上一个任务的数据。\n铁律： 用完必须 remove()。\n如果不主动区remove()，那么这个threadLocal内部的key-value就会在下一次调用这个线程的时候访问到，产生内存泄漏。\n","date":"2025-11-25T11:43:54+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1/%E5%9C%BA%E6%99%AF2.0/","title":"面试八股/场景2.0"},{"content":"面试题总结 HashMap的底层原理 Hashap 是基于哈希表的数据结构，用于存储键值对(key-value )。其核心是将键的哈希值映射到数组索引位置，通过数组 +链表(在 Java 8 及之后是数组 +链表 +红黑树)来处理哈希冲突。\nHashmap 的默认初始容量为 16，负载因子为 0.75。也就是说，当存储的元素数量超过16x0.75=12个时， Hashmap 会触 发扩容操作，容量x2并重新分配元素位置。这种扩容是比较耗时的操作，频繁扩容会影响性能。\nHashMap 的红黑树优化: 从Java8开始，为了优化当多个元素映射到同一个哈希桶(即发生哈希冲突)时的查找性能，当链表长度超过8时，链表会转变为红黑树。红黑树是一种自平衡二叉搜索树，能够将最坏情况下的査找复杂度从 O(n) 降低到 O(log n)。如果树中元素的数量低于 6，红黑树会转换回链表，以减少不必要的树操作开销。\nhashCode()和 equals()的重要性: HashMp 的键必须实现 hashcode()和 equals()方法。 hashcode()用于计算哈希值，以决定键的存储位置，而 equals()用于比较两个键是否相同。在 put 操作时，如果两个键的 hashcode()相同，但 equals()返回 false，则这两个键会被视为不同的键，存储在同一个桶的不同位置。\n经典的“哈希冲突”案例 在 Java 中，最著名的例子就是字符串 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot;。\nJava\n1 2 3 4 5 6 String s1 = \u0026#34;Aa\u0026#34;; String s2 = \u0026#34;BB\u0026#34;; System.out.println(s1.hashCode()); // 输出 2112 System.out.println(s2.hashCode()); // 输出 2112 System.out.println(s1.equals(s2)); // 输出 false 发生了什么？\nJava 字符串的哈希算法是 s[0]*31 + s[1]：\n'A' 是 65，'a' 是 97 \\rightarrow 65 \\times 31 + 97 = 2112\n'B' 是 66 \\rightarrow 66 \\times 31 + 66 = 2112\n虽然算出来的数字一样，但显然 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot; 是完全不同的字符串。\nHashMap成环 由于线程1已经指向了B和A，线程2却先一步执行了扩容操作，而停止循环的条件就是e.next为null，当执行完扩容后，线程1苏醒，此时e为B，e.next为A，当前e的next指向A，导致A与B之间产生死循环，颠倒后依旧产生连接，就形成了环。\nJDK1.7HashMap多线程死循环问题_哔哩哔哩_bilibili\nSynchronized 和 ReentrantLock有什么区别? 实现层面 synchronized：\n是 Java 的关键字，属于 JVM 层面的实现。 ReentrantLock：\n是 JDK 提供的一个类（java.util.concurrent.locks.ReentrantLock），属于 API 层面的实现。 锁的释放 synchronized：\n自动释放。代码执行完同步代码块，或者抛出异常时，JVM 会自动释放锁，不会导致死锁。 ReentrantLock：\n手动释放。必须手动调用 unlock() 方法。 锁的公平性 synchronized：\n只能是非公平锁。线程获取锁的顺序是不确定的，可能发生“饥饿”现象。 ReentrantLock：\n默认是非公平锁（性能更好）。\n可以通过构造函数 new ReentrantLock(true) 指定为公平锁（遵循先来后到原则），但性能会下降。\n等待可中断 synchronized：\n不可中断。如果一个线程正在等待获取锁，它不能被中断（interrupt），只能一直阻塞等待。 ReentrantLock：\n可中断。通过 lockInterruptibly() 方法，可以让正在等待锁的线程响应中断，放弃等待去处理其他事情。 尝试获取锁 synchronized：\n不行。要么拿到锁，要么阻塞死等。 ReentrantLock：\n提供 tryLock() 方法。可以尝试获取锁，如果锁被占用，可以选择立即返回 false 或者等待一段指定的时间，非常灵活。 特性 synchronized（隐式锁） ReentrantLock（显式锁） 实现方式 关键字 (JVM 层面) 类 (JDK API 层面) 锁的释放 隐式自动释放 显式手动释放 (需在 finally 中 unlock) 公平性 非公平 默认非公平，可设置为公平 响应中断 不支持 支持 (lockInterruptibly) 条件队列 单个 (wait/notify) 多个 (Condition) 尝试获取 不支持 (死等) 支持 (tryLock) 灵活性 低 高 锁升级 锁升级流程图解 锁状态 触发条件 优点 缺点 偏向锁 只有一个线程反复加锁 加锁/解锁几乎零消耗 如果存在线程竞争，撤销偏向锁会有额外开销 轻量级锁 线程交替执行，无同时竞争 不会阻塞线程，利用 CAS 和自旋，响应速度快 如果始终得不到锁，自旋会空耗 CPU 重量级锁 发生长时间或多线程同时竞争 不会空耗 CPU，未获锁线程进入阻塞 线程阻塞/唤醒涉及上下文切换，开销大，较慢 CAS与自旋 什么是CAS（乐观锁） 你看到原句是“Hello”（A）。\n你想改成“Hi”（B）。\n在你提交修改的一瞬间，系统检查文档当前还是不是“Hello”（V）。\n如果是，修改成功。\n如果文档已经被别人改成了“Hello World”，你的预期（A）和实际（V）不符，提交失败，你需要重新读取再尝试。\nCAS 的三大问题 ABA 问题（最著名的坑）：\n虽然 V 还是 A，但不代表它没变过。它可能经历了 A -\u0026gt; B -\u0026gt; A 的过程。\n比喻：桌上有一杯水（A），你离开了一会儿。回来时水还是满的（A），你以为没人动过。实际上可能有人喝光了（B），又给你倒满了（A）。虽然结果一样，但过程可能由于“杯子被用过”而产生副作用。\n解决：加版本号。变成 1A -\u0026gt; 2B -\u0026gt; 3A。Java 中的 AtomicStampedReference 就是干这个的。给提交结果加版本号\n只能保证一个变量的原子性：无法同时操作多个变量。\nCPU 开销大：这通常与“自旋”结合在一起，见下文。\n什么是 自旋 ？ 自旋是一种线程等待的策略。\n当线程抢不到锁（或 CAS 失败）时，它不放弃 CPU，不进入阻塞状态（不睡觉），而是执行一个空循环（Loop），不断地检查“锁释放了吗？”或者“我能重试 CAS 了吗？”。\n为什么要自旋？ 为了避免上下文切换的开销。\n阻塞/唤醒：线程挂起和恢复需要操作系统介入，保存和恢复现场，非常耗时（可能比执行代码本身还慢）。\n自旋：如果锁被占用的时间很短，我在门口转两圈（自旋）锁就释放了，这样比“回家睡觉再被电话叫醒”快得多。\n概念 作用 核心词 优缺点 CAS 实现原子更新 比较并交换 优点：非阻塞，性能好\n缺点：ABA 问题 自旋 等待锁的策略 循环重试 优点：避免上下文切换\n缺点：耗费 CPU SpringBean的生命周期 阶段一：创建与注入 (的基础) 1. 实例化 (Instantiation) 发生了什么： Spring 容器通过反射（Constructor.newInstance()）调用 Bean 的构造函数。\n状态： 此时对象已经在堆内存中存在了，但它只是一个“空壳子”，里面的属性（依赖）全是 null。\n类比： 刚买了一个毛坯房，房子建好了，但里面什么家具都没有。\n2. 属性赋值 (Populate Properties) 发生了什么： Spring 依据配置（XML 或 @Autowired、@Value），将依赖的对象或属性值注入到 Bean 中。\n状态： 对象内部的依赖已经填充完毕。\n类比： 装修工进场，把沙发（Service）、电视（Dao）都搬进了房子里。\n阶段二：容器感知 (Aware 接口回调) 3. Aware 接口回调 (Invoke Aware Interfaces) 发生了什么： 如果 Bean 实现了特定的 Aware 接口，Spring 会把容器内部的一些资源“告诉”这个 Bean。 阶段三：初始化与增强 (最关键的步骤) 所谓的“初始化阶段”，就是 Spring 给你一个机会，在“属性都装好了”之后，但在“给别人使用”之前，让你执行一段自己的业务代码（比如连数据库、加载缓存、校验配置）。\nSpring AOP（默认机制）使用的是 动态代理（Dynamic Proxy）。它的逻辑是委托（Delegation）。\n原本的流程：\n调用者 \\rightarrow 目标对象（Target）\nSpring AOP 的流程：\n调用者 \\rightarrow 代理对象（Proxy） \\rightarrow 执行增强代码（Before） \\rightarrow 调用目标对象 \\rightarrow 执行增强代码（After） \\rightarrow 返回\n特性 Spring AOP AspectJ（静态代理） 原理 动态代理 (Proxy) 字节码织入 (Bytecode Weaving) 修改方式 运行时生成新类包裹目标 编译期/加载期直接修改目标类字节码 是否需要接口 JDK模式需要，CGLIB不需要 不需要 性能 稍慢（有反射和代理调用的开销） 极快（就是普通的方法调用） 能力范围 只能拦截 public 方法 的调用 无所不能：可拦截 private 方法、静态方法、构造函数、字段访问等 内部调用(this) 失效 有效 (完美解决自调用问题) 复杂度 低（Spring Boot 开箱即用） 高（需要配置编译器或 JVM Agent） Redis和Memcached的区别 特性 Memcached Redis 数据结构 单一 (仅支持 String/二进制块) 丰富 (String, List, Hash, Set, ZSet, Bitmap, HyperLogLog, Stream, Geo) 线程模型 多线程 (Multi-threaded) 单线程 (主逻辑) + I/O 多线程 (Redis 6.0+) 持久化 不支持 (重启后数据丢失) 支持 (RDB 快照 \u0026amp; AOF 日志) 分布式支持 客户端实现 (服务端互不通信) 服务端支持 (Redis Cluster, Sentinel) 内存管理 Slab Allocation (预分配，无碎片，但在非均匀大小数据下有浪费) jemalloc/libc (按需分配，利用率高，但可能有内存碎片) 功能丰富度 仅缓存 Lua 脚本、发布/订阅 (Pub/Sub)、事务、Pipeline 最大值限制 Value 最大 1MB Value 最大 512MB A. 数据类型 (Data Types) —— 最大的区别 Memcached: 就像一个巨大的 Map\u0026lt;String, String\u0026gt;。如果你想存一个列表，必须先把列表序列化成 JSON 字符串存进去；取出来时，必须把整个字符串取出来反序列化，修改后再序列化存回去。这非常消耗网络带宽和 CPU。\nRedis: 就像一个瑞士军刀。你可以直接在服务端操作数据结构。\n例子： 你想给一个排行榜加分。\nRedis: ZINCRBY rank_list 10 \u0026quot;user_id\u0026quot; (直接在内存里改数值，极快)。\nMemcached: get -\u0026gt; 反序列化 -\u0026gt; value + 10 -\u0026gt; 序列化 -\u0026gt; set (并发下还需要加锁，否则数据不一致)。\nB. 线程模型 (Threading Model) —— 性能的分水岭 Redis (单线程为主):\nRedis 的核心操作（执行命令）是单线程的。\n优势： 没有线程切换开销，没有锁竞争（Lock-free），代码简单稳定。\n劣势： 无法利用多核 CPU 的优势（但在 6.0 版本引入了多线程 I/O 来处理网络读写，核心计算依然是单线程）。\nMemcached (多线程):\n它使用主线程监听端口，Worker 线程处理读写。\n优势： 可以轻松利用 64 核 CPU 的计算能力，在极高并发（数十万 QPS 以上）且 Value 很小 的场景下，吞吐量可能高于 Redis。\nC. 持久化 (Persistence) —— 数据安全性 Memcached: 把它当作一个易失性缓存。如果服务器断电或重启，所有缓存数据瞬间清空，数据库会瞬间面临巨大的“缓存击穿”压力。\nRedis: 支持持久化。\nRDB: 定期生成快照保存在磁盘。\nAOF: 记录每一条写命令。\n用途： 重启后可以自动恢复数据，甚至可以用来做主数据库使用。\nD. 分布式/集群 (Clustering) Memcached: 服务端是“傻瓜式”的，节点之间互不通信。分布式的逻辑完全由客户端（Client）控制（通常使用一致性哈希算法）。如果你加一台服务器，客户端需要重新计算哈希。\nRedis: 支持原生的 Redis Cluster。服务端之间会通信（Gossip 协议），支持自动分片、故障转移（Failover）。\n内核内存 vs. 用户内存 (The Two Worlds) 操作系统（如 Linux）为了安全和稳定，把内存划分成了两个隔离的区域：\n1. 内核内存 (Kernel Memory / Kernel Space) 权限： 最高权限 (Ring 0)。CPU 可以执行任何指令，访问任何硬件地址。\n居住者： 操作系统内核代码、驱动程序（网卡驱动）、硬件缓冲区。\n特点： 如果这块区域的代码崩溃了，整个操作系统就蓝屏或死机了。它是神圣不可侵犯的。\n2. 用户内存 (User Memory / User Space) 权限： 受限权限 (Ring 3)。只能访问自己的内存空间，严禁直接访问硬件（不能直接读写网卡、硬盘）。\n居住者： 你运行的应用程序（Redis, Java JVM, 浏览器, QQ）。\n特点： 如果你的 Redis 崩了，只是这一个进程死掉，操作系统照样运行。\n核心矛盾： 网卡收到的数据首先必须存放在内核内存（因为它是由驱动程序管理的）。但是，你的 Redis 运行在用户内存。\n代价： 数据必须从“内核态”拷贝 (Copy) 到“用户态”，应用程序才能处理。这就是 Redis 6.0 引入多线程 I/O 想要优化的那个“搬运”过程。###\nSocket 是什么？ (The Abstraction) 很多初学者认为 Socket 就是“插座”或者“连接”。在操作系统层面，Socket 本质上是内核内存中的两个缓冲区（Buffer）。\n当你创建一个 Socket（比如 Java 的 new Socket() 或 Redis 监听的端口），内核会在内核内存里为你申请两块地：\n接收缓冲区 (Recv Buffer): 存放网卡发过来、等待你读取的数据。\n发送缓冲区 (Send Buffer): 存放你写进去、等待网卡发送的数据。\nSocket 就是应用程序（用户态）和网络协议栈（内核态）交互的句柄 (File Descriptor)。\nRedis数据的全生命周期流程 假设外网发来一个 TCP 包给 Redis（端口 6379），流程如下：\n1. 物理层：网卡收货 (NIC) 网线传来电信号，网卡将其转换为二进制数据。\nDMA (Direct Memory Access): 网卡不经过 CPU，直接利用 DMA 技术，把数据包写入到 内核内存 中的一块公用区域（通常叫 Ring Buffer）。\n此时，数据在内核，但还不知道属于哪个 Socket。\n2. 链路层 \u0026amp; 网络层：内核协议栈介入 网卡给 CPU 发送中断 (Interrupt)。\nCPU 停下手中的活，运行网卡驱动程序。\n驱动程序把数据包包装成内核的数据结构（Linux 下叫 sk_buff）。\n操作系统检查 IP 头：是发给本机的吗？是的。\n3. 传输层：分发给 Socket (Demultiplexing) 操作系统检查 TCP 头：目标端口是 6379。\n内核查找：“哪个 Socket 正在监听 6379 端口？” -\u0026gt; 找到了 Redis 的那个 Socket。\n关键动作： 内核把这个数据包（sk_buff）挂到该 Socket 的接收缓冲区 (Recv Buffer) 队列的尾部。\n此时，数据依然在内核内存中，但已经归属到了特定的 Socket 名下。\n4. 应用层：数据搬运 (Copy to User) Redis 主线程（或 I/O 线程）调用系统函数 read(socket_fd)。\nCPU 发生上下文切换： 从用户态切入内核态。\n内存拷贝： CPU 把数据从 内核内存（Socket 的接收缓冲区） 复制到 用户内存（Redis 定义的 buffer）。\nRedis 终于拿到了数据，开始解析处理 set name ...。\n那 Redis 6.0 的 I/O 线程到底解决了什么？ 既然都要经过内核拷贝，那用主线程调 write 和用 I/O 线程调 write 有什么区别？\n区别在于“谁在等”和“谁在分担开销”。\n场景：如果你只有主线程（Redis \u0026lt; 6.0） 主线程：“我要处理 10,000 个客户端的 get 请求。”\n对于每一个请求，主线程都要亲自调用 write。\n每次 write，主线程都要经历：用户态-\u0026gt;内核态切换 (耗时) + CPU 搬运数据 (耗时) + 内核态-\u0026gt;用户态切换 (耗时)。\n结果： 主线程大量时间花在和内核打交道、等待搬运上，导致它处理命令（KV 读写）的时间变少了。\n场景：你有 I/O 线程（Redis 6.0+） 主线程：“我要处理 10,000 个请求。算出结果后，我不亲自发了。”\n主线程把结果扔给 4 个 I/O 线程，说：“你们去调 write 发给客户。”\n主线程立刻转头去处理下一个命令的计算（KV 读写）。\nI/O 线程们 并行地去调用 write，去承担上下文切换和 CPU 搬运数据的开销。\n结果： 主线程被解放了，只专注于纯内存计算，吞吐量大增。\n内核线程，内核级线程，用户级线程 用户级线程是怎么“骗”过内核的？（M:N 模型） 用户级线程通过一个**中间层（Runtime/Scheduler）**来实现。\nM 个用户级线程（比如 1000 个 Goroutine）。\nN 个内核级线程（通常等于 CPU 核数，比如 8 个）。\n映射关系：\n这 8 个内核线程是“干活的苦力”。\n这 1000 个协程是“待办的任务”。\nGo 语言的运行时（Runtime）负责把这 1000 个任务，源源不断地塞给这 8 个苦力去做。\n如果一个任务（协程）卡在 I/O 上了，Runtime 把它拿开，换一个新任务给苦力，苦力（内核线程）永远不休息，也永远不阻塞。\n我们可以把计算机系统看作一家大型工厂（操作系统）：\n内核线程 (Kernel Thread): 工厂的内部设施维护人员（只在核心区工作，不生产对外产品）。\n内核级线程 (Kernel-Level Thread, KLT): 工厂正式聘用的流水线工人（有工牌，受人事部直接管理）。\n用户级线程 (User-Level Thread, ULT): 包工头带来的临时工/外包团队（人事部不知道他们的存在，只知道包工头）。\n一、 详细拆解：三者的定义与区别 1. 内核线程 (Kernel Thread / kthread) 这是最底层的存在，它们完全运行在内核空间（Ring 0）。\n定义： 它是操作系统内核用来执行后台任务的线程。它没有用户地址空间（不映射用户内存），只能访问内核代码和数据。\n谁创建/管理： 操作系统内核。\n能干啥：\n将内存中的脏页刷写到磁盘（如 Linux 的 kflush 或 pdflush）。\n处理软中断和网络包（如 ksoftirqd）。\n执行磁盘 I/O 调度。\n特点： 也就是我们常说的“纯内核线程”。你在 Linux 用 ps -ef 看到的那些名字带中括号 [kthreadd]、[migration] 的进程，就是它们。\n与用户程序的关系： 完全没关系。它们不运行你的 Java 或 Redis 代码，它们只服务于 OS 本身。\n2. 内核级线程 (Kernel-Level Thread, KLT) 这是我们日常开发中最常接触的概念（虽然你可能没意识到）。 在 Linux 中，它们通常被称为 轻量级进程 (LWP, Light Weight Process)。\n定义： 这是一个由内核管理、但用于执行用户态代码的执行实体。它是**“用户进程”在内核眼里的分身**。\n谁创建/管理： 操作系统内核调度器（如 CFS）。\n能干啥： 执行你的 main() 函数，执行 Redis 的主逻辑，执行 Java 的线程。\n特点：\n拥有双重身份： 既有内核栈（陷入内核时用），也有用户栈（运行程序时用）。\n可被独立调度： 操作系统知道它的存在，可以将它分配给任意 CPU 核心。\n高开销： 创建、销毁、切换都需要系统调用，涉及内核态/用户态切换，成本较高（微秒级）。\n代表： Java 的 java.lang.Thread (在 Linux 上)，C++ 的 std::thread，Redis 的主线程和 I/O 线程。\n3. 用户级线程 (User-Level Thread, ULT) 也叫协程、纤程、Green Thread。\n定义： 完全在用户空间实现的线程机制。内核完全不知道它们的存在，内核只看到承载它们的那个 KLT。\n谁创建/管理： 编程语言的运行时（Runtime）或库（如 Go Runtime, JVM）。\n能干啥： 处理高并发逻辑，阻塞式写法的异步执行。\n特点：\n极轻量： 切换只涉及寄存器保存，无需陷入内核，纳秒级。\n不可独立调度： 操作系统无法直接把一个 ULT 分配给 CPU，必须依附于一个 KLT 才能运行。\n代表： Go 的 Goroutine, Python 的 Gevent, Java 21 的 Virtual Thread。\n二、 它们之间的映射模型 (The Mapping Models) 弄清楚关系的关键，在于理解用户级线程 (ULT) 和 内核级线程 (KLT) 是如何搭配工作的。这主要有三种模型：\n1. 多对一模型 (M : 1) —— 上古时代的产物 描述： 多个用户级线程（M）跑在 1 个内核级线程（1）上。\n例子： 老版本的 Python 异步库，某些老旧的 JVM 实现（Green Threads）。\n缺点： 没有并行能力。因为底层只有一个 KLT，所以一次只能用 1 个 CPU 核。如果其中一个 ULT 阻塞了（比如发起系统调用），底层的 KLT 就阻塞了，其他所有 M 个 ULT 全都卡死。\n2. 一对一模型 (1 : 1) —— 现代主流 (Redis, Nginx, Java) 描述： 1 个用户级线程（逻辑上的线程）直接对应 1 个内核级线程。\n机制： 当你在 Java 里 new Thread()，操作系统就在底层真的创建一个 KLT（LWP）。\n优点： 真正的并行。一个线程阻塞，不影响其他线程。实现简单，直接依赖 OS 调度。\n缺点： 线程太贵，开不了一百万个。\n现状： Redis 的主线程和 I/O 线程，Java 目前默认的线程模型，都是 1:1。 所谓的“用户线程”此时只是 KLT 的一个句柄。\n3. 多对多模型 (M : N) —— 高并发的未来 (Go,Java21 Virtual Threads) 描述： M 个用户级线程（协程）动态映射到 N 个内核级线程上。\n机制：\nRuntime 维护一个线程池（N 个 KLT）。\nRuntime 维护一个任务队列（M 个 ULT）。\nRuntime 负责把 ULT 喂给 KLT 执行。如果一个 ULT 阻塞了，Runtime 把它拿下来，换另一个 ULT 上去。\n优点： 既有 ULT 的轻量（可以开百万个），又有 KLT 的并行（利用多核 CPU）。\n现状： Go 语言之所以火，就是因为它的调度器（G-M-P 模型）把这个做到了极致。\n三、 总结与对比表 特性 内核线程 (Kernel Thread) 内核级线程 (KLT / LWP) 用户级线程 (ULT / Coroutine) 可见性 仅内核可见 内核可见，用户可见 仅用户程序可见 (内核不可见) 内存空间 仅内核空间 用户空间 + 内核空间 仅用户空间 调度者 OS 调度器 OS 调度器 语言运行时 (Runtime) 切换开销 小 (无需切换地址空间) 中 (需切入内核态) 极小 (纯用户态操作) 并行性 利用多核 利用多核 依赖于底层的 KLT 阻塞影响 - 线程阻塞，释放 CPU 给别人 协程阻塞，Runtime 切换其他协程 典型例子 ksoftirqd, kworker java.lang.Thread, Redis 线程 Go Goroutine, Java Virtual Thread 一般什么情况下需要陷入内核态？ 简单来说，“陷入内核态”（Trap into Kernel Mode） 也就是 CPU 从 特权级 3 (User Ring 3) 切换到 特权级 0 (Kernel Ring 0) 的过程。\n一般情况下，陷入内核态主要有且仅有三种场景：\n1. 系统调用 (System Call) —— 主动请求 这是最常见的情况。当你的程序需要做一些自己权限不够的事情时，必须主动向操作系统“打报告”。\n因为用户程序不能直接操作硬件（硬盘、网卡、声卡）或管理内存，必须通过特定的接口（System Call Interface）请求内核代劳。\n硬件 I/O 操作：\n读写文件： read(), write(), open()（Redis 写日志、读数据库）。\n网络通信： socket(), connect(), send(), recv()（Redis 处理请求）。\n屏幕输出： printf()（底层调用 write 输出到标准输出）。\n进程控制：\n创建进程： fork(), exec()（Redis 做 RDB 快照时会 fork 子进程）。\n退出程序： exit()。\n内存管理：\n申请内存： malloc() 在堆内存不够时，底层会调用 brk() 或 mmap() 向内核要内存。 比喻： 你要去银行取钱（操作硬件资源），你不能自己冲进金库拿，必须填单子（系统调用），交给柜员（内核），柜员帮你拿出来给你。\n2. 异常 (Exception) —— 内部错误或特殊事件 这是由 CPU 在执行指令时，内部检测到的意外情况。程序“闯祸了”或者遇到了“特殊指令”。\n缺页异常 (Page Fault)：\n当你访问一块内存地址，CPU 发现这块数据不在物理内存里（可能被换到了磁盘 swap 分区，或者刚申请还没分配物理页），CPU 会暂停程序，陷入内核。内核负责把数据从磁盘加载到内存，然后恢复程序运行。 程序错误：\n除以零： 代码里写了 100 / 0。\n非法内存访问 (Segfault)： 试图访问不属于你的内存地址（比如空指针解引用）。\n内核捕获这些错误后，通常会杀死进程（就是你看到的 Segmentation fault）。\n调试断点：\n当你用 GDB 调试代码打断点时，实际上是插入了一条特殊指令（如 x86 的 INT 3）。CPU 执行到这里会自动陷入内核，暂停程序，把控制权交给调试器。 比喻： 你在家里（用户态）做饭，突然锅炸了（除以零）或者你想进邻居家里（非法内存访问），这时候警察（内核）会立刻破门而入处理状况。\n3. 硬件中断 (Hardware Interrupt) —— 被动打断 这是来自 CPU 外部的信号。无论你的程序正在干什么，只要硬件中断来了，CPU 必须无条件停下手头的工作，切到内核态去处理中断。\n时钟中断 (Clock Interrupt)：\n最重要！ 这是多任务操作系统的基石。\n硬件时钟每隔几毫秒就会发一次中断。内核收到中断后，会看：“Redis，你的时间片用完了，该让给 Nginx 跑一会儿了。”\n这就是为什么死循环的程序不会把电脑彻底卡死，因为内核会强行通过时钟中断夺回控制权。\nI/O 完成中断：\n网卡： “新数据包到了！”（内核把数据拷贝到 Socket 缓冲区）。\n硬盘： “刚才你要读的数据我已经读完放到内存了！”\n键盘/鼠标输入：\n你按下一个键，键盘控制器发送中断，CPU 陷入内核读取按键码。 比喻： 你正在家里专心打游戏（用户态运行代码），突然快递员狂按门铃（网卡中断），或者你的闹钟响了（时钟中断），你必须停下游戏去开门或者关闹钟（陷入内核处理）。\n触发方式 来源 例子 主动/被动 系统调用 程序代码 read(), fork(), sleep() 主动 (程序自己写的) 异常 CPU 内部 缺页、除零、Segfault 被动 (通常是闯祸了) 硬件中断 CPU 外部 网卡收包、时钟滴答、键盘 被动 (外部环境强制) Redis单线程避免上下文切换的开销 1. 什么是“昂贵”的上下文切换？ 首先，我们要明确，为什么切换线程很贵？\n当 CPU 从 线程 A 切换到 线程 B 时，不仅仅是“换个人干活”这么简单，它涉及两个巨大的成本：\n直接成本 (CPU 寄存器重置)：\nCPU 需要把线程 A 的“现场”（程序计数器 PC、堆栈指针 SP、通用寄存器等）保存到内存里。\n然后从内存里把线程 B 的“现场”恢复到寄存器里。\n这本身需要花费几微秒 ($\\mu s$)。\n间接成本 (Cache 失效 —— 这才是真正的杀手)：\nCPU 有 L1/L2/L3 高速缓存。线程 A 跑得正欢的时候，缓存Cache里全是线程 A 需要的数据（热数据）。\n突然切到线程 B，线程 B 要用的数据不在缓存里（Cache Miss）。\nCPU 被迫去慢如蜗牛的内存（RAM）里拿数据。\n这会导致 CPU 的执行效率瞬间暴跌。\n2. 多线程模式的痛点 (The \u0026ldquo;Context Switch Storm\u0026rdquo;) 假设 Redis 是传统的多线程模型（比如像早期的 Tomcat 或 MySQL）：\n场景： 来了 1000 个请求。\n处理： 系统开启 1000 个线程（或者用线程池）。\n锁竞争： 线程 A 要修改 Key \u0026ldquo;user:1\u0026rdquo;，线程 B 也要修改。线程 B 抢不到锁，被迫挂起 (Block)。\n自愿切换 (Voluntary Context Switch)：\n因为抢不到锁，或者等待磁盘 I/O，线程 B 主动告诉操作系统：“我干不下去了，把 CPU 让给别人吧。”\n操作系统进行上下文切换。\n结果： 在高并发下，CPU 把大量的时间花在** “保存现场、恢复现场、调度线程、等待锁” **上，真正用来执行 set name gemini 这行代码的时间反而被挤压了。\n3. Redis 的单线程魔法 (The \u0026ldquo;Run-to-Completion\u0026rdquo;) Redis 的主处理逻辑（Command Execution）是单线程的，这意味着：\nA. 彻底消灭“锁竞争” 因为只有我一个人（主线程）在动数据，所以我根本不需要锁（Lock-free）。\n没有锁，就不会出现“因为抢不到锁而挂起”的情况。\n不存在“挂起”，就没有“自愿上下文切换”。\n结果： Redis 主线程是一路狂奔的，它处理完一个请求，马上处理下一个，中间没有任何停顿。\nB. 极致的 Cache 亲和性 (Cache Affinity) 因为始终是这同一个线程在这一颗 CPU 核心上跑。\nRedis 的核心数据结构（dict, ziplist, skiplist）和代码指令，会一直停留在 CPU 的 L1/L2 缓存里。\nCache Hit 率极高。\n这就像一个熟练工人在自己的工位上干活，所有工具都在手边（L1 Cache），闭着眼睛都能拿到。\nC. I/O 多路复用 (Epoll) —— 避免 I/O 阻塞 你可能会问：“那如果读 Socket 数据的时候，数据还没来怎么办？线程不就阻塞了吗？”\nRedis 使用 epoll (Linux)。\n机制： Redis 告诉内核：“这一万个 Socket 你帮我盯着，谁有数据来了你告诉我。”\n非阻塞： Redis 主线程永远不会在某个 Socket 上死等（Block）。它只处理那些“已经准备好数据”的 Socket。\n所以，Redis 永远不会因为 I/O 等待而发生上下文切换。\n4. 总结对比：多线程 vs 单线程 我们可以用去银行办事来比喻：\n模式 场景比喻 上下文切换情况 效率 多线程模型 10 个窗口，10 个柜员。 所有的柜员都要抢同一个账本（锁）来记账。抢不到的柜员就去喝茶（切换）。柜员之间换班还要交接工作（保存现场）。 极高 (锁竞争、线程调度) 低 (大量时间花在抢锁和交接上) Redis 单线程 1 个超级柜员 (Flash)。 只有他一个人，账本就在手边（Cache）。他动作极快，处理完张三马上处理李四，不用跟任何人抢账本，也不用交接班。 极低 (几乎为 0，除非时间片用完) 极高 (CPU 100% 用在干活上) 5. 什么时候 Redis 还是会切换？ 虽然 Redis 尽力避免切换，但被动切换 (Involuntary Context Switch) 是无法避免的，因为操作系统才是老大。\n时间片用完 (Time Slice): 操作系统采用了分时调度。给 Redis 的 10ms 用完了，不管你活干没干完，OS 必须强行把 CPU 抢走给别的进程（比如 SSH、系统日志）用一下。 Redis 单线程避免上下文切换的核心在于：它通过“非阻塞 I/O”和“单线程串行执行”，消灭了代码层面的“锁”和“等待”，从而让 CPU 始终处于全速运算的高效状态。\nRedis写数据全生命周期 假设有一个 Java 客户端，发送了一条命令 SET user:1 \u0026quot;Alice\u0026quot;。\n第一阶段：请求到达与分发 (进 - I/O 阶段) 客户端发送：\n外部的 Java 客户端（用户级线程）发起 TCP 连接，将命令 SET user:1 \u0026quot;Alice\u0026quot; 转换成 Redis 协议（RESP），通过网线发送出去。\n数据到达 Redis 服务器的网卡，进入操作系统的内核 Socket 缓冲区。\n主线程感知 (epoll)：\nRedis 的主线程正在运行事件循环（Event Loop），通过 epoll_wait 监听到这个 Socket 有数据来了（可读事件）。 任务分发 (Distribute)：\n关键点：主线程不亲自去读数据。\n主线程把这个 Socket 连接分配给一组 I/O 线程（IO Thread Pool） 中的某一个。\nI/O 线程并行读取与解析：\n多线程并行：被选中的 I/O 线程（内核级线程）发起系统调用 read()，从内核缓冲区把数据搬运到用户态。\n协议解析：I/O 线程解析数据流，识别出这是一条 SET 命令，参数是 user:1 和 Alice。\n注意：此时主线程会短暂等待，直到所有分配出去的 I/O 任务都完成读取和解析。\n第二阶段：命令执行 (做 - 执行阶段) 主线程串行执行 (Execute)：\n所有 I/O 线程都解析完后，汇报给主线程。\n单线程独占：主线程按照队列顺序，串行地拿到解析好的命令。\n内存操作：主线程在内存的 HashMap 中找到 user:1 这个槽位，填入 \u0026quot;Alice\u0026quot;。\n原子性：因为只有主线程在动这个 Map，所以绝对安全，不需要加锁。\n生成结果：\n执行成功，主线程生成响应结果 +OK。\n主线程把这个结果写入到该客户端的用户态输出缓冲区中。\n第三阶段：响应返回 (出 - I/O 阶段) 任务再次分发：\n主线程依然不亲自把数据发回网卡。\n它再次把“写回数据”的任务分配给 I/O 线程。\nI/O 线程并行回写：\nI/O 线程并行地调用 write() 系统调用，把缓冲区里的 +OK 发送给内核 Socket 缓冲区。\n内核负责通过网卡把数据发回给 Java 客户端。\n第四阶段：持久化 (存 - 后台阶段) 这部分是异步发生的，不影响给客户端返回结果的速度。\n触发持久化：\nAOF：主线程刚才执行完 SET 后，顺手把这条命令写到了内核缓冲区（Page Cache）。\n后台线程 (BIO)：稍后（如每秒）醒来，调用 fsync 把内核缓冲区的数据刷到物理磁盘。 RDB：如果满足了触发条件（如 1 分钟改了 1 万次）。\n主线程：调用 fork 生成子进程。\n子进程：默默地在后台把内存里的 user:1 等所有数据写成 RDB 文件。\nKafka为什么比RocketMQ快 参照物：传统 I/O (Standard I/O) 假设你要把磁盘上的一个文件通过网卡发给消费者（比如读取日志发送）。 代码通常是：read(file, buffer) -\u0026gt; write(socket, buffer)。\n这中间发生了 4 次拷贝 + 4 次上下文切换：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区（Read Buffer）。\nCPU 拷贝：内核缓冲区 -\u0026gt; 用户态缓冲区（数据进来了）。\nCPU 拷贝：用户态缓冲区 -\u0026gt; 内核 Socket 缓冲区（数据又出去了）。\nDMA 拷贝：Socket 缓冲区 -\u0026gt; 网卡。\n痛点：数据在内核和用户态之间反复横跳，CPU 忙着搬运数据，没空干别的。\nKafka 的绝技：sendfile (数据管道) Kafka 在发送消息给消费者时，调用了 Java 的 FileChannel.transferTo()，底层就是 Linux 的 sendfile 系统调用。\n核心机制 sendfile 告诉内核：“把这个文件里的数据，直接发给那个 Socket，不要经过我的手（用户态）。”\n流程（2 次拷贝 + 2 次切换）：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区 (Page Cache)。\nCPU/DMA 拷贝：\n早期 Linux：内核缓冲区 -\u0026gt; Socket 缓冲区。\n现代 Linux (DMA Gather Copy)：内核缓冲区 -\u0026gt; 直接给网卡（只把描述符给 Socket，真正做到了 CPU 0 拷贝）。\n这里的零拷贝指的是零CPU拷贝。\nRocketMQ 的绝技：mmap (内存映射) RocketMQ 选择了 mmap（Memory Mapped Files），在 Java 中对应 MappedByteBuffer。\n核心机制 mmap 告诉内核：“把磁盘上的这个文件，映射到我的虚拟内存地址里来。”\n流程：\n建立映射：用户态的一个虚拟地址指针，直接指向内核的 Page Cache。\n读写数据：\nRocketMQ 读取这个指针，就像读内存数组一样简单。\n操作系统负责在后台利用 DMA 把磁盘数据加载到 Page Cache（缺页中断机制）。\n发送数据：RocketMQ 读取这块“内存”，然后 write 给 Socket。\n这里依然需要一次 CPU 拷贝（从映射内存拷贝到 Socket 缓冲区）。 特性 Kafka (sendfile) RocketMQ (mmap) 数据路径 磁盘 -\u0026gt; 内核 -\u0026gt; 网卡 磁盘 -\u0026gt; 内核 -\u0026gt; 用户态 -\u0026gt; 内核 -\u0026gt; 网卡 CPU 参与度 极低 (几乎不参与拷贝) 中等 (需要一次 CPU 拷贝) 用户态可见性 不可见 (黑盒传输) 可见 (可读、可修改) 适用场景 海量数据流式传输 (只管发，不处理) 复杂业务消息 (需要过滤 Tag、事务回查等) Java API FileChannel.transferTo() MappedByteBuffer 限制 无法对内容进行逻辑处理 文件不能太大 (RocketMQ 限制 1GB) Kafka 之所以吞吐量宇宙第一，是因为它放弃了对消息细节的掌控，直接用 sendfile 当了一个“甩手掌柜”，把数据直接丢给网卡。\nRocketMQ 之所以功能强大（支持 Tag 过滤、复杂的事务状态），是因为它用了 mmap，保留了对数据的访问权，虽然牺牲了一点点传输性能，但换来了业务灵活性。\n一句话概括：Kafka 是为了“运货”而生，RocketMQ 是为了“验货”而生。\nPage Cache 是 Linux 内核为了掩盖磁盘龟速而用闲置内存做的“障眼法”。\n为什么RPC/HTTP2能比HTTP1.1快那么多 简单来说，HTTP/1.1 像是单车道，而 HTTP/2 + RPC 像是多车道高速公路，且路上跑的都是压缩后的跑车而不是臃肿的大卡车。\n以下是具体的技术核心差异：\n1. 多路复用 (Multiplexing) —— 解决核心痛点 这是 HTTP/2 相比 HTTP/1.1 最大的性能提升点，解决了“队头阻塞”（Head-of-Line Blocking）问题。\nHTTP/1.1 的问题：\n在同一个 TCP 连接中，请求是串行的。浏览器/客户端必须等上一个请求响应回来，才能发下一个。如果第一个请求处理很慢（比如数据库卡了），后面的所有请求都会被堵住。\n补救措施： 浏览器通常会针对同一个域名建立 6 个 TCP 连接来并行传输，但这对服务器资源消耗很大。 HTTP/2 (RPC) 的方案：\n它引入了 流 (Stream) 和 帧 (Frame) 的概念。\n所有的请求和响应都共用同一个 TCP 连接。\n不同的请求被拆分成许多小的二进制“帧”，这些帧像洗牌一样混在一起传输，每一帧都有 ID 标识属于哪个请求。\n结果： 请求 A 的数据包不需要等请求 B 处理完就能发送。高并发下，吞吐量极高。\n2. 头部压缩 (HPACK) —— 节省带宽 在微服务架构中，RPC 调用非常频繁，HTTP 头部（Headers）占用的开销比你想象的要大。\nHTTP/1.1 的问题：\nHTTP 是无状态的，每次请求都会携带完整的 Header（如 User-Agent, Cookie, Accept 等）。这些全是纯文本，往往几百字节甚至上 KB。如果你的请求体（Body）只有几十字节，那传输的有效数据比例极低。\nHTTP/2 (RPC) 的方案：\n使用了 HPACK 算法。\n客户端和服务器共同维护一张动态表和静态表。\n如果发送过 User-Agent: Chrome，第二次只需要发送一个索引号（比如 1），服务器查表就知道是 User-Agent: Chrome。\n这使得 Header 的大小几乎可以忽略不计。\n3. 二进制分帧 (Binary Framing) —— 解析更快 计算机处理二进制数据远快于处理文本。\nHTTP/1.1 的问题：\n是文本协议。解析文本需要处理换行符、空格、大小写等，对于高并发服务器来说，解析 JSON 或 HTTP 报文会消耗大量的 CPU 资源。\nHTTP/2 (RPC) 的方案：\n是二进制协议。数据在传输层就已经被分割为更小的消息和帧，并采用二进制编码。机器解析起来非常高效，出错率低，且更紧凑。\n4. 序列化协议 (Serialization) —— RPC 的独门秘籍 这一条主要针对 RPC（如 gRPC 使用的 Protocol Buffers）对比传统的 RESTful (HTTP/1.1 + JSON)。\nHTTP/1.1 + JSON：\nJSON 是基于文本的，冗余度极高。比如 {\u0026ldquo;id\u0026rdquo;: 12345, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;user\u0026rdquo;}，你需要传输字段名 id 和 name。且 JSON 的解析（反序列化）非常耗 CPU。\nRPC (Protobuf)：\n使用 Protocol Buffers (Protobuf) 或 Thrift 等二进制序列化协议。\n体积小： 它是通过 ID 映射字段，不传输字段名，压缩后的体积通常只有 JSON 的 1/3 到 1/10。\n速度快： 二进制流直接映射到内存对象，序列化/反序列化速度比 JSON 快 5-10 倍。\n5. 服务端推送 (Server Push) 虽然在 RPC 场景下用得相对少，但 HTTP/2 允许服务器在客户端请求之前“主动”推送资源，减少了往返延迟（RTT）。\n总结对比 特性 HTTP/1.1 HTTP/2 (及 gRPC) 优势 传输格式 文本 (Text) 二进制 (Binary) 解析更快，体积更小 连接模型 串行 (Keep-Alive) 多路复用 (Multiplexing) 解决队头阻塞，极大提高并发 头部开销 巨大 (纯文本重复发送) HPACK 压缩 节省带宽 负载内容 通常是 JSON (大、慢) 通常是 Protobuf (小、快) 序列化性能提升明显 TCP 连接数 多个 (通常 6 个) 只需 1 个 降低服务器握手和资源开销 HeavyKeeper和LRU，LFU 可以将它们的关系理解为：LRU 和 LFU 是“怎么扔垃圾”，而 HeavyKeeper 是“怎么用极小的代价找出谁是大佬”。\n以下是详细的对比和原理解析：\n1. LRU (Least Recently Used) - 最近最少使用 核心逻辑： “如果数据最近被访问过，那么它将来被访问的几率也很大。”\n关注点： 时间（Recency）。\n工作原理：\n新数据或刚被访问的数据放到队头。\n缓存满时，直接淘汰队尾的数据（最久没被摸过的）。\n优点：\n实现简单（HashMap + 双向链表）。\n适应突发性流量（Burst Traffic），因为热点往往是临近的。\n缺点：\n缓存污染（Cache Pollution）： 如果进行一次全表扫描（读取大量数据但只用一次），会把原本的热点数据全部挤出缓存，导致缓存命中率急剧下降。 2. LFU (Least Frequently Used) - 最不经常使用 核心逻辑： “如果数据过去被访问多次，那么它将来被访问的几率也很大。”\n关注点： 频率（Frequency）。\n工作原理：\n为每个数据维护一个计数器。\n缓存满时，淘汰计数器数值最小的数据。\n优点：\n抗扫描能力强。偶尔的一次性批量读取不会挤掉长期积累的热点数据。\n对于长期稳定的热点数据，命中率极高。\n缺点：\n实现复杂且内存开销大： 需要维护所有数据的计数器，且排序复杂度较高。\n旧数据滞留（Dusty Cache）： 一个以前很热但现在没用的数据（比如上个月的爆款商品），因为计数器很高，会一直霸占缓存，如果不引入衰减机制，很难被淘汰。\n3. HeavyKeeper - 专门抓“大象”的守门员 核心逻辑： “我不追求 100% 精确，但我用极小的内存就能告诉你谁是真正的热点（Top-K）。”\n关注点： 极低内存下的频率预估。\n本质： 它不是一个完整的缓存系统，而是一个算法结构（通常基于 Count-Min Sketch 的改进）。它常被用于 Redis 的热点发现工具或现代缓存系统（如 Caffeine 库）的频率过滤器中。\n工作原理（指纹衰减）：\n它使用类似哈希表的结构，但存储的是指纹（Fingerprint）和计数。\n关键创新： 传统的 Sketch 算法在哈希冲突时会错误地增加计数（导致高估）。HeavyKeeper 引入了衰减机制——当新元素进入并发生哈希冲突时，如果指纹不匹配，它会以一定概率减少（Decay）原有的计数器。\n结果： “小鼠流”（低频数据）的计数会被不断衰减消灭，“大象流”（高频数据）因为访问足够多，能抵抗衰减并幸存下来。\n优点：\n内存占用极小： 相比 LFU 记录所有 key 的完整计数，HeavyKeeper 只需要很少的 bucket 就能大概率找准热点。\n误差可控： 专门为 Top-K 场景设计，对高频数据极其准确。\n总结对比表 特性 LRU (时间) LFU (频率) HeavyKeeper (概率频率) 全称 Least Recently Used Least Frequently Used HeavyKeeper 核心维度 最近访问时间 访问总次数 访问总次数 (概率性) 主要用途 缓存淘汰策略 缓存淘汰策略 热点检测 (Top-K) / 辅助 LFU 抗扫描能力 弱 (容易被冲刷) 强 强 空间开销 中 (存 Key + 链表指针) 大 (存 Key + 计数器) 极小 (哈希桶 + 指纹) 实现复杂度 低 ($O(1)$) 高 (需堆或多级链表) 中 (哈希 + 概率逻辑) 精准度 精确 精确 有误差 (但对热点准确) 典型应用 MySQL Buffer Pool (改进版), 操作系统页置换 传统缓存系统 Redis 热 key 发现, 网络流量分析 LRU代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 package com.lucius.interviewproject.LRU; import java.util.HashMap; public class LRUCache { // 定义双向链表节点 class DLinkedNode { int key; int value; DLinkedNode prev; DLinkedNode next; public DLinkedNode() {} public DLinkedNode(int _key, int _value) {key = _key; value = _value;} } // 核心数据结构 private HashMap\u0026lt;Integer, DLinkedNode\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); private int size; private int capacity; private DLinkedNode head, tail; // 伪头部和伪尾部节点 public LRUCache(int capacity) { this.size = 0; this.capacity = capacity; // 使用伪头部和伪尾部节点，避免处理复杂的 null 边界情况 head = new DLinkedNode(); tail = new DLinkedNode(); head.next = tail; tail.prev = head; } public int get(int key) { DLinkedNode node = cache.get(key); if (node == null) { return -1; } // 如果 key 存在，先通过哈希表定位，然后移动到链表头部 moveToHead(node); return node.value; } public void put(int key, int value) { DLinkedNode node = cache.get(key); if (node == null) { // 如果 key 不存在，创建一个新节点 DLinkedNode newNode = new DLinkedNode(key, value); // 添加进哈希表 cache.put(key, newNode); // 添加至双向链表的头部 addToHead(newNode); size++; // 如果超出容量，删除双向链表的尾部节点 if (size \u0026gt; capacity) { DLinkedNode tail = removeTail(); // 删除哈希表中对应的项 cache.remove(tail.key); size--; } } else { // 如果 key 存在，更新 value，并移动到头部 node.value = value; moveToHead(node); } } // --- 以下是辅助的链表操作方法 --- // 1. 将节点移动到头部 (也就是最近使用的位置) private void moveToHead(DLinkedNode node) { removeNode(node); addToHead(node); } // 2. 将节点插入到伪头部之后 private void addToHead(DLinkedNode node) { node.prev = head; node.next = head.next; head.next.prev = node; head.next = node; } // 3. 删除节点 private void removeNode(DLinkedNode node) { node.prev.next = node.next; node.next.prev = node.prev; } // 4. 删除尾部节点（淘汰最久未使用的） private DLinkedNode removeTail() { DLinkedNode res = tail.prev; removeNode(res); return res; } } Redis的大key的问题怎么解决 由于 Redis 是单线程模型，处理一个巨大的 Key（无论是读取、写入还是删除）都会占用主线程，导致后续请求排队等待，造成 \u0026ldquo;卡顿\u0026rdquo;。\n以下是系统化的解决思路，分为 发现、删除 和 治理（预防） 三个阶段。\n一、 什么是 Big Key？（标准定义） 通常根据 Value 的大小或元素数量来判定：\nString 类型： Value \u0026gt; 10KB（严格标准）或 1MB（宽松标准）。\n集合类型（Hash, List, Set, ZSet）： 元素个数 \u0026gt; 5000 或 10000 个。\n二、 如何发现 Big Key？ 在治理之前，首先要定位它们。\nredis-cli --bigkeys 命令：\nRedis 自带的工具，会扫描整个 Key 空间。\n缺点： 它是阻塞式的扫描（虽然用了 SCAN），在数据量巨大时可能会轻微影响性能，且只能返回每种类型最大的那个 Key，信息不全。\nMEMORY USAGE key 命令：\n如果你怀疑某个 Key 是大 Key，可以用这个命令查询其实际内存占用。 RDB 文件分析（推荐）：\n使用工具（如 rdb-tools 或 redis-rdb-tools）离线分析 RDB 备份文件。\n优点： 完全不影响线上 Redis 性能，生成的报告非常详细（包含 Key 名称、大小、类型）。\n监控告警：\n如果在云服务商（如阿里云、AWS）上，通常控制台会有 \u0026ldquo;大 Key 分析\u0026rdquo; 功能。\n监控网络带宽，如果网络流出流量瞬间飙升，通常是有客户端读取了大 Key。\n三、 如何安全地删除 Big Key？ 绝对禁止直接使用 DEL 命令删除大 Key！\nDEL 是同步阻塞操作，删除一个几百 MB 的 Key 可能会阻塞 Redis 几秒钟，导致故障转移或请求超时。\n1. Redis 4.0 及以上版本（推荐） 使用 UNLINK 命令代替 DEL。\n原理： UNLINK 只是将 Key 从元数据中解绑（逻辑删除），真正的内存回收操作会由后台线程（Lazy Free）异步执行，不会阻塞主线程。 2. Redis 4.0 以下版本（手动渐进式删除） 如果版本较老，必须手动分批删除，避免阻塞：\nHash: 使用 HSCAN 每次扫描一部分字段，然后用 HDEL 删除。\nList: 使用 LPOP/RPOP 或 LTRIM 分批删除。\nSet: 使用 SSCAN 扫描，SREM 删除。\nZSet: 使用 ZREMRANGEBYRANK 分批删除。\n四、 如何彻底解决（设计与预防）？ 删除只是治标，只有修改业务设计才能治本。\n1. 拆分（Split） 将一个大 Key 拆分为多个小 Key。\n场景： 一个 Hash 存储了 100 万个用户对象。\n方案： 使用 Hash 取模设计。例如定义 hash_0 到 hash_99 共100个 Bucket。\n存取时：id % 100 决定存入哪个 Key。\n这样每个 Key 的大小就只有原来的 1/100。\n2. 压缩（Compression） 对于 String 类型的长文本（如 JSON、XML），使用压缩算法。\n方案： 写入 Redis 前使用 Gzip、Snappy 或 Protobuf 进行压缩/序列化。通常能减少 50%-80% 的体积。 3. 剪裁与清洗（Pruning） 不要把 Redis 当数据库用，只存 \u0026ldquo;热点数据\u0026rdquo;。\n场景： 一个 List 存了用户的历史浏览记录，长达几万条。\n方案： 业务上只需要展示最近 100 条。在写入时维持定长队列（LTRIM），或者定期清理过期数据。\n4. 设置过期时间（TTL） 防止 \u0026ldquo;僵尸\u0026rdquo; 大 Key 长期占用内存。给 Key 设置合理的 TTL，让其自动过期删除（注意：Redis 的自动过期在 4.0 之前删除大 Key 也可能阻塞，4.0+ 配置 lazyfree-lazy-expire yes 可解）。 5. 存储转移（Offloading） 如果数据本身就是很大（例如图片二进制、长文章），且必须完整读取，那么它不适合存入 Redis。\n方案： 存入 S3、MongoDB 或 CDN，Redis 只存该数据的 URL 或索引 ID。\n总结对照表 策略 适用场景 关键手段 发现 线上排查 / 离线分析 redis-cli --bigkeys, RDB Tools 应急处理 此时此刻必须删除 UNLINK (异步删除) 架构优化 集合元素过多 拆分 (Sharding/Bucketing) 架构优化 文本 Value 过大 压缩 (Gzip/Snappy) 架构优化 无效数据堆积 定期清理 (LTRIM) / 设置 TTL Redis是怎么找到key存储在哪个节点上？ Redis 在集群模式（Redis Cluster）下，并不是直接把 Key 存到节点上的，而是引入了一个中间层：哈希槽 (Hash Slot)。\n简单来说，Redis 集群预分好了一万多个坑位（Slot），所有的 Key 都要先算一下自己该去哪个坑，而具体的节点（Node）只是负责管理这些坑位。\n以下是具体的寻址过程，分为 理论计算 和 客户端交互 两个层面。\n一、 核心算法：CRC16 + 取模 Redis Cluster 固定的将数据空间划分为 16384 个哈希槽（编号 0 ~ 16383）。\n当你要存储一个 Key（比如 set name lucius）时，Redis 会通过以下两步计算出这个 Key 属于哪个槽：\n计算哈希值：使用 CRC16 算法对 Key 进行计算，得到一个整数。\n取模运算：将得到的整数对 16384 取模。\n公式：\n$$ Slot = CRC16(key) \\pmod{16384} $$计算出 Slot 编号（比如 5000）后，Redis 只需要查看当前集群配置中，编号 5000 的槽是由哪个节点负责的，就能确定数据在哪个节点。\n二、 生动比喻：快递分拣中心 为了方便理解，我们可以把 Redis Cluster 想象成一个巨大的物流分拣系统：\n货物 (Key)：你要存的数据。\n快递筐 (Hash Slot)：系统里一共有 16384 个固定的筐子，编号 0-16383。\n货车 (Node)：实际负责运货的物理服务器（比如有 3 台服务器 A、B、C）。\n流程是这样的：\n分配规则：\n货车 A 负责运送 0 ~ 5500 号筐子。\n货车 B 负责运送 5501 ~ 11000 号筐子。\n货车 C 负责运送 11001 ~ 16383 号筐子。\n存货过程：\n来了一个包裹 name。\n系统算一下（CRC16），发现它应该进 5000 号筐子。\n查表发现 5000 号筐子归 货车 A 管。\n于是包裹被丢进货车 A。\n为什么要这么设计？\n如果因为业务繁忙，你要加一辆货车 D，你不需要把所有包裹重新拆包计算一遍。你只需要把 货车 A 上的一部分筐子（比如 0~1000号）搬到 货车 D 上即可。\n这就是 Redis Cluster 扩容方便的原因：数据迁移的单位是“槽”，而不是单个 Key。\n三、 客户端是怎么知道去哪个节点的？ 虽然服务器知道槽位映射关系，但**客户端（比如你的 Java 代码）**是怎么知道的呢？\n通常有两种情况：\n1. 笨客户端（每次都问，或问错了）—— MOVED 重定向错误 假设客户端不知道 Key name 在哪个节点，它随便连了一个节点（比如节点 B）发送命令：GET name。\n节点 B 收到命令，计算 CRC16('name') % 16384，发现属于 Slot 5000。\n节点 B 查自己的小本本，发现 Slot 5000 归 节点 A 管。\n节点 B 不会帮客户端去取数据（因为那是代理做的事），而是直接返回一个错误：\nMOVED 5000 192.168.1.100:6379\n(翻译：哥们你找错人了，这个 Key 归 5000 号槽管，那个槽在 IP 为 \u0026hellip; 的节点上，你自己去找它吧。)\n客户端收到报错，根据新地址，重新去连接节点 A。\n2. 聪明客户端（Smart Client，如 Jedis, Lettuce）—— 本地缓存 为了性能，现在的客户端（如 Java 的 Jedis、Lettuce）在启动时，会先连接集群，把 Slot -\u0026gt; Node 的映射表 下载下来缓存在本地内存里。\n你要 GET name。\nJava 客户端在本地算一下：Slot = 5000。\n查本地缓存：Slot 5000 -\u0026gt; 节点 A。\n直接连接节点 A 发送请求。\n这避免了额外的网络跳转，效率最高。\n四、 特殊情况：Hash Tag（强制特定 Key 去特定节点） 面试高频考点：\n由于 CRC16 算法是随机的，user:1001 和 order:1001 很大概率会被分到不同的节点上。\n这就导致一个问题：如果你想在一个事务（Multi/Exec）里同时操作这两个 Key，或者用 Lua 脚本同时处理它们，会报错！ 因为 Redis 要求事务或脚本涉及的所有 Key 必须在同一个节点上。\n解决方案：Hash Tag {}\n你可以在 Key 中使用花括号 {}。Redis 计算 Hash 时，如果发现 Key 里有 {}，就只计算 {} 内部字符串的 Hash 值。\nKey 1: user:{1001} -\u0026gt; 计算 CRC16(\u0026quot;1001\u0026quot;)\nKey 2: order:{1001} -\u0026gt; 计算 CRC16(\u0026quot;1001\u0026quot;)\n因为 {} 里的内容一样，算出来的 Slot 肯定一样，它们就一定会落到同一个节点上。\n没有 Hash Tag 之前，Redis 的分拣员（CRC16 算法）是非常老实的，它会把 Key 的每一个字符都算进去。\n1. 没有 Hash Tag（老实模式） 分拣员看到什么就算什么，全名参与计算。\nKey A: user:1001\n算法输入：\u0026quot;user:1001\u0026quot; (9 个字符)\n结果：哈希值 X $\\rightarrow$ 对应 Slot 500\nKey B: order:1001\n算法输入：\u0026quot;order:1001\u0026quot; (10 个字符)\n结果：哈希值 Y $\\rightarrow$ 对应 Slot 8000\n因为 \u0026quot;user:1001\u0026quot; 和 \u0026quot;order:1001\u0026quot; 是完全不同的两个字符串，算出来的结果自然千差万别，所以它们被分到了不同的节点。\n2. 有 Hash Tag（偷懒模式） 分拣员一旦看到 {}，就只算花括号里面的内容，外面的前缀后缀全当看不见。\nKey A: user:{1001}\n算法输入：\u0026quot;1001\u0026quot; (只算这 4 个数字)\n结果：哈希值 Z $\\rightarrow$ 对应 Slot 300\nKey B: order:{1001}\n算法输入：\u0026quot;1001\u0026quot; (还是只算这 4 个数字)\n结果：哈希值 Z $\\rightarrow$ 对应 Slot 300\n因为输入完全一样（都是 \u0026quot;1001\u0026quot;），所以算出来的 Slot 编号绝对一样，这两个 Key 就必定会去同一个节点“团聚”。\n小贴士（Hash Tag使用风险） 虽然 Hash Tag 很好用，但千万不要滥用。\n如果你把几百万个 Key 都加上同一个 Hash Tag（比如 user:{beijing}），那么这几百万个 Key 算出来的 Slot 全都一样，它们会全部挤到同一台机器上。\n后果： 这就导致了数据倾斜（Data Skew）—— 集群里的一台机器忙死（内存爆满、CPU 飙升），而其他机器闲死。\nMySQL三层B+树能存储多少数据? 但在通常的估算标准下（主键为 BigInt，单行数据约 1KB），三层 B+ 树大约能存储 2000 万（2000w）条数据。\n1. 核心预设条件 MySQL 的 InnoDB 存储引擎有以下几个默认属性，这是计算的基础：\n页大小 (Page Size)：默认是 16KB ($16384$ 字节)。\n指针大小：InnoDB 页指针为 6 字节。\n主键类型：通常假设为 BigInt (8 字节)。如果用 Int (4 字节)，存的更多。\n2. B+ 树结构拆解 B+ 树分为非叶子节点（存索引和指针）和叶子节点（存真实数据）。\n第一步：计算非叶子节点能存多少索引？ 非叶子节点不存数据，只存“主键 + 指针”。\n单个索引项大小 = 主键大小 (8B) + 指针大小 (6B) = 14 字节。\n单页可存索引数 = 页大小 / 索引项大小 = $16384 / 14 \\approx 1170$ 个。\n这意味着，一个非叶子节点可以指向 1170 个下级节点。\n第二步：计算叶子节点能存多少数据？ 叶子节点存储真实的行数据。这里变量最大的就是“一行数据的大小”。\n假设 1：一行数据大小为 1KB（比较常见的预设）。\n单页可存行数 = $16384 / 1024 = 16$ 条。\n3. 三层 B+ 树容量计算 结构如下：\n根节点（第1层）：非叶子节点，指向 1170 个第2层节点。\n分支节点（第2层）：非叶子节点，每个节点指向 1170 个叶子节点。总共有 $1170 \\times 1170$ 个叶子节点。\n叶子节点（第3层）：存数据。\n计算公式：\n$\\text{总记录数} = (\\text{根节点指针数}) \\times (\\text{第二层指针数}) \\times (\\text{叶子节点单页行数})$\n代入数值（行数据 1KB）：\n$1170 \\times 1170 \\times 16 \\approx \\mathbf{21,902,400}$\n结论 1： 如果一行数据是 1KB，三层能存约 2190 万 条数据。\n4. 如果数据行很小怎么办？ 有些表可能只有几个字段，一行数据可能只有 100 字节。如果不算页分裂等损耗：\n单页可存行数 = $16384 / 100 \\approx 160$ 条。\n总容量 = $1170 \\times 1170 \\times 160 \\approx \\mathbf{2.19 亿}$。\n结论 2： 数据行越小，三层 B+ 树能存的数据就越多，甚至能过亿。\n5. 现实中的误差（Fill Factor） 上面的计算是理论最大值（所有页都填满 100%）。但在实际运行中：\n页头页尾开销：每个页有 Header、Directory Slot 等元数据，大约占用几十到几百字节，不能全用来存数据。\n页填充率：InnoDB 不会把页填得满满当当，为了减少页分裂，通常填充率在 1/2 到 15/16 之间。如果频繁随机插入，页碎片化会导致填充率下降。\n如果按照 50%-75% 的利用率折算，通常认为三层树的舒适区确实就在 2000万 左右。一旦超过这个数量级，B+ 树可能分裂出第四层，导致磁盘 I/O 增加，查询性能轻微下降。\n事务的四大特性（ACID） 为了保证上述逻辑的严密性，数据库理论规定事务必须满足 ACID 四个特性，这经常在面试中被问到：\nA - 原子性 (Atomicity)：\n核心：要么全做，要么全不做。\n实现靠 Undo Log（回滚日志）。\nC - 一致性 (Consistency)：\n核心：事务前后，数据必须符合逻辑（比如转账前后，两人的钱加起来总数不变）。 I - 隔离性 (Isolation)：\n核心：多个事务并发执行时，互不干扰（这就是我们之前讨论的 RR、RC 隔离级别）。\n实现靠 锁 + MVCC。\nD - 持久性 (Durability)：\n核心：事务一旦提交，数据就是永久的，哪怕下一秒服务器爆炸，重启后数据依然在。\n实现靠 Redo Log（重做日志）。\nMySQL的事务隔离级别 并发事务的三大问题 脏读 (Dirty Read)：事务 A 读到了事务 B 未提交的数据。如果 B 回滚，A 读到的就是脏数据。\n不可重复读 (Non-repeatable Read)：事务 A 在同一个事务中两次读取同一行数据，结果不一样。这是因为在两次读取之间，事务 B 修改或删除了该数据并提交了。\n幻读 (Phantom Read)：事务 A 在同一个事务中两次查询同一个范围，第二次发现多了一些数据。这是因为在两次查询之间，事务 B 插入了新数据并提交了。\n四种隔离级别详解 按照隔离程度从低到高排序：\n1. 读未提交 (Read Uncommitted) 描述：这是最低的隔离级别。一个事务可以读取到另一个事务未提交的修改。\n现象：相当于“裸奔”，没有任何隔离。\n存在问题：脏读、不可重复读、幻读都会发生。\n应用场景：实际开发中极少使用。\n2. 读已提交 (Read Committed - RC) 描述：一个事务只能读取到已经提交的数据。\n实现原理：MVCC（多版本并发控制）。每次执行 SELECT 语句时，都会重新生成一个 Read View（一致性视图）。\n存在问题：解决了“脏读”，但可能发生“不可重复读”（因为每次 Select 都生成新视图，如果中间有人提交修改，你就能看到）。\n备注：这是大多数主流数据库（如 Oracle, PostgreSQL, SQL Server）的默认隔离级别，但不是 MySQL 的默认值。\n3. 可重复读 (Repeatable Read - RR) —— MySQL 默认 描述：确保在同一个事务中，多次读取同样的数据结果是一样的。\n实现原理：MVCC。与 RC 不同的是，RR 级别下，Read View 是在事务启动后的第一次查询时生成的，之后一直复用这个视图。\n存在问题：解决了“脏读”和“不可重复读”。\n关于幻读：在标准 SQL 定义中，RR 是无法解决幻读的。但是，MySQL 的 InnoDB 引擎通过 MVCC + Next-Key Lock 技术，在 RR 级别下很大程度上避免了幻读（正如我上一个回答所解释的）。\n4. 串行化 (Serializable) 描述：最高的隔离级别。它强制事务串行执行，通过强制对读取的数据行加锁（共享锁），避免了并发冲突。\n存在问题：解决了所有问题（脏读、不可重复读、幻读）。\n代价：并发性能极差，容易导致大量的超时和锁竞争。\n应用场景：只有在对数据一致性要求极高且并发量很小的场景下才会使用。\n隔离级别对比总结表 隔离级别 脏读 不可重复读 幻读 性能 备注 Read Uncommitted ✅ 可能 ✅ 可能 ✅ 可能 极高 极少使用 Read Committed (RC) ❌ 无 ✅ 可能 ✅ 可能 高 Oracle/PG 默认 Repeatable Read (RR) ❌ 无 ❌ 无 ❌ (大部分解决) 中 MySQL 默认 Serializable ❌ 无 ❌ 无 ❌ 无 低 强制排队，性能差 为什么可重复读的情况下不能避免幻读 数据在被修改（Update/Delete）的时候，必须基于“最新”的版本进行，而不能基于“历史”版本。\n时间点 事务 A 事务 B 现象/旁白 1 BEGIN; SELECT * FROM users WHERE id = 5; 结果：Empty (空) 事务 A 确认 id=5 还没人用。 2 BEGIN; INSERT INTO users (id, name) VALUES (5, '小明'); COMMIT; 事务 B 抢先插入了 id=5 并提交。 3 SELECT * FROM users WHERE id = 5; 结果：Empty (空) MVCC 生效。事务 A 依然看不到小明。一切看似正常。 4 UPDATE users SET name = '被修改' WHERE id = 5; 结果：Query OK, 1 row affected 关键点来了！ Update 是“当前读”，它能看到最新的提交。它不仅修改成功了，还把这条记录的“版本号”改成了事务 A 自己的。 5 SELECT * FROM users WHERE id = 5; 结果：id=5, name=\u0026lsquo;被修改\u0026rsquo; 【幻读发生】\n事务 A 吓死了：“我刚才查还没有 id=5，怎么我一更新，它就突然冒出来，还被我改了？” 注意，在第二步的时候，事务2已经插入并且提交了，这个时候数据库的内容发生了变化，后续步骤4进行update的时候就得根据最新的数据进行update，然后更新成功，并且，\n假设：\n事务 A 的 ID = 100。\n事务 B 的 ID = 200。\n幻读示例（自己修改或插入的数据，trx_id会变为自己的，可见） 阶段 1：事务 A 开启，生成 ReadView 事务 A 执行第一条 SELECT。\n生成 ReadView，记录当前活跃事务。此时系统里只有 A。\nReadView 只要生成了，在 RR 级别下就永远不会变了。\n阶段 2：事务 B 插入并提交 事务 B 插入 id=5。\n这行数据现在的状态是：{id: 5, name: '小明', trx_id: 200}。\n事务 B 提交。\n阶段 3：事务 A 第一次查询 id=5 事务 A 拿着 ReadView 来看这行数据。\n发现数据的 trx_id 是 200。\nReadView 判断：200 是在我（100）开启之后才进来的“将来的人”。\n结论：不可见。\n阶段 4：事务 A 执行 UPDATE（关键转折点！） 动作：UPDATE users SET name = '被修改' WHERE id = 5;\n当前读：正如之前所说，UPDATE 也是一种读，但它是“当前读”。它不看 ReadView，直接看物理磁盘。它看到了 trx_id=200 的数据（因为 B 已经提交，物理上存在）。\n修改数据：事务 A 把数据改了。\n打标签：这是最重要的一步！事务 A 把这行数据的 trx_id 更新成了自己的 ID（100）。\n现在的行数据变成了：{id: 5, name: '被修改', trx_id: 100}。\n阶段 5：事务 A 第二次查询 id=5 事务 A 再次执行 SELECT。\nReadView 变了吗？ 没有，还是那个旧的 ReadView。\n数据变了吗？ 变了。\n事务 A 再次检查可见性：\n这行数据的 trx_id 是多少？ -\u0026gt; 100。\n当前事务 A 的 ID 是多少？ -\u0026gt; 100。\n触发规则 1：trx_id 等于我自己。\n结论：可见！\n你之所以能看到，是因为你通过 UPDATE 操作，把这行数据的所有权**“抢”**过来了。\n修改前：这行数据属于事务 B（trx_id=200），对你是“未来数据”，不可见。\n修改后：这行数据属于事务 A（trx_id=100），对你是“自家数据”，无条件可见。\nReadView 到底存了什么？ 当你第一次执行 SELECT * FROM user 时，生成的 ReadView 是一张黑名单，长这样：\n1 2 3 4 5 { \u0026#34;m_ids\u0026#34;: [100, 101, 102], // 当前全数据库里，所有还没提交的事务 ID \u0026#34;min_trx_id\u0026#34;: 100, // 最小活跃 ID \u0026#34;max_trx_id\u0026#34;: 103 // 下一个要分配的 ID（水位线） } 请注意： 这个列表里完全没有提 user 表或 student 表的名字。它只规定了谁是老数据（可见），谁是活跃数据（不可见）。\n这个规则对全库所有表通用。\nMVCC简单的流程 事务在第一次select的时候会去检查当前活跃事务，然后会查看下一个要分配的事务id，然后记录下来，后面查询的时候会先去查询当前行数据的trx_id，查看数据的trx_id如果小于当前事务的id就应该直接使用这条数据，如果大于自己的事务id，就去查undo log，顺着undolog版本链找到真正自己能看到的数据，然后修改查询得到的数据。\nMySQL的锁 共享锁 在sql语句末尾加上for share代表共享锁，所有事务都可以读，但是不能修改，直至事务提交\n1 select * from uploaded_file where id = 1981221658045493248 for share; 排他锁 在sql语句末尾加上for update代表排他锁，其他事务不能修改，也不能读。\n1 select * from uploaded_file where id = 1981221658045493248 for update; 表锁 定义：最基本的锁策略，开销最小。它会锁定整张表。\n特点：\n无死锁：因为一次性获取所有需要的锁。\n并发度低：一个用户在写，其他用户都不能读写。\n适用场景：主要由 MyISAM 引擎使用；InnoDB 在特定情况下（如没有索引或手动指定 LOCK TABLES）也会用到，但通常尽量避免。\n意向锁 痛点：假设事务 A 锁住了表中的某一行（行锁），此时事务 B 想申请整个表的写锁（表锁）。事务 B 怎么知道表里有没有人正在改数据？它必须遍历每一行去检查，效率极低。\n定义：意向锁是表级锁。\n当事务 A 想要给某一行加锁时，必须先给表加一个“意向锁”。\n这就像在写字楼门口挂个牌子：“楼里有人（意向锁）”。\n作用：事务 B 看到门口有“意向锁”的牌子，就知道表里有人在忙，直接等待，不用进去逐个房间（行）检查了。它主要用于快速判断表锁和行锁的冲突。\n行锁 定义：InnoDB 的核心特性。只锁定被操作的那一行数据。\n特点：\n并发度高：多个人可以同时修改同一张表的不同行。\n开销大：需要加锁、解锁，且容易发生死锁。\n关键点：InnoDB 的行锁是加在索引上的。如果你查询时没有用到索引，InnoDB 会退化为锁定整张表（虽然实现机制上是把所有行都锁了），导致并发性能大跌。\n间隙锁 含义：只锁住两个记录之间的**“缝隙”**，不包含记录本身。\n锁住范围：(10, 20) —— 指的是大于 10 且小于 20 的范围。\n作用：纯粹是为了防止插入。别人不能在这个范围内 INSERT 任何数据（比如插 15）。但他如果要修改 id=20 这行数据，Gap Lock 是不管的。\nNext-Key Lock 假设数据库表中只有三行数据：id = 10, 20, 30。\n含义：锁住一段间隙 + 锁住间隙右边的那个记录。\n锁住范围：(10, 20] —— 左开右闭区间。\n组成：即锁住了 (10, 20) 这个缝隙，也锁住了 20 这个记录。\n作用：既不准你在缝隙里插数据（防幻读），也不准你修改右边那个记录。\n$Next\\text{-}Key \\ Lock = Gap \\ Lock + Record \\ Lock$\nMDL锁 定义：它不是用来锁数据的，而是用来锁**表结构（Schema）**的。\n触发机制（系统自动控制，用户无需显式调用）：\nMDL 读锁：当你对表进行增删改查（DML）时，自动加 MDL 读锁。\nMDL 写锁：当你对表结构进行修改（DDL，如 ALTER TABLE）时，自动加 MDL 写锁。\n互斥关系：\n读锁和读锁不互斥（大家可以一起查数据）。\n读写互斥、写写互斥。这意味着，如果有长事务正在查询数据（持有 MDL 读锁），你此时想给表加个字段（申请 MDL 写锁），会被阻塞。\n危险场景（MDL 风暴）：\nSession A 开启事务查数据（持有 MDL 读）。\nSession B 想加字段（申请 MDL 写，被阻塞）。\nSession C 及其后的所有查询（申请 MDL 读），因为写锁优先级通常高于读锁，或者写锁在排队，导致后续所有查询全部堵塞。\n结果：数据库线程瞬间爆满，导致宕机。\n索引下推是什么？ MySQL 处理 SQL 语句时，主要分为两层： Server 层（服务器层）： 负责解析 SQL、优化器生成执行计划、调用存储引擎接口、并处理最终的数据过滤（WHERE 条件判断）。\nStorage Engine 层（存储引擎层，如 InnoDB）： 负责真正的数据存储、提取，通过索引在磁盘上找数据。\n“下推”的意思是： 把原本只能在 Server 层做的事情，推给 存储引擎层去做。\n场景复盘 我们使用你的例子：\n表结构： user 表，有列 id (主键), name, age, address 等。\n索引： 联合索引 idx_name_age (name, age)。\nSQL：\nSQL\n1 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; AND age = 20; (注意：这里是 SELECT *，意味着必须回表拿到 address 等其他字段，不能仅靠覆盖索引)\n为什么这个场景特殊？ 根据最左前缀原则：\nname LIKE '王%' 是范围查询。索引能帮我们快速定位到所有姓“王”的人的起始位置。\n但是，一旦使用了范围查询（Range），索引后续的列（这里是 age）就无法用于定位（Seek）了。\n索引里的数据排序是：先按 name 排，name 相同才按 age 排。\n对于 王五 和 王六，他们的 age 是无序的（相对于整个“王%”区间），所以引擎必须扫描所有姓王的数据。\n虽然无法用来定位，但 age 的值确实存在于索引树的叶子节点中。ICP 的核心就在于是否利用了这个已有的数据。\n详细对比：无 ICP vs 有 ICP 假设数据库里有 4 条记录，索引结构 (name, age) 如下：\n(王五, 10) —— 主键 ID: 1\n(王六, 20) —— 主键 ID: 2 \u0026lt;\u0026ndash; 目标数据\n(王七, 30) —— 主键 ID: 3\n(张三, 20) —— 主键 ID: 4\n❌ 阶段一：没有 ICP (MySQL 5.6 之前) 在没有 ICP 的时候，存储引擎认为自己的任务就是找所有 name 以“王”开头的数据。它会忽略 age = 20 这个条件，因为按老规矩，范围查询后的列“失效”了。\n执行流程：\nServer 层告诉 InnoDB：“给我找所有 name LIKE '王%' 的记录。”\nInnoDB 在索引树上找到第一条 (王五, 10)。\nInnoDB 此时无视 age=10 不等于 20 这个事实。\nInnoDB 拿着 ID: 1 去聚簇索引回表，取出整行数据。\nInnoDB 把整行数据返回给 Server 层。\nServer 层拿到数据，进行 WHERE 判断：age 是 20 吗？\n发现是 10，丢弃。 InnoDB 继续找下一条 (王六, 20)。\n回表，取整行，返回给 Server。 Server 层 判断：age 是 20 吗？\n是，保留。 InnoDB 继续找下一条 (王七, 30)。\n回表，取整行，返回给 Server。 Server 层 判断：age 是 20 吗？\n不是，丢弃。 结果： 进行了 3 次回表，Server 层做了 3 次判断，最后只得到了 1 条数据。做了很多无用功（多回了 2 次表）。\n✅ 阶段二：开启 ICP (MySQL 5.6 及以后) MySQL 意识到：“嘿，InnoDB 兄弟，虽然你正在扫描索引，但我需要的 age 其实就在你手里的索引节点上。你能不能顺便帮我看一眼？如果 age 不对，你就别回表了，直接看下一个。”\n这就是 Index Condition Pushdown：把 age = 20 这个条件下推到存储引擎层。\n执行流程：\nServer 层告诉 InnoDB：“给我找 name LIKE '王%' 的记录，同时，如果 age 不等于 20，你就别给我了。”\nInnoDB 在索引树上找到第一条 (王五, 10)。\nInnoDB 直接检查索引上的值：age 是 10。\n不符合 age = 20。\nInnoDB 直接跳过（不回表，不返回给 Server）。\nInnoDB 继续找下一条 (王六, 20)。\n检查索引：age 是 20。\n符合！\nInnoDB 拿着 ID: 2 回表，取出整行数据，返回给 Server。\nServer 层 再次确认（兜底），保留数据。\nInnoDB 继续找下一条 (王七, 30)。\n检查索引：age 是 30。\n不符合，直接跳过。\n结果： 只进行了 1 次回表。I/O 操作大幅减少，性能提升。\n特性 判断 age=20 的位置 处理 (王五, 10) 处理 (王六, 20) 处理 (王七, 30) 总回表次数 无 ICP Server 层 (回表之后) 回表 -\u0026gt; 丢弃 回表 -\u0026gt; 保留 回表 -\u0026gt; 丢弃 3 次 (慢) 有 ICP 存储引擎层 (回表之前) 索引层直接丢弃 回表 -\u0026gt; 保留 索引层直接丢弃 1 次 (快) 怎么看有没有用到 ICP？ 你可以使用 EXPLAIN 命令查看执行计划。\n1 EXPLAIN SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; AND age = 20; 如果输出的 Extra 列中包含：Using index condition\n这就说明 ICP 生效了。\n(注：如果 Extra 是 Using where，说明在 Server 层过滤；如果是 Using index，说明是覆盖索引，不需要回表，性能更好)\n正常的联合索引（完美匹配） 假设索引还是 (name, age)。 SQL: SELECT * FROM user WHERE name = '王五' AND age = 20;\n在这种情况下，都是等值查询，符合最左前缀原则。\n怎么执行？ InnoDB 里的 B+ 树是严格排序的：先按 name 排，name 此时固定是 \u0026lsquo;王五\u0026rsquo;，那么里面的数据就是严格按 age 排序的。 InnoDB 不需要“先找王五，再遍历过滤 age”，而是直接根据 B+ 树的算法，一次性跳（Seek） 到 (王五, 20) 这个节点的位置。\n谁在做？ 存储引擎 (InnoDB)。它利用 B+ 树结构直接定位数据。\nServer 层在干嘛？ Server 层只是给 InnoDB 下达了一个指令：“把 name='王五' AND age=20 的数据给我。” InnoDB 说：“好的，我通过索引直接定位到了，这是数据。” Server 层拿到数据，甚至不需要再判断一次（但在代码实现逻辑上可能会做双重确认），直接发给客户端。\n索引下推 ICP（范围查询导致断档） 这是我们刚才聊的场景。 SQL: SELECT * FROM user WHERE name LIKE '王%' AND age = 20;\n怎么执行？ 因为 name 是范围，B+ 树只能帮你定位到“姓王的开始了”和“姓王的结束了”。在这个范围内，age 是乱序的（相对全局而言）。 InnoDB 不能直接跳到 age=20 的位置，只能从“王”的第一个数据开始扫描。\nICP 的作用： 在扫描过程中，InnoDB 顺便看一眼索引里的 age。如果不符合，就不回表了。\n谁在做？ 还是 存储引擎 (InnoDB)。但是这次它不是“直接定位”，而是“扫描 + 顺便过滤”。\nServer层处理“无法下推”的条件 这是 Server 层更重要的工作。如果 SQL 中包含不在索引里的字段条件，InnoDB 是无能为力的，必须由 Server 层来做。\n举个例子：\n索引： (name, age)\nSQL：\n1 2 3 4 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; -- 索引前缀（用于范围扫描） AND age = 20 -- 索引下推（ICP 在 InnoDB 过滤） AND address = \u0026#39;北京\u0026#39;; -- 索引里没有（Server 层过滤） 详情见下方流程\n索引下推查询的全流程 场景设定 表结构： user (id, name, age, address)\n索引： idx_name_age (name, age) —— 联合二级索引\nSQL 语句：\n1 2 3 4 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; -- 索引范围查询 (Range) AND age = 20 -- 索引下推过滤 (ICP) AND address = \u0026#39;北京\u0026#39;; -- 普通条件 (Server 层过滤) 2. 详细执行流程 (Pipeline) 这个流程就像一个漏斗，每经过一层，数据就变少一点，性能就越高。\n第一步：Server 层（准备阶段） 解析与优化： MySQL 优化器分析 SQL，发现可以使用 idx_name_age 索引。\n生成计划： 虽然 name 是范围查询导致 age 无法用于定位，但优化器决定开启 ICP。\n标志： EXPLAIN 中的 Extra 显示 Using index condition。 下发指令： Server 层告诉 InnoDB：“去 idx_name_age 索引里找 name 以 \u0026lsquo;王\u0026rsquo; 开头的数据。同时，把 age = 20 这个条件带上，如果不满足就别给我了。”\n第二步：InnoDB 存储引擎层（ICP 核心阶段） 定位游标： InnoDB 在二级索引 B+ 树上，找到第一个 name 匹配 '王%' 的叶子节点记录（假设是 王五, 10岁, ID:1）。\n索引内过滤 (ICP Check)：\nInnoDB 不急着回表。\n它先看手头索引元组里的 age。\n情况 A（不匹配）： 发现 age 是 10（不等于 20）。\n动作： 直接忽略该条记录，指针移向下一条。（省下一次回表 I/O） 情况 B（匹配）： 指针移向下一条（假设是 王六, 20岁, ID:2）。\n检查 age 是 20。符合条件！准备回表。 第三步：InnoDB 存储引擎层（回表阶段） 读取主键： 拿到符合 ICP 条件的记录的主键 ID:2。\n回表 (Table Lookup)： 拿着 ID:2 去**聚簇索引（主键索引）**树里查找。\n提取行数据： 从聚簇索引叶子节点里读取完整的行数据（包含 name, age, address 等所有列）。\n返回数据： 把这行完整数据返回给 Server 层。\n第四步：Server 层（最终兜底阶段） 接收数据： Server 层拿到 王六 的完整行数据。\n二次确认 (Double Check)： 尽管 InnoDB 过滤过，Server 层依然会校验 name LIKE '王%' 和 age = 20（流程规范）。\n补充过滤： Server 层检查 SQL 中剩下的、没法下推的条件 —— address = '北京'。\n如果 王六 的 address 是 \u0026lsquo;上海\u0026rsquo; -\u0026gt; 丢弃。\n如果 王六 的 address 是 \u0026lsquo;北京\u0026rsquo; -\u0026gt; 放入结果集。\n发送结果： 将最终通过的记录发送给客户端。\n3. 流程总结图解 步骤 所在层级 处理内容 数据状态 (示例) 关键作用 1 Server 生成执行计划 指令：Scan idx, Filter age=20 开启 ICP 2 InnoDB 扫描二级索引 (王五, 10) -\u0026gt; ❌ 直接丢弃\n(王六, 20) -\u0026gt; ✅ 保留 ICP 核心：减少回表 3 InnoDB 回表 (聚簇索引) 拿 ID:2 去找完整行数据 最耗时的 I/O 操作 4 Server 最终过滤 检查 address='北京' 处理非索引列逻辑 PriorityQueue的相关API 操作 复杂度 (Time Complexity) 备注 offer() / add() $O(\\log N)$ 插入操作，需要维护堆的属性。 poll() / remove() $O(\\log N)$ 移除最小/最大元素，需要重新堆化。 peek() / element() $O(1)$ 仅查看堆顶元素。 remove(Object o) $O(N)$ 移除任意元素，需要线性搜索。 方法 签名 描述 int size() public int size() 返回队列中元素的数量。 void clear() public void clear() 移除队列中的所有元素。 boolean isEmpty() public boolean isEmpty() 如果队列不包含任何元素，则返回 true。 Comparator\u0026lt;? super E\u0026gt; comparator() public Comparator\u0026lt;? super E\u0026gt; comparator() 返回用于对此队列中元素进行排序的比较器，或者返回 null（如果使用自然顺序）。 Object[] toArray() public Object[] toArray() 返回包含队列中所有元素的数组。注意：返回的数组不保证是排序的。 ","date":"2025-11-21T21:35:16+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1/%E5%9C%BA%E6%99%AF/","title":"面试八股/场景"},{"content":"刷! 字母异位词分组 题目 给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。\n字母异位词 是由重新排列源单词的所有字母得到的一个新单词。\n示例 1:\n输入: strs = [\u0026quot;eat\u0026quot;, \u0026quot;tea\u0026quot;, \u0026quot;tan\u0026quot;, \u0026quot;ate\u0026quot;, \u0026quot;nat\u0026quot;, \u0026quot;bat\u0026quot;] 输出: [[\u0026ldquo;bat\u0026rdquo;],[\u0026ldquo;nat\u0026rdquo;,\u0026ldquo;tan\u0026rdquo;],[\u0026ldquo;ate\u0026rdquo;,\u0026ldquo;eat\u0026rdquo;,\u0026ldquo;tea\u0026rdquo;]]\n示例 2:\n输入: strs = [\u0026quot;\u0026quot;] 输出: [[\u0026quot;\u0026quot;]]\n示例 3:\n输入: strs = [\u0026quot;a\u0026quot;] 输出: [[\u0026ldquo;a\u0026rdquo;]]\n题意就是一个单词里面所有字母都相同的就是字母异位词\n解法: 题目要求返回格式是List\u0026lt;List\u0026gt;,那么每个字母异位词都要放入List里面\n可以通过给字符串排序,然后判断这个字符串是否和其他字符串相等来判断字母异位词\n可以使用Char[] arr=string.toCharArray();函数来将String转为Char[]类型,然后用Arrays.sort()进行排序.\n互相比较很麻烦,所以我们使用HashMap数据结构\nMap\u0026lt;String,List\u0026gt;\n其中String是排完序后的Char[]转为的String,用String str=new String(arr);来获取\n如果有这个key,就直接在map.get(key)里面add(str)\n如果没有这个key,就新建一个List,一定要加入排序好的str\n最后return的时候要遍历map获取所有List\n使用for-each\n1 2 3 4 5 List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(List\u0026lt;String\u0026gt; list:map.values()){ ans.add(list); } return ans; 完整版代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Solution { public List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; groupAnagrams(String[] strs) { Map\u0026lt;String,List\u0026lt;String\u0026gt;\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;strs.length;i++){ String string=strs[i]; char[] arr=string.toCharArray(); Arrays.sort(arr); String str=new String(arr); if(map.containsKey(str)){ map.get(str).add(string); }else{ List\u0026lt;String\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(string); map.put(str,list); } } List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (List\u0026lt;String\u0026gt; list : map.values()) { result.add(list); } return result; } } ","date":"2025-06-06T10:06:50+08:00","permalink":"https://LuciusWan.github.io/p/leetcode%E5%88%B7%E9%A2%98/","title":"Leetcode刷题"},{"content":"设计模式 OOP七大原则 单一职责原则 每个类最好只有一个任务或职责比如Controller类就负责接收前端请求,然后向Service层请求结果,而不是直接请求Mapper层或者直接处理数据返回.\n开闭原则 对扩展开放，对修改关闭，具体来说是写程序的时候可以多实现接口,让这个接口对应的类有更多功能,而不是删去以前的代码去修改功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 抽象支付接口 interface Payment { void pay(BigDecimal amount); } // 实现类（扩展时新增类即可） @Service class Alipay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;支付宝支付：\u0026#34; + amount); } } @Service class WechatPay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;微信支付：\u0026#34; + amount); } } // 控制器（对修改关闭） @RestController class PaymentController { @Autowired private List\u0026lt;Payment\u0026gt; payments; // Spring自动注入所有实现 @PostMapping(\u0026#34;/pay\u0026#34;) public String pay(@RequestParam String type, @RequestParam BigDecimal amount) { payments.stream() .filter(p -\u0026gt; p.getClass().getSimpleName() .equalsIgnoreCase(type + \u0026#34;Pay\u0026#34;)) .findFirst() .ifPresent(p -\u0026gt; p.pay(amount)); return \u0026#34;success\u0026#34;; } } 依赖倒置原则 依赖抽象而非实现，多定义很多层接口,最后再对接口进行实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 抽象层 interface UserRepository { User findById(Long id); } // 高层模块 @Service class UserService { private final UserRepository repository; // 依赖抽象 @Autowired public UserService(UserRepository repository) { this.repository = repository; } public User getUser(Long id) { return repository.findById(id); } } // 低层实现（可以是MySQL/MongoDB等） @Repository class JpaUserRepository implements UserRepository { @Override public User findById(Long id) { // 实际数据库操作 } } 它不关心具体的数据来源是 MySQL、MongoDB 还是其他方式，只依赖于接口，上层接口只关心数据。 合成复用原则 类最好要组合使用,而不是继承添加特性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 错误示范：用继承获取日志能力 class OrderService extends LoggingUtil { ... } // 正确示范：通过组合引入能力 @Service class OrderService { private final LoggingUtil logger; // 组合 @Autowired public OrderService(LoggingUtil logger) { this.logger = logger; } public void createOrder() { logger.log(\u0026#34;创建订单\u0026#34;); // 业务逻辑 } } SpringBoot项目中,多使用@Autowired,组合不同的类,让类之间共享方法\n口隔离原则 不应强迫客户端依赖于它们不使用的接口。换句话说，一个类应该只提供给其他类它实际需要的方法，而不是所有可能的方法。\n迪米特法则 也被称为最少知识原则，表明一个对象应该尽可能少地了解其他对象。每个单元对于其他的单元只能拥有最少的知识，并且仅仅与那些与之紧密相关的单元进行交互。\n比如有Mapper,Service,Controller三层架构,此时我们最好让他们之间一层一层通信,而不是Controller直接去找Mapper层找数据输出.\n里氏替换原则 在继承父类的时候最好不要修改父类的方法,可以扩展方法,这样在要使用父类的时候,可以用子类替代.\n单例模式 饿汉式单例模式 在项目启动的时候创建出的单例对象的行为就是饿汉式单例模式,比如下列代码\n1 2 3 4 5 6 7 8 9 public class Singleton { private static final Singleton INSTANCE = new Singleton(); private Singleton() {} public static Singleton getInstance() { return INSTANCE; } } static表示是静态资源,存在与静态资源池里面,final表示这个对象不会再被改变了,因此对象在启动的时候就创建好了.\nSpring容器创建的Bean对象默认就是饿汉式单例模式,通过@Autowired实现控制反转与依赖注入.\n优点：\n实现简单，代码清晰。 线程安全。 缺点：\n无论是否使用，都会在类加载时创建实例，可能浪费资源。\n懒汉式单例模式 懒汉式单例模式是指单例对象在需要使用的时候才会创建,样例代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 这种情况下可能导致线程安全问题,高并发的时候并不能保证单例,因此要在创建对象的时候加上锁\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 工厂模式 简单工厂 简单工厂创建对象的时候要考虑对象的类型,然后用if-else语句来判断是要创建哪个对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 工厂类 public class ShapeFactory { // 根据传入的类型创建对应的对象 public Shape getShape(String shapeType) { if (shapeType == null || shapeType.isEmpty()) { return null; } if (shapeType.equalsIgnoreCase(\u0026#34;CIRCLE\u0026#34;)) { return new Circle(); } else if (shapeType.equalsIgnoreCase(\u0026#34;SQUARE\u0026#34;)) { return new Square(); } else if (shapeType.equalsIgnoreCase(\u0026#34;RECTANGLE\u0026#34;)) { return new Rectangle(); } return null; } } 这样局限性还是很高,判断很多if else语句也会导致代码效率不高\n工厂方法模式 一个类只负责创建一种产品，通过继承和多态性，可以方便地扩展新的产品类型。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // 定义产品接口 public interface Product { void use(); } // 具体产品A public class ConcreteProductA implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品A\u0026#34;); } } // 具体产品B public class ConcreteProductB implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品B\u0026#34;); } } // 抽象工厂接口 public abstract class Creator { // 工厂方法，由子类实现 public abstract Product factoryMethod(); } // 具体工厂A public class ConcreteCreatorA extends Creator { @Override public Product factoryMethod() { return new ConcreteProductA(); } } // 具体工厂B public class ConcreteCreatorB extends Creator { @Override public Product factoryMethod() { return new ConcreteProductB(); } } // 测试类 public class FactoryMethodTest { public static void main(String[] args) { // 使用具体工厂A创建产品A Creator creatorA = new ConcreteCreatorA(); Product productA = creatorA.factoryMethod(); productA.use(); // 使用具体工厂B创建产品B Creator creatorB = new ConcreteCreatorB(); Product productB = creatorB.factoryMethod(); productB.use(); } } 一个工厂只负责创建一种对象\n抽象工厂 抽象工厂模式提供了一组用于创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。能够创建一系列相关的对象，而不是单一的产品。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 // 定义产品族接口 public interface AbstractProductA { void useA(); } public interface AbstractProductB { void useB(); } // 具体产品A1 public class ConcreteProductA1 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A1\u0026#34;); } } // 具体产品A2 public class ConcreteProductA2 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A2\u0026#34;); } } // 具体产品B1 public class ConcreteProductB1 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B1\u0026#34;); } } // 具体产品B2 public class ConcreteProductB2 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B2\u0026#34;); } } // 抽象工厂接口 public interface AbstractFactory { AbstractProductA createProductA(); AbstractProductB createProductB(); } // 具体工厂1 public class ConcreteFactory1 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA1(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB1(); } } // 具体工厂2 public class ConcreteFactory2 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA2(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB2(); } } // 测试类 public class AbstractFactoryTest { public static void main(String[] args) { // 使用具体工厂1创建产品族1 AbstractFactory factory1 = new ConcreteFactory1(); AbstractProductA productA1 = factory1.createProductA(); AbstractProductB productB1 = factory1.createProductB(); productA1.useA(); productB1.useB(); // 使用具体工厂2创建产品族2 AbstractFactory factory2 = new ConcreteFactory2(); AbstractProductA productA2 = factory2.createProductA(); AbstractProductB productB2 = factory2.createProductB(); productA2.useA(); productB2.useB(); } } 每个具体工厂可以创建不同的对象\n在Spring中,配置类就使用了工厂模式\n1 2 3 4 5 6 7 8 9 @Bean public ChatClient DesignPattern(OpenAiChatModel model, ChatMemory chatMemory) { return ChatClient.builder(model) .defaultSystem(AIConstant.DESIGN_PATTERN) .defaultAdvisors( new MessageChatMemoryAdvisor(chatMemory), new SimpleLoggerAdvisor()) .build(); } 而一个配置类里面有多个@Bean注解下的工厂方法,可以实现抽象工厂和工厂方法模式\n","date":"2025-05-16T20:56:35+08:00","permalink":"https://LuciusWan.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"设计模式"},{"content":"Redis高级篇 Redis持久化 RDB(RedisDatabase) RDB 会在指定的时间间隔（比如每 5 分钟）对 Redis 的内存数据进行一次“拍照”，生成一个二进制文件（dump.rdb）。这个文件可以自己设置名称,默认为dump.rdb.这个文件包含了当时的所有数据状态。\n如果 Redis 崩溃了，重启时会加载最近的dump.rdb来恢复数据。\n如果使用命令save可以直接保存rdb文件\n每次启动Redis的时候Redis就会访问这个rdb文件来获取以前的数据\n每次关闭Redis服务端的时候都会生成一个新的dump.rdb\n文件就在这里\n如果只是关机的时候使用,万一什么时候Redis宕机了,就无法恢复数据了,这时候得用间隔保存了,这时候只需要打开Redis配置文件,修改如下字段\n# save \u0026quot;\u0026quot;表示注释掉了 Redis 的默认 RDB 持久化策略（即禁用默认的自动快照生成）。\n下面的意思是900秒内有1次操作就保存一次,300秒内10次操作就自动保存一次,60秒内有10000次操作就保存一次.\nfork 子进程：Redis 调用 fork() 创建一个子进程，子进程与主进程共享内存数据。\nCOW（Copy-On-Write）：\n子进程开始快照操作时，主进程仍可处理客户端请求并修改数据。 当主进程修改某个数据页时，操作系统会将该页复制一份（写时复制），子进程看到的仍是修改前的数据。 子进程将所有数据页写入磁盘生成 .rdb 文件，而主进程不影响快照的一致性。 COW有缺点就是,如果我的Redis已经占用了很高的内存,此时我要修改的数据也很多,复制的数据非常多会导致内存溢出\n并且修改次数多,导致复制次数也多,开销也很大\n修改次数少的时候如果宕机就会导致大部分数据丢失\nAOF（Append-Only File） AOF则是记录每一次操作Redis的命令,把命令记录在磁盘中,如果后面需要恢复就再执行一次所有Redis命令,下面的就是AOF文件\n只有修改了redis.conf中的如下文件后才能使用\n有如下三种记录频率\n第一个是每写一次命令,执行完后就写入磁盘,然后返回信息,这样就很慢了,和直接操作数据库没有区别,第二个方法是隔了一秒后进行,实现了异步处理,顶多丢失1秒的数据,最后一种由操作系统判断什么时候写回磁盘,推荐使用第二种.\n下面是AOF文件中的内容\n如果我写三个如下命令\n1 2 3 4 5 6 127.0.0.1:6379\u0026gt; set name111 dinglz OK 127.0.0.1:6379\u0026gt; set name111 wfg OK 127.0.0.1:6379\u0026gt; set name111 666 OK 这样直接写入aof文件会比较占内存,可以使用如下命令来重写AOF文件\n1 BGREWRITEAOF 重写后的文件如下\n直接就看不懂了,但是这样确实简化了AOF文件,不用连续设置三次才得到最终数据.\n1 2 3 127.0.0.1:6379\u0026gt; bgrewriteaof Background append only file rewriting started 127.0.0.1:6379\u0026gt; 可以看到这个命令甚至是在后台执行的\n通常情况下是两种持久化机制一起使用,可以保证数据的稳定性\nRedis主从同步 主从同步示例要三个Redis,我们可以使用windows本地复制三个Redis文件,然后修改配置文件,端口号6379,6380,6381,或者直接用docker,pull下redis的最新版本,然后创建三个实例.\n分别启动三个Redis的服务端,然后再Redis-cli的6380上输入如下名令\n1 slaveof 127.0.0.1 6379 意思是Redis6380要成为6379的从节点\n也可以使用如下命令\n1 replicaof 127.0.0.1 6379 这时候6380就是6379的从节点了\n当我们在6379上使用set命令\n1 2 3 127.0.0.1:6379\u0026gt; set number 111 OK 127.0.0.1:6379\u0026gt; 那么从节点上也可以看到被修改了\n1 2 3 4 5 6 ~ .\\redis-cli.exe -p 6381 -h localhost localhost:6381\u0026gt; replicaof localhost 6379 OK localhost:6381\u0026gt; get number \u0026#34;111\u0026#34; localhost:6381\u0026gt; 这就实现了主从同步\n全量同步 在我们输入slaveof host port之后,slave向master发送了自己的replid和offset,id和master肯定不一样,这时候就告知master这时候得做全量同步,清空slave本地缓存,把master生成的RDB发给slave进行数据同步.\n并且在建立主从关系后,master会把自己的命令都交给slave去做数据同步,增量同步.\n增量同步 repl_baklog是记录了RDB期间的所有命令的一个文件,是环状读写的,每次做增量同步的时候slave都会发送自己的offset,master在自己的repl_baklog表中查找offset,如果找到的话就把offset后面的数据交给master.下图红绿交接就是offset\n如果slave宕机了,而且时间还挺长,master写repl_baklog文件已经覆盖了offset,那此时只能做一个全量同步.\n可以从以下几个方面来优化Redis主从就集群:\n在master中配置repl-diskless-syncyes启用无磁盘复制，避免全量同步时的磁盘IO。\nRedis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO\n适当提高repl baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力,可以直接从其他slave上直接读取数据,而不是都找master\n哨兵模式 哨兵的工作原理 Redis的哨兵（Sentinel）是一个监控和故障转移系统，用于管理Redis主从复制架构中的高可用性。它在Redis 2.8版本中被引入，主要目的是解决当主节点出现故障时，如何自动完成故障发现和故障转移的问题。以下是关于Redis哨兵的一些\n哨兵每一秒广播发送一次ping命令,告诉所有节点,自己没有宕机\n如果某个节点在指定时间内没有响应，则会被标记为“主观下线”。如果主节点被标记为主观下线，哨兵会询问其他哨兵实例，根据多数哨兵的意见决定是否将其标记为“客观下线”。\n客观下线后就会触发主从交换,选出一个offset最大的slave,向其发送slaveof no one,让其成为master节点,然后强制修改原主节点的配置文件,让那个redis slave of新的master,然后让所有节点都执行slaveof新master.\n","date":"2025-05-13T20:22:24+08:00","permalink":"https://LuciusWan.github.io/p/redis%E9%AB%98%E7%BA%A7%E7%AF%87/","title":"Redis高级篇"},{"content":"Docker初体验 Docker 是什么 Docker 是一个应用打包、分发、部署的工具\n你也可以把它理解为一个轻量的虚拟机，它只虚拟你软件需要的运行环境，多余的一点都不要，\n而普通虚拟机则是一个完整而庞大的系统，包含各种不管你要不要的软件。\n跟普通虚拟机的对比 特性 普通虚拟机 Docker 跨平台 通常只能在桌面级系统运行，例如 Windows/Mac，无法在不带图形界面的服务器上运行 支持的系统非常多，各类 windows 和 Linux 都支持 性能 性能损耗大，内存占用高，因为是把整个完整系统都虚拟出来了 性能好，只虚拟软件所需运行环境，最大化减少没用的配置 自动化 需要手动安装所有东西 一个命令就可以自动部署好所需环境 稳定性 稳定性不高，不同系统差异大 稳定性好，不同系统都一样部署方式 打包、分发、部署 打包：就是把你软件运行所需的依赖、第三方库、软件打包到一起，变成一个安装包\n分发：你可以把你打包好的“安装包”上传到一个镜像仓库，其他人可以非常方便的获取和安装\n部署：拿着“安装包”就可以一个命令运行起来你的应用，自动模拟出一模一样的运行环境，不管是在 Windows/Mac/Linux。\n下载\u0026amp;安装docker 下面是桌面版链接,点击下载\nhttps://www.docker.com/products/docker-desktop\n推荐下载这个\n下载完后是个exe文件,点开后开始安装\n我们在安装完成后可能会遇到这个报错\n这是因为我们没开启虚拟化,如果你下载过Linux虚拟机应该就不会有这个错误,同时我们还要下载Linux子系统,跟着引导来就好\n解决方法：\n控制面板-\u0026gt;程序-\u0026gt;启用或关闭 windows 功能，开启 Windows 虚拟化和 Linux 子系统（WSL2)\n要确定BIOS支持虚拟化\n添加镜像源 我们如果每次都到docker官方去获取镜像,那么没有魔法就会非常慢,所以我们可以添加镜像源\n可用的国内镜像源如下.可以添加多个镜像源\n镜像加速器 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://ud6340vz.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 用docker安装软件 我们可以下载个redis玩玩\n下载Redis镜像 打开命令提示符（CMD）或PowerShell，然后使用以下命令从Docker Hub下载官方的Redis镜像：\n1 docker pull redis 这将下载最新版本的Redis镜像。你也可以指定版本号来下载特定版本的Redis镜像，例如：\n1 docker pull redis:latest 运行Redis容器 下载完成后，你可以使用以下命令来启动一个Redis容器：\n1 docker run --name my-redis -d -p 6379:6379 redis 这里的参数解释如下：\n--name my-redis：为容器指定一个名称，这里是my-redis。 -d：表示以分离模式运行容器,在后台运行。 -p 6379:6379：将容器的6379端口映射到宿主机的6379端口，这样你就可以通过宿主机的6379端口访问Redis服务。 验证Redis服务 为了验证Redis服务是否正常运行，你可以使用以下命令连接到Redis容器：\n1 docker exec -it my-redis redis-cli 这将打开一个Redis命令行接口。你可以在这里输入Redis命令来测试服务，例如：\n1 ping 如果服务正常运行，你应该看到输出PONG。\n我们可以在docker的终端上打开redis并使用 停止和删除容器 当你完成测试并想要停止Redis容器时，可以使用以下命令：\n1 docker stop my-redis 要删除容器，可以使用：\n1 docker rm my-redis 如果你想要强制删除正在运行的容器，可以添加-f参数：\n1 docker rm -f my-redis 配置Redis密码（可选） 如果你需要为Redis设置密码，可以在运行容器时通过环境变量REDIS_PASSWORD来设置。例如：\n1 docker run --name my-redis -d -p 6379:6379 -e REDIS_PASSWORD=mypassword redis redis-server --requirepass mypassword 这将设置Redis的密码为mypassword。之后，你需要使用这个密码来连接到Redis服务。\n制作自己的镜像 我们可以把自己的项目打包成一个镜像,让这个镜像在别的电脑上不配环境就能跑起来\n下面是springboot项目的制作镜像案例\n在制作镜像的时候,我们要先写一个dockerfile,这个dockerfile怎么写可以直接问AI\nSpringBoot的dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 使用官方的 OpenJDK 作为基础镜像,写清楚你的jdk版本 FROM openjdk:17-jdk-alpine # 设置工作目录 WORKDIR /app # 将构建好的 JAR 文件复制到镜像中 COPY target/你的jar包的名字.jar /app/app.jar # 暴露应用运行的端口（例如 Spring Boot 默认的 8080 端口） EXPOSE 8083 # 设置容器启动时运行的命令 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;] 这个文件就跟src和pom.xml坐一桌(放一块)就行了\n然后我们就可以通过下面的命令来制作这个docker镜像\n1 docker build -t test:v1 . test是镜像的名称,v1是版本号\n然后我们可以在本地跑一下这个镜像\n1 docker run -p 8083:8083 --name test-hello test:v1 \u0026ndash;name test-hello指的是容器的名称是test-hello,后面跟的是要跑的是什么镜像的什么版本\n多容器通信 多容器通信的意义 在Docker中，多容器通信是指多个容器之间能够相互发现并进行数据交换的能力。\n这种通信机制在构建微服务架构和分布式应用时尤为重要，因为它允许不同服务之间高效地协作。\nDocker提供了多种网络模式来实现容器间的通信，包括桥接网络（Bridge）、主机网络（Host）、覆盖网络（Overlay）以及Macvlan网络等。\n在本地,我们通过本地回环的测试网络localhost127.0.0.1来相互通信,前端代码,后端代码,中间件,数据库等都通过127.0.0.1通信,而我们在docker部署多个容器并没有这样一个网络实现容器间通信,这时候就要用这样个网络.\n上面三种网络形式挺麻烦的,我们直接用docker-compose.yml,当容器多了,这种方法的好处就体现出来了. 举个例子 我的这个项目要用到3个redis,还有rabbitmq,下面这个是我的docker-compose.yml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 services: springboot-app: image: test:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: YourUserName RABBITMQ_DEFAULT_PASS: YourPassword #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network networks: my-network: 我们的这个网络就叫my-network,然后所有的容器都配置在这一个文件中,我们只需要在项目目录里面加上这个yml文件就可以准备启动整个项目了\n在这里打开终端,然后输入如下命令\n1 docker-compose up -d 然后项目就启动了\n这样可以方便快捷的实现容器间的通信互联\n容器的通信路由 我们的容器现在都在一个网络下了,我们要通过域名来访问对应的容器\n比如我这个java代码,这是Redisson的配置代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.config; import ... @Configuration public class RedissonConfig { @Autowired private RedisProperties redisProperties; @Bean public RedissonClient redisson6379() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis1:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6380() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis2:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6381() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis3:6379\u0026#34;); return Redisson.create(config); } } ip地址localhost改写为容器的名称,也就是容器的域名\n后面的端口一定要是镜像暴露出来的端口,redis暴露出来的就是6379端口\nrabbitmq的配置也要改\n1 2 3 4 5 6 rabbitmq: host: rabbitmq port: 5672 username: YourUserName password: YourPassword virtual-host: / host要改为容器名称.\nDocker部署MySQL 修改docker-compose.yml 想要在docker上部署MySQL,先要关掉MySQL的本地服务,可以直接在任务管理器里找mysql,然后关闭这个任务即可.\n然后修改docker-compose.yml，加上这个即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: YourDataBaseName #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network 1 2 volumes: - ./mysql/data:/var/lib/mysql 这个语句的意思是挂载目录\n挂载目录 在使用 Docker 部署 MySQL 时，挂载目录（通常使用 Docker 的 volume 功能）主要有以下几个目的：\n1. 数据持久化 背景：Docker 容器是无状态的，当容器被删除或重新启动时，容器内部的数据（如 MySQL 数据库文件）会丢失。\n解决方案：通过挂载宿主机的目录到容器内部，可以将 MySQL 的数据文件存储在宿主机上。这样，即使容器被删除或重新启动，数据仍然可以被保留。\n2 . 方便数据迁移 背景：当需要将数据库从一个环境迁移到另一个环境时，数据的迁移是一个关键步骤。\n解决方案：通过挂载目录，可以直接将宿主机上的数据目录复制到新的宿主机上，然后启动新的 MySQL 容器，从而实现数据的迁移。\n示例：\n1 2 # 将数据目录从旧宿主机复制到新宿主机 scp -r /path/to/mysql-data user@new-host:/path/to/mysql-data 具体就是这个语句让我本地建了个文件夹，实现了持久化存储\n然后我们在终端上登录mysql,使用对应的数据库,然后把表数据填进去就可以再次启动容器了\n实现多端负载均衡 我的这个项目是开了8083和8084端口同时接受前端请求,用nginx实现负载均衡,目前只开放了8083端口,修改docker-compose.yml即可\n修改docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network 加入这个语句即可,启动后就实现了多端口接收数据\n发布Docker镜像 镜像仓库介绍 镜像仓库用来存储我们 build 出来的“安装包”，Docker 官方提供了一个 镜像库，里面包含了大量镜像，基本各种软件所需依赖都有，要什么直接上去搜索。\n我们也可以把自己 build 出来的镜像上传到 docker 提供的镜像库中，方便传播。\n当然你也可以搭建自己的私有镜像库，或者使用国内各种大厂提供的镜像托管服务，例如：阿里云、腾讯云\n上传镜像 首先要 注册一个账号 创建一个镜像库 然后在命令行中登录一下\n注意:这里登录只能是小写字母,之前写的大写字母username也得转为小写\n新建一个tag，名字必须跟你注册账号一样 1 docker tag test:v1 username/test:v1 推上去 1 docker push username/test:v1 然后我们可以随便新建一个文件夹,修改一下docker-compose.yml文件,然后粘过来\n修改docker-compose.yml文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8084:8083\u0026#34; # 映射 8084 端口到容器的 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP 协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ networks: - my-network mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: driver: bridge 主要是修改这个image\n1 image: luciuswan/hmdp:v1 docker,启动! 然后在这里启动powershell,输入命令即可运行项目\n1 docker-compose -p hmdp up -d 如果直接输入docker-compose -d,会提示你没有容器名称\n正常输入的话,我们的项目就跑起来了\n这时候还跑不了,因为数据没有迁移\nDocker数据迁移 部署的时候每次都得重新建数据库,建表,这样并没有提现到docker的方便部署,我们可以通过docker指令来复制docker中的mysql数据库,然后复制到宿主机,也就是windows本地,然后把这个文件送到别的宿主机\n1. 备份旧容器的数据 在旧容器中，使用mysqldump工具备份数据库。\n步骤： 进入旧MySQL容器：\n1 docker exec -it \u0026lt;旧容器名称或ID\u0026gt; bash 备份所有数据库：\n1 mysqldump -u root -p --all-databases \u0026gt; /backup_all_databases.sql 如果只需要备份特定数据库，可以指定数据库名称：\n1 mysqldump -u root -p your_database_name \u0026gt; /backup_your_database.sql 将备份文件从旧容器复制到宿主机：\n1 docker cp \u0026lt;旧容器名称或ID\u0026gt;:/backup_all_databases.sql ./backup_all_databases.sql 效果如下图\n2. 将备份文件上传到新机器 将备份文件（如backup_all_databases.sql）上传到目标机器上。可以使用文件传输工具（如SCP、FTP、WinSCP等）。\n我是直接上传到云服务器了\n3. 在新机器上使用docker-compose部署MySQL 确保你的docker-compose.yml文件正确配置，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network mysql: image: mysql:8.0 container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: 运行以下命令启动服务：\n1 docker-compose -p hmdp up -d 在宝塔面板里面进入包含这个yml文件的文件夹中\n1 2 3 4 cd /www cd wwwroot cd hmdp docker-compose -p hmdp up -d 这样,容器就在新的宿主机启动了\n4. 将备份数据恢复到新容器 将备份文件复制到新容器：\n1 docker cp ./backup_all_databases.sql mysql-container:/backup_all_databases.sql 进入新容器并恢复数据：\n1 docker exec -it mysql-container bash 在容器内部，运行以下命令恢复数据：\n1 mysql -u root -p \u0026lt; /backup_all_databases.sql 输入root用户的密码后，数据将被恢复到新容器中。\n然后我们的数据就同步在新的宿主机了\n5. 验证数据 在新容器中登录MySQL，检查数据是否正确恢复：\n1 docker exec -it mysql-container mysql -u root -p 输入密码后，执行以下命令查看数据库列表：\n1 SHOW DATABASES; 确保你的数据库和数据已经正确恢复。\n然后项目就可以正常跑起来了,如果遇到java代码无法连接MySQL,并且原因是MySQL不支持publicKey,可以在配置MySQL连接方式处这么修改\n然后我们这个项目在哪里跑都一样了\n","date":"2025-04-08T14:25:17+08:00","permalink":"https://LuciusWan.github.io/p/docker%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"Docker初体验"},{"content":"Linux实战 OpenEuler安装 可以参考这个up主的视频 B站视频链接 下载VirtualBox虚拟机 在浏览器官网搜索virtualBox官网Oracle VirtualBox然后直接下载即可\n打开VirtualBox后发现并没有操作系统(),那么我们就再去浏览器下载openEuler操作系统\n下载OpenEuler操作系统 在浏览器上搜索OpenEuler社区openEuler | 开源社区 | openEuler社区官网\n点开后找到Offline Everything ISO，下载就好了\n事实上并没有删除()\n在VirtualBox中加载OpenEuler 点击注册,然后按照下图配置\n然后新建虚拟电脑的时候配置一下\n全都配置好就可以使用了\n注意!!!一定要记住自己的root密码 OpenEuler实践报告 一、实验环境 操作系统：OpenEuler（通过VirtualBox虚拟机运行） 编译器：GCC 二、作业要求的代码 例1：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { fork(); fork(); fork(); printf(\u0026#34;hello\\n\u0026#34;); return 0; } 例2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { int x = 1; pid_t p = fork(); if(p \u0026lt; 0){ perror(\u0026#34;fork fail\u0026#34;); exit(1); } else if (p == 0) printf(\u0026#34;Child has x = %d\\n\u0026#34;, ++x); else printf(\u0026#34;Parent has x = %d\\n\u0026#34;, --x); return 0; } 例题一操作 创建文件并输入代码：\n1 vim example1.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example1.c -o example1 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example1 观察输出结果。\n运行结果及分析 例1运行结果：\n1 2 3 4 5 6 7 8 hello hello hello hello hello hello hello hello 例一分析： 每次fork()调用都会创建一个新的进程，三次fork()会创建8个进程（2^3），每个进程都会执行printf(\u0026quot;hello\\n\u0026quot;);，所以输出8次\u0026quot;hello\u0026quot;。\n例题二操作 创建文件并输入代码：\n1 vim example2.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example2.c -o example2 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example2 观察输出结果。\n运行结果及分析 例2运行结果：\n例二分析：\n父进程和子进程各自拥有变量x的独立副本。 子进程中x的值被递增（++x），所以输出2。 父进程中x的值被递减（--x），所以输出0。 五、总结 通过本次实践，我掌握了在Linux环境下使用GCC编译C代码的基本流程，理解了fork()系统调用的原理和用法，以及进程控制的基本概念。同时，也熟悉了在OpenEuler操作系统下的开发环境和工具的使用。\nHW3-多线程-git 1. 编写和编译多线程代码 1.1 创建代码文件 在Linux命令行中，使用vi或nano编辑器创建一个名为pthread_hello.c的文件：\n1 vi pthread_hello.c 编写如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; /* Thread function that prints \u0026#34;Hello World\u0026#34; */ void *worker(void *arg) { printf(\u0026#34;Hello World!\\n\u0026#34;); return NULL; /* Thread exits (dies) */ } int main() { pthread_t thread; int ret; /* Create a new thread */ ret = pthread_create(\u0026amp;thread, NULL, worker, NULL); if (ret != 0) { perror(\u0026#34;pthread_create failed\u0026#34;); return 1; } /* Wait for the thread to finish */ pthread_join(thread, NULL); return 0; } 1.2 编译代码 使用gcc编译代码，并链接pthread库：\n1 gcc pthread_hello.c -o pthread_hello -lpthread 1.3 运行程序 运行编译后的程序：\n1 ./pthread_hello 输出结果为：\nHello World!\n2. 使用Git管理项目 2.1 创建项目目录 在主目录下创建一个名为os_practice的项目目录：\n1 2 mkdir os_practice cd os_practice 2.2 初始化Git仓库 初始化Git仓库：\n1 git init 2.3 创建子目录 为每次的实践创建单独的子目录，例如：\n1 2 mkdir hw1 cd hw1 将pthread_hello.c文件复制到该目录下：\n1 cp ~/pthread_hello.c . 2.4 添加文件到Git 将文件添加到Git仓库：\n1 git add pthread_hello.c 2.5 提交更改 提交更改并添加描述信息：\n1 git commit -m \u0026#34;Added pthread Hello World example\u0026#34; 2.6 检查Git状态 检查当前Git仓库的状态：\n1 git status 提交代码至github 在github中注册好之后,创建代码仓库 创建好之后,使用github给的bash代码 1 2 3 4 5 6 7 echo \u0026#34;# OS-HomeWork\u0026#34; \u0026gt;\u0026gt; README.md git init git add README.md git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/LuciusWan/OS-HomeWork.git git push -u origin main 然后本地仓库就和github连上了.\n我们可以在本地编译,提交代码至github仓库\n分别使用下面bash语句\n1 2 3 git add . git commit -m \u0026#34;update\u0026#34; git push git add .\n将当前工作区中的所有更改（包括新文件、修改的文件和删除的文件）添加到 Git 的暂存区\ngit commit -m \u0026ldquo;update\u0026rdquo;\n将暂存区中的更改正式提交到本地仓库，并添加一条提交信息。\n提交（commit）是 Git 的一个快照，记录了当前暂存区中的所有更改。\n-m \u0026quot;update\u0026quot; 是提交信息，用来描述这次提交的内容或目的。\n提交信息是可选的，但强烈建议添加，以便以后能够清楚地了解每次提交的更改内容。\ngit push\n很好理解,把本地仓库修改内容和修改信息一并推送到远程仓库\n提交后,我们的仓库就会发生变化 OS第一次上机课 作业内容如下\n任务二 编写nosync-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) sum += 1; } int main(void) { pthread_t tid1, tid2; pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下不上锁,线程之间互相抢资源,导致线程错误,最终结果错误\n结果如下:\n1 2 3 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim nosync-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc nosync-ex.c -o nosync-exadmin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./nosync-ex 1000000 + 1000000 = 1172208 编写mutex-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; pthread_mutex_t mutex; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { pthread_mutex_lock(\u0026amp;mutex); sum += 1; pthread_mutex_unlock(\u0026amp;mutex); } } int main(void) { pthread_t tid1, tid2; pthread_mutex_init(\u0026amp;mutex, NULL); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下可以上锁,线程之间只能有一个能使用锁资源,保证了线程安全,结果正确\n结果如下\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim mutex-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc mutex-ex.c -o mutex-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./mutex-ex 1000000 + 1000000 = 2000000 编写sem-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; int sum = 0; sem_t sem; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { sem_wait(\u0026amp;sem); sum += 1; sem_post(\u0026amp;sem); } } int main(void) { pthread_t tid1, tid2; sem_init(\u0026amp;sem, 0, 1); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 信号量可以通过其操作原语（如 sem_wait() 和 sem_post()）实现互斥访问,这里使用了信号量保证了线程安全,结果正确\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim sem-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc sem-ex.c -o sem-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./sem-ex 1000000 + 1000000 = 2000000 任务三 编写生产者消费者问题 生产者消费者问题是一个消息队列,实现了异步处理,可以达到削峰填谷的作用\n代码实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define BUFFER_SIZE 5 #define NUM_ITEMS 10 int buffer[BUFFER_SIZE]; int count = 0; // 当前缓冲区中的元素数量 int in = 0, out = 0; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t full = PTHREAD_COND_INITIALIZER; pthread_cond_t empty = PTHREAD_COND_INITIALIZER; void* producer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == BUFFER_SIZE) { pthread_cond_wait(\u0026amp;full, \u0026amp;mutex); // 等待缓冲区不满 } buffer[in] = i; printf(\u0026#34;Produced: %d at position %d\\n\u0026#34;, i, in); in = (in + 1) % BUFFER_SIZE; count++; pthread_cond_signal(\u0026amp;empty); // 通知消费者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } void* consumer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == 0) { pthread_cond_wait(\u0026amp;empty, \u0026amp;mutex); // 等待缓冲区不空 } int item = buffer[out]; printf(\u0026#34;Consumed: %d from position %d\\n\u0026#34;, item, out); out = (out + 1) % BUFFER_SIZE; count--; pthread_cond_signal(\u0026amp;full); // 通知生产者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } int main() { pthread_t prod, cons; pthread_create(\u0026amp;prod, NULL, producer, NULL); pthread_create(\u0026amp;cons, NULL, consumer, NULL); pthread_join(prod, NULL); pthread_join(cons, NULL); return 0; } 运行结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc MesssageQueue.c -o MessageQueue admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./MessageQueue Produced: 0 at position 0 Produced: 1 at position 1 Produced: 2 at position 2 Produced: 3 at position 3 Produced: 4 at position 4 Consumed: 0 from position 0 Consumed: 1 from position 1 Consumed: 2 from position 2 Consumed: 3 from position 3 Consumed: 4 from position 4 Produced: 5 at position 0 Produced: 6 at position 1 Produced: 7 at position 2 Produced: 8 at position 3 Produced: 9 at position 4 Consumed: 5 from position 0 Consumed: 6 from position 1 Consumed: 7 from position 2 Consumed: 8 from position 3 Consumed: 9 from position 4 消息队列的容量上限为5个item,因此当生产者获取消息队列资源后给这个资源上锁,只有生产者可以向里面写入数据,可以看到从0-4一共五个数被填入消息队列,然后由于队列已满,通知消费者读取数据,消费者读取了0-4的数据后由于消息队列中没有元素,消费者释放锁资源,并且通知生产者可以生产数据,生产者继续生产5-9的数据,队列又满,通知消费者读取,最后完成所有数据的生产消费,进程结束.\nGit提交代码 使用命令,把所有文件提交到工作区\n1 git add . 然后使用命令提交代码\n1 git commit -m \u0026#34;update\u0026#34; 查看提交记录\n1 git log 结果如下\n提交成功\n","date":"2025-03-21T14:01:52+08:00","permalink":"https://LuciusWan.github.io/p/linux%E5%AE%9E%E6%88%98/","title":"Linux实战"},{"content":"JavaWeb 三层解耦 这里会用到面向对象七大原则中的单一职责原则，即每个程序有自己的任务，而不是有很多任务导致单一程序复杂，耦合度高，复用性差\n我们可以将后端划分为三个部分，MVC框架是Controller，View，Model\n而springboot可以划分为Controller，Service，Dao三层，分别为监听层，逻辑处理层，数据管理层，原来复杂的Controller层是这样的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @RestController public class EmpController { String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } });); List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 现在可以使用三层架构来分别放置 Controller，Service，Dao三层\nDao层的接口及实现如下 1 2 3 public interface EmpDao { public List\u0026lt;Emp\u0026gt; listEmp(); } 1 2 3 4 5 6 7 8 9 10 11 public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } Service层的接口及实现如下 1 2 3 public interface EmpService { public List\u0026lt;Emp\u0026gt; list(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.util.List; public class EmpServiceA implements EmpService { private EmpDao empDao=new EmpDaoA(); @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 这里通过创建Dao层对象然后调用其方法来获取数据，但这会让Dao层和Service层紧耦合\nController代码如下 1 2 3 4 5 6 7 8 9 10 @RestController public class EmpController { private EmpServiceA empServiceA =new EmpServiceA(); @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 同样的，这里的创建对象也会让Service层和Controller层紧耦合\n我们可以考虑使用设计模式中的工厂模式来解决这个紧耦合办法，但是springboot已经想好了解决对策，那就是\n控制反转与依赖注入 控制反转:Inversion Of control，简称IOC。对象的创建控制权由程序自身转移到外部(容器)，这种思想称为控制反转\n依赖注入: Dependency Injection，简称DI。容器为应用程序提供运行时所依赖的资源，称之为依赖注入。\nBean对象:IOC容器中创建、管理的对象，称之为Bean\n解耦之后的代码演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 //Dao层 @Component public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //Service层 @Component public class EmpServiceA implements EmpService { @Autowired private EmpDao empDao; @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 1 2 3 4 5 6 7 8 9 10 11 12 //Controller层 @RestController public class EmpController { @Autowired private EmpService empService; @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empService.list(); System.out.println(empList); return Result.success(empList); } } 如果我此时要加入EmpDaoB（通过MySQL等数据库传送数据），那就吧EmpDaoA的@Component注释了\nspringboot给三层架构分别出了三个衍生注解@Repository，@Service，@Controller\n后续基本上都用数据库传输，并且springboot继承了Mybatis，Mybatis可以使用注解@Mapper来替代@Repository，而Controller层自带@RestController注解，因此可以不用@Controller\n@Component注解可以在不属于这三层，但是很有用的工具类上加这个注解\nPojo文件 pojo文件中存放各种JavaBean\nSpringboot特有的JavaBean写法，使用前要引入Lombok依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package com.test.springboottest03_crud.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.time.LocalDate; import java.time.LocalDateTime; @Data @NoArgsConstructor @AllArgsConstructor public class Emp { private Integer id; private String username; private String password; private String name; private Short gender; private String image; private Short job; private LocalDate entryDate; private Integer deptId; private LocalDateTime createTime;//创建时间 private LocalDateTime updateTime;//修改时间 } 这里用到了三个注解 @Data 同时包含了toString方法，HashCode，所有get，set方法\n@NoArgsConstructor 是无参构造\n@AllArgsConstructor 是全参构造\nMybatis的增删改查(注解写法) 在文件中创建mapper文件夹，创建对应的Mapper接口\n使用注解@Mapper\n1 2 3 4 5 6 7 8 9 @Mapper//程序开始时会自动创建代理对象 public interface EmpMapper { @Delete(\u0026#34;delete from emp where id=#{id}\u0026#34;) public int delete(Integer id); @Options(useGeneratedKeys = true,keyProperty = \u0026#34;id\u0026#34;) @Insert(\u0026#34;insert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time)\u0026#34; + \u0026#34; values (#{username},#{name},#{gender},#{image},#{job},#{entryDate},#{deptId},#{createTime},#{updateTime})\u0026#34;) public void insert(Emp emp); } 第一个是删除操作，@Delete里面写SQL语句，d=#{id}是Mybatis的占位符 使用Integer是因为int不支持不输入就是null，与SQL语句不吻合\n该删除操作删除的是指定id对象\n第二个是插入操作 写正常的insert语句，然后每个占位符都是JavaBean里面的，注意驼峰命名法\n插入操作的形参是JavaBean对象\nTest类的写法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class SpringBootTest03CrudApplicationTests { @Autowired EmpMapper empMapper; @Test public void testDelete() { int a = empMapper.delete(17); System.out.println(a); } public void testInsert() { //构造员工对象 Emp emp = new Emp(); emp.setUsername(\u0026#34;Tom7\u0026#34;); emp.setName(\u0026#34;汤姆3\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setCreateTime(LocalDateTime.now()); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); //执行新增员工信息操作 empMapper.insert(emp); System.out.println(emp.getId()); } } 在测试类中，先用抽象父类创建对象，然后使用依赖注入@Autowire，等价于EmpMapper empMapp=new EmpMapperA()，把和数据库连接好的bean对象传过来，这样就可以对数据库或者xml等数据载体进行操作了。\n删除操作 前面定义了delete接口是int返回值，这里a返回为删除多少个对象\n1 2 3 public void testDelete() { int a = empMapper.delete(17); System.out.println(a); 插入操作 insert方法要将创建好的对象初始化后使用empMapper.insert(emp)来插入\n如果直接输出emp.getId()是没有结果的，在定义接口的时候使用注解@Options\n1 @Options(useGeneratedKeys = true,keyProperty = \u0026#34; 这样就可以返回Id了\n使用LocalDateTime.now()这个方法最后的返回值符合MySQL的date格式\n修改操作 mapper中的代码\n1 2 3 @Update(\u0026#34;update emp set username =#{username},name=#{name},gender=#{gender},image=#{image},\u0026#34; + \u0026#34;job=#{job},entrydate=#{entryDate},dept_id=#{deptId},update_time=#{updateTime} where id=#{id}\u0026#34;) public void update(Emp emp); Test中的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 public void testUpdate() { Emp emp = new Emp(); emp.setId(1); emp.setUsername(\u0026#34;Tom12\u0026#34;); emp.setName(\u0026#34;汤姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); empMapper.update(emp); } 查询操作 mapper中的代码\n1 2 @Select(\u0026#34;select * from emp where id=#{id}\u0026#34;) public Emp selectById(Integer id); Test中的代码\n1 2 3 4 5 6 public void testSelect() { Integer id=12; Emp emp= new Emp(); emp=empMapper.selectById(id); System.out.println(emp); } 这里是根据id来对数据查询，但是在注入对象empMapper对应的代理对象赋值的时候，数据库中的下划线命名法和java中的驼峰命名法冲突，导致后面使用驼峰命名法的字段赋值失败\n这时候可以在application.properties中输入camel+Tab 1 2 #Mybatis的驼峰命名法映射开关打开 mybatis.configuration.map-underscore-to-camel-case=true 这时候所有输出就对味了\n查询操作ProMax：模糊查询 对员工姓名进行模糊查询，对应的SQL语句是\n1 select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc 其中‘%张%’的意思是其中有一个字是张就行了，前面和后面都有字也在查询范围里面，张无忌，我是张三等名字都可以被查询到，模糊查询要用关键词like，时间范围可以用between\n但是在@Select注解中不能直接这么写，‘%#{name}%’，其中#{name}不能放到引号里面，因为#{name}会在预编译期间变为？，如果是%?%那么任何一个索引都可以被查询到\n1 2 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by updateTime desc\u0026#34;) 可以调用函数concat(\u0026rsquo;%\u0026rsquo;,#{name},\u0026rsquo;%')\nTest代码为\n1 2 3 4 public void testSelectPlus() { List\u0026lt;Emp\u0026gt; empList=empMapper.selectAll(\u0026#34;张\u0026#34;,(short)1,LocalDate.of(2010,01,01),LocalDate.of(2020,01,01)); System.out.println(empList); } LocalDate.of(2010,01,01)可以输入时间\nMybatis的XML写法 要想使用XML映射来实现增删改查需要在resources中添加一致包名和xml文件\n注：在resources里面创建的不是软件包，是资源包，分隔符不是\u0026rsquo;.\u0026lsquo;而是\u0026rsquo;/\u0026rsquo;，之后会自动转化为\u0026rsquo;.\u0026rsquo;,并且之后创建的xml文件要和接口文档命名一致\n两种方法对比：\n1 2 3 4 //条件查询注解法 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by update_time desc\u0026#34;) public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 //xml法 public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; XML法的前面部分是固定语句，可以直接从官网复制\n创建一个接口的xml语句可以先创建好接口，然后按下Alt+Enter点击最上面的选项\n然后就可以在xml文件里编辑了\n想通过这种方式创建得按照下面方式下载MybatisX插件\n在XML文件中，SQL语句很长，可以选中所有SQL语句然后按下Ctrl+Alt+L格式化\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp set username =#{username}, name=#{name}, gender=#{gender}, image=#{image}, job=#{job}, entrydate=#{entryDate}, dept_id=#{deptId}, update_time=#{updateTime} where id = #{id} \u0026lt;/update\u0026gt; 注：Ctrl+Alt+L可能被网易云音乐或者QQ占用，需要去对应的软件中关闭此快捷键\n不管哪一种方法，都要有方法体，只是说把SQL语句移到了xml文件中\n可以在IDEA中下载MybatisX插件，跳转非常方便\n官方提示 使用注解来映射简单语句会使代码显得更加简洁，但对于稍微复杂一点的语句，Java 注解不仅力不从心，还会让你本就复杂的 SQL 语句更加混乱不堪。 因此，如果你需要做一些很复杂的操作，最好用 XML 来映射语句。\n动态SQL语句 实际业务需求:\n所有搜索条件都是null，此时服务器发送数据为查找所有。\n当有搜索条件的时候，也有条件为null\n若直接写刚才的select语句很容易就搜索不到数据，因为搜索对应的值为null和无搜索条件逻辑不符，此时可以引入动态SQL语句\nSelect动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;, #{name}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender = #{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 其中语句可以判断是否有这个条件，如果没有则跳过这条语句。\n可以动态判断是否该加and，如果搜索条件为后面两个条件，那么SQL语句开头就是and导致语法错误，但是where可以解决这个问题\nUpdate的动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;username!=null\u0026#34;\u0026gt;username =#{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt;name=#{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt;gender=#{gender},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image!=null\u0026#34;\u0026gt;image=#{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;job!=null\u0026#34;\u0026gt;job=#{job},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;entryDate!=null\u0026#34;\u0026gt;entrydate=#{entryDate},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;deptId!=null\u0026#34;\u0026gt;dept_id=#{deptId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime!=null\u0026#34;\u0026gt;update_time=#{updateTime}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 这里同样用到了if来设置默认搜索条件，并且引入来判断逗号是否多余导致的SQL语句错误，与的用法一致\n在上述xml写好后，修改条件就可以如下\n1 2 3 4 5 6 7 8 9 public void testUpdate() { Emp emp = new Emp(); emp.setId(12); emp.setUsername(\u0026#34;Sam54235\u0026#34;); /*emp.setName(\u0026#34;萨姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setUpdateTime(LocalDateTime.now());*/ empMapper.update2(emp); } 动态SQL\u0026mdash;批量删除操作 一次性删除多个对象可以这样写SQL语句\n1 delete from emp where id in(18,21); 1 2 3 4 5 6 7 //接口部分这么写 public void deleteById(List\u0026lt;Integer\u0026gt; list); //Test类中这样写 public void deleteTest() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(10, 11); empMapper.deleteById(list); } 因为要删除多个，所以此时传参以集合的方式传递，并且后面集合的名称要和xml中的一致\n在xml中需要这么写\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;deleteById\u0026#34;\u0026gt; delete from emp where id in \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 其中foreach操作可以遍历传递过来的集合list，然后拼凑出所要的sql语句\n其中collection是集合的名称，item是告诉sql语句这时候要按照什么进行删除，separator是SQL语句的分隔符，open和close分别是开始和结尾的字符#{id}通过占位符来加入数据，最后就可以形成(10,11)这样的语句，和之前的delete from emp where id in结合起来就是完整的SQL语句\nSQL代码复用 在企业中直接使用select * from emp速度没有全参访问速度快\n1 2 select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp 1 2 3 4 \u0026lt;sql id=\u0026#34;commonSelect\u0026#34;\u0026gt; select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp \u0026lt;/sql\u0026gt; 这时候可以使用动态SQL语句sql来封装SQL代码\nid就是以后调用的时候的名称\n要调用的时候就这样写\n1 2 3 4 \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; \u0026lt;include refid=\u0026#34;commonSelect\u0026#34;/\u0026gt; /**/ \u0026lt;/select\u0026gt; 简易Web网站开发 前端部分已经写好，我们只用对照产品经理写的API文档接口来写后端程序即可\n创建springboot项目，勾选springweb依赖，lombok依赖，mybaties和MySQL依赖\n在application.properties中配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring.application.name=SpringBootProject01 #????? spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver #??????url spring.datasource.url=jdbc:mysql://localhost:3306/springboottest #????????? spring.datasource.username=root #???????? spring.datasource.password=123456 #??mybatis???, ???????? mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl #??mybatis??????????? a_column ------\u0026gt; aCloumn mybatis.configuration.map-underscore-to-camel-case=true----\u0026gt; aCloumn 配置MySQL信息，MySQL用户名，密码，还有Mybatis的驼峰命名法转蛇形命名法\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping 使用三层架构，分别是DeptController，DeptService，DeptMapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Slf4j @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { Dept dp=new Dept(); @Autowired private DeptService deptService; /*@RequestMapping(value = \u0026#34;/depts\u0026#34;,method = RequestMethod.GET)*/ @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public Result delete(@PathVariable Integer id){ log.info(\u0026#34;删除所选部门数据\u0026#34;); deptService.delete(id); return Result.success(); } @PostMapping() public Result save(@RequestBody Dept dept){ log.info(\u0026#34;添加部门{}\u0026#34;, dept); deptService.save(dept); return Result.success(); } @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable Integer id){ log.info(\u0026#34;根据ID{}查询部门\u0026#34;, id); dp=deptService.select(id); return Result.success(dp); } @PutMapping() public Result update(@RequestBody Dept dept){ log.info(\u0026#34;修改部门{}\u0026#34;, dept); deptService.update(dept); return Result.success(); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/depts)后可以在后面定义类似GetMapping(\u0026quot;/depts/{id}\u0026quot;)时直接省略前面的/depts\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } public void delete(Integer id){ deptMapper.delete(id); } public void save(Dept dept){ dept.setCreateTime(LocalDateTime.now()); dept.setUpdateTime(LocalDateTime.now()); deptMapper.save(dept); } @Override public void update(Dept dept) { dept.setUpdateTime(LocalDateTime.now()); deptMapper.update(dept); } @Override public Dept select(Integer id) { return deptMapper.list1(id); } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示全用xml格式\n1 2 3 4 5 6 7 8 9 @Mapper public interface DeptMapper { /* @Select(\u0026#34;select * from springboottest.dept\u0026#34;)*/ public List\u0026lt;Dept\u0026gt; list(); public void delete(Integer id); public void save(Dept dept); public void update(Dept dept); public Dept list1(Integer id); } xml文件如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;insert id=\u0026#34;save\u0026#34;\u0026gt; insert into springboottest.dept(springboottest.dept.name,springboottest.dept.create_time,springboottest.dept.update_time) values(#{name},#{createTime},#{updateTime}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update springboottest.dept set springboottest.dept.name=#{name},springboottest.dept.update_time=#{updateTime} where springboottest.dept.id=#{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.dept where id=#{id} \u0026lt;/delete\u0026gt; \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;list1\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept where id=#{id} \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n注意到这里update接口应当先根据ID查询到对应的数据，然后再将更改后的数据发送给服务端存储\n点击编辑按钮后，前端发送get请求，将查询到的数据发送到这个窗口页面上\n然后我们可以对其进行修改，然后将改正后的数据通过post请求发送给后端，然后后端对这个数据进行存储，完成了一次更新操作\n@PathVariable注解的使用 当前端发送数据且根据id给后端时，前端的id和后端的id不一定相同\n但是数据库中的内容并不是如此\n所以这里可以通过@PathVariable注解来寻找到之前数据库传过来的正确的id，格式如下\n1 2 3 4 5 6 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable(\u0026#34;id\u0026#34;) Integer id) { log.info(\u0026#34;根据id{}查询数据\u0026#34;,id); Emp emp1=empService.selectId(id); return Result.success(emp1); } @RequestBody注解的使用 前端此时传回来的数据是JSON格式，并不能直接把这个数据转化为对象传给数据库做select或者存储，此时可以通过注解@RequestBody来转化为Java对象,格式如下\n1 2 3 4 5 6 @PutMapping public Result update(@RequestBody Emp emp){ log.info(\u0026#34;{}修改数据\u0026#34;,emp.getUsername()); empService.update(emp); return Result.success(); } 查询emp部分稍有麻烦\n分页查询员工 根据API接口文档\n前端返回的数据为当前页数和每页有多少个数据\n此时后端应当给前端返回的是当前页所查询到的数据和总共数据库中有多少条数据\n后面的查询很简单，可以直接用个select语句来完成\n1 select count(*) from springboottest.emp 前面的数据得用到分页查询，条件为limit #{page},#{pageSize}，\n此时EmpService得设置page和pageSize\n1 2 3 4 5 6 7 8 9 @Override public PojoBean select(String name, Short gender, LocalDate begin, LocalDate end, Integer page, Integer pageSize) { PojoBean pojoBean = new PojoBean(); pojoBean.setTotal(empMapper.count()); pojoBean.setRows(empMapper.list(name,gender,begin,end,(page-1)*pageSize,pageSize)); System.out.println((page-1)*pageSize); System.out.println(pageSize); return pojoBean; } 在数据库中limit 0,5代表第0索引开始，且每页有5个元素，前端应该是第1页，每页有5个元素，因此索引数和前端页码对上的话，索引为(page-1)*pageSize\n分页条件查询员工 此时前端可能会给出查询条件，姓名name，性别gender，入职时间，entryDate\n这些条件可能给，也可能全给，也可能给部分，也可能一个都不给，可以用之前提到的动态SQL语句来解决这个问题，这种复杂的sql语句不能用注解来写，只能通过XML文件配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Emp\u0026#34;\u0026gt; select * from springboottest.emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender=#{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; limit #{page},#{pageSize} \u0026lt;/select\u0026gt; 前端总共返回的数据如下\n1 2 3 4 5 6 7 @GetMapping public Result emp(String name, Short gender, LocalDate begin, LocalDate end, @RequestParam(defaultValue = \u0026#34;1\u0026#34;) Integer page, @RequestParam(defaultValue = \u0026#34;10\u0026#34;) Integer pageSize) { PojoBean pb=empService.select(name,gender,begin,end,page,pageSize); return Result.success(pb); } @RequestParam 注解的使用 @RequestParam注解可以让参数有默认值，这样用户不使用任何条件查询就可以查询到默认的10条记录\n最终给前端因为要返回两种数据，一个是总页数，一个是查询到的员工的list集合\n因此这时候创建一个PojoBean类\n最后把数据封装好后以Result的标准JSON格式返回给前端\n批量删除员工 前端返回的删除指令可能有多条，这时候返回来的是个数组\n1 2 3 4 5 6 @DeleteMapping(\u0026#34;/{ids}\u0026#34;) public Result delete(@PathVariable(\u0026#34;ids\u0026#34;) Integer [] ids) { log.info(\u0026#34;删除所选员工数据\u0026#34;); empService.delete(ids); return Result.success(); } 接受到前端的数据后可以去service层,然后再把数组交给Mapper层\n最后的xml语句为\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.emp where springboottest.emp.id in \u0026lt;foreach collection=\u0026#34;ids\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入jwt的依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package com.test.springbootproject01.interceptor; import ... @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package com.test.springbootproject01.config; import ... @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.test.springbootproject01.Controller; import ... @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } AOP 面向切面/方法编程 要在使用AOP之前先引入依赖\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 一个简单的AOP入门示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.test.springbootproject01.AOP; import ... @Slf4j @Component @Aspect public class TimeAspect { @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) public Object recordTime(ProceedingJoinPoint joinPoint) throws Throwable { //方法启动时间 long startTime = System.currentTimeMillis(); //执行方法 Object result = joinPoint.proceed(); //方法结束时间 long endTime = System.currentTimeMillis(); log.info(joinPoint.getSignature()+\u0026#34;方法执行时间为\u0026#34;+(endTime - startTime) + \u0026#34;ms\u0026#34;); return result; } } 1 @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) execution是用来提示后面是切入点，第一个*指的是返回值为任意类型，com.test.springbootproject01.Service第二个是指任何类，第三个是任何方法，(..)表示匹配任何数量和类型的参数\nNginx的反向代理 后端部署在服务器上默认占用8080端口，前端若也要在服务器上部署，最好不要也选择8080，此时就要用到反向代理。\n打开\nnginx配置界面、\n然后修改这里的代码\nlisten代表前端服务器占用的端口\nlocation /api/ 块说明 1 2 3 location /api/ { proxy_pass http://localhost:8080/emprequest/; } location 指令（/api/ 路径情况）： 这里的 location /api/ 表示匹配所有以 /api/ 开头的客户端请求 URI。例如，像 http://localhost:100/api/user、http://localhost:100/api/order 这样的请求都会进入到这个 location 块中进行后续处理。 proxy_pass 指令： 用于设置反向代理，即将匹配到 /api/ 开头的请求转发到指定的后端服务器地址及路径上。在这里，它会把请求转发到 http://localhost:8080/emprequest/。具体来说，比如前端页面发起了一个 http://localhost:100/api/some-api 的请求，Nginx 会把这个请求去掉 /api/ 这部分前缀后，转发到 http://localhost:8080/emprequest/some-api 这个路径上，让运行在 8080 端口的后端服务器去处理对应的请求，然后后端服务器返回的响应结果又会通过 Nginx 再传递回发起请求的客户端（比如浏览器）。 总体来讲，这段 Nginx 配置定义了一个监听在 100 端口的服务器，针对根路径请求会查找并返回 html 目录下的相关文件，而针对以 /api/ 开头的请求则会将其代理转发到本地 8080 端口下的特定路径上让后端服务进行处理。 此时前端的代码为\n以后设计接口最好这样搞\nTODO标签代表还没做完的事，后面可以查看TODO标签对没写完的代码进行完善\n","date":"2025-03-16T15:38:21+08:00","permalink":"https://LuciusWan.github.io/p/javaweb%E9%83%A8%E5%88%86%E7%AC%94%E8%AE%B0/","title":"JavaWeb部分笔记"},{"content":"API接口文档 1. 文档概述 产品经理的任务 产品经理定义每个版本需要实现的具体功能和细节，通常通过撰写产品需求文档来明确需求。并且撰写API接口文档告诉前后端工程师，怎样开发才能在双方完成任务后，前后端能够完美对接。\n文档目的 API接口文档旨在帮助开发人员了解如何调用和使用本系统提供的API。文档包括了接口的定义、请求与响应格式、错误处理机制等内容。\n系统架构 前端：原生JS 或 Vue.js 后端：Java原生 或 SpringBoot框架 API接口文档示例 部门管理 1.1 部门列表查询 1.1.1 基本信息 请求路径：/depts\n请求方式：GET\n接口描述：该接口用于部门列表数据查询\n1.1.2 请求参数 无\n1.1.3 响应数据 参数格式：application/json\n参数说明：\n参数名 类型 是否必须 备注 code number 必须 响应码，1 代表成功，0 代表失败 msg string 非必须 提示信息 data object[ ] 非必须 返回的数据 \\ - id number 非必须 \\ - name string 非必须 \\ - createTime string 非必须 \\ - updateTime string 非必须 响应数据样例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;学工部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;教研部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; } ] } 2. 前端使用说明 前端框架选择 1. JS原生代码（使用fetch） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fetch(\u0026#39;/depts\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; { if (data.code === 1) { console.log(\u0026#34;部门列表:\u0026#34;, data.data); } else { console.log(\u0026#34;请求失败:\u0026#34;, data.msg); } }) .catch(error =\u0026gt; { console.error(\u0026#39;Error:\u0026#39;, error); }); Vue.js 在Vue组件中，可以使用Axios来简化API调用。\n示例代码（使用Axios发送GET请求）：\n错误处理 前端应对API请求中的常见错误进行处理，如404（未找到），500（服务器错误）等。\n错误处理示例：\n1 2 3 4 5 6 7 8 9 10 fetch(\u0026#39;https://api.example.com/data\u0026#39;) .then(response =\u0026gt; { if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return response.json(); }) .catch(error =\u0026gt; { console.error(\u0026#39;API call failed:\u0026#39;, error); }); 3. 后端实现说明 后端语言/框架选择 Java原生 使用Java原生编写API接口，通常通过HttpServlet处理请求。\n示例代码（Java原生实现GET请求）：\n1 2 3 4 5 6 7 8 9 10 11 import javax.servlet.*; import javax.servlet.http.*; import java.io.*; public class DataServlet extends HttpServlet { protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;application/json\u0026#34;); PrintWriter out = response.getWriter(); out.println(\u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Hello, World!\\\u0026#34;}\u0026#34;); } } SpringBoot 使用SpringBoot框架，MySQL数据库，Mybatis框架来实现后端数据的提供\n示例代码（SpringBoot实现前端Get的请求）：\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping\n使用三层架构，DeptController，DeptService，DeptMapper,响应，处理数据，调取数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //日志输出的注解 @Slf4j //controller层必带的注解 @RestController @RequestMapping(\u0026#34;/dept\u0026#34;) public class DeptController { Dept dp=new Dept(); //依赖注入 @Autowired private DeptService deptService; @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/dept\u0026quot;)后可以在后面定义类似GetMapping(\u0026quot;/dept\u0026quot;)时直接省略前面的/dept\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n统一返回格式大致如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示Mapper层配合xml格式调用数据\n1 2 3 4 @Mapper public interface DeptMapper { public List\u0026lt;Dept\u0026gt; list(); } xml文件如下\n1 2 3 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package com.test.springbootproject01.interceptor; import com.alibaba.fastjson.JSONObject; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import jakarta.servlet.http.HttpServletRequest; import jakarta.servlet.http.HttpServletResponse; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.test.springbootproject01.config; import com.test.springbootproject01.interceptor.LoginCheckInterceptor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.test.springbootproject01.Controller; import com.test.springbootproject01.Service.EmpService; import com.test.springbootproject01.pojo.Emp; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import io.jsonwebtoken.Claims; import io.jsonwebtoken.impl.DefaultClaims; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } java代码是这样的(\n","date":"2025-03-16T15:29:26+08:00","permalink":"https://LuciusWan.github.io/p/api%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"API接口文档使用教程"}]
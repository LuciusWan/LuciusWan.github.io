[{"content":"Redis学习与实战 缓存穿透 缓存穿透是指客户端请求的数据,Redis和Mysql里面都没有,缓存永远不会生效,如果客户端一直请求相同的id,请求就会一直到达数据库,给数据库上压力了.\n解决方案1:缓存空对象 缓存空对象:如果客户端请求找不到的数据,就把找不到的数据缓存到Redis里,并且设置过期时间,在一定时间内,客户端的空对象请求不会经过Mysql\n缺点:有额外内存消耗,如果管理端新增对象和空对象id相同,可能造成缓存与数据库内容不一致\n解决缓存穿透的业务逻辑: 对应的java逻辑代码: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result getByIdRedis(Long id) { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 解决方案2:布隆过滤 缓存穿透后,穿透的信息进入布隆过滤器,如果再进行查询,先查询布隆过滤器,如果这个id是穿透信息,就直接拒绝查询\n其他解决方案: 做好热点参数的限流\n加强用户权限校验\n缓存雪崩 缓存雪崩是指大量数据同时到期,或者Redis服务直接宕机,大量请求涌入Mysql)\n简单解决办法 把数据存储进Redis的时候直接随机过期时间存储\njava代码如下（其实就是生成随机数) 1 2 3 4 5 private Long cacheAvalanche(){ Random random=new Random(); Long number=random.nextInt(11)+20L; return number; } 其他高级解决方案: Redis集群,分布式部署\n给缓存业务添加降级限流策略,如果redis集体驾崩,就直接拒绝大量请求,防止MySQL数据库压力过大\n给业务添加多级缓存\n缓存击穿 一个热点数据过期,大量线程同时访问,每个线程都选择查询完Redis后查询数据库,导致数据库压力剧增\n解决方案1:互斥锁 使用Redis的setnx作为互斥条件,所有线程同时设置一个键值对,只有一个线程可以设置成功,并且操作数据库,写入缓存,写完后释放锁资源\n1 2 3 4 5 6 7 8 9 10 11 12 13 //设置锁和释放锁的方法 private Boolean setLock(String key){ Boolean flag= stringRedisTemplate.opsForValue().setIfAbsent(key,\u0026#34;1\u0026#34;,10,TimeUnit.SECONDS); if(flag==null){ return false; }else if(flag){ return true; } return false; } private void unLock(String key){ stringRedisTemplate.delete(key); } 互斥锁解决缓存穿透的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result getByIdRedis(Long id) throws InterruptedException { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程休眠对应的时间后重新尝试获取资源(递归) }else { Thread.sleep(50); getByIdRedis(id); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 其中为防止获得锁的线程挂了不会释放锁资源,给锁设置过期时间\n解决方案2:逻辑过期时间 在Redis中存储数据时,多存储一条过期时间,如果过期的话,最快发现的线程会主动申请互斥锁,并且查询数据库,查完后设置过期时间并且写回redis,同时返回给客户端,其他的线程请求完锁后,请求不到就直接返回过期的数据,这种方式可以防止死锁的发生,但是牺牲了一部分redis空间 java代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Override public Result redisLogicExpireTime(Long id){ String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); logger.info(shop); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ RedisData redisData=JSONUtil.toBean(shop,RedisData.class); //判断是否过期 if(redisData.getExpireTime().isAfter(LocalDateTime.now())){ Shop shopRedis= redisData.getData(); System.out.println(shopRedis); logger.info(\u0026#34;查询redis直接输出\u0026#34;); return Result.ok(shopRedis); } } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null\u0026amp;\u0026amp;shop.equals(\u0026#34;\u0026#34;)){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,cacheAvalanche(), TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } RedisData redisData=new RedisData(); redisData.setData(shop1); redisData.setExpireTime(LocalDateTime.now().plusMinutes(cacheAvalanche())); String json= JSON.toJSONString(redisData); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,cacheAvalanche(), TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程直接返回过期的数据 }else { RedisData redisData=new RedisData(); redisData.setData(JSONUtil.toBean(shop,Shop.class)); Shop redis=redisData.getData(); return Result.ok(redis); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 订单秒杀问题 限量限时商品可能会在短时间内面临大量请求,可能会出现超卖的情况\n如果第一次遇到1的时候没来得及写到数据库里,后面的线程查询的时候遇到的还是1,就可以继续执行扣减的操作,导致超卖的情况发生\nJMeter测试结果 200次线程请求直接超卖了9个商品\n解决方案1:乐观锁 • 假设：乐观锁假设冲突发生的概率很小，允许多个事务同时操作数据，但在提交时检查是否有其他事务修改了数据。\n• 实现：通常通过版本号（version）或时间戳（timestamp）实现。在更新数据时，比较当前版本号与数据库中的版本号，如果一致则更新并增加版本号；如果不一致，则说明数据已被其他事务修改，需要重新获取数据并重试。\n• 适用场景：适用于读多写少的场景，或者数据竞争不激烈的情况下。\nJava实现 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .eq(\u0026#34;stock\u0026#34;, seckillVoucher.getStock()) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } 在写入数据库之前,先查询数据库目前的值和之前查询到的是否一样,是否在写入之前被修改了,如果被修改了就不能写入\nJMeter测试结果 可以发现成功率低的可怜,200次请求只抢到了21张票,原因就是每次写入都要查询到之前是否已经写过,请求频率太高,导致不写入的概率也更高,写入越多的情况越不能用乐观锁\n解决方案2:悲观锁 • 假设：悲观锁假设会发生冲突，即多个事务会同时修改同一数据，因此它在操作开始时就锁定数据，防止其他事务修改。\n• 实现：通常通过数据库的锁机制实现，如行锁、表锁等。\n• 适用场景：适用于写操作频繁的场景，或者数据竞争非常激烈的情况下。\n只要在每次写入更新结果之前先查看一下剩余的量是不是大于0就可以了\nJava代码 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } JMeter测试结果 200次请求,只卖出100张,异常比例正确\n单人订单问题 有些商品给购买者限量,比如买火车票或者限定周边,如果一个黄牛用脚本在短时间大量请求,则有可能会多卖\n简单解决\n1 2 3 4 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } JMeter测试结果显示,200个请求同时下单,一共能购买10张票\n解决方案:共享锁 在 Java 中， synchronized是一个关键字，用于控制对共享资源的访问，确保在同一时刻只有一个线程可以访问特定的代码块或方法。这是实现线程同步的一种方式，主要用于解决多线程环境下的并发问题。\n我们可以把订单秒杀的代码先抽离出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Transactional(rollbackFor = Exception.class) public Result createVoucherOrder(Long voucherId) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); voucherOrderMapper.insert(voucherOrder); return Result.ok(voucherOrder.getVoucherId() + \u0026#34;下单成功\u0026#34;); } 如果是对整个函数加锁,也就是在public后面,那么不是同一个用户也会被锁给拦截,性能不高\n或者可以给锁限定userId,如果同一id就被拦截,串行进行\n1 2 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) 这里intern的作用是,toString会导致产生新的字符串对象,字符串对象虽然值是相同的,但是哈希值不一样,被锁认为是不同的对象,这时用intern可以从字符串池里找相同的串,哈希值相同\n锁应当在事务结束之后再释放才行,否则又会产生冲突,事务还没结束,有个线程又进来了,会引发异常,因此应当把锁放到整个方法外面\n1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } JMeter测试结果 200次买票,只买到1次,解决了单人买票的问题\n上述写法依然有问题\nJava魅力时刻 1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } 注意到这里的return createVoucherOrder(voucherId);是目标对象引用的函数，相当于\nreturn this.createVoucherOrder(voucherId);但是只有代理对象才有事务管理的功能,代理对象就是加上@Controller,@Service,@Mapper,@Component,@Bean的对象,这个对象协助目标对象完成工作.\n要想在这个对象里面调用代理对象可以通过如下办法\n1 2 3 4 5 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } AopContext.currentProxy()获取本类的代理对象,然后从Object转成本类的对象,然后调用对应的方法,要在接口里面重新声明这个方法\n同时要引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectjweaver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.22.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在springboot启动类上加注解\n1 @EnableAspectJAutoProxy(exposeProxy = true) 允许SpringIOC容器暴露代理对象,这样我们才能正常获取代理对象\nRedis实现分布式锁 如果现在同时开两个进程,服务器集群部署,由nginx实现负载均衡,实现轮询发送请求,先给8081端口发送,再给8082端口,导致进程内的锁无法和另一个进程的锁联动\n这时可以使用伟大的Redis制作分布式锁来解决这个问题!\n分布式锁的设计 这个锁应当起到互斥作用,很多个线程同时发送过来,只能有一个线程获取锁资源,因此得用setnx.\n在此线程结束运行的时候应当及时释放锁资源,防止服务器资源浪费,及时del key\n如果一个服务器在发送完这个请求后就宕机了,不会执行这个释放锁资源的代码,那么锁资源就不会被释放,导致其他服务器资源浪费.这时候就要给锁设置过期时间,到时间自动释放锁资源\n如果在还没执行expire time的时候服务器就宕机了,那么锁资源一样不会被释放,这时候就得这么写获取锁的语句\n1 set lock thread1 nx ex 10 保持了原子性,让互斥和过期时间一起设置\n同时采用非阻塞的锁,防止很多线程一直等待锁资源释放,尝试一次,如果没获取锁资源就return false,成功就return true\nJava代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { Long threadId = Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId+\u0026#34;\u0026#34;,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } 将分布式锁加入业务逻辑 1 2 3 4 5 6 7 8 9 10 11 12 Long userId =UserHolder.getUser().getId(); SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock=lock.tryLock(1200L); if(!isLock){ return Result.fail(\u0026#34;一人只能买一张票\u0026#34;); } try{ IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); }finally { lock.unlock(); } 分布式锁误删问题: 由于业务阻塞,导致线程1获取锁后没有及时释放锁资源,锁自动释放,线程2请求锁成功,开始执行业务逻辑\n这时候线程1完成业务,执行释放锁的指令,导致业务2的锁被意外删除,以此类推,锁会被意外删除.\n改进办法很简单,只要每次执行删除锁之前先查询锁的线程是否是自己的,是自己的就可以删,不是自己的就跳过.\nJava代码改进 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.UUID; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private static final String ID_PREFIX = UUID.randomUUID().toString(); private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { String threadId =ID_PREFIX+ Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { String UnlockName= stringRedisTemplate.opsForValue().get(LOCK_PREFIX+lockName); String threadId =ID_PREFIX+ Thread.currentThread().getId(); if(threadId.equals(UnlockName)){ stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } } 对程序打断点调试,获取锁后拦截,当我修改这里的ThreadId并且重新放行后,这里的新锁并没有被删掉,解决了误删的问题.\nLua脚本 当我们使用最新的分布式锁的时候,如果在执行finally语句里面的代码时,遭遇JVM进行垃圾回收,这时候会遇到无法战胜的业务阻塞,,代码还是没有做到原子性.如果已经验证完这个线程对应这个锁后突然垃圾回收,那么就会导致del锁这个操作会很危险.\n这时候可以把整个unlock操作用Lua脚本完成\n在Redis客户端使用lua脚本 无参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,\u0026#39;name\u0026#39;,\u0026#39;jack\u0026#39;)\u0026#34; 0 语句的意思是使用脚本,脚本是一个字符串,就是引号里面的,脚本相当于set name jack 0代表没有参数\n有参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,KEYS[1],ARGV[1])\u0026#34; 1 dinglz sb 用KEYS[1]和ARGV[1]作为占位符,后面有一对参数\n使用lua脚本解决删除锁问题 1 2 3 4 5 6 7 8 --查询锁的id local id=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(ARGV[1]==id) then --释放锁 return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) end --不是自己的锁,不用释放锁 return 0 Java代码调用Lua脚本 把lua脚本创建在这个目录下,等下方便读取 重写unlock方法 1 2 3 4 5 6 7 8 9 @Override public void unlock() { List list = new ArrayList(); list.add(LOCK_PREFIX+lockName); stringRedisTemplate.execute( UNLOCK_SCRIPT, list, ID_PREFIX+ Thread.currentThread().getId()); } 向redis传输指令,显示脚本,然后是参数,KEYS[1]参数要用集合封装,第二个参数是线程id也就是ARGV[1]\n同时要配置好脚本\n1 2 3 4 5 6 private static DefaultRedisScript\u0026lt;Long\u0026gt; UNLOCK_SCRIPT; static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unLock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 设置文件位置,然后设置返回格式,返回值为0表示删除锁失败,1表示删除锁成功\nRedisson Redisson是一个封装好的分布式锁工具,这里面的锁是已经写好的,并且比前文介绍的锁多一些功能和奇效\n引入依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置Redisson 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.hmdp.config; import org.redisson.Redisson; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RedissonConfig { @Bean public RedissonClient redisson() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://Yourip:Yourport\u0026#34;).setPassword(\u0026#34;Yourpassword\u0026#34;); return Redisson.create(config); } } @Configuration注解 这里顺带提一嘴Springboot框架面试高频考点,@Configuration是什么,和@Component有啥区别. @Configuration是配置类要添加的注解,它的构成是\n1 2 3 4 5 6 7 8 9 10 11 12 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Component public @interface Configuration { @AliasFor( annotation = Component.class ) String value() default \u0026#34;\u0026#34;; boolean proxyBeanMethods() default true; } 这里面也有@Component,但是它比前者多实现单例模式\n如果你在创建Bean对象的时候一次性创建多个,Spring容器并不会去对象池去找是否有已经创建过的对象,而是直接再创建,这样无法保证单例性\n而如果用@Configuration就可以只创建一次Bean对象\n使用Redisson制作分布式锁 1 2 3 //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); 中间那一行代码就等价于之前写的SimpleRedisLock\nRedisson解决不可重入 不可重入导致死锁 如果一个线程请求锁资源,然后又请求了一次锁资源,第二次请求会失败,因为已经有线程获取过锁,并且就是自身,这导致了这个线程请求不到锁,也释放不了锁,导致了死锁.\n解决方案 于是Redisson改变了锁的结构,让锁的数据结构变为Hash,key存储锁的名称,field存储线程名称,value存储该锁被同一个线程调用了几次,每次调用会给value自增,如果释放锁资源就value自减一次,如果value==0,那么就删除这个锁资源.\nRedisson解决不可重试 不可重试导致大量请求失败 正常线程如果获取锁失败就直接返回false了,或者说一直循环递归等待下去,导致了大量请求无法返回客户需要的内容\n解决方案 1 Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); 注意到我们之前在设置tryLock的时候设置了尝试时间1L,单位是秒.这个意思是我可以总共等待1秒,如果这1秒内获取到锁资源,就返回true,如果没请求到就返回false,当然这个1L可以改为任何数值.\nRedisson的tryLock原码 1 2 3 4 5 6 7 long time = unit.toMillis(waitTime); long current = System.currentTimeMillis(); long threadId = Thread.currentThread().getId(); Long ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { return true; } ttl是剩余等待时间,后面的tryAcquire是看是否获取锁成功,如果获取锁成功就返回null,如果获取成功就返回剩余等待时间.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 else { current = System.currentTimeMillis(); RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } else { boolean var16; try { time -= System.currentTimeMillis() - current; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); boolean var20 = false; return var20; } do { long currentTime = System.currentTimeMillis(); ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { var16 = true; return var16; } time -= System.currentTimeMillis() - currentTime; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); var16 = false; return var16; } currentTime = System.currentTimeMillis(); if (ttl \u0026gt;= 0L \u0026amp;\u0026amp; ttl \u0026lt; time) { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); } else { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(time, TimeUnit.MILLISECONDS); } time -= System.currentTimeMillis() - currentTime; } while(time \u0026gt; 0L); this.acquireFailed(waitTime, unit, threadId); var16 = false; } finally { this.unsubscribe(subscribeFuture, threadId); } return var16; } } 主要看else中的原码,如果获取锁失败,并且要进入等待,RFuture subscribeFuture = this.subscribe(threadId）指的是这个线程订阅了请求的锁的信息,如果锁被释放了,这个线程就会收到信息,这正是观察者模式.但是这个等待并不是无限制的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } 如果时间到达上限了,直接返回false,并且取消订阅.\n如果时间没到上限,就再尝试获取锁,没获取到就继续订阅,因为很多线程同时请求过来,得按顺序获取锁.直到获取到锁或者直接到时间才结束这个循环.\nRedis本地集群部署 只要改一下端口号就能实现本地的Redis集群\n在config文件下修改端口号\n用记事本或者vscode打开都可以,然后按下Ctrl+F搜索6379,下面的端口号改成没设置过的端口号,但也不要跟其他进程冲突了,我这里改为了6381\n然后分别启动Redis就实现Redis集群了\nRedisson实现分布式联锁 1 2 3 4 RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); 使用随机一个redisson客户端来调用它的.getMultiLock方法就可以制作出联锁\n联锁就可以在Redis集群的情况下,所有Redis共有一把锁,以免出现重复申请锁资源的情况\ngetMultiLock会尝试同时获取所有指定的锁，只有当所有锁都成功获取时，才算加锁成功。如果任何一个锁获取失败，它会回滚已经获取的锁，确保加锁操作的原子性。\n通过将多个锁的获取和释放封装在一起，getMultiLock简化了在复杂业务场景下的并发控制逻辑，减少了开发人员在处理多个锁时的错误风险。\n其中redisson.getMultilock使用任意一个对象都可以的原因是,这里是统一新创建\n1 2 3 public RLock getMultiLock(RLock... locks) { return new RedissonMultiLock(locks); } 通过这样制作联锁,可以让每一个Redis都有lock\n异步秒杀问题 将超卖和判重用Redis解决 把卖票过程比喻成厨子做饭,如果饭店只有一个人,那么他自己得招待顾客,还得自己下厨,但是这时候多来了个服务员,服务员负责招待顾客下单,厨子只是来做菜,卖票过程就是用Redis作为先手,把订单都收到手了,交给后端再交给数据库来异步处理这些订单.\nJMeter测试数据时,随着时间请求量会增长,因此可能会面对短时间超高并发,并且现有的代码还有很多查询MySQL的操作,比如:\n查询优惠券剩余数量,查询stock\n顾客是否已经买过一张票,查询是否有这个订单\n于是我们可以通过改变订单流程来解决\n在商家添加优惠券信息的时候就把优惠券的信息和数量同步到Redis\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+voucher.getId()+\u0026#34;:stock\u0026#34;,voucher.getStock().toString()); } 然后在请求到达后端时,先查询Redis,判断优惠券数量是否够,这个用户是否下过单了\nlua脚本 由于一次性操作Redis次数过多,直接使用多条java语句没有原子性,因此要用lua脚本 1 2 3 4 5 6 7 8 9 10 local stock=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(tonumber(stock)\u0026lt;1) then return 1 end local success = redis.call(\u0026#39;SADD\u0026#39;, KEYS[2], ARGV[1]) if(success==0) then return 2 end redis.call(\u0026#39;decr\u0026#39;,KEYS[1]) return 0 由于KEYS传过来时必须得是String类型,而只有number才能比较大小,因此先转化为数字,如果票没了就返回1.\nRedis的set集合 Redis的set集合在插入的时候,要判重,如果重复就不能插入,返回0,如果插入成功就返回1,故可以作为锁.\n多人秒杀的存储效果是这样的\n然后就可以写代码调用脚本了\n1 2 3 4 5 6 7 8 9 10 11 //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } 后端接受到可以下单的信息后制作订单\n1 2 3 4 5 6 7 8 9 Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); 然后把订单数据交给阻塞队列来异步执行,这里要用java自带的阻塞队列,然后多创建一个线程来解决这些下单问题\n1 2 3 4 5 6 7 8 9 //创建阻塞队列 private BlockingQueue\u0026lt;VoucherOrder\u0026gt; queue=new ArrayBlockingQueue\u0026lt;VoucherOrder\u0026gt;(1024*1024); //创建线程池 private static final ExecutorService SECKILL_ORDER_EXECUTOR= Executors.newSingleThreadExecutor( ); //在启动类初始化完就马上把 @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); }着重讲一下\n@PostConstruct 注解：\n当类的实例被创建后，Spring容器会自动调用这个方法。\n通常用于执行一些初始化操作，比如启动线程、加载配置等。\nSECKILL_ORDER_EXECUTOR：\n它的作用是管理线程的生命周期，避免频繁创建和销毁线程的开销。 submit(new VoucherOrderHandler())：\nsubmit方法将一个任务提交到线程池中执行。\nVoucherOrderHandler实现了Runnable接口的类\n这里创建了一个VoucherOrderHandler实例，并将其提交到线程池中，线程池会选择一个空闲线程来执行这个任务。\n这是线程池的任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //给线程池分配任务 private class VoucherOrderHandler implements Runnable{ @Override public void run() { while(true){ try{ VoucherOrder voucherOrder=queue.take(); voucherHandler(voucherOrder); }catch (Exception e){ System.out.println(\u0026#34;订单处理异常\u0026#34;+e.getMessage()); } } } } 在队列中有元素的时候,子线程取出voucherOrder对象,然后解决下单问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private void voucherHandler(VoucherOrder voucherOrder) throws InterruptedException { Long userId=voucherOrder.getUserId(); //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ proxy.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;id为\u0026#34;+userId+\u0026#34;的顾客买到票了\u0026#34;); lock.unlock(); } } 注意到这是个子线程的任务,子线程的任务无法获得代理对象,也就是SpringBoot的IOC容器管理的对象,但是我们需要事务回滚,所以还是得用代理对象,所以只能把代理对象作为私有变量,然后在类的方法中对这个私有代理对象进行赋值\n1 2 3 4 5 6 7 8 private IVoucherOrderService proxy; @Override public Result order(Long voucherId) { ... //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); ... } 然后改进createVoucherOrde方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Transactional(rollbackFor = Exception.class) public void createVoucherOrder(VoucherOrder voucherOrder) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherOrder.getVoucherId(),voucherOrder.getUserId()); if(!list.isEmpty()){ return ; } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherOrder.getVoucherId()) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return ; } voucherOrderMapper.insert(voucherOrder); } 至此,异步下单已经初步完成了.\nJMeter测试 由于要实现多人秒杀,所以就得用多个账户登录来抢票,但是找不到1000个真人来测试,总不能一个一个敲登录来获取token吧,所以可以写一个自动登录1000个账户的测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.hmdp; import com.hmdp.utils.RedisConstants; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.HashMap; import java.util.Map; import java.util.UUID; import java.util.concurrent.TimeUnit; @SpringBootTest public class TokenTest { private static final Integer NUMBER_OF_TOKEN = 1000; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN+1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token= UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY+token,map); System.out.println(token); stringRedisTemplate.expire(token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); } } } 在 Redis里存一份即可,然后把所有的token输出出来,后面拿来给JMeter,这样绕过了拦截器\n把tokens存到txt文件中\n在JMeter里面这样设置一下\n注意那个路径就是txt文件存储位置\n然后改一下登录状态头\n然后就可以开始测试了!\n测试结果:\n1000人抢200张票,只有20%成功率,80%的异常率,测试成功\nRedis实现消息队列 认识消息队列 消息队列（Message Queue，简称MQ）是一种在软件架构中用于实现应用程序之间异步通信的中间件。它允许一个或多个生产者（消息的发送者）将消息发送到队列中，然后由一个或多个消费者（消息的接收者）从队列中读取消息。消息队列的主要作用是解耦、缓冲、异步通信和负载均衡等,可以用来削峰填谷,减轻服务器和数据库的处理压力。 之前有用到spring的阻塞队列,但是这个阻塞队列效果不是很好,如果中途服务挂机了,或者说停机后JVM会强制删除所有内存数据,那么后续请求就无法完成,并且不保留记录.这时候就需要外部的消息队列了,这里先用Redis实现,后面还可以用实现好的消息队列,kafka,RocketMQ\nRedis要求: redis必须达到5版本及其以上,这里使用的是stream数据结构来制作消息队列\nRedis单消费模式 我们可以使用XADD来向消息队列里面加入元素,用XREAD来读取消息队列的元素\n1 XADD users * k2 v2 第一次redis会去查存储空间里面有没有users这个消息队列如果没有就创建\n这个语句的意思是添加名称为users的消息队列,然后*为自动生成id,k2 v2为一个键值对\n添加成功后会返回一个数据\u0026quot;1743079174227-0\u0026quot;这是一个时间戳,用来唯一标识这个队列\n同样的我们可以用XREAD来读取消息队列中的数据\n1 XREAD count 1 streams users 0 这个语句的意思是读消息,一次读一条,读取消息队列users的消息,并且从0开始读\n1 XREAD count 1 block 0 streams users $ 这个语句的意思是读取users的消息,($)读取最新的消息,然后无限阻塞,直到有消息进入队列就读取一条消息.\n这样看上去一个消息队列建好了,但是有bug,如果存储数据时间较长,存储数据没来得及存储完,又传来了一堆新的消息,$只能读取最新的消息,导致中间有很多消息都漏掉了\nRedis消费者组模式 省流版: 消费者组里面有很多消费者,它们是竞争关系,都来争着处理消息,可以解决消息漏处理的问题\n消息表示指的是最后被处理的消息会被打上标签,就像看书有个书签,看完后下次再看就立马知道在哪了\n消息确认就跟TCP三次握手相似,只是没有最后一段客户端向服务端的确认信息,每次处理完信息都会确认一下,并且有个pending-list,如果没处理这个消息就根据这个list继续处理\n创建消费者组 1 XGROUP CREATE users group1 0 这个语句的意思是在users这个消息队列中创建消费者组,如果没有users这个消息队列就会创建失败,这个消费者组的名称为group1,每次从id=0开始读\n通过消费者组读消息队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743074094428-0\u0026#34; 2) 1) \u0026#34;k1\u0026#34; 2) \u0026#34;v1\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743079174227-0\u0026#34; 2) 1) \u0026#34;k2\u0026#34; 2) \u0026#34;v2\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082841091-0\u0026#34; 2) 1) \u0026#34;k3\u0026#34; 2) \u0026#34;v3\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082847320-0\u0026#34; 2) 1) \u0026#34;k4\u0026#34; 2) \u0026#34;v4\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082852967-0\u0026#34; 2) 1) \u0026#34;k5\u0026#34; 2) \u0026#34;v5\u0026#34; 这个语句的含义是通过消费者组进行读取,group的名称是group1(刚刚创建的),消费者名称叫c1(随便取的名字,没有的话会自动创建),每次消费一条信息,阻塞2秒,消息队列名称为users,选择从最早发过来的未读消息开始读,\u0026gt;换成0可以使因为之前处理消息的时候,服务器炸了,重新处理的时候读取pending-list,直接从未处理完成的消息继续处理\n确认信息方法XACK 1 2 XACK users group1 1743074094428-0 1743079320687-0 1743082841091-0 1743082847320-0 (integer) 4 前面是消息队列名称和消费者组名,后面是消息被消费后发出的时间戳\n通过如下语句查询pending-list\n1 2 3 4 5 6 xpending users group1 1) (integer) 1 2) \u0026#34;1743079174227-0\u0026#34; 3) \u0026#34;1743079174227-0\u0026#34; 4) 1) 1) \u0026#34;c1\u0026#34; 2) \u0026#34;1\u0026#34; 通过Redis实现消息队列替代阻塞队列 其实没必要这么实现(绝对不是因为我这边IDEA无法识别我写的函数才不实现的)\n我们可以直接上正经的消息队列\n通过RabbitMQ替代阻塞队列 RabbitMQ是个消息队列,文档非常完整好懂,可以通过文档学习.要使用RabbitMQ要先下载,这里我在ubuntu虚拟机上下载并使用这个消息队列\n在 Ubuntu 上安装 RabbitMQ 通常需要以下步骤：\n1. 更新系统包列表 在安装任何软件之前，建议先更新系统的包列表，以确保安装的软件是最新的版本。运行以下命令：\n1 sudo apt update 2. 安装 Erlang RabbitMQ 是基于 Erlang 编程语言开发的，因此需要先安装 Erlang。可以使用以下命令安装 Erlang：\n1 sudo apt install erlang 3. 添加 RabbitMQ 的官方仓库 为了获取最新版本的 RabbitMQ，建议添加 RabbitMQ 的官方仓库。运行以下命令：\n1 2 3 sudo apt install apt-transport-https wget -O- https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add - echo \u0026#34;deb https://dl.bintray.com/rabbitmq/debian $(lsb_release -sc) main\u0026#34; | sudo tee /etc/apt/sources.list.d/rabbitmq.list 4. 更新包列表 添加完官方仓库后，需要再次更新包列表：\n1 sudo apt update 5. 安装 RabbitMQ Server 现在可以安装 RabbitMQ 了。运行以下命令：\n1 sudo apt install rabbitmq-server 6. 启动和启用 RabbitMQ 服务 安装完成后，RabbitMQ 服务应该会自动启动。可以通过以下命令检查服务状态：\n1 sudo systemctl status rabbitmq-server 如果服务未启动，可以手动启动并设置开机自启：\n1 2 sudo systemctl start rabbitmq-server sudo systemctl enable rabbitmq-server 7. 配置 RabbitMQ（可选） 如果需要进行额外配置，例如设置用户、权限等，可以使用以下命令：\n添加用户：\n1 sudo rabbitmqctl add_user myuser mypassword 设置用户权限：\n1 2 sudo rabbitmqctl set_user_tags myuser administrator sudo rabbitmqctl set_permissions -p / myuser \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; 启用管理插件（用于访问 Web 管理界面，默认端口为 15672）：\n1 sudo rabbitmq-plugins enable rabbitmq_management 正式使用RabbitMQ 按照以上步骤下载完rabbitmq后,我们可以打开网址馆里rabbitmq\nhttp://虚拟机的ip地址:15672\n注! 如果你用的不是docker下载的rabbitmq,那么你虚拟机的ip地址会改变,下次连不上rabbitmq有可能是因为ip地址变了 rabbitmq管理界面长这样\n你可以在主机上打开,也可以在虚拟机上打开,第一次登录只能在虚拟机上打开,因为有默认账号密码.输入账号:guest,密码:guest.然后进去后可以给自己之前用命令行创建的用户改权限\n点击创建的用户,这样修改权限\n这样你就可以用后端语言操控rabbitmq了!\n然后我们就可以打开心爱的IDEA\n引入maven坐标 先引入几个maven坐标\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--rabbitMQ的maven坐标--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 注意:springboot2.0版本只能用这套maven坐标,要用3.0版本maven坐标的话会出bug\n配置rabbitmq 先写好yaml\n然后这样写配置类,把rabbitmq交给IOC容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package com.hmdp.config; import com.hmdp.properties.RabbitMQProperties; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitMQConfig { @Autowired private RabbitMQProperties rabbitMQProperties; @Bean public ConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(rabbitMQProperties.getHost()); connectionFactory.setUsername(rabbitMQProperties.getUsername()); connectionFactory.setPassword(rabbitMQProperties.getPassword()); connectionFactory.setVirtualHost(rabbitMQProperties.getVirtualHost()); connectionFactory.setPort(rabbitMQProperties.getPort()); return connectionFactory; } @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { return new RabbitTemplate(connectionFactory); } @Bean public Queue voucherOrderQueue() { return new Queue(\u0026#34;voucher_order_queue\u0026#34;, true); } } 之前我们用的是阻塞队列,单独为消费者new了个线程来处理消息,现在我们可以创建一个消费者类,并且把对象交给IOC容器,让这个消费者持续处理信息\n消费者类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package com.hmdp.Consumer; import com.hmdp.entity.VoucherOrder; import com.hmdp.service.IVoucherOrderService; import org.redisson.api.RLock; import org.redisson.api.RedissonClient; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import org.springframework.transaction.annotation.Transactional; import javax.annotation.Resource; import java.util.concurrent.TimeUnit; @Component public class VoucherOrderConsumer { @Autowired private IVoucherOrderService voucherOrderService; @Resource private RedissonClient redisson6379; @Resource private RedissonClient redisson6380; @Resource private RedissonClient redisson6381; @Transactional @RabbitListener(queues = \u0026#34;voucher_order_queue\u0026#34;) public void handle(VoucherOrder voucherOrder) throws InterruptedException { //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ voucherOrderService.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;订单处理成功：\u0026#34; + voucherOrder.getId()); lock.unlock(); } } } 然后ServiceImpl类就成为了生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override public Result order(Long voucherId) { //查询优惠券信息 SeckillVoucher seckillVoucher = seckillVoucherMapper.selectById(voucherId); //判断秒杀是否开始 LocalDateTime timeEnd = seckillVoucher.getEndTime(); LocalDateTime timeBegin=seckillVoucher.getBeginTime(); if(timeBegin.isAfter(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动暂未开始\u0026#34;); }else if (timeEnd.isBefore(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动现已结束\u0026#34;); } //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long id=redisId.nextId(\u0026#34;order\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } Long userId= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(id); // 使用 RabbitMQ 发送消息 rabbitTemplate.convertAndSend(\u0026#34;voucher_order_queue\u0026#34;, voucherOrder); //queue.add(voucherOrder); //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); return Result.ok(\u0026#34;下单成功\u0026#34;+id); } 这样我们就使用了rabbitmq作为消息队列完成了异步秒杀.这只是rabbitmq的一点实力,后面我可能会专开一个坑来学rabbitmq\n测试类更新 简单更新了一下测试类 把token一键写入.txt文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Test public void test1() { // 指定文件路径 String filePath = \u0026#34;C:\\\\Users\\\\86180\\\\Desktop\\\\Test\\\\秒杀订单TOKEN数据.txt\u0026#34;; File file = new File(filePath); // 如果文件不存在则创建文件夹和文件 if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } // 如果文件存在，先清空文件内容 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file))) { writer.write(\u0026#34;\u0026#34;); // 清空文件内容 } catch (IOException e) { e.printStackTrace(); } // 写入新的 token 数据 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file, true))) { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN + 1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token = UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY + token, map); stringRedisTemplate.expire(RedisConstants.LOGIN_USER_KEY + token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); // 将 token 写入文件 writer.write(token); writer.newLine(); // 换行 } } catch (IOException e) { e.printStackTrace(); } } 一键刷新测试数据,让我们和JMETER再抢一千次优惠券吧!!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.hmdp; import com.hmdp.mapper.SeckillVoucherMapper; import com.hmdp.service.impl.VoucherOrderServiceImpl; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; @SpringBootTest public class RefreshData { private static final Long VOUCHER_ID=16L; private static final Long STOCK=1000L; @Autowired private VoucherOrderServiceImpl voucherOrderService; @Autowired private SeckillVoucherMapper seckillVoucherMapper; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { //删除所有订单 voucherOrderService.deleteByVoucherId(VOUCHER_ID); //将剩余票数刷新为指定数值 seckillVoucherMapper.updateByVoucherId(VOUCHER_ID,STOCK); //同步修改redis的剩余票数 stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:stock\u0026#34;,STOCK+\u0026#34;\u0026#34;); //删除redis的set stringRedisTemplate.delete(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:set\u0026#34;); } } 点赞功能 问题分析 点赞要求我们第一次点上去是点赞数+1,再点一次是点赞数-1,这完全可以交给数据库去解决,然后就是点赞前五名的人要展示在页面上,这时候可以用到redis的ZSET,排序集合\n业务逻辑: 点赞后,java代码查看是否点赞过,没点赞就点赞数+1,同时记录这个人点赞的时间戳,作为ZSET的排序依据,越早点赞的人越靠前,所有人都加入这个集合,点过赞再点就取消之前点赞,并且从这个集合中remove.查看点赞前五的代码就只用根据时间戳选择前五个用户就好,下面是代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Override //更新点赞 public void updateLike(Long id) { Long userId= UserHolder.getUser().getId(); //获取时间戳 long timestamp = System.currentTimeMillis(); //向ZSET中插入,看是否点过赞了 Boolean success = stringRedisTemplate.opsForZSet().add(RedisConstants.BLOG_LIKED_KEY + id, userId.toString(), timestamp); if(!Boolean.TRUE.equals(success)){ //点过了赞就无法插入,就取消点赞,点赞数减一,从点赞集合中移除用户 boolean success1 =update().setSql(\u0026#34;liked = liked - 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); if(success1) { stringRedisTemplate.opsForZSet().remove(RedisConstants.BLOG_LIKED_KEY + id, userId.toString()); } }else{ //没点过赞就可以插入,点赞数量加一 update().setSql(\u0026#34;liked = liked + 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result selectLike(Long id) { //从ZSET中取最早点赞的5个人 Set\u0026lt;String\u0026gt; ids = stringRedisTemplate.opsForZSet().range(RedisConstants.BLOG_LIKED_KEY + id, 0, 4); if(ids==null||ids.size()==0){ return Result.ok(); } //获取点赞人的Id,然后查表,查到人后返回icon和username List\u0026lt;Long\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); for (String userId : ids) { list.add(Long.parseLong(userId)); } String strId= StrUtil.join(\u0026#34;,\u0026#34;,ids); List\u0026lt;User\u0026gt; users = userService.query() .in(\u0026#34;id\u0026#34;, ids) .last(\u0026#34;order by field(id,\u0026#34;+strId+\u0026#34;)\u0026#34;) .list(); List\u0026lt;UserDTO\u0026gt; userDTOS = new ArrayList\u0026lt;\u0026gt;(); for (User user : users) { UserDTO userDTO = new UserDTO(); //只返回icon,userId和userName,其实userName都可以不传 BeanUtils.copyProperties(user, userDTO); userDTOS.add(userDTO); } return Result.ok(userDTOS); } 关注与互关 关注 关注很好办,只用在数据库的follow表中插入一条数据,谁关注了谁,业务逻辑非常EZ\n查看互关 现在有用户A,B,C.A关注了C,B也关注了C,这时候我们如果是A,我们盒B的账号的时候就能发现,我们共同关注了C,实现这个功能需要两个关注列表取交集,这就可以用到Redis的SET集合了\n在关注好友的时候同时创建集合,集合名就是被关注用户的ID,集合内容就是关注者的ID\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public Result followServer(Long bloggerId, Boolean isFollow) { Long userId= UserHolder.getUser().getId(); if(isFollow){ Follow follow=new Follow(); follow.setUserId(userId); follow.setFollowUserId(bloggerId); follow.setCreateTime(LocalDateTime.now()); followMapper.insert(follow); stringRedisTemplate.opsForSet().add(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;的用户关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); }else if(!isFollow){ followMapper.deleteByUserId(userId,bloggerId); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;取消关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); stringRedisTemplate.opsForSet().remove(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); } return Result.ok(); } 然后我们写查询共同关注者的时候就可以用set的\n下面是redis里实现set的取交集\n1 2 3 4 5 6 7 8 127.0.0.1:6379\u0026gt; SADD key1 a b c d (integer) 4 127.0.0.1:6379\u0026gt; SADD key2 c d e f (integer) 4 127.0.0.1:6379\u0026gt; SADD key3 a c e (integer) 3 127.0.0.1:6379\u0026gt; SINTER key1 key2 key3 1) \u0026#34;c\u0026#34; 在java代码中我们可以这么写,用java中的Set集合接收共同关注者的id\n1 Set\u0026lt;String\u0026gt; intersect = stringRedisTemplate.opsForSet().intersect(RedisConstants.FOLLOW + userId.toString() , RedisConstants.FOLLOW+id.toString()); 然后共同关注就做好了\nfeed流\u0026amp;滚动分页查询 Feed流是一种常见的信息展示方式\nfeed流定义 Feed流是一种基于用户社交关系或兴趣偏好的信息分发机制。它通过动态地向用户推送个性化的内容，让用户在浏览过程中能够快速获取到自己感兴趣的信息。\n核心特点 个性化推荐：Feed流会根据用户的浏览历史、兴趣标签、社交关系等多维度数据，为每个用户量身定制内容。例如，抖音会根据用户点赞、关注、评论等行为，推荐相关的短视频；微博会根据用户的关注列表和兴趣偏好，推送微博动态。\n动态更新：内容会实时更新，用户每次刷新页面或打开应用时，都能看到最新的信息。这种动态性让用户能够及时获取到新鲜的内容，增强了用户的粘性和活跃度。\n分析B站的推送机制 当你特别关注了一个up主,那个up主每次发视频就会私信发送给你,这叫推模式,直接推送给个人\n如果你直接去查看up主的主页,你就能看到他所有的内容,这种叫拉模式,拉取up主的所有内容\n上述两种模式,推模式不适合大V,如果不特别关注就推送,那么网络资源消耗过大.\n这次我要用Redis实现推模式,写一个feed流\n设计思路 我们要实现推流,就要在博主发送blog的时候把信息发到关注他的粉丝账号上,我们先查数据库,找到粉丝id,然后选取Redis数据结构来存储推流信息.\nList和SortedSet都可以来记录有序集合,但是要实现分页滚动查询,还是用ZSET好 我们可以这样写保存blog的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Override public Result saveBlog(Blog blog) { // 获取登录用户 UserDTO user = UserHolder.getUser(); blog.setUserId(user.getId()); // 保存探店博文 boolean saveSuccess = blogService.save(blog); if(!saveSuccess){ return Result.fail(\u0026#34;发布笔记失败\u0026#34;); } List\u0026lt;Long\u0026gt; idList=userMapper.selectByFollower(user.getId()); if(idList!=null\u0026amp;\u0026amp;!idList.isEmpty()){ for(Long id:idList){ stringRedisTemplate.opsForZSet().add(RedisConstants.FEED_KEY + id, blog.getId().toString(), System.currentTimeMillis()); } } // 返回id return Result.ok(blog.getId()); } 存储结果是这样的\n我们以时间戳作为分数,越靠前的blog时间戳大,到时候用户最先看到的就是最新消息\n滚动分页查询 用户每次查询2条记录,记录按照时间戳来排序,第一次查询的最大时间戳为当前时间,要找到最新的消息,后面再查就是上一次查到的最小的时间戳,然后偏移量加一,因为要查询后面两条,偏移量是通过之前重复时间戳数量计算出来的,当很多人同时建立blog时,时间戳可能会一样,这时候就得去重,加上偏移量\n附Java代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result queryBlogByUserId(Long time, Long offset) { Long userId=UserHolder.getUser().getId(); Set\u0026lt;ZSetOperations.TypedTuple\u0026lt;String\u0026gt;\u0026gt; typedTuples; if(offset==0){ typedTuples= stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, System.currentTimeMillis(), offset, 2); }else{ typedTuples = stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, time, offset, 2); } if(typedTuples==null|| typedTuples.isEmpty()){ return Result.fail(\u0026#34;没有文章可以看了捏\u0026#34;); } List\u0026lt;Blog\u0026gt; blogs = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Long\u0026gt; score=new ArrayList\u0026lt;\u0026gt;(); for (ZSetOperations.TypedTuple\u0026lt;String\u0026gt; object : typedTuples) { score.add(Objects.requireNonNull(object.getScore()).longValue()); Blog blog = blogMapper.selectById(Long.parseLong(Objects.requireNonNull(object.getValue()))); blogs.add(blog); } int count=1; Long lastScore=score.get(0); for (int i = 1; i \u0026lt; score.size(); i++) { if(score.get(i)!=lastScore){ count=1; lastScore=score.get(i); }else{ count++; } } ScrollResult scrollResult = new ScrollResult(); scrollResult.setList(blogs); scrollResult.setMinTime(score.get(score.size()-1)); scrollResult.setOffset(count); return Result.ok(scrollResult); } 注意reverseRangeByScoreWithScores函数参数顺序,集合名称,分数最小值,分数最大值,偏移量,查询信息数,这个函数可以同时返回score和value\n最后的效果: Redis-Geo实现搜索附近商户 Redis-Geo可以实现两个经纬度之间的距离测算\n比如我给出一个店铺的经纬度是87.588076 43.841359\n我的坐标是87.5795849 43.81927399\n那我们可以通过redis计算出这两地之间的距离\n1 2 3 4 5 6 7 8 localhost:6379\u0026gt; geoadd g1 87.529252 43.841359 urmuqizhan (integer) 1 localhost:6379\u0026gt; geoadd g1 87.588076 43.8242569 ShenZhenCheng (integer) 1 localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng \u0026#34;5088.3803\u0026#34; localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng km \u0026#34;5.0884\u0026#34; 这里我们通过geoadd语句添加了两地坐标,然后通过geodist计算出了两地之间的距离,如果限定输出格式的话,默认是米,可以限制输出为千米\n软件设计思路 用户要查看周围店铺的时候,我们就要按照距离顺序来给用户推荐,比如美团外卖的最近店铺,用户会给我们自己的坐标,也就是经纬度,我们要做的就是按照他传过来的位置和店铺位置算一个距离数据,然后排序查询后的搜索结果,返回给前端.\n注意到这里面有typeId,表示店铺的类型,比如美食,娱乐等等\n我们要在redis上存储这些店铺的信息,先把经纬度存进去,还有店铺的ID,还有typeId,我们这样可以设计\nshop:geo表示redis数据类型,1表示typeId\n具体实现 当我们把查询到的typeId用来查询所有相关的店铺\n1 2 3 4 5 6 7 GeoResults\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; result = stringRedisTemplate.opsForGeo().search( key, GeoReference.fromCoordinate(x, y), //默认米为单位,5公里 new Distance(5000), RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end) ); 这个函数的参数为,key,用户坐标,查询附近5km的所有店铺,查询到分页表的最后一个下标,因为redis没有设置from 到end的查询方式,所以只能全查了,这样查出来的就按照距离顺序\n这里同时查询出来了距离和店铺的id,我们可以这样取出所有值\n1 2 3 4 5 6 7 8 9 10 11 List\u0026lt;Long\u0026gt; ids=new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Distance\u0026gt; distances=new ArrayList\u0026lt;\u0026gt;(); for (GeoResult\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; r : result) { if (sum\u0026lt;from) { sum++; continue; } RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt; location = r.getContent(); ids.add(Long.valueOf(location.getName())); distances.add(r.getDistance()); } 然后查询数据库,把店铺所有信息和距离返回给前端\n1 2 3 4 5 6 7 for (int i =0;i\u0026lt;ids.size();i++) { Shop shop= shopMapper.selectById(ids.get(i)); shop.setDistance(Double.valueOf(distances.get(i).toString().replaceAll(\u0026#34;[^\\\\d.]\u0026#34;, \u0026#34;\u0026#34;))); if(shop!=null){ shops.add(shop); } } 最后结果就是这样了\n查询的时候是按照距离来搜的,并且附带距离\n","date":"2025-03-16T20:30:40+08:00","permalink":"https://LuciusWan.github.io/p/redis%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E6%88%98/","title":"Redis学习与实战"},{"content":"Redis高级篇 Redis持久化 RDB(RedisDatabase) RDB 会在指定的时间间隔（比如每 5 分钟）对 Redis 的内存数据进行一次“拍照”，生成一个二进制文件（dump.rdb）。这个文件可以自己设置名称,默认为dump.rdb.这个文件包含了当时的所有数据状态。\n如果 Redis 崩溃了，重启时会加载最近的dump.rdb来恢复数据。\n如果使用命令save可以直接保存rdb文件\n每次启动Redis的时候Redis就会访问这个rdb文件来获取以前的数据\n每次关闭Redis服务端的时候都会生成一个新的dump.rdb\n文件就在这里\n如果只是关机的时候使用,万一什么时候Redis宕机了,就无法恢复数据了,这时候得用间隔保存了,这时候只需要打开Redis配置文件,修改如下字段\n# save \u0026quot;\u0026quot;表示注释掉了 Redis 的默认 RDB 持久化策略（即禁用默认的自动快照生成）。\n下面的意思是900秒内有1次操作就保存一次,300秒内10次操作就自动保存一次,60秒内有10000次操作就保存一次.\nfork 子进程：Redis 调用 fork() 创建一个子进程，子进程与主进程共享内存数据。\nCOW（Copy-On-Write）：\n子进程开始快照操作时，主进程仍可处理客户端请求并修改数据。 当主进程修改某个数据页时，操作系统会将该页复制一份（写时复制），子进程看到的仍是修改前的数据。 子进程将所有数据页写入磁盘生成 .rdb 文件，而主进程不影响快照的一致性。 COW有缺点就是,如果我的Redis已经占用了很高的内存,此时我要修改的数据也很多,复制的数据非常多会导致内存溢出\n并且修改次数多,导致复制次数也多,开销也很大\n修改次数少的时候如果宕机就会导致大部分数据丢失\nAOF（Append-Only File） AOF则是记录每一次操作Redis的命令,把命令记录在磁盘中,如果后面需要恢复就再执行一次所有Redis命令,下面的就是AOF文件\n只有修改了redis.conf中的如下文件后才能使用\n有如下三种记录频率\n第一个是每写一次命令,执行完后就写入磁盘,然后返回信息,这样就很慢了,和直接操作数据库没有区别,第二个方法是隔了一秒后进行,实现了异步处理,顶多丢失1秒的数据,最后一种由操作系统判断什么时候写回磁盘,推荐使用第二种.\n下面是AOF文件中的内容\n如果我写三个如下命令\n1 2 3 4 5 6 127.0.0.1:6379\u0026gt; set name111 dinglz OK 127.0.0.1:6379\u0026gt; set name111 wfg OK 127.0.0.1:6379\u0026gt; set name111 666 OK 这样直接写入aof文件会比较占内存,可以使用如下命令来重写AOF文件\n1 BGREWRITEAOF 重写后的文件如下\n直接就看不懂了,但是这样确实简化了AOF文件,不用连续设置三次才得到最终数据.\n1 2 3 127.0.0.1:6379\u0026gt; bgrewriteaof Background append only file rewriting started 127.0.0.1:6379\u0026gt; 可以看到这个命令甚至是在后台执行的\n通常情况下是两种持久化机制一起使用,可以保证数据的稳定性\nRedis主从同步 主从同步示例要三个Redis,我们可以使用windows本地复制三个Redis文件,然后修改配置文件,端口号6379,6380,6381,或者直接用docker,pull下redis的最新版本,然后创建三个实例.\n分别启动三个Redis的服务端,然后再Redis-cli的6380上输入如下名令\n1 slaveof 127.0.0.1 6379 意思是Redis6380要成为6379的从节点\n也可以使用如下命令\n1 replicaof 127.0.0.1 6379 这时候6380就是6379的从节点了\n当我们在6379上使用set命令\n1 2 3 127.0.0.1:6379\u0026gt; set number 111 OK 127.0.0.1:6379\u0026gt; 那么从节点上也可以看到被修改了\n1 2 3 4 5 6 ~ .\\redis-cli.exe -p 6381 -h localhost localhost:6381\u0026gt; replicaof localhost 6379 OK localhost:6381\u0026gt; get number \u0026#34;111\u0026#34; localhost:6381\u0026gt; 这就实现了主从同步\n全量同步 在我们输入slaveof host port之后,slave向master发送了自己的replid和offset,id和master肯定不一样,这时候就告知master这时候得做全量同步,清空slave本地缓存,把master生成的RDB发给slave进行数据同步.\n并且在建立主从关系后,master会把自己的命令都交给slave去做数据同步,增量同步.\n增量同步 repl_baklog是记录了RDB期间的所有命令的一个文件,是环状读写的,每次做增量同步的时候slave都会发送自己的offset,master在自己的repl_baklog表中查找offset,如果找到的话就把offset后面的数据交给master.下图红绿交接就是offset\n如果slave宕机了,而且时间还挺长,master写repl_baklog文件已经覆盖了offset,那此时只能做一个全量同步.\n可以从以下几个方面来优化Redis主从就集群:\n在master中配置repl-diskless-syncyes启用无磁盘复制，避免全量同步时的磁盘IO。\nRedis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO\n适当提高repl baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力,可以直接从其他slave上直接读取数据,而不是都找master\n哨兵模式 哨兵的工作原理 Redis的哨兵（Sentinel）是一个监控和故障转移系统，用于管理Redis主从复制架构中的高可用性。它在Redis 2.8版本中被引入，主要目的是解决当主节点出现故障时，如何自动完成故障发现和故障转移的问题。以下是关于Redis哨兵的一些\n哨兵每一秒广播发送一次ping命令,告诉所有节点,自己没有宕机\n如果某个节点在指定时间内没有响应，则会被标记为“主观下线”。如果主节点被标记为主观下线，哨兵会询问其他哨兵实例，根据多数哨兵的意见决定是否将其标记为“客观下线”。\n客观下线后就会触发主从交换,选出一个offset最大的slave,向其发送slaveof no one,让其成为master节点,然后强制修改原主节点的配置文件,让那个redis slave of新的master,然后让所有节点都执行slaveof新master.\n","date":"2025-05-13T20:22:24+08:00","permalink":"https://LuciusWan.github.io/p/redis%E9%AB%98%E7%BA%A7%E7%AF%87/","title":"Redis高级篇"},{"content":"Linux实战 OpenEuler安装 可以参考这个up主的视频 B站视频链接 下载VirtualBox虚拟机 在浏览器官网搜索virtualBox官网Oracle VirtualBox然后直接下载即可\n打开VirtualBox后发现并没有操作系统(),那么我们就再去浏览器下载openEuler操作系统\n下载OpenEuler操作系统 在浏览器上搜索OpenEuler社区openEuler | 开源社区 | openEuler社区官网\n点开后找到Offline Everything ISO，下载就好了\n事实上并没有删除()\n在VirtualBox中加载OpenEuler 点击注册,然后按照下图配置\n然后新建虚拟电脑的时候配置一下\n全都配置好就可以使用了\n注意!!!一定要记住自己的root密码 OpenEuler实践报告 一、实验环境 操作系统：OpenEuler（通过VirtualBox虚拟机运行） 编译器：GCC 二、作业要求的代码 例1：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { fork(); fork(); fork(); printf(\u0026#34;hello\\n\u0026#34;); return 0; } 例2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { int x = 1; pid_t p = fork(); if(p \u0026lt; 0){ perror(\u0026#34;fork fail\u0026#34;); exit(1); } else if (p == 0) printf(\u0026#34;Child has x = %d\\n\u0026#34;, ++x); else printf(\u0026#34;Parent has x = %d\\n\u0026#34;, --x); return 0; } 例题一操作 创建文件并输入代码：\n1 vim example1.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example1.c -o example1 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example1 观察输出结果。\n运行结果及分析 例1运行结果：\n1 2 3 4 5 6 7 8 hello hello hello hello hello hello hello hello 例一分析： 每次fork()调用都会创建一个新的进程，三次fork()会创建8个进程（2^3），每个进程都会执行printf(\u0026quot;hello\\n\u0026quot;);，所以输出8次\u0026quot;hello\u0026quot;。\n例题二操作 创建文件并输入代码：\n1 vim example2.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example2.c -o example2 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example2 观察输出结果。\n运行结果及分析 例2运行结果：\n例二分析：\n父进程和子进程各自拥有变量x的独立副本。 子进程中x的值被递增（++x），所以输出2。 父进程中x的值被递减（--x），所以输出0。 五、总结 通过本次实践，我掌握了在Linux环境下使用GCC编译C代码的基本流程，理解了fork()系统调用的原理和用法，以及进程控制的基本概念。同时，也熟悉了在OpenEuler操作系统下的开发环境和工具的使用。\nHW3-多线程-git 1. 编写和编译多线程代码 1.1 创建代码文件 在Linux命令行中，使用vi或nano编辑器创建一个名为pthread_hello.c的文件：\n1 vi pthread_hello.c 编写如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; /* Thread function that prints \u0026#34;Hello World\u0026#34; */ void *worker(void *arg) { printf(\u0026#34;Hello World!\\n\u0026#34;); return NULL; /* Thread exits (dies) */ } int main() { pthread_t thread; int ret; /* Create a new thread */ ret = pthread_create(\u0026amp;thread, NULL, worker, NULL); if (ret != 0) { perror(\u0026#34;pthread_create failed\u0026#34;); return 1; } /* Wait for the thread to finish */ pthread_join(thread, NULL); return 0; } 1.2 编译代码 使用gcc编译代码，并链接pthread库：\n1 gcc pthread_hello.c -o pthread_hello -lpthread 1.3 运行程序 运行编译后的程序：\n1 ./pthread_hello 输出结果为：\nHello World!\n2. 使用Git管理项目 2.1 创建项目目录 在主目录下创建一个名为os_practice的项目目录：\n1 2 mkdir os_practice cd os_practice 2.2 初始化Git仓库 初始化Git仓库：\n1 git init 2.3 创建子目录 为每次的实践创建单独的子目录，例如：\n1 2 mkdir hw1 cd hw1 将pthread_hello.c文件复制到该目录下：\n1 cp ~/pthread_hello.c . 2.4 添加文件到Git 将文件添加到Git仓库：\n1 git add pthread_hello.c 2.5 提交更改 提交更改并添加描述信息：\n1 git commit -m \u0026#34;Added pthread Hello World example\u0026#34; 2.6 检查Git状态 检查当前Git仓库的状态：\n1 git status 提交代码至github 在github中注册好之后,创建代码仓库 创建好之后,使用github给的bash代码 1 2 3 4 5 6 7 echo \u0026#34;# OS-HomeWork\u0026#34; \u0026gt;\u0026gt; README.md git init git add README.md git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/LuciusWan/OS-HomeWork.git git push -u origin main 然后本地仓库就和github连上了.\n我们可以在本地编译,提交代码至github仓库\n分别使用下面bash语句\n1 2 3 git add . git commit -m \u0026#34;update\u0026#34; git push git add .\n将当前工作区中的所有更改（包括新文件、修改的文件和删除的文件）添加到 Git 的暂存区\ngit commit -m \u0026ldquo;update\u0026rdquo;\n将暂存区中的更改正式提交到本地仓库，并添加一条提交信息。\n提交（commit）是 Git 的一个快照，记录了当前暂存区中的所有更改。\n-m \u0026quot;update\u0026quot; 是提交信息，用来描述这次提交的内容或目的。\n提交信息是可选的，但强烈建议添加，以便以后能够清楚地了解每次提交的更改内容。\ngit push\n很好理解,把本地仓库修改内容和修改信息一并推送到远程仓库\n提交后,我们的仓库就会发生变化 OS第一次上机课 作业内容如下\n任务二 编写nosync-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) sum += 1; } int main(void) { pthread_t tid1, tid2; pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下不上锁,线程之间互相抢资源,导致线程错误,最终结果错误\n结果如下:\n1 2 3 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim nosync-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc nosync-ex.c -o nosync-exadmin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./nosync-ex 1000000 + 1000000 = 1172208 编写mutex-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; pthread_mutex_t mutex; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { pthread_mutex_lock(\u0026amp;mutex); sum += 1; pthread_mutex_unlock(\u0026amp;mutex); } } int main(void) { pthread_t tid1, tid2; pthread_mutex_init(\u0026amp;mutex, NULL); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下可以上锁,线程之间只能有一个能使用锁资源,保证了线程安全,结果正确\n结果如下\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim mutex-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc mutex-ex.c -o mutex-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./mutex-ex 1000000 + 1000000 = 2000000 编写sem-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; int sum = 0; sem_t sem; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { sem_wait(\u0026amp;sem); sum += 1; sem_post(\u0026amp;sem); } } int main(void) { pthread_t tid1, tid2; sem_init(\u0026amp;sem, 0, 1); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 信号量可以通过其操作原语（如 sem_wait() 和 sem_post()）实现互斥访问,这里使用了信号量保证了线程安全,结果正确\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim sem-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc sem-ex.c -o sem-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./sem-ex 1000000 + 1000000 = 2000000 任务三 编写生产者消费者问题 生产者消费者问题是一个消息队列,实现了异步处理,可以达到削峰填谷的作用\n代码实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define BUFFER_SIZE 5 #define NUM_ITEMS 10 int buffer[BUFFER_SIZE]; int count = 0; // 当前缓冲区中的元素数量 int in = 0, out = 0; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t full = PTHREAD_COND_INITIALIZER; pthread_cond_t empty = PTHREAD_COND_INITIALIZER; void* producer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == BUFFER_SIZE) { pthread_cond_wait(\u0026amp;full, \u0026amp;mutex); // 等待缓冲区不满 } buffer[in] = i; printf(\u0026#34;Produced: %d at position %d\\n\u0026#34;, i, in); in = (in + 1) % BUFFER_SIZE; count++; pthread_cond_signal(\u0026amp;empty); // 通知消费者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } void* consumer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == 0) { pthread_cond_wait(\u0026amp;empty, \u0026amp;mutex); // 等待缓冲区不空 } int item = buffer[out]; printf(\u0026#34;Consumed: %d from position %d\\n\u0026#34;, item, out); out = (out + 1) % BUFFER_SIZE; count--; pthread_cond_signal(\u0026amp;full); // 通知生产者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } int main() { pthread_t prod, cons; pthread_create(\u0026amp;prod, NULL, producer, NULL); pthread_create(\u0026amp;cons, NULL, consumer, NULL); pthread_join(prod, NULL); pthread_join(cons, NULL); return 0; } 运行结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc MesssageQueue.c -o MessageQueue admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./MessageQueue Produced: 0 at position 0 Produced: 1 at position 1 Produced: 2 at position 2 Produced: 3 at position 3 Produced: 4 at position 4 Consumed: 0 from position 0 Consumed: 1 from position 1 Consumed: 2 from position 2 Consumed: 3 from position 3 Consumed: 4 from position 4 Produced: 5 at position 0 Produced: 6 at position 1 Produced: 7 at position 2 Produced: 8 at position 3 Produced: 9 at position 4 Consumed: 5 from position 0 Consumed: 6 from position 1 Consumed: 7 from position 2 Consumed: 8 from position 3 Consumed: 9 from position 4 消息队列的容量上限为5个item,因此当生产者获取消息队列资源后给这个资源上锁,只有生产者可以向里面写入数据,可以看到从0-4一共五个数被填入消息队列,然后由于队列已满,通知消费者读取数据,消费者读取了0-4的数据后由于消息队列中没有元素,消费者释放锁资源,并且通知生产者可以生产数据,生产者继续生产5-9的数据,队列又满,通知消费者读取,最后完成所有数据的生产消费,进程结束.\nGit提交代码 使用命令,把所有文件提交到工作区\n1 git add . 然后使用命令提交代码\n1 git commit -m \u0026#34;update\u0026#34; 查看提交记录\n1 git log 结果如下\n提交成功\n","date":"2025-03-21T14:01:52+08:00","permalink":"https://LuciusWan.github.io/p/linux%E5%AE%9E%E6%88%98/","title":"Linux实战"},{"content":"Docker初体验 Docker 是什么 Docker 是一个应用打包、分发、部署的工具\n你也可以把它理解为一个轻量的虚拟机，它只虚拟你软件需要的运行环境，多余的一点都不要，\n而普通虚拟机则是一个完整而庞大的系统，包含各种不管你要不要的软件。\n跟普通虚拟机的对比 特性 普通虚拟机 Docker 跨平台 通常只能在桌面级系统运行，例如 Windows/Mac，无法在不带图形界面的服务器上运行 支持的系统非常多，各类 windows 和 Linux 都支持 性能 性能损耗大，内存占用高，因为是把整个完整系统都虚拟出来了 性能好，只虚拟软件所需运行环境，最大化减少没用的配置 自动化 需要手动安装所有东西 一个命令就可以自动部署好所需环境 稳定性 稳定性不高，不同系统差异大 稳定性好，不同系统都一样部署方式 打包、分发、部署 打包：就是把你软件运行所需的依赖、第三方库、软件打包到一起，变成一个安装包\n分发：你可以把你打包好的“安装包”上传到一个镜像仓库，其他人可以非常方便的获取和安装\n部署：拿着“安装包”就可以一个命令运行起来你的应用，自动模拟出一模一样的运行环境，不管是在 Windows/Mac/Linux。\n下载\u0026amp;安装docker 下面是桌面版链接,点击下载\nhttps://www.docker.com/products/docker-desktop\n推荐下载这个\n下载完后是个exe文件,点开后开始安装\n我们在安装完成后可能会遇到这个报错\n这是因为我们没开启虚拟化,如果你下载过Linux虚拟机应该就不会有这个错误,同时我们还要下载Linux子系统,跟着引导来就好\n解决方法：\n控制面板-\u0026gt;程序-\u0026gt;启用或关闭 windows 功能，开启 Windows 虚拟化和 Linux 子系统（WSL2)\n要确定BIOS支持虚拟化\n添加镜像源 我们如果每次都到docker官方去获取镜像,那么没有魔法就会非常慢,所以我们可以添加镜像源\n可用的国内镜像源如下.可以添加多个镜像源\n镜像加速器 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://ud6340vz.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 用docker安装软件 我们可以下载个redis玩玩\n下载Redis镜像 打开命令提示符（CMD）或PowerShell，然后使用以下命令从Docker Hub下载官方的Redis镜像：\n1 docker pull redis 这将下载最新版本的Redis镜像。你也可以指定版本号来下载特定版本的Redis镜像，例如：\n1 docker pull redis:latest 运行Redis容器 下载完成后，你可以使用以下命令来启动一个Redis容器：\n1 docker run --name my-redis -d -p 6379:6379 redis 这里的参数解释如下：\n--name my-redis：为容器指定一个名称，这里是my-redis。 -d：表示以分离模式运行容器,在后台运行。 -p 6379:6379：将容器的6379端口映射到宿主机的6379端口，这样你就可以通过宿主机的6379端口访问Redis服务。 验证Redis服务 为了验证Redis服务是否正常运行，你可以使用以下命令连接到Redis容器：\n1 docker exec -it my-redis redis-cli 这将打开一个Redis命令行接口。你可以在这里输入Redis命令来测试服务，例如：\n1 ping 如果服务正常运行，你应该看到输出PONG。\n我们可以在docker的终端上打开redis并使用 停止和删除容器 当你完成测试并想要停止Redis容器时，可以使用以下命令：\n1 docker stop my-redis 要删除容器，可以使用：\n1 docker rm my-redis 如果你想要强制删除正在运行的容器，可以添加-f参数：\n1 docker rm -f my-redis 配置Redis密码（可选） 如果你需要为Redis设置密码，可以在运行容器时通过环境变量REDIS_PASSWORD来设置。例如：\n1 docker run --name my-redis -d -p 6379:6379 -e REDIS_PASSWORD=mypassword redis redis-server --requirepass mypassword 这将设置Redis的密码为mypassword。之后，你需要使用这个密码来连接到Redis服务。\n制作自己的镜像 我们可以把自己的项目打包成一个镜像,让这个镜像在别的电脑上不配环境就能跑起来\n下面是springboot项目的制作镜像案例\n在制作镜像的时候,我们要先写一个dockerfile,这个dockerfile怎么写可以直接问AI\nSpringBoot的dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 使用官方的 OpenJDK 作为基础镜像,写清楚你的jdk版本 FROM openjdk:17-jdk-alpine # 设置工作目录 WORKDIR /app # 将构建好的 JAR 文件复制到镜像中 COPY target/你的jar包的名字.jar /app/app.jar # 暴露应用运行的端口（例如 Spring Boot 默认的 8080 端口） EXPOSE 8083 # 设置容器启动时运行的命令 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;] 这个文件就跟src和pom.xml坐一桌(放一块)就行了\n然后我们就可以通过下面的命令来制作这个docker镜像\n1 docker build -t test:v1 . test是镜像的名称,v1是版本号\n然后我们可以在本地跑一下这个镜像\n1 docker run -p 8083:8083 --name test-hello test:v1 \u0026ndash;name test-hello指的是容器的名称是test-hello,后面跟的是要跑的是什么镜像的什么版本\n多容器通信 多容器通信的意义 在Docker中，多容器通信是指多个容器之间能够相互发现并进行数据交换的能力。\n这种通信机制在构建微服务架构和分布式应用时尤为重要，因为它允许不同服务之间高效地协作。\nDocker提供了多种网络模式来实现容器间的通信，包括桥接网络（Bridge）、主机网络（Host）、覆盖网络（Overlay）以及Macvlan网络等。\n在本地,我们通过本地回环的测试网络localhost127.0.0.1来相互通信,前端代码,后端代码,中间件,数据库等都通过127.0.0.1通信,而我们在docker部署多个容器并没有这样一个网络实现容器间通信,这时候就要用这样个网络.\n上面三种网络形式挺麻烦的,我们直接用docker-compose.yml,当容器多了,这种方法的好处就体现出来了. 举个例子 我的这个项目要用到3个redis,还有rabbitmq,下面这个是我的docker-compose.yml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 services: springboot-app: image: test:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: YourUserName RABBITMQ_DEFAULT_PASS: YourPassword #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network networks: my-network: 我们的这个网络就叫my-network,然后所有的容器都配置在这一个文件中,我们只需要在项目目录里面加上这个yml文件就可以准备启动整个项目了\n在这里打开终端,然后输入如下命令\n1 docker-compose up -d 然后项目就启动了\n这样可以方便快捷的实现容器间的通信互联\n容器的通信路由 我们的容器现在都在一个网络下了,我们要通过域名来访问对应的容器\n比如我这个java代码,这是Redisson的配置代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.config; import ... @Configuration public class RedissonConfig { @Autowired private RedisProperties redisProperties; @Bean public RedissonClient redisson6379() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis1:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6380() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis2:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6381() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis3:6379\u0026#34;); return Redisson.create(config); } } ip地址localhost改写为容器的名称,也就是容器的域名\n后面的端口一定要是镜像暴露出来的端口,redis暴露出来的就是6379端口\nrabbitmq的配置也要改\n1 2 3 4 5 6 rabbitmq: host: rabbitmq port: 5672 username: YourUserName password: YourPassword virtual-host: / host要改为容器名称.\nDocker部署MySQL 修改docker-compose.yml 想要在docker上部署MySQL,先要关掉MySQL的本地服务,可以直接在任务管理器里找mysql,然后关闭这个任务即可.\n然后修改docker-compose.yml，加上这个即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: YourDataBaseName #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network 1 2 volumes: - ./mysql/data:/var/lib/mysql 这个语句的意思是挂载目录\n挂载目录 在使用 Docker 部署 MySQL 时，挂载目录（通常使用 Docker 的 volume 功能）主要有以下几个目的：\n1. 数据持久化 背景：Docker 容器是无状态的，当容器被删除或重新启动时，容器内部的数据（如 MySQL 数据库文件）会丢失。\n解决方案：通过挂载宿主机的目录到容器内部，可以将 MySQL 的数据文件存储在宿主机上。这样，即使容器被删除或重新启动，数据仍然可以被保留。\n2 . 方便数据迁移 背景：当需要将数据库从一个环境迁移到另一个环境时，数据的迁移是一个关键步骤。\n解决方案：通过挂载目录，可以直接将宿主机上的数据目录复制到新的宿主机上，然后启动新的 MySQL 容器，从而实现数据的迁移。\n示例：\n1 2 # 将数据目录从旧宿主机复制到新宿主机 scp -r /path/to/mysql-data user@new-host:/path/to/mysql-data 具体就是这个语句让我本地建了个文件夹，实现了持久化存储\n然后我们在终端上登录mysql,使用对应的数据库,然后把表数据填进去就可以再次启动容器了\n实现多端负载均衡 我的这个项目是开了8083和8084端口同时接受前端请求,用nginx实现负载均衡,目前只开放了8083端口,修改docker-compose.yml即可\n修改docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network 加入这个语句即可,启动后就实现了多端口接收数据\n发布Docker镜像 镜像仓库介绍 镜像仓库用来存储我们 build 出来的“安装包”，Docker 官方提供了一个 镜像库，里面包含了大量镜像，基本各种软件所需依赖都有，要什么直接上去搜索。\n我们也可以把自己 build 出来的镜像上传到 docker 提供的镜像库中，方便传播。\n当然你也可以搭建自己的私有镜像库，或者使用国内各种大厂提供的镜像托管服务，例如：阿里云、腾讯云\n上传镜像 首先要 注册一个账号 创建一个镜像库 然后在命令行中登录一下\n注意:这里登录只能是小写字母,之前写的大写字母username也得转为小写\n新建一个tag，名字必须跟你注册账号一样 1 docker tag test:v1 username/test:v1 推上去 1 docker push username/test:v1 然后我们可以随便新建一个文件夹,修改一下docker-compose.yml文件,然后粘过来\n修改docker-compose.yml文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8084:8083\u0026#34; # 映射 8084 端口到容器的 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP 协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ networks: - my-network mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: driver: bridge 主要是修改这个image\n1 image: luciuswan/hmdp:v1 docker,启动! 然后在这里启动powershell,输入命令即可运行项目\n1 docker-compose -p hmdp up -d 如果直接输入docker-compose -d,会提示你没有容器名称\n正常输入的话,我们的项目就跑起来了\n这时候还跑不了,因为数据没有迁移\nDocker数据迁移 部署的时候每次都得重新建数据库,建表,这样并没有提现到docker的方便部署,我们可以通过docker指令来复制docker中的mysql数据库,然后复制到宿主机,也就是windows本地,然后把这个文件送到别的宿主机\n1. 备份旧容器的数据 在旧容器中，使用mysqldump工具备份数据库。\n步骤： 进入旧MySQL容器：\n1 docker exec -it \u0026lt;旧容器名称或ID\u0026gt; bash 备份所有数据库：\n1 mysqldump -u root -p --all-databases \u0026gt; /backup_all_databases.sql 如果只需要备份特定数据库，可以指定数据库名称：\n1 mysqldump -u root -p your_database_name \u0026gt; /backup_your_database.sql 将备份文件从旧容器复制到宿主机：\n1 docker cp \u0026lt;旧容器名称或ID\u0026gt;:/backup_all_databases.sql ./backup_all_databases.sql 效果如下图\n2. 将备份文件上传到新机器 将备份文件（如backup_all_databases.sql）上传到目标机器上。可以使用文件传输工具（如SCP、FTP、WinSCP等）。\n我是直接上传到云服务器了\n3. 在新机器上使用docker-compose部署MySQL 确保你的docker-compose.yml文件正确配置，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network mysql: image: mysql:8.0 container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: 运行以下命令启动服务：\n1 docker-compose -p hmdp up -d 在宝塔面板里面进入包含这个yml文件的文件夹中\n1 2 3 4 cd /www cd wwwroot cd hmdp docker-compose -p hmdp up -d 这样,容器就在新的宿主机启动了\n4. 将备份数据恢复到新容器 将备份文件复制到新容器：\n1 docker cp ./backup_all_databases.sql mysql-container:/backup_all_databases.sql 进入新容器并恢复数据：\n1 docker exec -it mysql-container bash 在容器内部，运行以下命令恢复数据：\n1 mysql -u root -p \u0026lt; /backup_all_databases.sql 输入root用户的密码后，数据将被恢复到新容器中。\n然后我们的数据就同步在新的宿主机了\n5. 验证数据 在新容器中登录MySQL，检查数据是否正确恢复：\n1 docker exec -it mysql-container mysql -u root -p 输入密码后，执行以下命令查看数据库列表：\n1 SHOW DATABASES; 确保你的数据库和数据已经正确恢复。\n然后项目就可以正常跑起来了,如果遇到java代码无法连接MySQL,并且原因是MySQL不支持publicKey,可以在配置MySQL连接方式处这么修改\n然后我们这个项目在哪里跑都一样了\n","date":"2025-04-08T14:25:17+08:00","permalink":"https://LuciusWan.github.io/p/docker%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"Docker初体验"},{"content":"设计模式 OOP七大原则 单一职责原则 每个类最好只有一个任务或职责比如Controller类就负责接收前端请求,然后向Service层请求结果,而不是直接请求Mapper层或者直接处理数据返回.\n开闭原则 对扩展开放，对修改关闭，具体来说是写程序的时候可以多实现接口,让这个接口对应的类有更多功能,而不是删去以前的代码去修改功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 抽象支付接口 interface Payment { void pay(BigDecimal amount); } // 实现类（扩展时新增类即可） @Service class Alipay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;支付宝支付：\u0026#34; + amount); } } @Service class WechatPay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;微信支付：\u0026#34; + amount); } } // 控制器（对修改关闭） @RestController class PaymentController { @Autowired private List\u0026lt;Payment\u0026gt; payments; // Spring自动注入所有实现 @PostMapping(\u0026#34;/pay\u0026#34;) public String pay(@RequestParam String type, @RequestParam BigDecimal amount) { payments.stream() .filter(p -\u0026gt; p.getClass().getSimpleName() .equalsIgnoreCase(type + \u0026#34;Pay\u0026#34;)) .findFirst() .ifPresent(p -\u0026gt; p.pay(amount)); return \u0026#34;success\u0026#34;; } } 依赖倒置原则 依赖抽象而非实现，多定义很多层接口,最后再对接口进行实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 抽象层 interface UserRepository { User findById(Long id); } // 高层模块 @Service class UserService { private final UserRepository repository; // 依赖抽象 @Autowired public UserService(UserRepository repository) { this.repository = repository; } public User getUser(Long id) { return repository.findById(id); } } // 低层实现（可以是MySQL/MongoDB等） @Repository class JpaUserRepository implements UserRepository { @Override public User findById(Long id) { // 实际数据库操作 } } 它不关心具体的数据来源是 MySQL、MongoDB 还是其他方式，只依赖于接口，上层接口只关心数据。 合成复用原则 类最好要组合使用,而不是继承添加特性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 错误示范：用继承获取日志能力 class OrderService extends LoggingUtil { ... } // 正确示范：通过组合引入能力 @Service class OrderService { private final LoggingUtil logger; // 组合 @Autowired public OrderService(LoggingUtil logger) { this.logger = logger; } public void createOrder() { logger.log(\u0026#34;创建订单\u0026#34;); // 业务逻辑 } } SpringBoot项目中,多使用@Autowired,组合不同的类,让类之间共享方法\n口隔离原则 不应强迫客户端依赖于它们不使用的接口。换句话说，一个类应该只提供给其他类它实际需要的方法，而不是所有可能的方法。\n迪米特法则 也被称为最少知识原则，表明一个对象应该尽可能少地了解其他对象。每个单元对于其他的单元只能拥有最少的知识，并且仅仅与那些与之紧密相关的单元进行交互。\n比如有Mapper,Service,Controller三层架构,此时我们最好让他们之间一层一层通信,而不是Controller直接去找Mapper层找数据输出.\n里氏替换原则 在继承父类的时候最好不要修改父类的方法,可以扩展方法,这样在要使用父类的时候,可以用子类替代.\n单例模式 饿汉式单例模式 在项目启动的时候创建出的单例对象的行为就是饿汉式单例模式,比如下列代码\n1 2 3 4 5 6 7 8 9 public class Singleton { private static final Singleton INSTANCE = new Singleton(); private Singleton() {} public static Singleton getInstance() { return INSTANCE; } } static表示是静态资源,存在与静态资源池里面,final表示这个对象不会再被改变了,因此对象在启动的时候就创建好了.\nSpring容器创建的Bean对象默认就是饿汉式单例模式,通过@Autowired实现控制反转与依赖注入.\n优点：\n实现简单，代码清晰。 线程安全。 缺点：\n无论是否使用，都会在类加载时创建实例，可能浪费资源。\n懒汉式单例模式 懒汉式单例模式是指单例对象在需要使用的时候才会创建,样例代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 这种情况下可能导致线程安全问题,高并发的时候并不能保证单例,因此要在创建对象的时候加上锁\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 工厂模式 简单工厂 简单工厂创建对象的时候要考虑对象的类型,然后用if-else语句来判断是要创建哪个对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 工厂类 public class ShapeFactory { // 根据传入的类型创建对应的对象 public Shape getShape(String shapeType) { if (shapeType == null || shapeType.isEmpty()) { return null; } if (shapeType.equalsIgnoreCase(\u0026#34;CIRCLE\u0026#34;)) { return new Circle(); } else if (shapeType.equalsIgnoreCase(\u0026#34;SQUARE\u0026#34;)) { return new Square(); } else if (shapeType.equalsIgnoreCase(\u0026#34;RECTANGLE\u0026#34;)) { return new Rectangle(); } return null; } } 这样局限性还是很高,判断很多if else语句也会导致代码效率不高\n工厂方法模式 一个类只负责创建一种产品，通过继承和多态性，可以方便地扩展新的产品类型。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // 定义产品接口 public interface Product { void use(); } // 具体产品A public class ConcreteProductA implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品A\u0026#34;); } } // 具体产品B public class ConcreteProductB implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品B\u0026#34;); } } // 抽象工厂接口 public abstract class Creator { // 工厂方法，由子类实现 public abstract Product factoryMethod(); } // 具体工厂A public class ConcreteCreatorA extends Creator { @Override public Product factoryMethod() { return new ConcreteProductA(); } } // 具体工厂B public class ConcreteCreatorB extends Creator { @Override public Product factoryMethod() { return new ConcreteProductB(); } } // 测试类 public class FactoryMethodTest { public static void main(String[] args) { // 使用具体工厂A创建产品A Creator creatorA = new ConcreteCreatorA(); Product productA = creatorA.factoryMethod(); productA.use(); // 使用具体工厂B创建产品B Creator creatorB = new ConcreteCreatorB(); Product productB = creatorB.factoryMethod(); productB.use(); } } 一个工厂只负责创建一种对象\n抽象工厂 抽象工厂模式提供了一组用于创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。能够创建一系列相关的对象，而不是单一的产品。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 // 定义产品族接口 public interface AbstractProductA { void useA(); } public interface AbstractProductB { void useB(); } // 具体产品A1 public class ConcreteProductA1 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A1\u0026#34;); } } // 具体产品A2 public class ConcreteProductA2 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A2\u0026#34;); } } // 具体产品B1 public class ConcreteProductB1 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B1\u0026#34;); } } // 具体产品B2 public class ConcreteProductB2 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B2\u0026#34;); } } // 抽象工厂接口 public interface AbstractFactory { AbstractProductA createProductA(); AbstractProductB createProductB(); } // 具体工厂1 public class ConcreteFactory1 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA1(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB1(); } } // 具体工厂2 public class ConcreteFactory2 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA2(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB2(); } } // 测试类 public class AbstractFactoryTest { public static void main(String[] args) { // 使用具体工厂1创建产品族1 AbstractFactory factory1 = new ConcreteFactory1(); AbstractProductA productA1 = factory1.createProductA(); AbstractProductB productB1 = factory1.createProductB(); productA1.useA(); productB1.useB(); // 使用具体工厂2创建产品族2 AbstractFactory factory2 = new ConcreteFactory2(); AbstractProductA productA2 = factory2.createProductA(); AbstractProductB productB2 = factory2.createProductB(); productA2.useA(); productB2.useB(); } } 每个具体工厂可以创建不同的对象\n在Spring中,配置类就使用了工厂模式\n1 2 3 4 5 6 7 8 9 @Bean public ChatClient DesignPattern(OpenAiChatModel model, ChatMemory chatMemory) { return ChatClient.builder(model) .defaultSystem(AIConstant.DESIGN_PATTERN) .defaultAdvisors( new MessageChatMemoryAdvisor(chatMemory), new SimpleLoggerAdvisor()) .build(); } 而一个配置类里面有多个@Bean注解下的工厂方法,可以实现抽象工厂和工厂方法模式\n","date":"2025-05-16T20:56:35+08:00","permalink":"https://LuciusWan.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"设计模式"},{"content":"API接口文档 1. 文档概述 产品经理的任务 产品经理定义每个版本需要实现的具体功能和细节，通常通过撰写产品需求文档来明确需求。并且撰写API接口文档告诉前后端工程师，怎样开发才能在双方完成任务后，前后端能够完美对接。\n文档目的 API接口文档旨在帮助开发人员了解如何调用和使用本系统提供的API。文档包括了接口的定义、请求与响应格式、错误处理机制等内容。\n系统架构 前端：原生JS 或 Vue.js 后端：Java原生 或 SpringBoot框架 API接口文档示例 部门管理 1.1 部门列表查询 1.1.1 基本信息 请求路径：/depts\n请求方式：GET\n接口描述：该接口用于部门列表数据查询\n1.1.2 请求参数 无\n1.1.3 响应数据 参数格式：application/json\n参数说明：\n参数名 类型 是否必须 备注 code number 必须 响应码，1 代表成功，0 代表失败 msg string 非必须 提示信息 data object[ ] 非必须 返回的数据 \\ - id number 非必须 \\ - name string 非必须 \\ - createTime string 非必须 \\ - updateTime string 非必须 响应数据样例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;学工部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;教研部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; } ] } 2. 前端使用说明 前端框架选择 1. JS原生代码（使用fetch） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fetch(\u0026#39;/depts\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; { if (data.code === 1) { console.log(\u0026#34;部门列表:\u0026#34;, data.data); } else { console.log(\u0026#34;请求失败:\u0026#34;, data.msg); } }) .catch(error =\u0026gt; { console.error(\u0026#39;Error:\u0026#39;, error); }); Vue.js 在Vue组件中，可以使用Axios来简化API调用。\n示例代码（使用Axios发送GET请求）：\n错误处理 前端应对API请求中的常见错误进行处理，如404（未找到），500（服务器错误）等。\n错误处理示例：\n1 2 3 4 5 6 7 8 9 10 fetch(\u0026#39;https://api.example.com/data\u0026#39;) .then(response =\u0026gt; { if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return response.json(); }) .catch(error =\u0026gt; { console.error(\u0026#39;API call failed:\u0026#39;, error); }); 3. 后端实现说明 后端语言/框架选择 Java原生 使用Java原生编写API接口，通常通过HttpServlet处理请求。\n示例代码（Java原生实现GET请求）：\n1 2 3 4 5 6 7 8 9 10 11 import javax.servlet.*; import javax.servlet.http.*; import java.io.*; public class DataServlet extends HttpServlet { protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;application/json\u0026#34;); PrintWriter out = response.getWriter(); out.println(\u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Hello, World!\\\u0026#34;}\u0026#34;); } } SpringBoot 使用SpringBoot框架，MySQL数据库，Mybatis框架来实现后端数据的提供\n示例代码（SpringBoot实现前端Get的请求）：\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping\n使用三层架构，DeptController，DeptService，DeptMapper,响应，处理数据，调取数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //日志输出的注解 @Slf4j //controller层必带的注解 @RestController @RequestMapping(\u0026#34;/dept\u0026#34;) public class DeptController { Dept dp=new Dept(); //依赖注入 @Autowired private DeptService deptService; @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/dept\u0026quot;)后可以在后面定义类似GetMapping(\u0026quot;/dept\u0026quot;)时直接省略前面的/dept\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n统一返回格式大致如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示Mapper层配合xml格式调用数据\n1 2 3 4 @Mapper public interface DeptMapper { public List\u0026lt;Dept\u0026gt; list(); } xml文件如下\n1 2 3 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package com.test.springbootproject01.interceptor; import com.alibaba.fastjson.JSONObject; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import jakarta.servlet.http.HttpServletRequest; import jakarta.servlet.http.HttpServletResponse; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.test.springbootproject01.config; import com.test.springbootproject01.interceptor.LoginCheckInterceptor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.test.springbootproject01.Controller; import com.test.springbootproject01.Service.EmpService; import com.test.springbootproject01.pojo.Emp; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import io.jsonwebtoken.Claims; import io.jsonwebtoken.impl.DefaultClaims; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } java代码是这样的(\n","date":"2025-03-16T15:29:26+08:00","permalink":"https://LuciusWan.github.io/p/api%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"API接口文档使用教程"},{"content":"JavaWeb 三层解耦 这里会用到面向对象七大原则中的单一职责原则，即每个程序有自己的任务，而不是有很多任务导致单一程序复杂，耦合度高，复用性差\n我们可以将后端划分为三个部分，MVC框架是Controller，View，Model\n而springboot可以划分为Controller，Service，Dao三层，分别为监听层，逻辑处理层，数据管理层，原来复杂的Controller层是这样的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @RestController public class EmpController { String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } });); List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 现在可以使用三层架构来分别放置 Controller，Service，Dao三层\nDao层的接口及实现如下 1 2 3 public interface EmpDao { public List\u0026lt;Emp\u0026gt; listEmp(); } 1 2 3 4 5 6 7 8 9 10 11 public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } Service层的接口及实现如下 1 2 3 public interface EmpService { public List\u0026lt;Emp\u0026gt; list(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.util.List; public class EmpServiceA implements EmpService { private EmpDao empDao=new EmpDaoA(); @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 这里通过创建Dao层对象然后调用其方法来获取数据，但这会让Dao层和Service层紧耦合\nController代码如下 1 2 3 4 5 6 7 8 9 10 @RestController public class EmpController { private EmpServiceA empServiceA =new EmpServiceA(); @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 同样的，这里的创建对象也会让Service层和Controller层紧耦合\n我们可以考虑使用设计模式中的工厂模式来解决这个紧耦合办法，但是springboot已经想好了解决对策，那就是\n控制反转与依赖注入 控制反转:Inversion Of control，简称IOC。对象的创建控制权由程序自身转移到外部(容器)，这种思想称为控制反转\n依赖注入: Dependency Injection，简称DI。容器为应用程序提供运行时所依赖的资源，称之为依赖注入。\nBean对象:IOC容器中创建、管理的对象，称之为Bean\n解耦之后的代码演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 //Dao层 @Component public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //Service层 @Component public class EmpServiceA implements EmpService { @Autowired private EmpDao empDao; @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 1 2 3 4 5 6 7 8 9 10 11 12 //Controller层 @RestController public class EmpController { @Autowired private EmpService empService; @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empService.list(); System.out.println(empList); return Result.success(empList); } } 如果我此时要加入EmpDaoB（通过MySQL等数据库传送数据），那就吧EmpDaoA的@Component注释了\nspringboot给三层架构分别出了三个衍生注解@Repository，@Service，@Controller\n后续基本上都用数据库传输，并且springboot继承了Mybatis，Mybatis可以使用注解@Mapper来替代@Repository，而Controller层自带@RestController注解，因此可以不用@Controller\n@Component注解可以在不属于这三层，但是很有用的工具类上加这个注解\nPojo文件 pojo文件中存放各种JavaBean\nSpringboot特有的JavaBean写法，使用前要引入Lombok依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package com.test.springboottest03_crud.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.time.LocalDate; import java.time.LocalDateTime; @Data @NoArgsConstructor @AllArgsConstructor public class Emp { private Integer id; private String username; private String password; private String name; private Short gender; private String image; private Short job; private LocalDate entryDate; private Integer deptId; private LocalDateTime createTime;//创建时间 private LocalDateTime updateTime;//修改时间 } 这里用到了三个注解 @Data 同时包含了toString方法，HashCode，所有get，set方法\n@NoArgsConstructor 是无参构造\n@AllArgsConstructor 是全参构造\nMybatis的增删改查(注解写法) 在文件中创建mapper文件夹，创建对应的Mapper接口\n使用注解@Mapper\n1 2 3 4 5 6 7 8 9 @Mapper//程序开始时会自动创建代理对象 public interface EmpMapper { @Delete(\u0026#34;delete from emp where id=#{id}\u0026#34;) public int delete(Integer id); @Options(useGeneratedKeys = true,keyProperty = \u0026#34;id\u0026#34;) @Insert(\u0026#34;insert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time)\u0026#34; + \u0026#34; values (#{username},#{name},#{gender},#{image},#{job},#{entryDate},#{deptId},#{createTime},#{updateTime})\u0026#34;) public void insert(Emp emp); } 第一个是删除操作，@Delete里面写SQL语句，d=#{id}是Mybatis的占位符 使用Integer是因为int不支持不输入就是null，与SQL语句不吻合\n该删除操作删除的是指定id对象\n第二个是插入操作 写正常的insert语句，然后每个占位符都是JavaBean里面的，注意驼峰命名法\n插入操作的形参是JavaBean对象\nTest类的写法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class SpringBootTest03CrudApplicationTests { @Autowired EmpMapper empMapper; @Test public void testDelete() { int a = empMapper.delete(17); System.out.println(a); } public void testInsert() { //构造员工对象 Emp emp = new Emp(); emp.setUsername(\u0026#34;Tom7\u0026#34;); emp.setName(\u0026#34;汤姆3\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setCreateTime(LocalDateTime.now()); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); //执行新增员工信息操作 empMapper.insert(emp); System.out.println(emp.getId()); } } 在测试类中，先用抽象父类创建对象，然后使用依赖注入@Autowire，等价于EmpMapper empMapp=new EmpMapperA()，把和数据库连接好的bean对象传过来，这样就可以对数据库或者xml等数据载体进行操作了。\n删除操作 前面定义了delete接口是int返回值，这里a返回为删除多少个对象\n1 2 3 public void testDelete() { int a = empMapper.delete(17); System.out.println(a); 插入操作 insert方法要将创建好的对象初始化后使用empMapper.insert(emp)来插入\n如果直接输出emp.getId()是没有结果的，在定义接口的时候使用注解@Options\n1 @Options(useGeneratedKeys = true,keyProperty = \u0026#34; 这样就可以返回Id了\n使用LocalDateTime.now()这个方法最后的返回值符合MySQL的date格式\n修改操作 mapper中的代码\n1 2 3 @Update(\u0026#34;update emp set username =#{username},name=#{name},gender=#{gender},image=#{image},\u0026#34; + \u0026#34;job=#{job},entrydate=#{entryDate},dept_id=#{deptId},update_time=#{updateTime} where id=#{id}\u0026#34;) public void update(Emp emp); Test中的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 public void testUpdate() { Emp emp = new Emp(); emp.setId(1); emp.setUsername(\u0026#34;Tom12\u0026#34;); emp.setName(\u0026#34;汤姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); empMapper.update(emp); } 查询操作 mapper中的代码\n1 2 @Select(\u0026#34;select * from emp where id=#{id}\u0026#34;) public Emp selectById(Integer id); Test中的代码\n1 2 3 4 5 6 public void testSelect() { Integer id=12; Emp emp= new Emp(); emp=empMapper.selectById(id); System.out.println(emp); } 这里是根据id来对数据查询，但是在注入对象empMapper对应的代理对象赋值的时候，数据库中的下划线命名法和java中的驼峰命名法冲突，导致后面使用驼峰命名法的字段赋值失败\n这时候可以在application.properties中输入camel+Tab 1 2 #Mybatis的驼峰命名法映射开关打开 mybatis.configuration.map-underscore-to-camel-case=true 这时候所有输出就对味了\n查询操作ProMax：模糊查询 对员工姓名进行模糊查询，对应的SQL语句是\n1 select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc 其中‘%张%’的意思是其中有一个字是张就行了，前面和后面都有字也在查询范围里面，张无忌，我是张三等名字都可以被查询到，模糊查询要用关键词like，时间范围可以用between\n但是在@Select注解中不能直接这么写，‘%#{name}%’，其中#{name}不能放到引号里面，因为#{name}会在预编译期间变为？，如果是%?%那么任何一个索引都可以被查询到\n1 2 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by updateTime desc\u0026#34;) 可以调用函数concat(\u0026rsquo;%\u0026rsquo;,#{name},\u0026rsquo;%')\nTest代码为\n1 2 3 4 public void testSelectPlus() { List\u0026lt;Emp\u0026gt; empList=empMapper.selectAll(\u0026#34;张\u0026#34;,(short)1,LocalDate.of(2010,01,01),LocalDate.of(2020,01,01)); System.out.println(empList); } LocalDate.of(2010,01,01)可以输入时间\nMybatis的XML写法 要想使用XML映射来实现增删改查需要在resources中添加一致包名和xml文件\n注：在resources里面创建的不是软件包，是资源包，分隔符不是\u0026rsquo;.\u0026lsquo;而是\u0026rsquo;/\u0026rsquo;，之后会自动转化为\u0026rsquo;.\u0026rsquo;,并且之后创建的xml文件要和接口文档命名一致\n两种方法对比：\n1 2 3 4 //条件查询注解法 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by update_time desc\u0026#34;) public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 //xml法 public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; XML法的前面部分是固定语句，可以直接从官网复制\n创建一个接口的xml语句可以先创建好接口，然后按下Alt+Enter点击最上面的选项\n然后就可以在xml文件里编辑了\n想通过这种方式创建得按照下面方式下载MybatisX插件\n在XML文件中，SQL语句很长，可以选中所有SQL语句然后按下Ctrl+Alt+L格式化\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp set username =#{username}, name=#{name}, gender=#{gender}, image=#{image}, job=#{job}, entrydate=#{entryDate}, dept_id=#{deptId}, update_time=#{updateTime} where id = #{id} \u0026lt;/update\u0026gt; 注：Ctrl+Alt+L可能被网易云音乐或者QQ占用，需要去对应的软件中关闭此快捷键\n不管哪一种方法，都要有方法体，只是说把SQL语句移到了xml文件中\n可以在IDEA中下载MybatisX插件，跳转非常方便\n官方提示 使用注解来映射简单语句会使代码显得更加简洁，但对于稍微复杂一点的语句，Java 注解不仅力不从心，还会让你本就复杂的 SQL 语句更加混乱不堪。 因此，如果你需要做一些很复杂的操作，最好用 XML 来映射语句。\n动态SQL语句 实际业务需求:\n所有搜索条件都是null，此时服务器发送数据为查找所有。\n当有搜索条件的时候，也有条件为null\n若直接写刚才的select语句很容易就搜索不到数据，因为搜索对应的值为null和无搜索条件逻辑不符，此时可以引入动态SQL语句\nSelect动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;, #{name}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender = #{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 其中语句可以判断是否有这个条件，如果没有则跳过这条语句。\n可以动态判断是否该加and，如果搜索条件为后面两个条件，那么SQL语句开头就是and导致语法错误，但是where可以解决这个问题\nUpdate的动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;username!=null\u0026#34;\u0026gt;username =#{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt;name=#{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt;gender=#{gender},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image!=null\u0026#34;\u0026gt;image=#{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;job!=null\u0026#34;\u0026gt;job=#{job},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;entryDate!=null\u0026#34;\u0026gt;entrydate=#{entryDate},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;deptId!=null\u0026#34;\u0026gt;dept_id=#{deptId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime!=null\u0026#34;\u0026gt;update_time=#{updateTime}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 这里同样用到了if来设置默认搜索条件，并且引入来判断逗号是否多余导致的SQL语句错误，与的用法一致\n在上述xml写好后，修改条件就可以如下\n1 2 3 4 5 6 7 8 9 public void testUpdate() { Emp emp = new Emp(); emp.setId(12); emp.setUsername(\u0026#34;Sam54235\u0026#34;); /*emp.setName(\u0026#34;萨姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setUpdateTime(LocalDateTime.now());*/ empMapper.update2(emp); } 动态SQL\u0026mdash;批量删除操作 一次性删除多个对象可以这样写SQL语句\n1 delete from emp where id in(18,21); 1 2 3 4 5 6 7 //接口部分这么写 public void deleteById(List\u0026lt;Integer\u0026gt; list); //Test类中这样写 public void deleteTest() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(10, 11); empMapper.deleteById(list); } 因为要删除多个，所以此时传参以集合的方式传递，并且后面集合的名称要和xml中的一致\n在xml中需要这么写\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;deleteById\u0026#34;\u0026gt; delete from emp where id in \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 其中foreach操作可以遍历传递过来的集合list，然后拼凑出所要的sql语句\n其中collection是集合的名称，item是告诉sql语句这时候要按照什么进行删除，separator是SQL语句的分隔符，open和close分别是开始和结尾的字符#{id}通过占位符来加入数据，最后就可以形成(10,11)这样的语句，和之前的delete from emp where id in结合起来就是完整的SQL语句\nSQL代码复用 在企业中直接使用select * from emp速度没有全参访问速度快\n1 2 select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp 1 2 3 4 \u0026lt;sql id=\u0026#34;commonSelect\u0026#34;\u0026gt; select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp \u0026lt;/sql\u0026gt; 这时候可以使用动态SQL语句sql来封装SQL代码\nid就是以后调用的时候的名称\n要调用的时候就这样写\n1 2 3 4 \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; \u0026lt;include refid=\u0026#34;commonSelect\u0026#34;/\u0026gt; /**/ \u0026lt;/select\u0026gt; 简易Web网站开发 前端部分已经写好，我们只用对照产品经理写的API文档接口来写后端程序即可\n创建springboot项目，勾选springweb依赖，lombok依赖，mybaties和MySQL依赖\n在application.properties中配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring.application.name=SpringBootProject01 #????? spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver #??????url spring.datasource.url=jdbc:mysql://localhost:3306/springboottest #????????? spring.datasource.username=root #???????? spring.datasource.password=123456 #??mybatis???, ???????? mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl #??mybatis??????????? a_column ------\u0026gt; aCloumn mybatis.configuration.map-underscore-to-camel-case=true----\u0026gt; aCloumn 配置MySQL信息，MySQL用户名，密码，还有Mybatis的驼峰命名法转蛇形命名法\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping 使用三层架构，分别是DeptController，DeptService，DeptMapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Slf4j @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { Dept dp=new Dept(); @Autowired private DeptService deptService; /*@RequestMapping(value = \u0026#34;/depts\u0026#34;,method = RequestMethod.GET)*/ @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public Result delete(@PathVariable Integer id){ log.info(\u0026#34;删除所选部门数据\u0026#34;); deptService.delete(id); return Result.success(); } @PostMapping() public Result save(@RequestBody Dept dept){ log.info(\u0026#34;添加部门{}\u0026#34;, dept); deptService.save(dept); return Result.success(); } @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable Integer id){ log.info(\u0026#34;根据ID{}查询部门\u0026#34;, id); dp=deptService.select(id); return Result.success(dp); } @PutMapping() public Result update(@RequestBody Dept dept){ log.info(\u0026#34;修改部门{}\u0026#34;, dept); deptService.update(dept); return Result.success(); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/depts)后可以在后面定义类似GetMapping(\u0026quot;/depts/{id}\u0026quot;)时直接省略前面的/depts\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } public void delete(Integer id){ deptMapper.delete(id); } public void save(Dept dept){ dept.setCreateTime(LocalDateTime.now()); dept.setUpdateTime(LocalDateTime.now()); deptMapper.save(dept); } @Override public void update(Dept dept) { dept.setUpdateTime(LocalDateTime.now()); deptMapper.update(dept); } @Override public Dept select(Integer id) { return deptMapper.list1(id); } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示全用xml格式\n1 2 3 4 5 6 7 8 9 @Mapper public interface DeptMapper { /* @Select(\u0026#34;select * from springboottest.dept\u0026#34;)*/ public List\u0026lt;Dept\u0026gt; list(); public void delete(Integer id); public void save(Dept dept); public void update(Dept dept); public Dept list1(Integer id); } xml文件如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;insert id=\u0026#34;save\u0026#34;\u0026gt; insert into springboottest.dept(springboottest.dept.name,springboottest.dept.create_time,springboottest.dept.update_time) values(#{name},#{createTime},#{updateTime}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update springboottest.dept set springboottest.dept.name=#{name},springboottest.dept.update_time=#{updateTime} where springboottest.dept.id=#{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.dept where id=#{id} \u0026lt;/delete\u0026gt; \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;list1\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept where id=#{id} \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n注意到这里update接口应当先根据ID查询到对应的数据，然后再将更改后的数据发送给服务端存储\n点击编辑按钮后，前端发送get请求，将查询到的数据发送到这个窗口页面上\n然后我们可以对其进行修改，然后将改正后的数据通过post请求发送给后端，然后后端对这个数据进行存储，完成了一次更新操作\n@PathVariable注解的使用 当前端发送数据且根据id给后端时，前端的id和后端的id不一定相同\n但是数据库中的内容并不是如此\n所以这里可以通过@PathVariable注解来寻找到之前数据库传过来的正确的id，格式如下\n1 2 3 4 5 6 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable(\u0026#34;id\u0026#34;) Integer id) { log.info(\u0026#34;根据id{}查询数据\u0026#34;,id); Emp emp1=empService.selectId(id); return Result.success(emp1); } @RequestBody注解的使用 前端此时传回来的数据是JSON格式，并不能直接把这个数据转化为对象传给数据库做select或者存储，此时可以通过注解@RequestBody来转化为Java对象,格式如下\n1 2 3 4 5 6 @PutMapping public Result update(@RequestBody Emp emp){ log.info(\u0026#34;{}修改数据\u0026#34;,emp.getUsername()); empService.update(emp); return Result.success(); } 查询emp部分稍有麻烦\n分页查询员工 根据API接口文档\n前端返回的数据为当前页数和每页有多少个数据\n此时后端应当给前端返回的是当前页所查询到的数据和总共数据库中有多少条数据\n后面的查询很简单，可以直接用个select语句来完成\n1 select count(*) from springboottest.emp 前面的数据得用到分页查询，条件为limit #{page},#{pageSize}，\n此时EmpService得设置page和pageSize\n1 2 3 4 5 6 7 8 9 @Override public PojoBean select(String name, Short gender, LocalDate begin, LocalDate end, Integer page, Integer pageSize) { PojoBean pojoBean = new PojoBean(); pojoBean.setTotal(empMapper.count()); pojoBean.setRows(empMapper.list(name,gender,begin,end,(page-1)*pageSize,pageSize)); System.out.println((page-1)*pageSize); System.out.println(pageSize); return pojoBean; } 在数据库中limit 0,5代表第0索引开始，且每页有5个元素，前端应该是第1页，每页有5个元素，因此索引数和前端页码对上的话，索引为(page-1)*pageSize\n分页条件查询员工 此时前端可能会给出查询条件，姓名name，性别gender，入职时间，entryDate\n这些条件可能给，也可能全给，也可能给部分，也可能一个都不给，可以用之前提到的动态SQL语句来解决这个问题，这种复杂的sql语句不能用注解来写，只能通过XML文件配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Emp\u0026#34;\u0026gt; select * from springboottest.emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender=#{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; limit #{page},#{pageSize} \u0026lt;/select\u0026gt; 前端总共返回的数据如下\n1 2 3 4 5 6 7 @GetMapping public Result emp(String name, Short gender, LocalDate begin, LocalDate end, @RequestParam(defaultValue = \u0026#34;1\u0026#34;) Integer page, @RequestParam(defaultValue = \u0026#34;10\u0026#34;) Integer pageSize) { PojoBean pb=empService.select(name,gender,begin,end,page,pageSize); return Result.success(pb); } @RequestParam 注解的使用 @RequestParam注解可以让参数有默认值，这样用户不使用任何条件查询就可以查询到默认的10条记录\n最终给前端因为要返回两种数据，一个是总页数，一个是查询到的员工的list集合\n因此这时候创建一个PojoBean类\n最后把数据封装好后以Result的标准JSON格式返回给前端\n批量删除员工 前端返回的删除指令可能有多条，这时候返回来的是个数组\n1 2 3 4 5 6 @DeleteMapping(\u0026#34;/{ids}\u0026#34;) public Result delete(@PathVariable(\u0026#34;ids\u0026#34;) Integer [] ids) { log.info(\u0026#34;删除所选员工数据\u0026#34;); empService.delete(ids); return Result.success(); } 接受到前端的数据后可以去service层,然后再把数组交给Mapper层\n最后的xml语句为\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.emp where springboottest.emp.id in \u0026lt;foreach collection=\u0026#34;ids\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入jwt的依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package com.test.springbootproject01.interceptor; import ... @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package com.test.springbootproject01.config; import ... @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.test.springbootproject01.Controller; import ... @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } AOP 面向切面/方法编程 要在使用AOP之前先引入依赖\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 一个简单的AOP入门示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.test.springbootproject01.AOP; import ... @Slf4j @Component @Aspect public class TimeAspect { @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) public Object recordTime(ProceedingJoinPoint joinPoint) throws Throwable { //方法启动时间 long startTime = System.currentTimeMillis(); //执行方法 Object result = joinPoint.proceed(); //方法结束时间 long endTime = System.currentTimeMillis(); log.info(joinPoint.getSignature()+\u0026#34;方法执行时间为\u0026#34;+(endTime - startTime) + \u0026#34;ms\u0026#34;); return result; } } 1 @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) execution是用来提示后面是切入点，第一个*指的是返回值为任意类型，com.test.springbootproject01.Service第二个是指任何类，第三个是任何方法，(..)表示匹配任何数量和类型的参数\nNginx的反向代理 后端部署在服务器上默认占用8080端口，前端若也要在服务器上部署，最好不要也选择8080，此时就要用到反向代理。\n打开\nnginx配置界面、\n然后修改这里的代码\nlisten代表前端服务器占用的端口\nlocation /api/ 块说明 1 2 3 location /api/ { proxy_pass http://localhost:8080/emprequest/; } location 指令（/api/ 路径情况）： 这里的 location /api/ 表示匹配所有以 /api/ 开头的客户端请求 URI。例如，像 http://localhost:100/api/user、http://localhost:100/api/order 这样的请求都会进入到这个 location 块中进行后续处理。 proxy_pass 指令： 用于设置反向代理，即将匹配到 /api/ 开头的请求转发到指定的后端服务器地址及路径上。在这里，它会把请求转发到 http://localhost:8080/emprequest/。具体来说，比如前端页面发起了一个 http://localhost:100/api/some-api 的请求，Nginx 会把这个请求去掉 /api/ 这部分前缀后，转发到 http://localhost:8080/emprequest/some-api 这个路径上，让运行在 8080 端口的后端服务器去处理对应的请求，然后后端服务器返回的响应结果又会通过 Nginx 再传递回发起请求的客户端（比如浏览器）。 总体来讲，这段 Nginx 配置定义了一个监听在 100 端口的服务器，针对根路径请求会查找并返回 html 目录下的相关文件，而针对以 /api/ 开头的请求则会将其代理转发到本地 8080 端口下的特定路径上让后端服务进行处理。 此时前端的代码为\n以后设计接口最好这样搞\nTODO标签代表还没做完的事，后面可以查看TODO标签对没写完的代码进行完善\n","date":"2025-03-16T15:38:21+08:00","permalink":"https://LuciusWan.github.io/p/javaweb%E9%83%A8%E5%88%86%E7%AC%94%E8%AE%B0/","title":"JavaWeb部分笔记"},{"content":"这次二面主要考察了什么？ 面试围绕四个方向展开：\n实习时间：12月29日到岗，持续6个月以上 项目深挖：EduAgentX（比赛）、心理医生知识库（实习） 中间件原理：Redis/RPC 序列化 手写算法：求N次方根（二分法/牛顿迭代） 面试官问了很多细节（JVM参数、Redis内存、数据量），这些我都没做过怎么办？ 这叫\u0026quot;工程化细节拷打\u0026quot;，考察项目是\u0026quot;玩具\u0026quot;还是\u0026quot;产品\u0026quot;。需要准备合理的参数和回答逻辑。\nJVM 启动参数（JDK 17） 1 -Xms4g -Xmx4g # 初始堆和最大堆设为一致，避免内存抖动 JDK 17 默认 G1 GC，适合大内存服务器，主要依赖 G1 的自适应能力。\nRedis 内存规划 申请 8GB 是基于容量预估：\n对话上下文（List）：单条 1KB，几万条才几十 MB，设置 10分钟 TTL 预留 Buffer：避免后续频繁扩容 数据库文件大小 查看方式：\n1 2 SELECT table_name, ROUND((data_length + index_length) / 1024 / 1024, 2) AS \u0026#34;Size (MB)\u0026#34; FROM information_schema.TABLES WHERE table_schema = \u0026#34;数据库名\u0026#34;; 估算：1万条 × 1KB ≈ 10MB，加碎片约 50-100MB。256GB 内存服务器，数据库完全可加载进内存。\nRedis序列化和Dubbo RPC序列化不懂怎么办？ Redis 序列化 Java 对象存入 Redis 必须序列化，Redis 只认字节/字符串。\n方式 特点 场景 JDK 序列化 字节流长，不可读 不推荐 JSON 序列化 可读性强，方便调试 推荐 Protobuf 体积小，解析快 高并发微服务 话术：选 JSON 是因为需要在 Redis Desktop Manager 里直接看到清晰的 JSON 结构排查问题，可读性和开发效率优先。\nRPC Protobuf 机制 之前的错误理解：.proto 文件在运行时传输\n正确理解：\n.proto 是 IDL（接口定义语言），是服务契约 编译期：protoc 生成 Java 代码，服务端和客户端都依赖这份代码 运行时：只传序列化后的二进制流，不传文件 优势：TLV 编码，不传字段名只传字段编号，体积比 JSON 小很多 话术：Redis 侧选 JSON（可读性第一），RPC 侧选 Protobuf（性能第一）。\n应用程序和数据库部署在一块吗？数据库文件多大？ 部署架构 单机部署是合理选择：\n降低网络延迟（Localhost 通信比走网卡快） 方便维护 Docker 容器进行逻辑隔离 话术：\n\u0026ldquo;数据库文件只有几十 MB，服务器有 256GB 内存。操作系统 Page Cache 和 MySQL Buffer Pool 会将热点数据完全缓存，磁盘 I/O 不是瓶颈，所有查询本质上都是纯内存操作。\u0026rdquo;\n大模型应用怎么做评测？没做过指标评测怎么办？ 把\u0026quot;没做过\u0026quot;变成\u0026quot;我知道该怎么做\u0026quot;。\n双层评测框架 维度 方法 指标 准确性 离线评估 + 黄金数据集 Hit Rate, Faithfulness 性能 用户体验延迟 TTFT \u0026lt; 1.5s, Total \u0026lt; 15s 反馈 专家验收 + 人在回路 采纳率, 专家评分 RAG 评测指标（RAGAS 框架） 检索层：\nHit Rate@K：正确文档是否在前K个结果中 MRR：正确文档的排名位置 生成层：\nFaithfulness（忠实度）：答案是否基于检索文档，无幻觉 Answer Relevance（相关性）：是否答非所问 Context Precision（精确度）：检索内容的信噪比 性能评测 TTFT (Time To First Token)：首字延迟，目标 \u0026lt; 1.5秒 E2E Latency：端到端耗时，目标 \u0026lt; 15秒 话术：\n\u0026ldquo;当时受限于实习时间主要靠人工验收。如果复盘，我会引入 RAGAS 框架，重点考核 Faithfulness（防幻觉）和 Answer Relevance（防答非所问）。\u0026rdquo;\n比赛项目没有用户反馈，怎么证明生成结果有用？ 第一层防御：比赛本身就是测试 评委和竞争对手就是\u0026quot;种子用户\u0026quot;，评委充当\u0026quot;领域专家\u0026quot;角色，给出定性反馈。\n第二层防御：Human-in-the-Loop 机制 AI 生成只是初稿，老师的修改才是最终修正：\n教师点击\u0026quot;采纳\u0026quot; = 正向评分 教师修改/重新生成 = 负向反馈 第三层防御：黄金数据集 找教材目录和课后习题作为 Ground Truth，人工核查知识点覆盖率。\n话术：\n\u0026ldquo;采取\u0026rsquo;离线评估 + 专家抽检\u0026rsquo;策略。以经典教材为基准确保知识点不跑偏，设计 Human-in-the-Loop 机制让老师把关最后一道防线。AI 负责提供灵感，人类负责把控质量。\u0026rdquo;\n内部测试是怎么做的？怎么说是用公司服务器测试的？ 把\u0026quot;宝塔面板\u0026quot;翻译成\u0026quot;Docker + Nginx + Shell脚本\u0026quot;。\n环境搭建 \u0026ldquo;基于 Docker 的单机微服务部署。Docker Compose 编排中间件（MySQL、Redis、ES、Nacos），应用打包成 JAR 构建镜像，Volume 挂载日志目录。\u0026rdquo;\n接口暴露 \u0026ldquo;Nginx 反向代理转发请求，集成 Swagger/Knife4j 提供接口文档，组员通过内网 IP 访问。\u0026rdquo;\n代码更新 \u0026ldquo;写了简单的 Shell 脚本：git pull → mvn package → docker restart，实现半自动化部署。\u0026rdquo;\n服务挂了怎么办 \u0026ldquo;Docker 启动参数配置了 --restart=always，守护进程会自动拉起崩溃的服务。\u0026rdquo;\n怎么看日志 \u0026ldquo;登录服务器，去挂载的日志目录用 grep 搜 Error，或 tail -f 实时盯日志配合前端复现 Bug。\u0026rdquo;\n怎么体现做过接口评测？ 把\u0026quot;开会演示\u0026quot;包装成\u0026quot;UAT 验收测试\u0026quot;。\n演示前性能优化故事 \u0026ldquo;演示前冒烟测试发现历史记录接口响应超过 2秒。排查发现是深分页问题，引入时间游标分页 + 复合索引，响应时间从 2.1s 降至 0.7s。演示时业务方快速滑动历史记录非常丝滑。\u0026rdquo;\n演示中实时监控 \u0026ldquo;演示过程中通过 SSH 连接服务器，tail -f 查看日志，top 监控资源。观察 SSE 连接保持情况，验证心跳机制和断点续传逻辑正常工作。\u0026rdquo;\n话术：\n\u0026ldquo;业务方的现场验收就是最真实的评测。能扛住演示时的随机操作和现场网络环境，比单纯跑 Benchmark 更有说服力。\u0026rdquo;\nAI生成内容的评测怎么做？医院有反馈过问题 医院的反馈就是最好的\u0026quot;UAT 验收测试\u0026quot;证据。\n问题1：语气冰冷，像知识问答 痛点：直接把知识点甩给病人，缺乏共情，甚至输出表格\n解决方案：\n强化 System Prompt 角色设定：\u0026ldquo;你是有10年经验的心理咨询师，用温暖包容的口吻对话\u0026rdquo; Few-Shot Learning：找医生要 3-5 个优秀医患对话案例作为示例 结果：AI 会先说\u0026quot;我理解您的焦虑\u0026quot;，再给建议\n问题2：输出大量文本，Token 失控 痛点：一次性输出几百字\u0026quot;小作文\u0026quot;，病人没耐心看\n解决方案：\n限制 max_tokens 参数（300 token 以内） Prompt 约束：\u0026ldquo;不要一次性解决所有问题，每次回复控制在3句话以内\u0026rdquo; 结果：AI 能一句一句有来有回，还节省了 40% Token 成本\n话术：\n\u0026ldquo;早期 Demo 阶段，医院医生提出 AI \u0026lsquo;太冷漠\u0026rsquo;且\u0026rsquo;废话太多\u0026rsquo;。我通过 Prompt Few-Shot 技术解决共情问题，通过 Token 限制和对话策略优化解决长文本问题。最终版本经医生试用通过。\u0026rdquo;\n心理医生平台还会遇到什么问题？ 安全风控（最致命） 危机干预熔断：\n用户输入\u0026quot;我不想活了\u0026quot;时，必须熔断 请求发给大模型前，先经过关键词/语义分类器 检测到高危意图，立即绕过大模型，输出危机干预话术并触发人工介入 诱导性回复拦截：\nSystem Prompt 加入安全围栏 接入内容安全 API 二次校验 技术架构 长期记忆丢失：\nRedis List 只存最近几十条，一个月前的信息丢失 解决：Memory Summarization，每天对话结束后异步任务浓缩成\u0026quot;侧写\u0026quot;存入向量数据库 语义检索不准：\n用户描述隐晦：\u0026ldquo;心里堵得慌\u0026rdquo; 解决：Query Rewrite，让大模型把口语翻译成标准医学术语再检索 隐私合规 PII 过滤器：\n调用大模型前，正则 + NLP 工具将手机号、姓名替换为占位符 确保核心隐私数据不出域 话术：\n\u0026ldquo;如果继续做，安全性和长期记忆是两个最大瓶颈。安全性上增加危机干预熔断机制，记忆上引入每日摘要功能解决长周期咨询问题。\u0026rdquo;\n正常实习写代码的流程是什么样的？ 写代码之前 需求评审：听懂需求，评估技术可行性 技术方案设计：写 TDD（接口定义、表结构、流程图） 方案评审：Mentor 审核技术选型 写代码之中 分支管理：基于最新代码拉 feature/xxx 分支 单元测试：JUnit/Mockito，覆盖率 60%-80% 代码规范：Checkstyle/Sonar 扫描 提交代码 发起 MR/PR Code Review：逐行审查，打回修改 3-5 次正常 合并主干 测试上线 测试环境验收：QA 提 Bug 单 灰度发布：先发一台观察 CPU/内存/日志，再全量 监控告警：配置日志报警 话术：\n\u0026ldquo;上一段实习团队规模较小，我主要锻炼了独立负责项目全生命周期的能力。但我也意识到在大型团队协作流程（Code Review、单元测试、CI/CD）上还缺乏实战经验，非常渴望加入规范的团队来补齐这块拼图。\u0026rdquo;\n面试暴露的所有问题清单 算法基础（最致命） 求N次方根无法解出，放弃过早 需掌握：二分查找、牛顿迭代法 底层原理（概念混淆） RPC Protobuf 机制理解错误（以为运行时传 .proto 文件） 序列化选择逻辑薄弱 Redis 数据结构理解不深 工程化细节（盲区最大） 不知道 JVM 启动参数 不知道 Redis 实际内存占用 不知道数据库文件大小 部署架构辩护不足 项目闭环（产品思维缺失） 缺乏量化指标（QPS、TP99、准确率） 缺乏用户反馈机制 沟通软技能 过度推卸责任（\u0026ldquo;不是我负责的\u0026quot;说太多） 主动暴露项目缺陷却没有补救方案 简历策略调整 把\u0026quot;水分较多\u0026quot;的实习经历转为\u0026quot;项目经历\u0026quot;展示，避免被问流程细节。\n如果被问到：\n\u0026ldquo;这其实是我在暑期实习期间主要负责的落地项目。因为团队规模精简，我拥有很大的技术自主权，作为核心开发者完整主导了从 RAG 架构设计到 Redis 异步通信的落地。虽然是实习期间做的，但我对底层逻辑和技术细节掌握得非常清楚。\u0026rdquo;\n好处：\n诚实承认是实习背景 把\u0026quot;公司小/流程水\u0026quot;转化为\u0026quot;权限大/独立负责/全栈锻炼\u0026rdquo; Dubbo3 进行 RPC 调用经历了什么？ 消费端（Consumer）—— 决策与封装 代理拦截 (Proxy)：业务代码调用接口，被动态代理拦截，封装成 Invocation 对象\n集群容错 (Cluster)：决定失败策略（Failover/Failfast），掩盖多个 Provider 的事实\n服务目录 (Directory)：从注册中心获取服务列表，Dubbo 3 采用应用级服务发现\n路由选路 (Router)：根据路由规则过滤机器（如标签路由、同机房优先）\n负载均衡 (LoadBalance)：从过滤后的列表选出一台（Random/RoundRobin/LeastActive/ConsistentHash）\n过滤器链 (Filter)：传递 Context、监控埋点、限流降级\n协议与序列化：Triple 协议封装为 HTTP/2 Frame，默认 Protobuf 序列化\n网络传输 Netty 通过 TCP/IP 发送到 Provider Triple 协议支持 Stream 流式调用和背压 服务端（Provider）—— 接收与执行 解码与线程池派发：Netty 解码，请求扔给业务线程池\n服务端过滤器：鉴权、超时检查、限流、解压 Context\n真实调用：通过反射调用 ServiceImpl 方法\n结果返回：序列化 -\u0026gt; 编码 -\u0026gt; Netty 发回 Consumer\n关键路径记忆 1 Proxy -\u0026gt; Cluster -\u0026gt; Directory -\u0026gt; Router -\u0026gt; LoadBalance -\u0026gt; Filter -\u0026gt; Codec/Transport -\u0026gt; ThreadPool -\u0026gt; Implementation Dubbo3 是怎么做序列化的？ 两大流派 流派 协议 默认序列化 特点 经典流派 Dubbo 协议 (TCP) Hessian2 → Fastjson2 Java 内部调用 云原生流派 Triple 协议 (HTTP/2) Protobuf 跨语言、网关穿透 Dubbo 协议处理流程 Consumer 将 POJO 通过 Hessian2/Fastjson2 序列化成字节数组 填充到 Dubbo TCP 报文的 Body 部分 Provider 读取 Header 中的序列化 ID，找到反序列化器还原对象 Triple 协议两种模式 Wrapper 模式（兼容 Java 接口）：\n第一层：Hessian2 序列化业务对象 第二层：封装进 Protobuf 对象（TripleRequestWrapper） 缺点：双重序列化，性能有损耗 IDL 模式（原生 gRPC）：\n直接使用 Protobuf 序列化 性能最高，天然支持跨语言 配置方式 1 2 3 4 dubbo: protocol: name: tri # 或 dubbo serialization: fastjson2 Dubbo 协议相比 Triple 协议差在哪？ 维度 Dubbo 协议 (TCP) Triple 协议 (HTTP/2) 穿透网关 差（私有协议） 极佳（标准 HTTP/2） 跨语言 困难 原生支持 流式通信 不支持 原生支持 (gRPC) 性能 (直连) 极高 较高 Service Mesh 难以治理 完美兼容 选择建议：\n老系统、纯 Java 内部调用、追求极致速度 → Dubbo 协议 新业务、跨语言、上云上 Mesh → Triple 协议 .proto 文件什么时候交换？新服务上线多久能感知？ .proto 文件交换时机 答案：编译期，而非运行期\n交换方式：Git 仓库或 Maven 依赖（api-jar） 原因：Protobuf 传输时完全剔除元数据（字段名、类型），客户端必须提前拿到 .proto 生成代码 新服务感知延迟 答案：通常 1 秒以内（Nacos 2.x），最慢 3-5 秒\n流程（以 Nacos 为例）：\nProvider 启动，向 Nacos 发送注册请求 (T0) Nacos 更新注册表 (T0 + 10ms) Nacos 通过 gRPC 长连接推送给 Consumer (T0 + 20ms) Consumer 更新本地服务目录 (T0 + 50ms) 下一个请求可能选中新机器 (T0 + 100ms) HTTP/2 的序列化一般基于什么？ HTTP/2 本身不限制序列化方式，Body 里装什么都可以。\n常见搭配 序列化 场景 说明 JSON Web 领域 浏览器访问后端，可读性好 Protobuf 微服务/RPC gRPC/Dubbo3，体积小解析快 Hessian2 Dubbo 兼容 Triple + Wrapper 模式 HTTP/2 + JSON 的优势是否发挥？ 你说得对，JSON 确实拖后腿：\n编解码 CPU 浪费（文本解析 vs 二进制复制） 体积膨胀（冗余字段名） 但 HTTP/2 核心优势依然生效：\n多路复用：50 个请求瞬间并发，不再排队 头部压缩 (HPACK)：Header 可能比 Body 还大，压缩 80%-90% 连接复用：避免 TCP 握手和慢启动 结论：\n浏览器 → 服务器：HTTP/2 + JSON 是最佳实践 服务器 → 服务器：请用 HTTP/2 + Protobuf 介绍 Hessian2 核心特点 二进制传输：体积比 JSON 小 Java 友好：无需 IDL，实现 Serializable 即可 性能均衡：比 Java 原生序列化快 10 倍，体积小 50% 三大坑 Java 8 时间类型支持差：LocalDateTime 可能变 null 或 HashMap 方法重载混乱：Dubbo 接口严禁方法重载 父类字段丢失：父类未实现 Serializable 时行为不一致 对比 特性 Hessian2 Protobuf JSON 开发模式 代码优先 IDL 优先 代码优先 性能 中等偏上 极高 中等 跨语言 差 完美 完美 可读性 不可读 不可读 可读 Hessian2 生成的字节流是怎样的？ 结构：类定义 + 实例数据 假设 new User(1, \u0026quot;dubbo\u0026quot;)：\n第一部分：类定义\n1 2 3 4 C (0x43) -\u0026gt; 类定义开始 \u0026#34;com.example.User\u0026#34; -\u0026gt; 类全限定名 2 (0x92) -\u0026gt; 字段数量 \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; -\u0026gt; 字段名 第二部分：实例数据\n1 2 3 4 O (0x4f) -\u0026gt; 对象标记 0 (0x90) -\u0026gt; 引用第 0 号类定义 1 (0x91) -\u0026gt; id 的值（紧凑写法，1 字节） 0x05 + \u0026#34;dubbo\u0026#34; -\u0026gt; name 的值 比 JSON 强在哪？ 发送 100 个 User 对象：\nJSON：\u0026quot;id\u0026quot; 和 \u0026quot;name\u0026quot; 重复写 100 次 Hessian2：类定义只发一次，后续只发值 比 Protobuf 弱在哪？ Protobuf：连类名和字段名都不发（双方代码里已生成） Hessian2：第一次传输必须带元数据（为了不写 .proto 的代价） Hessian2 每次服务器重启都要发送类结构吗？ 答案：不是每次重启，而是每次 RPC 请求都重新发送\n原因：请求级上下文 Hessian2 的\u0026quot;字典\u0026quot;是请求级的，不是连接级的：\n每次 RPC 调用创建新的 Hessian2ObjectOutput 保证无状态，请求可以打到任何机器 为什么不能跨请求复用？ 网络抖动导致 TCP 断开重连 负载均衡转发到另一台机器 新机器不知道\u0026quot;定义 #0\u0026quot;是什么 感知重启的机制 TCP 连接断开：Netty 监听 channelInactive 事件 心跳机制：默认 60 秒心跳，3 次无响应判定死亡 注册中心通知：Nacos 推送下线事件 .proto 生成的 Java 代码是干什么的？ 三件大事 造数据（DTO）：超级数据传输对象 转数据（序列化）：硬编码的位运算逻辑 传数据（RPC 桩）：客户端和服务端对接 消息类代码特点 强制 Builder 模式：\n1 2 3 UserRequest request = UserRequest.newBuilder() .setId(1001) .build(); 不可变性：build() 后无法修改，多线程安全 链式调用：代码流畅 丰富的访问器：\ngetId(), hasAddress(), getRolesList(), getRolesCount() 序列化逻辑（硬编码） 1 2 3 4 5 6 public void writeTo(Output output) { // 不需要反射，直接写字节 output.writeRawByte(0x08); // Tag output.writeRawByte(0xAC); // Value (Varint 编码) output.writeRawByte(0x02); } 优势：\n去掉反射，运行时不查找字段 直接操作字节位，CPU 指令数最少 自动 Varint 压缩，小数字只占 1 字节 服务类代码（Stub） 方法描述符：\n1 2 3 4 5 MethodDescriptor\u0026lt;UserRequest, UserResponse\u0026gt; GET_USER_METHOD = MethodDescriptor.newBuilder() .setFullMethodName(\u0026#34;com.example.UserService/GetUser\u0026#34;) .setRequestMarshaller(...) .build(); 客户端调用：\n1 2 3 4 public UserResponse getUser(UserRequest request) { ClientCall call = channel.newCall(GET_USER_METHOD, callOptions); return ClientCalls.blockingUnaryCall(call, request); } gRPC 的工作流程总结 三步走 定义数据结构：编写 .proto 文件（语言中立的公约）\n生成转换代码：protoc 编译器翻译成各语言代码\nJava → User.java + UserServiceGrpc.java Go → user.pb.go + user_grpc.pb.go 调用生成代码：像调本地方法一样顺滑\n1 stub.getUser(request); // 感觉不到网络存在 跨语言示例 1 2 3 // 共用一份 .proto message HelloRequest { string name = 1; } service Greeter { rpc SayHello (HelloRequest) ... } Java 客户端：\n1 stub.sayHello(HelloRequest.newBuilder().setName(\u0026#34;Lucius\u0026#34;).build()); Go 服务端：\n1 2 3 func (s *server) SayHello(ctx context.Context, req *pb.HelloRequest) { fmt.Println(req.Name) // 输出 \u0026#34;Lucius\u0026#34; } 生成代码做的 4 件事 数据校验与存储：setId(1) 存入内存字段 二进制打包：writeTo() 转换成紧凑字节流 路由填单：定义 MethodDescriptor 常量 交给运输队：ClientCalls.blockingUnaryCall 交给 Netty/HTTP2 一句话总结：根据 Java 对象，利用硬编码逻辑压缩进二进制缓冲区，贴上路由标签，交给 gRPC 核心层通过 HTTP/2 发送。\n","date":"2025-12-15T19:03:54+08:00","permalink":"https://LuciusWan.github.io/p/%E4%BA%8C%E9%9D%A2%E5%A4%8D%E7%9B%98%E7%AC%94%E8%AE%B0/","title":"二面复盘笔记"},{"content":"面试八股4.0 介绍RocketMQ中常用的组件 在 RocketMQ 的架构中，有四个最核心的组件，它们各司其职，共同支撑起整个消息系统的高性能和高可用。\n我们可以把 RocketMQ 想象成一个 “邮政系统” 来理解这些组件：\n1. NameServer (邮局总管 / 路由中心) 角色定位： 它是整个系统的大脑，是一个非常轻量级的注册中心（类似于 ZooKeeper，但更简单，无状态，节点之间互不通信）。\n核心功能：\n服务注册： 所有的 Broker 都要定期向 NameServer 汇报自己的“家庭住址”（IP、端口）和“能送哪些信”（Topic 信息）。\n路由发现： Producer 和 Consumer 启动时，先问 NameServer：“我要发信/收信，请给我一份最新的 Broker 地址名单。”\n特点： 如果 NameServer 挂了，只要集群里还有一台存活，系统就能正常工作。如果全挂了，已有连接的收发不受影响，但无法建立新连接或扩容。\n2. Broker (邮递员 / 分拣站) 角色定位： 它是系统的核心，干活最累的角色。负责存储消息、转发消息。\n核心功能：\n存信： 接收 Producer 发来的消息，持久化到硬盘（CommitLog）。\n送信： 响应 Consumer 的拉取请求，把消息发给它们。\n管理： 处理死信队列、重试队列、定时消息等复杂逻辑。\n部署架构：\nMaster (主)： 负责读和写。\nSlave (从)： 负责备份数据，也可以分担读压力（当主负载高时）。\n3. Producer (寄件人) 角色定位： 业务系统中的消息发送方（比如：订单系统、支付系统）。\n核心功能：\n它从 NameServer 获取路由信息，知道哪个 Topic 在哪些 Broker 上。\n它通过负载均衡算法，把消息发给具体的 Broker。\n发送方式： 支持同步发送（要回执）、异步发送（回调）、单向发送（发完不管，如日志）。\n4. Consumer (收件人) 角色定位： 业务系统中的消息接收方（比如：库存系统、积分系统）。\n核心功能：\n从 Broker 获取消息并进行业务处理（消费）。\n消费模式：\nClustering (集群模式)： 默认模式。同一个消费者组里的机器平分消息（你一条我一条，不重复）。\nBroadcasting (广播模式)： 每一条消息都会发给组里的所有机器（就像广播一样，大家都能听到）。\n辅助的重要概念 除了上面四个“物理组件”，还有几个“逻辑概念”必须知道：\nTopic (主题)： 消息的一级分类。比如“订单交易”是一个 Topic，“用户注册”是另一个 Topic。寄件人必须指定把信投到哪个 Topic。\nTag (标签)： 消息的二级分类。在同一个 Topic 下，可以用 Tag 进一步过滤。比如在“订单交易”Topic 下，可以用 Tag 区分 TagA=食品订单，TagB=服装订单。Consumer 可以只订阅 TagA。\nMessage Queue (消息队列)： 这是物理存储单元。一个 Topic 通常被切分成多个 Message Queue，分布在不同的 Broker 上，以此实现并行发送和消费（提高吞吐量的关键）。\nConsumer Group (消费者组)： 一组逻辑行为一致的 Consumer。RocketMQ 很多机制（如负载均衡、重试、死信）都是以“组”为单位管理的。\n一句话总结它们的协作： Producer 问 NameServer 拿到路由，把信（Message）分类（Topic/Tag）后寄给 Broker；Broker 把信存好；Consumer 从 Broker 拿信并拆开阅读。\nRocketMQ的死信队列是怎样的？ RocketMQ 的死信队列 (Dead Letter Queue, 简称 DLQ) 可以被理解为消息的ICU或者最终归宿。\n当一条消息被消费者不断重试消费，但仍然失败，达到最大重试次数（默认 16 次）后，RocketMQ 就认为这条消息“没救了”。为了不让这条失败的消息一直堵塞正常业务或无限占用资源，Broker 会把它扔到一个特殊的队列里，这个队列就是死信队列。\n以下是关于它的核心机制、特征和使用场景的详细拆解：\n1. 死信是如何产生的？（生命周期） 整个过程可以分为三个阶段：\n正常消费阶段： 生产者发送消息到 Topic，消费者尝试消费。\n重试阶段 (Retry)：\n如果你在代码里抛出异常或返回 RECONSUME_LATER（消费失败），Broker 不会立刻丢弃消息，而是把消息发到一个内部的重试 Topic（名字叫 %RETRY%消费者组名）。\nRocketMQ 会按照梯队时间（1s, 5s, 10s, 30s\u0026hellip; 2h）进行默认 16 次重试。\n死信阶段 (DLQ)：\n如果第 16 次重试依然失败，Broker 就会把这条消息从重试队列移出，发送到死信 Topic。 2. 死信队列的关键特征 你需要记住以下几个非常具有 RocketMQ 特色的点：\n对应关系： 死信队列是基于消费者组 (Consumer Group) 的，而不是基于 Topic 的。\n假设你有一个 Topic 叫 Order_Topic，被 Group_A 和 Group_B 订阅。\n如果 Group_A 消费失败，死信会进 Group_A 专属的死信队列。\nGroup_B 不受影响。\n命名规则： 死信 Topic 的名字是固定的：%DLQ%消费者组名。\n默认不可见： 正常的消费者在启动时，不会自动订阅死信 Topic。也就是说，进入死信队列的消息，默认情况下不再会被消费，静静地躺在那里。\n有效期： 死信队列里的消息也是有有效期的（和普通消息一样，通常 Broker 设置为 3 天）。如果 3 天没人管，它就被物理删除了，数据就真丢了。\n3. 我们该怎么处理死信消息？ 既然消息进了死信队列，说明你的程序可能有 Bug，或者这条消息的数据有问题（也就是所谓的“毒丸消息”）。\n处理死信的标准流程通常是 “人工干预”：\n告警 (Alert)：\n你应该监控 %DLQ% 开头的 Topic。一旦发现里面有消息（offset 增加了），立刻给开发人员发告警。 排查问题 (Debug)：\n开发人员登录 RocketMQ 控制台（Dashboard），查看死信消息的内容，分析为什么会消费失败（是代码逻辑错了？还是上游发的数据格式不对？）。 处理 (Action)：\n场景 A（Bug 修复了）： 在控制台上点击**“重发消息” (Resend)**。这会让消息重新回到正常 Topic，再次被消费者消费。\n场景 B（脏数据）： 确认数据本身就是错的，没法消费，直接在控制台跳过/忽略该消息。\n总结 你可以把 RocketMQ 的机制看作一个分诊系统：\n普通队列： 普通门诊，处理正常病人。\n重试队列 (%RETRY%)： 急诊留观室，病人情况不好，多观察几次，过一会再治治看。\n死信队列 (%DLQ%)： 太平间/ICU。常规手段治不好了，将其移出，以免占用医生资源，等待专家（开发者）专门来做尸检（排查问题）或最后决定。\n介绍TCP的流量控制和拥塞控制 虽然这两个概念经常一起出现，但它们的保护对象完全不同，这一点是面试时区分的关键：\n流量控制 (Flow Control)： 是为了不把接收端填满。是一个点对点（Sender to Receiver）的问题。\n拥塞控制 (Congestion Control)： 是为了不把整个网络（路由器、链路）堵死。是一个全局性的问题。\n1. 流量控制 (Flow Control) 核心机制：滑动窗口 (Sliding Window)\n想象一下，你（Sender）在往一个水缸（Receiver 的缓存）里倒水。\n接收端有一个接收窗口 (rwnd, Receive Window)，代表它的水缸还剩多少空间。\n接收端会在每次回传 ACK 时，顺便把这个 rwnd 的值带给你，告诉你：“我还剩 100字节 的空间，你最多只能发这么多。”\n如果接收端处理不过来了，把 rwnd 设为 0，你（发送端）就会停止发送，进入等待状态，直到收到新的窗口更新通知。\n注：为了防止死锁（接收端有了空间发了通知，但通知丢包了），发送端会定期发送“探测包”去问一下接收端。 2. 拥塞控制 (Congestion Control) 核心机制：拥塞窗口 (cwnd, Congestion Window) + 四大算法\n流量控制只管接收端能不能吃得消，不管中间的网线、路由器堵不堵。如果网络已经很堵了，你发得越快，丢包越多，网络就越堵（正反馈雪崩）。\n为了解决这个问题，发送端自己维护了一个拥塞窗口 (cwnd)。\n最终发送窗口 = min(接收端 rwnd, 自身 cwnd)。\nTCP 使用以下四个经典算法来动态调整 cwnd：\nA. 慢启动 (Slow Start) 原理： 刚建立连接时，不知道网络深浅，不能一上来就全速发送。\n过程：\n先把 cwnd 设为 1（个 MSS）。\n收到一个 ACK，cwnd 加 1。\n收到一轮 ACK 后，cwnd 翻倍（1 $\\rightarrow$ 2 $\\rightarrow$ 4 $\\rightarrow$ 8\u0026hellip;）。\n呈指数增长，直到达到一个阈值 (ssthresh, slow start threshold)。\nB. 拥塞避免 (Congestion Avoidance) 原理： 当 cwnd 超过 ssthresh 后，说明网络可能快饱和了，不能再翻倍了，要小心翼翼地加。\n过程：\n每经过一个 RTT（往返时间），cwnd 只加 1。\n呈线性增长（加法增大），慢慢试探网络的底线。\nC. 快重传 (Fast Retransmit) 触发条件： 发送端连续收到 3 个重复的 ACK。\n比如你发了包 1, 2, 3, 4, 5。接收端收到了 1，没收到 2，收到了 3, 4, 5。\n接收端收到 3, 4, 5 时，都会回复“我想要 2”（ACK 2）。\n发送端一连收到 3 个“ACK 2”，就知道包 2 肯定丢了，不用等超时定时器（Timeout），立刻重传包 2。\nD. 快恢复 (Fast Recovery) 原理： 既然能收到 3 个重复 ACK，说明网络虽然有点堵（丢了个包），但还没完全断（后续的包还能到），不需要像“超时”那样惨烈地重回“慢启动”。\n过程：\n把 ssthresh 设为当前 cwnd 的一半。\n把 cwnd 也设为当前的一半（或者一半 + 3）。\n直接进入拥塞避免阶段（线性增长）。\n注意： 如果是发生超时 (Timeout)，说明网络真的很烂了，连 ACK 都回不来。TCP 会判定为严重拥塞，直接把 cwnd 重置为 1，重新开始慢启动。\n总结对比 特性 流量控制 (Flow Control) 拥塞控制 (Congestion Control) 保护对象 接收端 (Receiver) 网络环境 (Network) 通信范围 点对点 全局性 反馈机制 接收端在 TCP Header 里显式告诉发送端 (rwnd) 发送端根据丢包或延迟自己推测 (cwnd) 核心算法 滑动窗口 (Sliding Window) 慢启动、拥塞避免、快重传、快恢复 发送上限 取决于接收端的缓冲区大小 取决于网络带宽和拥塞程度 HTTP/3 (QUIC) 可靠传输核心 1. 核心设计：传输 ID 与数据 ID 分离 这是 QUIC 区别于 TCP 最关键的设计，解决了 重传歧义 (Retransmission Ambiguity) 问题。\nTCP 的做法（混淆）： 序列号 (Seq) 既代表数据顺序，也代表包的身份。重传时序列号不变，导致发送端无法区分 ACK 到底是回给“原包”的还是“重传包”的，RTT 计算不准。\nQUIC 的做法（分离）：\nPacket Number (包号)： 这里的“快递单号”。严格递增，只增不减。即使是重传，也会用一个新的、更大的 Packet Number。\nStream Offset (流偏移量)： 这里的“书页码”。代表数据在流中的位置，永远不变。\n重传策略： 当包 #100 丢了，QUIC 会把 #100 里的旧数据（Offset），装进新的包 #103 里发出去。\n2. 丢包发现机制 (Loss Detection) 接收端的角色： 接收端不主动请求重传，它只是一个诚实的记录员。\nACK Ranges (SACK)： 接收端回复的 ACK 会明确指出收到的范围。例如：“我收到了 #1-#2，以及 #4”。\n跳号检测： 发送端收到 ACK 后，发现中间缺了 #3（跳号了），从而意识到可能发生了丢包。\n3. 什么时候重传？(Threshold) 发送端发现缺口后，不会立刻重传（防止网络只是抖动/乱序），而是基于阈值判断：\n包数量阈值 (Packet Threshold)： 比如后续又有 3 个包（#4, #5, #6）都到了，#3 还没到，判定 #3 丢失。\n时间阈值 (Time Threshold)： 超过一定时间的 RTT 还没到，判定丢失。\n触发动作： 发送端主动将丢失的数据取出，封装到新包中发送。\n4. 误判与虚假重传 (Spurious Retransmission) 针对“如果包传输太慢，会不会被误判为丢失”的问题：\nMTU 限制： 物理传输中不存在“巨大的包”，所有包最大约为 1.5KB (MTU)。包慢通常是因为排队或路径拥堵，而不是包太大。\n确实会误判： 如果网络抖动过大（超过阈值），发送端会误以为丢包并重传。\n后果（QUIC 优于 TCP）：\n接收端会收到两份数据（旧包迟到了，新包也到了）。\nQUIC 能完美处理： 因为两个包的 Packet Number 不同，发送端能区分哪个 ACK 对应哪个包。接收端只需根据 Offset 去重即可。这不会导致 TCP 那样的 RTT 计算混乱。\n形象记忆法：快递寄书 发货： 用“快递盒 #100”装“第 10 页”。\n丢包： 接收端说“收到 #101, #102，没看到 #100”。\n重传： 发送端拿个新盒子 “快递盒 #103”，装入旧复印件 “第 10 页” 发出去。\n确认： 发送端收到“收到 #103”的回执，精确计算耗时，不会搞混。\nRedis 持久化机制 (RDB) 1. 核心误区修正 Page Cache 归属：Redis 没有自己维护类似 MySQL Buffer Pool 的 Page Cache。所谓的 Page Cache 完全由操作系统内核 (OS Kernel) 管理。\n写入流程：Redis 只是把数据从堆内存写入到了 OS Page Cache，具体的物理刷盘由 OS 调度。\n2. BGSAVE 标准执行流程 (6步) 判断：检查是否有正在执行的 save/bgsave。\nFork (阻塞点)：主线程执行 fork() 创建子进程。此时主线程阻塞（仅阻塞页表复制的时间）。\nCOW (写时复制)：子进程共享父进程物理内存，父进程修改数据时会复制副本，子进程读取的是 fork 瞬间的快照。\n写入内核：子进程遍历内存，调用 write() 将数据写入 OS Page Cache。\n替换文件：写入完成后，原子替换旧的 RDB 文件。\n异步刷盘：操作系统负责将 OS Page Cache 中的数据最终刷入磁盘。\n3. SAVE vs BGSAVE 特性 SAVE BGSAVE (生产标准) 线程 主线程直接执行 子进程执行 阻塞 全程阻塞 (Stop the World) 仅 Fork 瞬间 阻塞 场景 关机维护/迁移 自动快照/主从复制/日常备份 Kafka \u0026amp; RocketMQ 存储底层原理 1. 写入与刷盘机制 两者都利用了顺序写 (Sequential Write) 和 OS Page Cache 来提升吞吐量。\n维度 Kafka RocketMQ 写入核心 FileChannel (Buffered IO) mmap (内存映射) 刷盘策略 异步刷盘 (完全依赖 OS) 异步 (默认) / 同步 (Sync Flush) 零拷贝技术 sendfile (读路径) mmap (读写路径) 2. 存储结构：LSM Tree 还是 Log？ 结论：它们都不是 LSM Tree。\n实质：它们是 Partitioned Log (分区日志) 或 Append-only Log。\n区别：\nLSM (HBase/RocksDB)：为了随机读 (Get Key)，需要排序、合并 (Merge/Compaction)。\nMQ (Kafka/RocketMQ)：为了顺序消费 (Stream)，只追加写，不排序，不合并。\n3. 消费者读取机制 (读写分离？) 是否等落盘？：不需要。\n热读 (Hot Read)：数据刚写入 Page Cache，消费者直接从 Page Cache 读取 (Zero Copy)，此时数据可能还没落盘。\n可见性控制：\nKafka：由 High Watermark (HW) 决定，等 ISR 副本同步完即可读。\nRocketMQ：由 Dispatch (构建索引) 决定，等消息位置写入 ConsumeQueue 即可读。\nRocketMQ 主节点挂了怎么办？(高可用 HA) RocketMQ 的容灾能力取决于部署架构：\n1. 传统主从架构 (Master-Slave) 表现：Master 挂掉后，无法写入，只能读（Consumer 自动切到 Slave）。\n恢复：无法自动切换，需要人工运维介入，修改配置重启。\n2. Dledger 架构 (RocketMQ 4.5+) 原理：引入 Raft 协议。\n表现：Master 挂掉后，Broker 组内自动投票选举出新的 Master。\n结果：自动故障转移 (Failover)，保证写入高可用。\n3. Controller 模式 (RocketMQ 5.0+) 原理：类似 Kafka Controller，由独立的管控节点监控并指定 Master。\n优势：解耦了存储和选主逻辑，更轻量。\n💡 核心总结 (One Liner) Redis、Kafka、RocketMQ 的快很大程度上都归功于“借力”——借用操作系统的 Page Cache 和顺序写能力，而不是自己造轮子去管理磁盘 IO；而高可用则是从“人工介入”向“算法自动选举 (Raft)”进化的过程。\n介绍Copy-On-Write（写时复制） Copy-On-Write (COW，写时复制) 是一种**“拖延战术”**（Lazy Optimization）。\n用一句大白话解释就是：“既然大家读的数据都一样，那就别费劲复制两份了，先共用一份。直到谁真正想修改数据时，再单独给它复制一份出来。”\n下面我从原理、流程、在 Redis 中的体现以及潜在坑点四个方面详细拆解。\n1. 为什么需要 COW？（传统的 Fork 太慢了） 在早期的 Unix 系统中，当一个进程执行 fork() 创建子进程时，操作系统会把父进程的所有内存数据**完整拷贝（Deep Copy）**一份给子进程。\n后果：\n慢：如果父进程占用 10GB 内存，拷贝这 10GB 数据需要很长时间，期间 CPU 满载，父进程阻塞。\n浪费：很多时候子进程只是为了读取数据（比如 Redis 生成快照），并不修改数据。这时候复制出来的 10GB 数据和父进程的一模一样，纯属浪费内存。\n2. COW 的执行原理（核心 4 步） 现代 Linux 系统在 fork() 时默认开启 COW 机制。\n第一步：Fork 瞬间（只复制页表） 当主线程执行 fork() 时，内核不复制物理内存，而是只复制页表 (Page Table)。\n页表就像是内存的“目录”或“指针”。\n结果：父子进程的虚拟内存空间不同，但它们指向的物理内存地址是完全一样的。\n关键动作：内核会将这些共享的物理内存页标记为 Read-Only（只读）。\n第二步：读取数据（相安无事） 如果父进程和子进程都只是读数据：\n大家访问同一个物理内存地址，速度极快，互不干扰。\n内存占用量几乎没有增加（10GB 父进程 + 微量子进程页表 ≈ 10GB）。\n第三步：尝试写入（触发异常） 当父进程（或子进程）试图修改某个数据页（比如修改 Key user:100 的值）：\nCPU 的内存管理单元 (MMU) 发现该页被标记为 Read-Only。\n触发一个缺页中断 (Page Fault) 或 保护异常，通知操作系统内核。\n第四步：复制与分离（Copy 发生） 操作系统内核捕获这个中断后，执行以下操作：\n分配内存：申请一个新的物理内存页。\n复制数据：把旧页面的数据复制一份到新页面中。\n修改映射：把发起修改的进程的页表指向这个新页面，并将权限改为 Read-Write。\n恢复执行：进程重新执行写入操作，这次就写入到自己的私有页面了。\n结果：只有被修改的那一小块内存页（通常是 4KB）被复制了，其他未修改的数据依然共享。\n3. COW 在 Redis BGSAVE 中的实战表现 回到 Redis 的场景，假设你的 Redis 占用了 8GB 内存。\n场景 A：读多写少（绝大部分数据不变更）\nFork 出来的子进程做快照时，大部分内存页面一直未被修改。\n实际内存开销：可能只比 8GB 多一点点（比如 8.1GB）。Redis 几乎不需要额外消耗物理内存。\n性能：极快，主线程几乎不感觉卡顿。\n场景 B：写多读少（疯狂修改数据）\n在子进程做快照期间，主线程接收了海量写请求，把这 8GB 里的数据几乎全改了一遍。\n触发 COW：每改一个页，OS 就要复制一个页。\n实际内存开销：随着修改量的增加，内存占用会迅速逼近 16GB（8GB 原数据 + 8GB 新数据）。\n性能：主线程在写入时会产生轻微的延迟（因为要处理缺页中断和内存拷贝）。\n面试金句： \u0026ldquo;Redis 的 BGSAVE 利用了操作系统的 COW 机制。Fork 子进程时并不复制数据，而是共享内存。只有当主线程修改数据时，才会在物理内存中复制被修改的数据页。这使得 Redis 在生成快照时，内存开销通常远小于 2 倍。\u0026rdquo;\n4. 进阶考点：COW 的“天敌”——HugePage (大页内存) 这是面试中的一个高阶坑点。\n背景：Linux 默认内存页大小是 4KB。但也支持 2MB 甚至 1GB 的 HugePage。\n问题：\n如果你开启了 2MB 的 HugePage。\n当你只修改了 Redis 中一个 10 字节 的 Key。\nCOW 机制为了隔离数据，必须复制整个 2MB 的大页。\n后果：\n内存写放大：明明只改了一点点，却拷贝了大量内存。\n延迟增加：拷贝 2MB 显然比拷贝 4KB 慢得多，会导致主线程在写操作时出现明显的阻塞（Latency Spike）。\n最佳实践： 在运行 Redis 的机器上，强烈建议关闭系统级的 Transparent Huge Pages (THP)。 命令通常是：echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\nTHP是什么：Transparent Huge Pages (THP) Huge Pages (大页内存)： Linux 默认的内存页大小是 4KB。为了提高内存访问效率（减少 TLB 缓存未命中），Linux 支持 2MB 甚至 1GB 的“大页”。\nTransparent (透明)： 以前使用大页需要手动配置，很麻烦。后来 Linux 搞了个 THP (Transparent Huge Pages) 功能。 它作为一个后台线程，会自动扫描内存，如果发现有连续的 4KB 页面，就自动把它们合并成一个 2MB 的大页。这对用户是“透明”的，应用程序不用改代码就能享受大页的好处。\n这听起来是个好功能，对吧？但在 Redis 场景下，它变成了“好心办坏事”。\nMySQL的char和varchar的区别是什么 特性 (Feature) CHAR(M) VARCHAR(M) 存储方式 固定长度 (Fixed-length) 可变长度 (Variable-length) 空间占用 始终占用 M 个字符的存储空间。 占用 实际字符串长度 + 1 或 2 字节的长度前缀。 空间填充 (Padding) 当存储的字符串长度小于 M 时，会在右侧填充空格 (Trailing spaces)。 存储时不会填充空格，只占用实际需要的空间。 检索处理 检索时通常会自动移除末尾填充的空格 (除非启用特殊模式)。 检索时会保留所有尾随空格。 最大长度 0 到 255 个字符。 0 到 65,535 个字符 (受限于行最大长度 65535 字节)。 性能/适用场景 适用于长度固定不变的数据 (如：MD5 散列、状态码、性别)。 查询和索引速度通常更快。 适用于长度变化较大的数据 (如：姓名、地址、描述)。 更节省存储空间。 介绍常见的JVM实现，介绍他们的区别 1. HotSpot VM (Oracle/OpenJDK) —— \u0026ldquo;绝对的霸主\u0026rdquo; 这是目前世界上使用最广泛的 JVM，也是你我日常开发、绝大多数公司生产环境默认使用的版本。\n厂商： Oracle（最初由 Sun 收购的 Longview Technologies 开发）。\n核心特点：\n热点探测 (Hot Spot Detection)： 它的名字由来。它不预先编译所有代码，而是像侦探一样通过计数器找到执行最频繁的“热点代码”，然后用 JIT (Just-In-Time) 编译器把它们编译成高度优化的本地机器码。\n双编译器架构： 拥有 C1 (Client Compiler，编译快但在优化上较保守) 和 C2 (Server Compiler，编译慢但在优化上极其激进) 两个编译器，现在通常混合使用（分层编译）。\n适用场景： 通杀。从桌面应用到大型微服务集群。\n现状： OpenJDK 的默认虚拟机。\n2. J9 (OpenJ9 / IBM J9) —— \u0026ldquo;内存管理的艺术大师\u0026rdquo; 如果你在 IBM 的体系（如 AIX 系统、WebSphere 中间件）下工作过，你一定见过它。现在已经贡献给 Eclipse 基金会，改名为 Eclipse OpenJ9。\n厂商： IBM（现 Eclipse 基金会）。\n核心区别 (vs HotSpot)：\n内存占用极低： J9 的设计初衷之一就是为了嵌入式和受限环境。同样的 Spring Boot 应用，跑在 OpenJ9 上通常比 HotSpot 节省 30%~50% 的内存。\n启动速度快： 它利用了 AOT (Ahead-Of-Time) 编译技术和类共享 (Shared Classes) 机制，使得应用启动非常快。\n吞吐量稍弱： 在长时间运行的极限吞吐量测试中，通常略逊于 HotSpot 的 C2 编译器。\n适用场景： 容器化环境（Docker/K8s）、微服务（因为省内存=省钱）、命令行工具。\n3. GraalVM —— \u0026ldquo;多语言通天塔 \u0026amp; 原生镜像\u0026rdquo; 这是 Oracle 实验室搞出来的“新物种”，近年来热度极高。严格来说，它不仅是一个 JVM，更是一个多语言运行时平台。\n厂商： Oracle Labs。\n核心区别：\nGraal Compiler： 它是用 Java 写的一个新的 JIT 编译器，旨在替代 HotSpot 老旧的 C++ 写的 C2 编译器。它的优化能力非常强，尤其是在通过逃逸分析消除对象分配方面。\nNative Image (原生镜像)： 这是它最杀手级的功能。它可以把 Java 代码直接编译成独立的二进制可执行文件（就像 C++ 编译出来的那样）。\n结果： 启动时间从几秒变成 毫秒级，内存占用极小。但失去了动态加载类的能力（反射受限）。 多语言互通： 你可以在 Java 里无缝调用 Python、R、JavaScript 代码，且性能极高（因为它们最终都变成了 Graal 的中间表示 IR）。\n适用场景： Serverless (AWS Lambda 等冷启动敏感场景)、云原生应用、多语言混合开发。\nJVM 实现 别名/特点 内存占用 启动速度 极限吞吐量 典型场景 HotSpot 标准版 中 中 极高 通用，绝大多数互联网后端 OpenJ9 省钱版 极低 快 高 容器、微服务、受限环境 GraalVM 未来版/原生版 低 (Native) 极快 (Native) 高 Serverless、云原生、多语言 Azul Zing 氪金版 高 快 (ReadyNow) 极高 金融高频交易、超大堆内存 为什么J9比GraalVM还省内存？ 1. 杀手锏：类共享缓存 (Shared Classes Cache, SCC) 这是 OpenJ9 最核心的黑科技。\nHotSpot/GraalVM 的做法：\n如果你在同一个机器（或容器宿主机）上启动了 5 个 Spring Boot 应用，HotSpot 会把 java.lang.String、ArrayList 这些基础类的元数据加载 5 次，存在 5 个不同的 Metaspace（元空间）里。这是极大的浪费。\nOpenJ9 的做法：\n它会在磁盘或内存中创建一个 SCC (Shared Classes Cache) 文件。\n第一个启动的进程把类加载进来，解析好，扔进 SCC。\n后面启动的第 2、3、4、5 个进程，直接映射（mmap）这块内存。它们不需要重新解析类，甚至不需要占用自己的私有内存，直接共用那一份只读内存。\n结果： 在微服务容器化场景下，OpenJ9 能节省惊人的内存（通常 30%~50%），因为 80% 的基础类大家都是一样的。\n2. 内存管理策略：吝啬 vs. 豪横 HotSpot (GraalVM) —— “占地为王”：\nHotSpot 的堆内存策略是为了减少和操作系统的交互。\n一旦它向操作系统申请了内存（比如堆涨到了 2GB），即便后来 GC 回收了对象，堆里空了 1.5GB，HotSpot 也往往不愿意把这块物理内存还给操作系统。它会留着，“万一等会儿又要用呢？”\n这就导致它的 RSS (常驻集大小，真正的物理内存占用) 一直很高。\nOpenJ9 —— “用多少借多少”：\nOpenJ9 的堆扩容极其“吝啬”。它启动时只申请极小的内存。\n更重要的是，GC 发生后，如果发现有空闲内存，它会非常积极地把物理内存归还给操作系统。\n这使得它的 RSS 曲线非常贴合实际使用量，而不是像 HotSpot 那样一直顶着上限跑。\n3. 对象头与指针压缩 (Compressed References) 虽然 HotSpot 也有指针压缩，但 IBM 在这方面做得更绝。\n设计渊源： J9 最早是 IBM 为小型机甚至嵌入式设备设计的（VisualAge Smalltalk 虚拟机演变而来）。\n实现细节： OpenJ9 的对象头（Object Header）设计得非常紧凑，甚至在某些复杂的继承结构和锁状态下，它用的辅助数据结构都比 HotSpot 小。对于成千上万个对象来说，每个少几个字节，总量就很客观了。\n4. 编译器线程的开销 GraalVM (JIT)：\nGraal 编译器本身是用 Java 写的。这意味着 JIT 编译器本身就在消耗 Java 堆内存。当应用刚启动在这个“编译热潮”期，Graal 编译器会产生大量的对象，导致堆内存瞬间飙升。\nOpenJ9：\n它的 JIT 编译器（Testarossa）是用 C++ 写的，而且对线程资源的调度非常克制。它不会为了追求极速启动而瞬间吃掉大量资源（除非你开启了激进模式）。\n总结 为什么 J9 比 GraalVM (JIT模式) 更省内存？\n特性 OpenJ9 GraalVM (HotSpot Based) 多进程复用 SCC 技术 (多个 JVM 共用一份类元数据) 无 (每个 JVM 独占一份) 归还内存 极度积极 (GC 后立刻还给 OS) 保守 (倾向于持有内存以换取吞吐量) JIT 开销 C++ 编写，且优化了内存占用 Java 编写，编译过程本身消耗堆内存 设计基因 嵌入式/受限环境 (够用就好) 服务器/高性能 (性能至上，空间换时间) 物理真相：Page Cache 才是真正的“幕后金主” 当 OpenJ9 调用 mmap 将 SCC 文件映射到内存时，发生了以下事情：\n文件映射： 操作系统并不会立刻把整个 SCC 文件读进内存，而是建立了一个“映射关系”。\n缺页中断 (Page Fault)： 当 JVM A 试图读取某个类（比如 java.lang.String）时，CPU 发现这块虚拟地址没有对应物理内存，触发缺页中断。\n内核加载 (Kernel Load)： 操作系统内核接管，从磁盘读取这部分数据，放入 内核管理的 Page Cache（物理 RAM） 中。\n建立页表 (Page Table)： 操作系统修改 JVM A 的页表，让 JVM A 的虚拟地址直接指向这块 Page Cache 的物理页。\n关键点来了： 当 JVM B 启动并也 mmap 同一个 SCC 文件时：\n它也要读 java.lang.String。\n操作系统一看：“嘿，这个文件的这部分数据已经在 Page Cache 里了（因为 JVM A 读过了）。”\n操作系统直接修改 JVM B 的页表，把它也指向 同一块 Page Cache 物理页。\n为什么比“自己解析”还要快？ 你可能会问：“都在 Page Cache 里，那也只是省了从磁盘读的时间，JVM 不需要解析吗？”\n这正是 OpenJ9 SCC 的高明之处： SCC 文件里存的不是原始的 .class 字节码（bytecodes），而是经过 JVM 解析处理后的内部数据结构（ROMClasses），甚至包含了 AOT 编译后的本地机器码。\n普通 JVM (HotSpot)： 磁盘 .class -\u0026gt; Page Cache -\u0026gt; Copy 到堆内存 -\u0026gt; 解析验证 -\u0026gt; 生成内部 Class 对象。 (每个 JVM 都要把这个流程走一遍，并在自己的堆里存一份)\nOpenJ9 (SCC)： 磁盘 SCC文件 (已经是解析好的结构) -\u0026gt; Page Cache -\u0026gt; JVM 直接指针引用。 (JVM 不需要解析，不需要 Verify，直接拿指针指过去就能用。这就是所谓的 \u0026ldquo;Pointer Swizzling\u0026rdquo; 技术)\n1. 业务场景：AI 流式响应的同步化 场景：在后端调用 AI 模型，既要向前端推送 SSE 流（实时），又要等待完整结果存库（同步）。\n解决方案：CompletableFuture (异步执行 AI 请求) + CountDownLatch (主线程阻塞等待)。\n核心逻辑：\n主线程 latch.await(30s) 阻塞。\n异步线程收到 AI 完成信号或报错时，执行 latch.countDown()。\n优缺：将异步流强行转为同步阻塞，适合必须存库的场景，但高并发下会占用 Servlet 容器线程。\n2. JUC 工具对比：CompletableFuture vs CountDownLatch 特性 CompletableFuture CountDownLatch 本质 异步编排工具 同步协作工具 核心作用 任务链式处理、回调、组合 (Future 的增强版) 多线程间的倒计时协调 (A 等 B、C、D 做完) 阻塞性 非阻塞 (基于回调 Callback) 阻塞 (调用 await 的线程被挂起) 底层 基于 ForkJoinPool (默认) 基于 AQS (共享锁模式) 适用 复杂的异步任务流 (如调用 AI、微服务聚合) 并发流程控制 (如压测发令枪、主线程等子线程) 3. 并发基石：AQS (AbstractQueuedSynchronizer) AQS 是 Java 并发包（Lock, Latch, Semaphore）的通用骨架。\n3.1 核心三要素 State (volatile int)：\n同步状态资源。\nReentrantLock 中代表“锁占用情况”；CountDownLatch 中代表“倒计时剩余次数”。\nCLH 队列 (FIFO)：\n双向链表，存放抢不到资源、需要排队的线程（Node）。 Owner Thread：\n当前持有资源的线程。 3.2 工作机制 抢锁 (Acquire)：线程尝试用 CAS 修改 state。\n成功 -\u0026gt; 执行业务。\n失败 -\u0026gt; 封装成 Node 入队 -\u0026gt; 自旋重试 -\u0026gt; 阻塞 (LockSupport.park)。\n释放 (Release)：修改 state -\u0026gt; 唤醒 (unpark) 队列头部的线程。\n3.3 概念辨析 CAS (砖块)：CPU 指令 (cmpxchg)，无锁原子操作，是实现 AQS 的基础工具。\nAQS (图纸)：定义了排队、阻塞、唤醒的逻辑框架。\nCountDownLatch (大门)：基于 AQS 实现的具体工具类。\nsynchronized (房间)：JVM 层面的互斥锁（Monitor），与 AQS 体系独立。\n4. 线程模型：Kernel-Level Threads (KLT) Java 线程与操作系统线程是 1:1 映射关系。\n4.1 运行位置辨析（易错点） 身份：Java 线程是内核级线程（由 OS 内核管理、调度、发工资）。\n工作地点：\n90% 时间：在用户态 (User Mode) 运行，执行 JVM 里的 Java 字节码（如 i++, Map.put）。\n10% 时间：在内核态 (Kernel Mode) 运行，当发起系统调用（如 IO、Thread Park）时。\n4.2 运行机制 双栈结构：每个线程拥有 User Stack (运行 Java 代码) 和 Kernel Stack (运行内核代码)。\n陷阱 (Trap)：线程从用户态切换到内核态的过程。\n开销：上下文切换 (Context Switch) 成本高，因为涉及 TLB 刷新、寄存器保存、特权级切换 (Ring 3 -\u0026gt; Ring 0)。\n5. JNI 与系统调用 (System Call) 5.1 JNI (Java Native Interface) 本质：Java 调用 C/C++ 代码的桥梁。\n通信方式：进程内直接调用，非 IPC（进程间通信）。Java 和 C++ 代码在同一个进程地址空间。\n是否陷入内核？：否。调用 JNI 方法本身只是 CPU 指令跳转，依然在用户态。\n5.2 系统调用 (System Call) 本质：用户态程序请求操作系统服务的接口（如 read, write, futex）。\n触发：通常由 JNI 调用的 C++ 代码（如 glibc 库）发起汇编指令（SYSCALL/INT 0x80）。\n结果：CPU 发生陷入 (Trap)，切换到内核态，在内核栈执行 OS 代码。\n5.3 完整链路（以 File Read 为例） Java: FileInputStream.read() (用户态)\nJNI: read0() -\u0026gt; JVM_Read (用户态，跳转到 C++)\nC/C++: 调用 glibc read() (用户态)\nAssembly: 执行 SYSCALL 指令 (触发点)\nKernel: CPU 陷入内核态 -\u0026gt; 执行文件系统驱动 -\u0026gt; 读取硬盘 (内核态)\nReturn: 数据拷回用户缓冲区 -\u0026gt; 返回 Java (回到用户态)\n1. Spring Boot/Tomcat 的核心网络模型 结论：Spring Boot（默认 Tomcat）底层确实使用了 I/O 多路复用。\n1.1 工作流程 在 Linux 环境下，Tomcat（NioEndpoint）通过 JDK NIO 映射到内核的 epoll 机制。\n监听 (Poller)：Tomcat 使用少量的 Poller 线程（持有 Selector）通过 epoll_wait 监听成千上万个连接。\n触发：仅当网卡接收到数据，并通过中断写入内核缓冲区后，epoll 才会唤醒 Poller 线程。\n分发 (Dispatch)：Poller 将就绪的 Socket 封装成任务，丢给 Worker 线程池。\n处理：Worker 线程执行 read()（将数据从内核态拷贝到用户态）、解析 HTTP、执行 Controller 业务逻辑。\n1.2 关键区分 硬件层：网卡到内核的数据传输由 硬中断/软中断 处理（不涉及 epoll）。\n应用层：内核通知应用“有数据了”，才是 epoll 发挥作用的地方。\n2. 架构对比：Tomcat NIO vs Redis 6.0+ 两者都利用多线程来减轻主线程在 “内核态 -\u0026gt; 用户态”数据拷贝 (read/write) 上的 CPU 开销，但业务处理模型截然不同。\n维度 Tomcat (NIO + ThreadPool) Redis 6.0+ (IO Threads) IO 读写执行者 Worker 线程 (并发) 辅助 IO 线程 (并发) 业务逻辑执行者 Worker 线程 (并发) Main 线程 (单线程) 并发安全性 需考虑锁 (多线程并发执行业务) 无需锁 (业务逻辑串行) 设计哲学 全栈代理：Worker 负责从读写到业务的全流程。 工具人模式：IO 线程只负责搬运数据，主线程独掌大权。 形象比喻：\nTomcat：多个服务员同时接待客人，每个人既负责点菜也负责炒菜（并发高，需解决资源竞争）。\nRedis：多个帮厨只负责洗菜切菜，所有菜都由同一个主厨亲自炒（无竞争，速度极快）。\n3. Java I/O 模型演进 (BIO vs NIO vs AIO) 核心区别在于 “谁在等数据” 和 “谁在拷贝数据”。\n3.1 BIO (Blocking I/O) - JDK 1.4 前 机制：One Thread Per Connection。\n痛点：线程在 read() 时，如果没数据会死等（阻塞）。\n状态：1000 个连接需要 1000 个线程，资源消耗极大。Tomcat 已弃用。\n3.2 NIO (Non-blocking I/O) - JDK 1.4+ (Tomcat 默认) 机制：多路复用 (Epoll/Selector)。\n流程：\n等数据：由 Selector（内核 epoll）负责，线程不阻塞。\n拷贝数据：数据就绪后，Worker 线程自己负责调用 read() 拷贝数据（此处是同步的）。\n优势：少量线程管理海量连接。\n3.3 AIO (Asynchronous I/O) - JDK 1.7+ 机制：Proactor (异步回调)。\n流程：\n应用发起读请求后直接返回。\n操作系统负责等待数据 并 将数据拷贝到用户内存。\n全部做完后，操作系统回调通知应用。\n现状：\nWindows (IOCP) 支持完美。\nLinux 底层缺乏真正 AIO 支持（本质还是 epoll 模拟），性能提升不明显且复杂。\n因此 Tomcat 和 Netty 均未采用 AIO。\n4. 操作系统底层差异 (Linux vs Windows) 4.1 BIO 的线程代价 1:1 模型：Java 的一个用户线程 = 操作系统的一个内核线程 (LWP)。\n阻塞后果：BIO 模式下，如果有 N 个 Socket，内核中就有 N 个线程处于阻塞状态，导致上下文切换和内存占用极高。\n4.2 为什么服务器首选 Linux？ 特性 Linux Windows 核心机制 epoll (高效、被动通知) IOCP (异步、主动通知) 内核设计 专为服务器吞吐量优化，系统调用开销低。 兼顾桌面响应性，内核对象复杂，高频 Syscall 开销较大。 生态 Java/Tomcat/Redis 等中间件原生适配度最高。 虽然支持，但在高并发网络 I/O 场景下通常不如 Linux 高效。 ","date":"2025-12-06T15:00:20+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A14.0/","title":"面试八股4.0"},{"content":"算法强基计划 快速排序 快速排序就是选择一个作为基准元素，左边的元素放比基准元素小的，右边放比基准元素大的，然后分别对左右两个区间进行递归。\n我的这个方法是以最左边的元素为基准，遍历区间，然后找到比当前元素大的元素就交换i和j对应的元素，然后i++，最后把i-1位置的元素和low位置的元素进行交换，最终实现排序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package com.lucius.interviewproject.SortTest; import java.util.Scanner; public class QuickSortTest { public static void quickSort(int[] arr,int low,int high){ if(low\u0026lt;high){ //采用分治法的思想，将数组分为左右两个子数组 int pivotIndex=partition(arr,low,high); quickSort(arr,low,pivotIndex-1); quickSort(arr,pivotIndex+1,high); } } public static int partition(int[] arr,int low,int high){ //将数组分为左右两个子数组，并返回中间位置 int pivot=arr[low]; int i=low+1; for(int j=low+1;j\u0026lt;=high;j++){ //将小于pivot的元素移到左边，大于pivot的元素移到右边 if(pivot\u0026gt;arr[j]){ int temp=arr[j]; arr[j]=arr[i]; arr[i]=temp; i++; } } //将pivot放到中间位置 int temp=arr[i-1]; arr[i-1]=pivot; arr[low]=temp; return i-1; } public static void main(String[] args){ Scanner sc=new Scanner(System.in); int n=sc.nextInt(); int[] arr=new int[n]; for(int i=0;i\u0026lt;n;i++){ arr[i]=sc.nextInt(); } for(int a:arr){ System.out.print(a+\u0026#34; \u0026#34;); } System.out.println(); quickSort(arr,0,n-1); for(int a:arr){ System.out.print(a+\u0026#34; \u0026#34;); } } } 142. 环形链表 II - 力扣（LeetCode） 直接逃课打法，哈希表查重\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Solution { public ListNode detectCycle(ListNode head) { HashSet\u0026lt;ListNode\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); while(head!=null){ if(set.contains(head)){ return head; } set.add(head); head=head.next; } return null; } } 24. 两两交换链表中的节点 - 力扣（LeetCode） 这题有点难搞，第n次做感觉都不一定能做出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public ListNode swapPairs(ListNode head) { ListNode dummy=new ListNode(); dummy.next=head; ListNode cur=dummy; while(cur.next!=null\u0026amp;\u0026amp;cur.next.next!=null){ ListNode node1=cur.next; ListNode node2=cur.next.next; ListNode node3=cur.next.next.next; node2.next=node1; node1.next=node3; //让当前的虚拟头节点的next指向正确的节点 cur.next=node2; //更新当前虚拟头节点的位置，继续进行下一轮交换 cur=node1; } return dummy.next; } } 19. 删除链表的倒数第 N 个结点 - 力扣（LeetCode） 简单题，先遍历n次节点，然后再用一个新的节点遍历剩余次数，然后进行节点删除即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy=new ListNode(); dummy.next=head; ListNode cur=dummy; for(int i=0;i\u0026lt;n;i++){ cur=cur.next; } ListNode node=dummy; while(cur.next!=null){ cur=cur.next; node=node.next; } node.next=node.next.next; return dummy.next; } } 面试题 02.07. 链表相交 - 力扣（LeetCode） 依旧简单题，找到两个链表的相同节点即可，记得用.equals()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { int aLen=0; int bLen=0; ListNode node1=headA; ListNode node2=headB; while(node1!=null){ node1=node1.next; aLen++; } while(node2!=null){ node2=node2.next; bLen++; } node1=headA; node2=headB; int count=Math.abs(aLen-bLen); if(aLen\u0026gt;bLen){ while(count\u0026gt;0){ node1=node1.next; count--; } }else{ while(count\u0026gt;0){ node2=node2.next; count--; } } for(int i=0;i\u0026lt;Math.min(aLen,bLen);i++){ if(node1.equals(node2)){ return node1; } node1=node1.next; node2=node2.next; } return null; } } 704. 二分查找 - 力扣（LeetCode） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution { public int search(int[] nums, int target) { int left=0; int right=nums.length-1; while(left\u0026lt;=right){ int mid=(right-left)/2+left; if(nums[mid]==target){ return mid; }else if(nums[mid]\u0026lt;target){ left=mid+1; }else{ right=mid-1; } } return -1; } } 27. 移除元素 - 力扣（LeetCode） 1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public int removeElement(int[] nums, int val) { int fast=0; int slow=0; for(;fast\u0026lt;nums.length;fast++){ if(nums[fast]!=val){ nums[slow]=nums[fast]; slow++; } } return slow; } } 977. 有序数组的平方 - 力扣（LeetCode） 最作弊的写法\n1 2 3 4 5 6 7 8 9 class Solution { public int[] sortedSquares(int[] nums) { for(int i=0;i\u0026lt;nums.length;i++){ nums[i]*=nums[i]; } Arrays.sort(nums); return nums; } } 因为数组已经排好序了，可以直接用双指针\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution { public int[] sortedSquares(int[] nums) { int n=nums.length; int[] arr=new int[n]; int slow=0; int fast=n-1; n-=1; while(n\u0026gt;=0){ int nFast=nums[fast]*nums[fast]; int nSlow=nums[slow]*nums[slow]; if(nFast\u0026lt;nSlow){ arr[n--]=nSlow; slow++; }else{ arr[n--]=nFast; fast--; } } return arr; } } 242. 有效的字母异位词 - 力扣（LeetCode） 非常简单的一个哈希表，字母可以考虑int[26]还有char c，arr[c-\u0026lsquo;a\u0026rsquo;]++;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public boolean isAnagram(String s, String t) { int[] hash=new int[26]; if(s.length()!=t.length()){ return false; } for(int i=0;i\u0026lt;s.length();i++){ hash[s.charAt(i)-\u0026#39;a\u0026#39;]++; } for(int i=0;i\u0026lt;t.length();i++){ hash[t.charAt(i)-\u0026#39;a\u0026#39;]--; } for(int i=0;i\u0026lt;26;i++){ if(hash[i]!=0){ return false; } } return true; } } 349. 两个数组的交集 - 力扣（LeetCode） 感觉写复杂了，其中遍历set集合中的元素方法应该记牢,还有遍历map的\n1 2 3 4 5 6 7 8 9 10 HashSet\u0026lt;Integer\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); ... for(int a:setResult){ result[index++]=a; } HashMap\u0026lt;Integer,Integer\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); ... for(Map.Entry\u0026lt;Integer,Integer\u0026gt; entry:map.entrySet()){ System.out.println(entry.getValue()); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class Solution { public int[] intersection(int[] nums1, int[] nums2) { int len1=nums1.length; int len2=nums2.length; if(len1\u0026gt;len2){ HashSet\u0026lt;Integer\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); HashSet\u0026lt;Integer\u0026gt; setResult=new HashSet\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;len1;i++){ set.add(nums1[i]); } for(int i=0;i\u0026lt;len2;i++){ if(set.contains(nums2[i])){ setResult.add(nums2[i]); } } int[] result=new int[setResult.size()]; int index=0; for(int a:setResult){ result[index++]=a; } return result; }else{ HashSet\u0026lt;Integer\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); HashSet\u0026lt;Integer\u0026gt; setResult=new HashSet\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;len2;i++){ set.add(nums2[i]); } for(int i=0;i\u0026lt;len1;i++){ if(set.contains(nums1[i])){ setResult.add(nums1[i]); } } int[] result=new int[setResult.size()]; int index=0; for(int a:setResult){ result[index++]=a; } return result; } } } 202. 快乐数 - 力扣（LeetCode） 非常简单的一道哈希表，如果遇到重复就退出就行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { public boolean isHappy(int n) { HashSet\u0026lt;Integer\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); while(true){ int result=func(n); n=result; if(result==1){ return true; } if(set.contains(result)){ return false; }else{ set.add(result); } } } public int func(int n){ List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); while(n!=0){ list.add(n%10); n/=10; } int [] arr=new int[list.size()]; int sum=0; for(int i=0;i\u0026lt;list.size();i++){ sum+=list.get(i)*list.get(i); } return sum; } } 1. 两数之和 - 力扣（LeetCode） 非常简单的哈希表，但是注意不能自己加自己\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Solution { public int[] twoSum(int[] nums, int target) { HashMap\u0026lt;Integer,Integer\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;nums.length;i++){ map.put(nums[i],i); } for(int i=0;i\u0026lt;nums.length;i++){ int a=target-nums[i]; if(map.containsKey(a)\u0026amp;\u0026amp;map.get(a)!=i){ int [] arr=new int[2]; arr[0]=i; arr[1]=map.get(a); return arr; } } return null; } } 454. 四数相加 II - 力扣（LeetCode） 这道题就是先两数之和，然后再进行两数之和，比较简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Solution { public int fourSumCount(int[] nums1, int[] nums2, int[] nums3, int[] nums4) { int n=nums1.length; int count=0; HashMap\u0026lt;Integer,Integer\u0026gt; map1=new HashMap\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;n;i++){ for(int j=0;j\u0026lt;n;j++){ int sum=nums1[i]+nums2[j]; if(map1.containsKey(sum)){ map1.put(sum,map1.get(sum)+1); }else{ map1.put(sum,1); } } } for(int i=0;i\u0026lt;n;i++){ for(int j=0;j\u0026lt;n;j++){ int sum=nums3[i]+nums4[j]; if(map1.containsKey(-sum)){ count+=map1.get(-sum); } } } return count; } } 383. 赎金信 - 力扣（LeetCode） 这道题就是26字母的哈希表问题，很简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public boolean canConstruct(String ransomNote, String magazine) { int[] arr=new int [26]; for(int i=0;i\u0026lt;ransomNote.length();i++){ arr[ransomNote.charAt(i)-\u0026#39;a\u0026#39;]++; } for(int i=0;i\u0026lt;magazine.length();i++){ if(arr[magazine.charAt(i)-\u0026#39;a\u0026#39;]\u0026gt;0){ arr[magazine.charAt(i)-\u0026#39;a\u0026#39;]--; } } for(int i=0;i\u0026lt;26;i++){ if(arr[i]!=0){ return false; } } return true; } } 15. 三数之和 - 力扣（LeetCode） 三数之和老朋友了，遍历+双指针，然后考虑去重，要用while，还有就是别忘了排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class Solution { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result=new ArrayList\u0026lt;\u0026gt;(); int a=Integer.MAX_VALUE; int n=nums.length; Arrays.sort(nums); for(int i=0;i\u0026lt;n-2;i++){ if(nums[i]==a){ continue; } a=nums[i]; int left=i+1; int right=n-1; while(left\u0026lt;right){ int sum=nums[i]+nums[right]+nums[left]; if(sum==0){ List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(nums[i]); list.add(nums[right]); list.add(nums[left]); result.add(list); while(left+1\u0026lt;right\u0026amp;\u0026amp;nums[left]==nums[left+1]){ left++; } while(right-1\u0026gt;left\u0026amp;\u0026amp;nums[right]==nums[right-1]){ right--; } left++; right--; }else if(sum\u0026gt;0){ right--; }else { left++; } } } return result; } } 18. 四数之和 - 力扣（LeetCode） 这题很有难度，但又好像没有，主要是比较复杂，前两个节点都要去重，其他的和三数之和一样\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class Solution { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; fourSum(int[] nums, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result=new ArrayList\u0026lt;\u0026gt;(); int n=nums.length; Arrays.sort(nums); for(int i=0;i\u0026lt;n-3;i++){ if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } for(int j=i+1;j\u0026lt;n-2;j++){ if(j\u0026gt;i+1\u0026amp;\u0026amp;nums[j]==nums[j-1]){ continue; } int left=j+1; int right=n-1; while(left\u0026lt;right){ long sum=(long)nums[i]+nums[j]+nums[left]+nums[right]; if(sum==target){ List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(nums[i]); list.add(nums[j]); list.add(nums[left]); list.add(nums[right]); result.add(list); while(left+1\u0026lt;right\u0026amp;\u0026amp;nums[left+1]==nums[left]){ left++; } while(right-1\u0026gt;left\u0026amp;\u0026amp;nums[right-1]==nums[right]){ right--; } left++; right--; }else if(sum\u0026lt;target){ left++; }else{ right--; } } } } return result; } } 344. 反转字符串 - 力扣（LeetCode） 最简单的字符串问题，直接用双指针做\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public void reverseString(char[] s) { int left=0; int right=s.length-1; while(left\u0026lt;right){ char temp=s[left]; s[left]=s[right]; s[right]=temp; left++; right--; } } } 541. 反转字符串 II - 力扣（LeetCode） 这道题有点复杂，我一开始用的方法写的很长，而且有些情况做不出来，并且通过这道题了解到不少String相关的api\n1 2 char[] arr = s.toCharArray return new Strin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public String reverseStr(String s, int k) { int n = s.length(); char[] arr = s.toCharArray(); for (int i = 0; i \u0026lt; n; i += 2 * k) { reverse(arr, i, Math.min(i + k, n) - 1); } return new String(arr); } public void reverse(char[] arr, int left, int right) { while (left \u0026lt; right) { char temp = arr[left]; arr[left] = arr[right]; arr[right] = temp; left++; right--; } } } 54. 替换数字（第八期模拟笔试） 第一次做这种题，直接傻了，一开始导包都错了，还有Scanner sc=new Scanner(System.in);都写错了\n还有一个常用的api\n1 2 //判断字符是否是数字 Character.isDigit(a); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.util.*; public class Main{ public static void main(String[] args){ Scanner sc=new Scanner(System.in); String s=sc.nextLine(); StringBuilder sb=new StringBuilder(); for(int i=0;i\u0026lt;s.length();i++){ if(Character.isDigit(s.charAt(i))){ sb.append(\u0026#34;number\u0026#34;); }else{ sb.append(s.charAt(i)); } } System.out.println(sb.toString()); } } 151. 反转字符串中的单词 - 力扣（LeetCode） 这题有点复杂，先要对字符串进行头尾空格删除，然后要删除字符串中多余的空格，然后要整体反转字符串，再进行局部反转字符串。\nStringBuilder的api\n1 2 StringBuilder sb=new StringBuilder(); sb.setCharAt(start,sb.charAt(end)); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class Solution { public String reverseWords(String s) { StringBuilder sb=delete(s); sb=reserve(sb,0,sb.length()-1); sb=result(sb); return sb.toString(); } public StringBuilder result(StringBuilder sb){ int index=0; for(int i=0;i\u0026lt;sb.length();i++){ if(sb.charAt(i)==\u0026#39; \u0026#39;){ sb=reserve(sb,index,i-1); index=i+1; }else if(i==sb.length()-1){ sb=reserve(sb,index,i); } } return sb; } public StringBuilder reserve(StringBuilder sb,int start,int end){ while(start\u0026lt;end){ char ch=sb.charAt(start); sb.setCharAt(start,sb.charAt(end)); sb.setCharAt(end,ch); start++; end--; } return sb; } public StringBuilder delete(String s){ int start=0; int end=s.length()-1; while(s.charAt(start)==\u0026#39; \u0026#39;){ start++; } while(s.charAt(end)==\u0026#39; \u0026#39;){ end--; } StringBuilder sb=new StringBuilder(); for(int i=start;i\u0026lt;end+1;i++){ char ch=s.charAt(start); if(ch!=\u0026#39; \u0026#39;||sb.charAt(sb.length()-1)!=\u0026#39; \u0026#39;){ sb.append(ch); } start++; } return sb; } } 459. 重复的子字符串 - 力扣（LeetCode） 这道题直接做很简单，把字符串拼在一起，然后切除两边的字符，这样就让重复子串数减少了两个，如果中间的两个仍然能拼成s，那么就是重复子字符串\nString的api\n1 2 3 String s=\u0026#34;abab\u0026#34;; Boolean b=s.contains(\u0026#34;a\u0026#34;); int a=s.indexOf(\u0026#34;a\u0026#34;); 1 2 3 4 5 6 7 8 9 10 11 12 13 class Solution { public boolean repeatedSubstringPattern(String s) { StringBuilder sb=new StringBuilder(); sb.append(s); sb.append(s); String s1=sb.substring(1,sb.length()-1); if(s1.contains(s)){ return true; }else { return false; } } } 55. 右旋字符串 最简单的做法就是新开一个空间\n1 2 3 4 5 6 //Scanner的使用方式 Scanner sc=new Scanner(System.in); int a=sc.nextInt(); //注意，这里有个回车 sc.nextLine(); String s=sc.nextLine(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import java.util.*; public class Main{ public static char[] func(char[] arr,int k){ char [] charArray=new char[arr.length]; int k1=k%arr.length; for(int i=0;i\u0026lt;arr.length;i++){ charArray[(i+k1)%arr.length]=arr[i]; } return charArray; } public static void main(String[] args) { Scanner sc = new Scanner(System.in); int k=sc.nextInt(); sc.nextLine(); String s=sc.nextLine(); char[] arr = s.toCharArray(); char[] charArray = func(arr, k); System.out.println(new String(charArray)); sc.close(); } } 232. 用栈实现队列 - 力扣（LeetCode） 两个栈实现队列，栈1用来压入数据，栈2充当队列，如果要出队列或者查看队首元素，可以通过查看栈2，如果栈2没有元素就要把栈1中所有元素取过来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class MyQueue { Stack\u0026lt;Integer\u0026gt; st1; Stack\u0026lt;Integer\u0026gt; st2; public MyQueue() { st1=new Stack\u0026lt;\u0026gt;(); st2=new Stack\u0026lt;\u0026gt;(); } public void push(int x) { st1.push(x); } public int pop() { if(st2.isEmpty()){ while(!st1.isEmpty()){ st2.push(st1.pop()); } } return st2.pop(); } public int peek() { if(st2.isEmpty()){ while(!st1.isEmpty()){ st2.push(st1.pop()); } } return st2.peek(); } public boolean empty() { if(st1.isEmpty()\u0026amp;\u0026amp;st2.isEmpty()){ return true; }else{ return false; } } } /** * Your MyQueue object will be instantiated and called as such: * MyQueue obj = new MyQueue(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.peek(); * boolean param_4 = obj.empty(); */ 225. 用队列实现栈 - 力扣（LeetCode） 如果想查看栈顶元素，就需要把q1中除了最后入队列的元素放入q2辅助队列，查看或者出栈后把所有元素再放进来即可\n1 2 3 4 5 6 7 8 //队列的api Queue\u0026lt;Integer\u0026gt; q1=new LinkedList\u0026lt;\u0026gt;(); q1.add(1); q1.add(2); //从队列中获取队头数据 q1.peek(); //取出队头元素并且获取其值 q1.poll(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class MyStack { Queue\u0026lt;Integer\u0026gt; q1; Queue\u0026lt;Integer\u0026gt; q2; public MyStack() { q1=new LinkedList\u0026lt;\u0026gt;(); q2=new LinkedList\u0026lt;\u0026gt;(); } public void push(int x) { q1.add(x); } public int pop() { while(q1.size()!=1){ q2.add(q1.poll()); } int result=q1.poll(); while(!q2.isEmpty()){ q1.add(q2.poll()); } return result; } public int top() { while(q1.size()!=1){ q2.add(q1.poll()); } int result=q1.poll(); while(!q2.isEmpty()){ q1.add(q2.poll()); } q1.add(result); return result; } public boolean empty() { if(q1.isEmpty()\u0026amp;\u0026amp;q2.isEmpty()){ return true; }else{ return false; } } } /** * Your MyStack object will be instantiated and called as such: * MyStack obj = new MyStack(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.top(); * boolean param_4 = obj.empty(); */ 20. 有效的括号 - 力扣（LeetCode） 这个闭眼写，不多做解释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class Solution { public boolean isValid(String s) { int length=s.length(); Stack\u0026lt;Character\u0026gt; st=new Stack\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;length;i++){ char ch=s.charAt(i); if(ch==\u0026#39;(\u0026#39;||ch==\u0026#39;[\u0026#39;||ch==\u0026#39;{\u0026#39;){ st.push(ch); }else{ if(st.isEmpty()){ return false; }else if(ch==\u0026#39;)\u0026#39;){ if(st.peek()!=\u0026#39;(\u0026#39;){ return false; }else{ st.pop(); } }else if(ch==\u0026#39;]\u0026#39;){ if(st.peek()!=\u0026#39;[\u0026#39;){ return false; }else{ st.pop(); } }else if(ch==\u0026#39;}\u0026#39;){ if(st.peek()!=\u0026#39;{\u0026#39;){ return false; }else{ st.pop(); } } } } if(!st.isEmpty()){ return false; } return true; } } 1047. 删除字符串中的所有相邻重复项 - 力扣（LeetCode） 这题本身挺简单的，但是有个小问题\n1 2 3 4 5 6 7 8 9 //这样是对的 int size=st.size(); for(int i=0;i\u0026lt;size;i++){ ... } //这样是错的 for(int i=0;i\u0026lt;st.size();i++){ ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Solution { public String removeDuplicates(String s) { Stack\u0026lt;Character\u0026gt; st=new Stack\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;s.length();i++){ if(st.isEmpty()){ st.push(s.charAt(i)); }else{ if(st.peek()==s.charAt(i)){ st.pop(); }else{ st.push(s.charAt(i)); } } } StringBuilder sb=new StringBuilder(); int size=st.size(); for(int i=0;i\u0026lt;size;i++){ sb.append(st.pop()); } return sb.reverse().toString(); } } 150. 逆波兰表达式求值 - 力扣（LeetCode） 这题较为简单，就入栈出栈就行，记得校验负号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Solution { public int evalRPN(String[] tokens) { int length=tokens.length; Stack\u0026lt;Integer\u0026gt; st=new Stack\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;length;i++){ if(!tokens[i].equals(\u0026#34;+\u0026#34;)\u0026amp;\u0026amp;!tokens[i].equals(\u0026#34;/\u0026#34;)\u0026amp;\u0026amp;!tokens[i].equals(\u0026#34;*\u0026#34;)\u0026amp;\u0026amp;!tokens[i].equals(\u0026#34;-\u0026#34;)){ st.push(func(tokens[i])); }else{ int a=st.pop(); int b=st.pop(); if(tokens[i].equals(\u0026#34;+\u0026#34;)){ st.push(a+b); }else if(tokens[i].equals(\u0026#34;-\u0026#34;)){ st.push(b-a); }else if(tokens[i].equals(\u0026#34;*\u0026#34;)){ st.push(a*b); }else if(tokens[i].equals(\u0026#34;/\u0026#34;)){ st.push(b/a); } } } return st.pop(); } public int func(String s){ int num=0; boolean flag=false; for(int i=0;i\u0026lt;s.length();i++){ if(s.charAt(i)==\u0026#39;-\u0026#39;){ flag=true; continue; } num*=10; num+=(s.charAt(i)-\u0026#39;0\u0026#39;); } return flag?num*-1:num; } } 239. 滑动窗口最大值 - 力扣（LeetCode） 使用堆来做，控制好滑动窗口大小，然后等需要删除滑动窗口值的时候统一删除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public int[] maxSlidingWindow(int[] nums, int k) { int length=nums.length; PriorityQueue\u0026lt;int []\u0026gt; queue=new PriorityQueue\u0026lt;\u0026gt;((o1,o2)-\u0026gt;o2[0]-o1[0]); for(int i=0;i\u0026lt;k;i++){ int[] array=new int[2]; array[0]=nums[i]; array[1]=i; queue.offer(array); } int[] result=new int[length-k+1]; result[0]=queue.peek()[0]; for(int i=1;i\u0026lt;length-k+1;i++){ int[] arr=new int[2]; arr[0]=nums[i+k-1]; arr[1]=i+k-1; queue.add(arr); while(queue.peek()[1]\u0026lt;i){ queue.poll(); } result[i]=queue.peek()[0]; } return result; } } 347. 前 K 个高频元素 - 力扣（LeetCode） 这道题思想不难，但是代码中的API比较多，比如map的entrySet()，PriorityQueue\n1 2 3 4 5 6 7 8 //这个是map的key-value的数据结构 Map.Entry\u0026lt;Integer,Integer\u0026gt; mapEntry; int key=mapEntry.getKey(); int value=mapEntry.getValue(); //遍历map中的元素 for(Map.Entry\u0026lt;Integer,Integer\u0026gt; entry:map.entrySet()){ ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Solution { public int[] topKFrequent(int[] nums, int k) { HashMap\u0026lt;Integer,Integer\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); PriorityQueue\u0026lt;Map.Entry\u0026lt;Integer,Integer\u0026gt;\u0026gt; queue=new PriorityQueue\u0026lt;\u0026gt;((o1,o2)-\u0026gt;o2.getValue()-o1.getValue()); for(int i=0;i\u0026lt;nums.length;i++){ if(map.containsKey(nums[i])){ map.put(nums[i],map.get(nums[i])+1); }else{ map.put(nums[i],1); } } for(Map.Entry\u0026lt;Integer,Integer\u0026gt; entry:map.entrySet()){ queue.add(entry); } int[] result=new int[k]; for(int i=0;i\u0026lt;k;i++){ result[i]=queue.poll().getKey(); } return result; } } 二叉树层序遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class TreeNode{ int val; TreeNode left; TreeNode right; TreeNode(int val){ this.val=val; } } public class TreeLevelOrder{ public static List\u0026lt;Integer\u0026gt; func(TreeNode root){ if(root==null){ return new ArrayList\u0026lt;\u0026gt;(); } LinkedList\u0026lt;TreeNode\u0026gt; ll=new LinkedList\u0026lt;\u0026gt;(); ll.add(root); List\u0026lt;Integer\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); while(!ll.isEmpty()){ int size=ll.size(); for(int i=0;i\u0026lt;size;i++){ TreeNode node=ll.pop(); list.add(node.val); if(node.left!=null){ ll.add(node.left); } if(node.right!=null){ ll.add(node.right); } } } return list; } public static void main(String[] args){ List\u0026lt;Integer\u0026gt; list=func(root); for(int a:list){ System.out.println(a); } } } 116. 填充每个节点的下一个右侧节点指针 - 力扣（LeetCode） 这道题是二叉树层序遍历的特殊题目，需要知道下一个节点的信息，可以通过LinkedList的peek()方法来获取下一个节点\n1 2 3 4 5 6 7 LinkedList\u0026lt;Integer\u0026gt; ll=new LinkedList\u0026lt;\u0026gt;(); //添加元素 ll.add(a); //取出队首元素 ll.pop(); //获取队首元素的值 ll.peek(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Solution { public Node connect(Node root) { LinkedList\u0026lt;Node\u0026gt; ll=new LinkedList\u0026lt;\u0026gt;(); ll.add(root); if(root==null){ return root; } while(!ll.isEmpty()){ int size=ll.size(); for(int i=0;i\u0026lt;size;i++){ Node node=ll.pop(); if(i==size-1){ node.next=null; }else{ node.next=ll.peek(); } if(node.left!=null){ ll.add(node.left); } if(node.right!=null){ ll.add(node.right); } } } return root; } } 226. 翻转二叉树 - 力扣（LeetCode） 这题也是比较简单，依旧层序遍历，然后设一个中间变量temp然后交换左右节点即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public TreeNode invertTree(TreeNode root) { LinkedList\u0026lt;TreeNode\u0026gt; ll=new LinkedList\u0026lt;\u0026gt;(); if(root==null){ return root; } ll.add(root); while(!ll.isEmpty()){ int size=ll.size(); for(int i=0;i\u0026lt;size;i++){ TreeNode node=ll.pop(); TreeNode temp=node.left; node.left=node.right; node.right=temp; if(node.left!=null){ ll.add(node.left); } if(node.right!=null){ ll.add(node.right); } } } return root; } } 101. 对称二叉树 - 力扣（LeetCode） 这道题一开始真没思路，就算以前做过这道题，以后一定得重点看看\n主要思路就是判断内侧的元素是否都相等，再看外侧元素是否相等\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public boolean isSymmetric(TreeNode root) { Boolean result=check(root.left,root.right); return result; } public boolean check(TreeNode left,TreeNode right){ if(left!=null\u0026amp;\u0026amp;right==null){ return false; } if(left==null\u0026amp;\u0026amp;right!=null){ return false; } if(left==null\u0026amp;\u0026amp;right==null){ return true; } if(left.val!=right.val){ return false; } //判断外侧是否都相等 boolean resultA=check(left.left,right.right); //判断内部是否都相等 boolean resultB=check(left.right,right.left); return resultA\u0026amp;\u0026amp;resultB; } } 104. 二叉树的最大深度 - 力扣（LeetCode） 这道题相对来说比较简单，直接搓出来了，查看左右两边的最大值，然后把全局变量赋值为左右两边最大值+1，同时返回当前节点最大深度，当然层序遍历的话更简单\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution { public int maxDepth(TreeNode root) { func(root); return depth; } int depth=0; public int func(TreeNode node){ if(node==null){ return 0; } int depthLeft=func(node.left); int depthRight=func(node.right); depth=Math.max(depthLeft,depthRight)+1; return Math.max(depthLeft,depthRight)+1; } } 111. 二叉树的最小深度 - 力扣（LeetCode） 这道题层序遍历依旧好解，但是递归就比较麻烦，有点像最近公共祖先的写法，都是在主函数内递归，额外要注意的是，必须得是叶子节点才可以判断层数，如果是链表状的树，最小深度就是最大深度\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public int minDepth(TreeNode root) { if(root==null){ return 0; } if(root.left==null\u0026amp;\u0026amp;root.right==null){ return 1; } int leftDepth=-1; if(root.left!=null){ leftDepth=minDepth(root.left); } int rightDepth=-1; if(root.right!=null){ rightDepth=minDepth(root.right); } return (leftDepth!=-1\u0026amp;\u0026amp;rightDepth!=-1)?Math.min(leftDepth,rightDepth)+1:Math.max(leftDepth,rightDepth)+1; } } ","date":"2025-12-06T13:29:41+08:00","permalink":"https://LuciusWan.github.io/p/%E7%AE%97%E6%B3%95%E5%BC%BA%E5%9F%BA%E8%AE%A1%E5%88%92/","title":"算法强基计划"},{"content":"面试八股3.0 介绍JVM堆的分代机制 Java 堆的分代机制 (Generational Collection) 是 JVM 垃圾回收（GC）性能优化的核心策略。\n其核心理论基础是 \u0026ldquo;弱分代假说\u0026rdquo; (Weak Generational Hypothesis)，即：\n绝大多数对象都是朝生夕死的（存活时间很短），而剩下的对象则往往能存活很久。\n基于这个假设，JVM 将堆内存划分为新生代 (Young Generation) 和 老年代 (Old Generation)，针对不同区域的特点使用不同的垃圾回收算法，从而提高 GC 效率。\n一、 堆内存的区域划分 在经典的垃圾收集器（如 Serial, ParNew, CMS, Parallel Scavenge）中，堆内存主要分为两大部分：\n1. 新生代 (Young Generation) 占比: 通常占堆内存的 1/3。\n特点: 对象生命周期极短，频繁发生 GC。\n内部结构: 进一步划分为三个区域（默认比例 8:1:1）：\nEden 区 (80%): 对象最初分配的地方。\nSurvivor 0 区 (From, 10%): 上一次 GC 的幸存者。\nSurvivor 1 区 (To, 10%): 垃圾回收时的复制目标。\nGC 方式: Minor GC (Young GC)。使用复制算法（效率高，无碎片，但浪费 10% 空间）。\n2. 老年代 (Old Generation) 占比: 通常占堆内存的 2/3。\n特点: 存放生命周期长的对象（如连接池、Spring Bean、缓存数据）。\nGC 方式: Major GC 或 Full GC。使用标记-清除或标记-整理算法（速度比 Minor GC 慢 10 倍以上）。\n(注：JDK 8 之后，永久代 PermGen 被移除，元空间 Metaspace 存储类信息，它使用的是本地内存，不属于堆。)\n二、 对象的生命周期流转 (核心流程) 对象在分代机制中的流转过程通常如下：\n1. 初始分配 (Allocation) 绝大多数新对象在 Eden 区 分配。\n例外: 如果对象非常大（超过 -XX:PretenureSizeThreshold），直接进入老年代，避免在 Survivor 区之间发生大量的内存复制。\n2. Minor GC (Eden 满了) 当 Eden 区满时，触发 Minor GC。\n存活判断: JVM 检查 Eden 和正在使用的 Survivor (From) 区中的对象。\n复制: 将存活的对象复制到空的 Survivor (To) 区。\n清理: 清空 Eden 和 From 区。\n交换: From 和 To 身份互换。\n3. 年龄增长 (Aging) 对象每经过一次 Minor GC 且存活下来，其年龄（Age）就 +1（记录在对象头中）。 4. 晋升老年代 (Promotion) 对象进入老年代通常有以下几种情况：\n长期存活: 年龄达到阈值（默认 15，可以通过 -XX:MaxTenuringThreshold 设置）。\n大对象直接进入: 如前所述，超大数组或字符串。\n动态年龄判断: 如果 Survivor 空间中，相同年龄所有对象的大小总和 \u0026gt; Survivor 空间的一半，则年龄大于或等于该年龄的对象直接进入老年代，无需等到阈值。\n空间担保失败: Minor GC 后，存活对象太多，Survivor 区放不下，借用老年代空间存储。\n三、 为什么需要分代？ (作用) 如果不分代，每次 GC 都必须扫描整个堆（几个 GB 甚至几十 GB），效率极低。\n提升效率:\n新生代: 只有少量对象存活，使用复制算法，只需处理少量存活对象，速度极快。\n老年代: 对象变动少，不需要频繁回收，减少了全堆扫描的次数。\n减少 STW (Stop-The-World):\n频繁发生的 Minor GC 耗时非常短，对用户体验影响小。\n耗时长的 Full GC 频率被尽可能降低。\n四、 常见参数总结 (面试常考) 参数 含义 示例 -Xms / -Xmx 堆的初始大小 / 最大大小 -Xms2g -Xmx2g (通常设为一样避免抖动) -Xmn 新生代大小 -Xmn1g -XX:NewRatio 老年代与新生代的比例 2 (表示 老年代:新生代 = 2:1) -XX:SurvivorRatio Eden 与 Survivor 的比例 8 (表示 Eden:S0:S1 = 8:1:1) -XX:MaxTenuringThreshold 晋升老年代的年龄阈值 15 总结 分代机制本质上是空间换时间和算法分治的思想。\nEden/Survivor: 用空间（浪费 10%）换取极快的分配和回收速度（复制算法）。\nOld: 用复杂的标记算法处理存活率高的对象。\n介绍JVM 内存结构 核心架构概览 JVM 在运行 Java 程序时，会把内存划分为以下 5 个主要区域：\n1. 线程私有（Thread Local） -\u0026gt; 随着线程创建而创建，线程结束而销毁。无需 GC。\n程序计数器 (Program Counter Register) 虚拟机栈 (Java Virtual Machine Stack) 本地方法栈 (Native Method Stack) 2. 线程共享（Shared） -\u0026gt; 随虚拟机启动而创建。是 GC 的重点区域。\n堆 (Heap) 方法区 (Method Area) 一、 线程私有区域 (Thread Local) 这部分内存是\u0026quot;私有\u0026quot;的，线程之间互不干扰，所以不存在线程安全问题。\n1. 程序计数器 (PC Register) 作用： 记录当前线程执行到哪一行字节码指令。\n如果执行的是 Java 方法，记录的是指令地址。 如果执行的是 Native 方法，这里是 Undefined。 特点：\n内存空间极小。 唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError (OOM) 情况的区域。 作用类似 CPU 的寄存器，用于线程切换后恢复执行位置。 2. 虚拟机栈 (JVM Stack) - 最常说的\u0026quot;栈\u0026quot; 作用： 描述 Java 方法执行的内存模型。\n栈帧 (Stack Frame)： 每个方法被执行的时候，都会创建一个\u0026quot;栈帧\u0026quot;压入栈中。栈帧包含：\n局部变量表： 存方法参数和内部定义的局部变量（int, boolean, 对象引用等）。 操作数栈： 类似于计算器的草稿纸，用于计算过程中的数据暂存和交换。 动态链接： 指向方法区中该方法的引用。 方法返回地址： 方法正常或异常退出的位置。 异常：\nStackOverflowError：递归过深，栈帧太多，撑爆了栈深度。 OutOfMemoryError：如果栈可以动态扩展，但申请不到足够内存时抛出。 3. 本地方法栈 (Native Method Stack) 作用： 与虚拟机栈类似，区别在于它是为 Native 方法（使用 C/C++ 编写的底层方法）服务的。\n注：在 HotSpot 虚拟机中，本地方法栈和虚拟机栈是合二为一的。\n二、 线程共享区域 (Shared) 这部分是多线程共享的，需要考虑线程安全问题，也是垃圾回收 (GC) 的主战场。\n1. 堆 (Heap) 作用： JVM 内存中最大的一块。存放几乎所有的对象实例和数组。\n细分： 新生代 (Eden, S0, S1) 和 老年代。\nTLAB (Thread Local Allocation Buffer)： 虽然堆是共享的，但为了提升对象分配效率，JVM 在 Eden 区为每个线程划分了一小块私有分配区（TLAB），避免多线程竞争锁。\n异常： OutOfMemoryError: Java heap space（堆内存溢出）。\n2. 方法区 (Method Area) 作用： 存储已被虚拟机加载的类信息 (Class)、常量、静态变量 (static)、即时编译器 (JIT) 编译后的代码缓存等。\n演进 (面试重点)：\nJDK 1.7 及之前： 实现为 永久代 (PermGen)。它在 JVM 内存中，受限于 JVM 大小，容易出现 OOM。 JDK 1.8 及之后： 永久代被移除，取而代之的是 元空间 (Metaspace)。 区别： 元空间不在虚拟机内存中，而是使用本地内存 (Native Memory)。这意味着它只受限于机器的物理内存大小，大大降低了 OOM 的风险。 运行时常量池 (Runtime Constant Pool)： 是方法区的一部分。用于存放编译期生成的各种字面量和符号引用。\n三、 堆外内存 (直接内存 Direct Memory) 这不是 JVM 运行时数据区的一部分，但也非常重要。\n作用： NIO 类库引入了一种基于通道与缓冲区的 I/O 方式，可以使用 Native 函数库直接分配堆外内存。\n优势： 避免了在 Java 堆和 Native 堆之间来回复制数据（零拷贝技术），显著提高 I/O 性能。\n异常： 虽然不受堆大小限制，但受本机总内存限制，也会抛出 OutOfMemoryError。\n四、 总结对比表 区域 线程归属 存储内容 抛出异常 生命周期 程序计数器 私有 指令地址 无 随线程 虚拟机栈 私有 局部变量、操作数栈 StackOverflow / OOM 随线程 本地方法栈 私有 Native 方法信息 StackOverflow / OOM 随线程 堆 共享 对象实例、数组 OOM 随进程 (JVM) 方法区 共享 类信息、常量、静态变量 OOM (Metaspace OOM) 随进程 (JVM) 介绍GC标记算法 在垃圾回收（GC）的世界里，\u0026ldquo;标记\u0026quot;其实包含两个层面的含义：\n判定标准： 怎么知道哪个对象是垃圾？（死活判定） 执行手段： 找出垃圾后，用什么算法去清理？（垃圾收集算法） 第一步：判定对象死活（怎么标记？） 在 Java (HotSpot) 中，主要使用的是 可达性分析算法，而不是引用计数法。\n1. 引用计数法 (Reference Counting) 原理： 给对象添加一个引用计数器。每当有一个地方引用它，计数器 +1；引用失效，计数器 -1。为 0 则可回收。\n优点： 简单，判定效率高。\n缺点 (致命)： 无法解决\u0026quot;循环引用\u0026quot;问题。\n例子： 对象 A 引用 B，对象 B 引用 A，除此之外没人引用它们。它们的计数器都是 1，永远无法归零，导致内存泄漏。 现状： Java 虚拟机（HotSpot）不使用此算法（Python 和 C++ 智能指针在使用）。\n2. 可达性分析算法 (Reachability Analysis) —— Java 的标准 原理： 通过一系列称为 \u0026ldquo;GC Roots\u0026rdquo; 的根对象作为起始节点集，从这些节点开始向下搜索。\n凡是能从 GC Roots \u0026ldquo;顺藤摸瓜\u0026rdquo; 搜索到的对象，都是存活的（标记为\u0026quot;可达\u0026rdquo;）。 凡是搜索不到的对象，就是垃圾（不可达）。 什么是 GC Roots？ (面试必考)\n可以作为 GC Roots 的对象主要包括以下 4 类：\n虚拟机栈（栈帧中的局部变量表） 中引用的对象。 方法区中类静态属性 引用的对象。（static User u = ...） 方法区中常量 引用的对象。（static final User u = ...） 本地方法栈中 JNI (Native 方法) 引用的对象。 第二步：执行垃圾收集（标记完怎么清理？） 当 GC 通过可达性分析标记出了哪些是活的、哪些是死的之后，就需要具体的算法来进行内存回收。常见的有以下三种：\n1. 标记-清除算法 (Mark-Sweep) 这是最基础的算法。\n过程：\n标记： 把所有活动对象标记出来。 清除： 统一回收未被标记的对象。 优点： 简单，不需要移动对象。\n缺点： 内存碎片化： 清除后会产生大量不连续的内存碎片。\n适用场景： 老年代（CMS 收集器就是基于此）。\n2. 标记-复制算法 (Mark-Copy) 为了解决碎片问题而生。\n过程：\n将内存分为大小相等的两块（A 和 B），每次只使用其中一块。 标记 A 中的存活对象。 复制 将 A 中所有存活的对象，整齐地复制到 B 中。 清理 一次性清空 A。 优点： 没有内存碎片，分配内存简单（指针碰撞）。\n缺点： 空间浪费（内存利用率只有 50%）。\n优化： 在 HotSpot 的新生代中，使用 Eden : Survivor : Survivor = 8 : 1 : 1 的比例，只浪费 10% 的空间。\n适用场景： 新生代（存活率低，复制成本低）。\n3. 标记-整理算法 (Mark-Compact) 结合了前两者的优点。\n过程：\n标记 存活对象。 整理 让所有存活的对象向内存的一端移动（滑动整理）。 清理 直接清理掉边界以外的内存。 优点： 没有内存碎片，也不浪费空间。\n缺点： 移动对象需要更新引用地址，成本较高，且需要暂停用户线程 (STW)。\n适用场景： 老年代（对象存活率高，不适合复制）。\n第三步：进阶 —— 三色标记法 (Tri-color Marking) 如果面试官问及\u0026quot;并发标记\u0026quot;或者 CMS/G1 的底层原理，这个是必杀技。\n为了让 GC 线程和用户线程能并发运行，JVM 引入了三色标记法来描述标记过程中的状态：\n白色： 尚未访问过。（如果在分析结束时仍为白色，代表是垃圾） 黑色： 自己和成员变量都已访问过。（肯定是活的对象，且扫描完毕） 灰色： 自己访问过，但成员变量还没访问完。（中间状态，待扫描） 并发标记的问题： 在并发过程中，用户线程可能会切断\u0026quot;灰色\u0026quot;到\u0026quot;白色\u0026quot;的引用，同时建立\u0026quot;黑色\u0026quot;到\u0026quot;白色\u0026quot;的引用。这会导致漏标。\n解决方案： CMS 使用 增量更新 (Incremental Update)。 G1 使用 原始快照 (SATB)。 总结对比表 算法 优点 缺点 适用区域 代表收集器 标记-清除 简单 内存碎片严重 老年代 CMS 标记-复制 无碎片，运行快 浪费空间 (需 Survivor) 新生代 Serial, ParNew, G1 (Young) 标记-整理 无碎片，无空间浪费 移动对象效率低，需 STW 老年代 Parallel Old, Serial Old, G1 (Mixed) 讲解常见的垃圾回收器 CMS (Concurrent Mark Sweep) —— 里程碑式产品 核心特点： 并发收集、低停顿。\n工作流程 (重点)：\n初始标记 (Initial Mark): STW。只标记 GC Roots 直接关联的对象（速度很快）。 并发标记 (Concurrent Mark): 不 STW。GC 线程和用户线程一起跑，遍历整个对象图。 重新标记 (Remark): STW。修正并发期间因用户程序变动而导致标记产生变动的那一部分对象。 并发清除 (Concurrent Sweep): 不 STW。清理垃圾。 缺点 (面试必问)：\nCPU 敏感： 占用线程资源，导致程序变慢。 浮动垃圾： 并发清理阶段产生的新垃圾无法在当次处理。 内存碎片： 使用标记-清除算法，容易产生碎片，导致大对象分配困难，触发 Full GC。 现状： JDK 9 标记废弃，JDK 14 正式移除。\nG1 (Garbage First) —— JDK 9 之后的默认王者 核心理念： 化整为零。\n内存布局： 不再有物理隔离的新生代和老年代。它把堆内存切分成很多个大小相等的 Region (区域)。这些 Region 逻辑上可以是 Eden、Survivor 或 Old。\n算法： 整体看是标记-整理，局部（两个 Region 之间）看是标记-复制。不会产生内存碎片。\n最大优势： 可预测的停顿模型。\n你可以告诉 G1：\u0026ldquo;即使堆很大，但我要求 GC 停顿时间不要超过 200ms\u0026rdquo;。G1 会分析哪个 Region 垃圾最多（回收收益最大），优先回收它（这也是 Garbage First 名字的由来）。 适用场景： 面向服务端应用，配备大内存（6GB - 8GB 以上），替代 CMS。\n介绍Java的线程池 Java 线程池（Thread Pool）是 Java 并发编程中的核心组件，主要用于管理线程的生命周期、减少资源消耗并提高系统响应速度。\n一、为什么要用线程池？ 如果不使用线程池，每当有新任务时手动创建线程（new Thread()），会带来以下问题：\n资源消耗大： 频繁创建和销毁线程需要消耗大量系统资源（CPU、内存）。 响应速度慢： 创建线程本身需要时间，增加了任务处理的延迟。 难以管理： 无限制创建线程可能导致 CPU 过载或 OOM（内存溢出）。 线程池的好处：\n降低资源消耗： 重复利用已创建的线程。 提高响应速度： 任务到达时无需等待线程创建即可立即执行。 提高可管理性： 可以统一分配、调优和监控线程。 二、核心类：ThreadPoolExecutor Java 线程池的核心实现类是 java.util.concurrent.ThreadPoolExecutor。构造函数包含 7 个核心参数（面试和实战的重点）：\n1 2 3 4 5 6 7 8 9 public ThreadPoolExecutor( int corePoolSize, // 1. 核心线程数 int maximumPoolSize, // 2. 最大线程数 long keepAliveTime, // 3. 空闲线程存活时间 TimeUnit unit, // 4. 时间单位 BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, // 5. 任务队列 ThreadFactory threadFactory, // 6. 线程工厂 RejectedExecutionHandler handler // 7. 拒绝策略 ) 参数详解：\n参数 说明 corePoolSize 核心线程数，线程池中长驻的线程数量 workQueue 任务队列，核心线程都在忙时，新任务暂存于此 maximumPoolSize 最大线程数，队列满了且线程数 \u0026lt; 最大线程数时，创建非核心线程 keepAliveTime 空闲线程存活时间，超过 corePoolSize 的线程空闲超时后被回收 unit keepAliveTime 的时间单位 threadFactory 线程工厂，用于创建新线程（可自定义线程名） handler 拒绝策略，队列满且线程数达到最大值时触发 三、线程池的工作流程（重要） 当一个新任务提交给线程池时，处理逻辑如下：\n判断核心线程： 如果当前运行的线程数 \u0026lt; corePoolSize，则立即创建新线程执行任务。 进入队列： 如果核心线程都在忙（\u0026gt;= corePoolSize），则将任务放入 workQueue 等待。 创建非核心线程： 如果队列也满了，判断当前线程数是否 \u0026lt; maximumPoolSize。如果是，则创建新线程执行任务。 触发拒绝策略： 如果队列满了，且线程数已达到 maximumPoolSize，则调用 handler 执行拒绝策略。 简记口诀： 先核心，后队列，再最大，最后拒绝。\n四、四种常见的拒绝策略 JDK 内置了四种 RejectedExecutionHandler 实现：\n策略 行为 AbortPolicy (默认) 直接抛出 RejectedExecutionException 异常 CallerRunsPolicy 由调用线程直接运行该任务（负反馈调节） DiscardPolicy 直接丢弃任务，不抛出异常 DiscardOldestPolicy 丢弃队列中等待最久的任务，然后重新提交当前任务 五、常见的线程池类型（Executors 工具类） JDK 提供了 Executors 工厂类来快速创建线程池，但在生产环境中通常不推荐直接使用（参考《阿里巴巴 Java 开发手册》），建议手动 new ThreadPoolExecutor。\n类型 特点 风险 FixedThreadPool 固定大小的线程池 使用无界队列，可能导致 OOM SingleThreadExecutor 只有一个线程，保证任务按顺序执行 同样使用无界队列，有 OOM 风险 CachedThreadPool 可缓存线程池，线程数无上限 创建大量线程，导致 CPU 100% 或 OOM ScheduledThreadPool 支持定时及周期性任务执行 - 六、线程池参数配置建议 配置线程池大小通常取决于任务类型：\n任务类型 特点 建议配置 CPU 密集型 加密、计算、压缩 CPU 核数 + 1 IO 密集型 数据库查询、HTTP 请求、文件读写 CPU 核数 * 2 或 CPU 核数 / (1 - 阻塞系数) 为什么协程适合处理IO密集型任务 协程（Coroutine）之所以被认为是处理 IO 密集型任务的神器，核心原因可以用一句话概括：\n协程把\u0026quot;等待 IO\u0026quot;的时间利用了起来，并且以极低的成本实现了并发。\n一、协程 vs 线程的核心差异 1. 极其轻量级的\u0026quot;挂起\u0026quot;和\u0026quot;恢复\u0026quot; 线程的痛点（阻塞）： 当一个线程发起 IO 请求时，如果数据没回来，这个线程就会阻塞（Block）。线程虽然什么都不干（在傻等），但它依然占用了系统资源。\n协程的优势（非阻塞/挂起）： 当协程发起 IO 请求时，它不会\u0026quot;傻等\u0026quot;，而是会主动挂起（Yield），把当前占用的线程控制权让出来。底层的物理线程没有被阻塞，它可以立即去执行其他协程的任务。\n2. 内存资源消耗极低 线程（Heavyweight）： Java 的线程是操作系统内核级线程。创建一个线程通常需要预留 1MB 左右的栈内存。\n10,000 个并发连接 = 10GB 内存 协程（Lightweight）： 协程是用户态的，完全由程序或语言运行时管理。一个协程的初始栈内存通常只有 几 KB（如 Go 协程约 2KB）。\n同样的 10GB 内存，理论上可以支撑数百万个协程。 3. 极低的上下文切换成本 线程切换（贵）： 线程调度由操作系统内核完成。涉及用户态和内核态的转换，需要保存和恢复大量的寄存器状态，开销较大。\n协程切换（便宜）： 协程调度完全在用户态完成，不涉及内核态切换。速度比线程切换快 1~2 个数量级。\n4. \u0026ldquo;同步的代码，异步的执行\u0026rdquo; 你可以用写同步代码的方式（顺序执行）来写异步逻辑，极大地降低了编写高并发 IO 代码的心智负担。\n二、通俗类比：餐厅服务员 多线程模型（1 对 1）： 来了 100 个客人，老板雇了 100 个服务员。每个服务员负责一个客人，客人点完菜，服务员就站在厨房门口死等厨师做好饭，期间什么也不干。\n缺点： 雇佣服务员成本太高，且大部分服务员都在发呆（阻塞）。 协程模型（1 对 多）： 来了 100 个客人，老板只雇了 1 个服务员。服务员给 1 号桌点完菜，把单子扔给厨房，立刻跑去给 2 号桌点菜。等厨房喊\u0026quot;1 号桌菜好了\u0026quot;，服务员再回来端菜。\n优点： 只需要很少的服务员就能服务大量客人，服务员一直在跑动（CPU 高效利用）。 三、协程到底做了什么？ 结论：协程并不能让 CPU 偷懒不做数据搬运。\n当数据准备好后，依然是 CPU 亲自把数据从内核缓冲区搬运（复制）到用户缓冲区。这一点，协程和线程没有任何区别。\n协程赢在\u0026quot;等待数据到达内核缓冲区\u0026quot;的这段时间。\n协程底层配合的是 非阻塞 I/O (Non-blocking I/O) 和 IO 多路复用 (Epoll/Selector)：\n协程调用读取操作，底层立即问内核：\u0026ldquo;数据到了吗？\u0026rdquo; 内核说\u0026quot;没到\u0026quot;。协程不睡，而是仅仅在用户态线程内部记录一下\u0026quot;我先暂停\u0026quot;，然后立刻让出 CPU 给其他协程用。 协程把\u0026quot;我在等数据\u0026quot;这件事注册给操作系统的监听器（Epoll）。 数据到达后，监听器通知程序，协程被恢复继续执行。 总结： 协程并不是让 CPU 少干了活（搬运工作量没变），而是让 CPU 在等待期间别闲着，也别瞎折腾（切换上下文），从而能处理更多的并发任务。\n四、什么时候用协程？ 任务类型 特点 是否适合协程 原因 IO 密集型 网络请求、读写数据库、微服务调用 非常适合 解决了大量\u0026quot;等待\u0026quot;造成的资源浪费，能支撑超高并发 CPU 密集型 视频转码、复杂的数学计算、加密解密 不适合 任务主要在用 CPU 计算，没有时间让出控制权，协程的调度反而会增加负担 IO操作的数据搬运是由谁来做的 从 Socket 内存缓冲区（内核空间）到用户内存缓冲区（用户空间）的数据搬运，必须由 CPU 亲力亲为。\n但是，整个 I/O 过程并非全由 CPU 完成。我们需要把一次网络 I/O 拆解为两个阶段：\n第一阶段：网卡 -\u0026gt; 内核缓冲区 干活的主角： DMA（Direct Memory Access，直接存储器访问） CPU 的角色： 基本不参与（只负责发号施令） 网线上的光电信号到达网卡（NIC）。 DMA 控制器（硬件芯片）接管总线，直接把数据从网卡拷贝到内存中的内核缓冲区。 搬运完成后，DMA 会给 CPU 发送一个中断信号，告诉 CPU：\u0026ldquo;数据已经卸到内核仓库了\u0026rdquo;。 为什么要用 DMA？ 如果没有 DMA，CPU 就得一个字节一个字节地从网卡读数据，效率极低。有了 DMA，CPU 就可以做\u0026quot;甩手掌柜\u0026quot;。\n第二阶段：内核缓冲区 -\u0026gt; 用户缓冲区 干活的主角： CPU 状态： 昂贵的\u0026quot;上下文切换\u0026quot;和\u0026quot;内存拷贝\u0026quot; 系统调用： Java 程序执行了 socket.read()。 模式切换： 线程从用户态切换到内核态。 CPU 搬运： CPU 亲自上阵，将数据从内核 Socket 缓冲区逐字节拷贝到用户空间缓冲区。 返回用户态： 拷贝完成后，CPU 切换回用户态，read() 方法返回。 总结：谁在搬运？ 数据流向 搬运工 (硬件) 消耗资源 备注 网卡 → 内核内存 DMA 控制器 总线带宽 CPU 几乎不参与，效率极高 内核内存 → 用户内存 CPU CPU 周期 这是性能瓶颈！ CPU 必须暂停其他计算工作来搬砖 延伸：零拷贝（Zero-Copy） 既然 CPU 搬运内核到用户空间很慢，那能不能不搬？这就是 Kafka、Netty 等高性能框架使用的零拷贝技术（如 sendfile 或 mmap）。\n核心思想： 如果你只是想把文件读取出来发给网卡（比如做静态资源服务器），数据其实不需要进入用户空间。 做法： 数据由 DMA 从磁盘搬到内核，再由 DMA 直接从内核搬到网卡。 结果： 完全跳过了 CPU 将数据搬运到用户缓冲区的步骤，CPU 占用率大幅下降，性能起飞。 Redis 6.0+ 的 IO 多线程 默认是否开启？ 默认是关闭的（Disabled）。 虽然 Redis 6.0 引入了多线程 I/O 特性，但在默认配置下，Redis 依然表现为传统的单线程模式。\n如何开启？ 修改 redis.conf 配置文件中的以下两个参数：\n参数 默认值 说明 io-threads 1 设置为大于 1 的值开启。4 核机器建议设为 2~3 个，8 核机器建议设为 6 个 io-threads-do-reads no 设置为 yes 开启多线程读。默认只开启多线程写 为什么默认不开启？ 性能没瓶颈： 对于绝大多数应用程序，Redis 的瓶颈通常在于网络带宽或内存，而不是 CPU。单线程的 Redis 已经足够快（每秒处理数万至十万级请求）。\n复杂性与稳定性： 引入多线程会增加系统的复杂性。保持默认关闭可以最大程度保证旧版本的行为一致性和稳定性。\n重要提示：核心逻辑依然是\u0026quot;单线程\u0026quot; 多线程只负责 I/O： 处理网络数据的读（Read/Decode）和网络数据的写（Write/Encode）。\n命令执行依然是单线程： 实际执行 GET、SET、LUA 脚本等操作的，依然是那个唯一的主线程。\n这意味着：\n你依然不需要担心多线程并发带来的数据竞争问题（不需要加锁）。 原子性依然得到天然保证。 单线程 Redis 会傻等吗？ 绝对不会傻等。 Redis 之所以快，靠的就是 I/O 多路复用（Epoll） 技术。\nDMA 搬运阶段： Redis 主线程不参与，它正在忙着处理其他请求。 数据到站： 操作系统通过 Epoll 标记该 Socket \u0026ldquo;可读\u0026rdquo;。 Redis 发现数据： 主线程调用 epoll_wait() 问操作系统哪些连接有数据。 搬运到用户态： 因为数据已经在内核缓冲区躺好了，read() 调用不需要等待。 结论： Redis 没开启多线程时，它绝不会等\u0026quot;网卡接收数据\u0026quot;（这是 DMA 干的），但它必须亲自做\u0026quot;内核到用户态的数据拷贝\u0026quot;（这是 CPU 干的）。\nMySQL 主从同步模型 新节点加入，主节点直接传全量 Binlog 吗？ 通常不会，甚至是不可能的。 如果数据库已经运行了一年，Binlog 可能早就滚动删除了。\n标准的新节点同步流程是\u0026quot;全量快照 + 增量 Binlog\u0026quot;：\n全量数据搬运（Snapshot）： 先手动将主节点（或某个现存从节点）当前的数据快照拷贝给新节点。\n工具：mysqldump（逻辑备份，慢）或 Percona XtraBackup（物理备份，快，生产环境首选） 记录位点（Position）： 在做快照的那一瞬间，记录下当前的 Binlog 文件名和偏移量，或者 GTID。\n增量追赶（Catch-up）： 将快照恢复到新节点后，新节点执行 CHANGE MASTER TO，指向记录的\u0026quot;时间戳\u0026quot;，请求之后产生的新 Binlog。\n从节点 \u0026gt; 1 时，是否由从节点来同步新的从节点？ 默认不会，但你可以配置成这样（级联复制）。\n默认架构（星型结构） 结构：1 主 -\u0026gt; N 从 行为：新节点配置的 Master IP 是主节点，它就会直接连接主节点 缺点：如果新节点太多，会把主节点的网卡或磁盘 I/O 打满 级联复制（Cascading Replication） 结构：Master -\u0026gt; Slave A -\u0026gt; Slave B（新节点） 做法：新节点的 MASTER_HOST 指向现有的从节点（Slave A） 前提：中间节点必须开启 log_slave_updates = 1 优点：减轻了主节点的压力 缺点：同步链路变长，延迟会叠加 Relay Log（中继日志）是什么？ Relay Log 是 MySQL 主从复制架构中，存在于从节点上的一种特殊日志文件。你可以把它理解为从节点上的**\u0026ldquo;临时待办箱\u0026rdquo;**。\n复制流程中的位置：\n1 Master (Binlog) --\u0026gt; 网络 --\u0026gt; Slave I/O 线程 --\u0026gt; [Relay Log] --\u0026gt; Slave SQL 线程 --\u0026gt; Slave 数据 为什么要设计 Relay Log？\n接收快，执行慢： 网络传输通常很快，但执行 SQL 通常很慢。有了 Relay Log，I/O 线程可以疯狂地把 Master 的日志拉取回来存在本地，哪怕 SQL 线程处理不过来也没关系。\n断点续传与崩溃恢复： 如果 Slave 宕机重启，Relay Log 还存在磁盘上。SQL 线程知道自己上次执行到了哪个位置，重启后可以继续执行。\n特性 Binlog Relay Log 存放位置 通常在 Master 只在 Slave 上 产生者 数据库自身的写操作 Slave 的 I/O 线程（从 Master 拷贝来的） 生命周期 长期保留 用完即焚，SQL 线程执行完后自动删除 SELECT FOR UPDATE 什么时候解锁 是事务结束时（Commit 或 Rollback 之后）。\n锁的生命周期 在 MySQL（InnoDB 引擎）中，SELECT ... FOR UPDATE 遵循两阶段锁协议（2PL）：\n加锁时刻： 当 CPU 执行到这条 SQL 语句时，开始申请并持有锁。 持有过程： 即使这条 SQL 执行完了，锁依然不会释放。 解锁时刻： 只有当整个事务执行了 COMMIT 或 ROLLBACK 后，锁才会释放。 为什么要设计成\u0026quot;事务结束才释放\u0026quot;？ 如果 SQL 执行完立刻释放锁，会发生严重的数据一致性问题（丢失更新）。\n只有拿到事务结束，才能保证在你处理完这行数据之前，没有任何人能修改它。\n致命的生产事故模型（千万小心） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Transactional public void buyTicket() { // 1. 获取锁（开启事务，加锁） ticketMapper.selectTicketForUpdate(ticketId); // 2. 危险操作！！！ // 在持有数据库锁的时候，去调用了第三方的 HTTP 接口 // 假设这个 HTTP 请求卡了 3 秒... thirdPartyPaymentService.pay(); // 3. 更新数据库 ticketMapper.reduceStock(ticketId); // 4. 事务结束（释放锁） } 后果： 在那 3 秒钟内，这行数据是被死锁住的。所有其他想买这张票的用户，全部卡在第 1 步等待。如果并发量大，数据库连接瞬间就会被这些等待的线程占满，导致整个系统宕机。\n最佳实践： 只有在必须要修改数据，且业务逻辑非常快（纯内存计算，无外部 IO）的代码块里，才使用 FOR UPDATE。不要拿着锁去逛街（做耗时操作）。\nMySQL 的 MHA 高可用架构 MHA (Master High Availability Manager and Tools for MySQL) 是 MySQL 领域非常经典、使用非常广泛的第三方高可用解决方案。\nMHA 是做什么的？ 核心目标只有一个：在 Master（主库）宕机后，以最快的速度（通常 10~30秒内）自动将某个 Slave 提升为新的 Master，并让其他 Slave 指向新的 Master，同时尽最大努力不丢失数据。\n核心组件架构 组件 部署位置 职责 MHA Manager 单独部署在一台机器上 大脑。监控 Master 状态，执行故障转移流程 MHA Node 每一台 MySQL 服务器上 执行者。解析 Binlog/Relay Log，对比差异，应用日志 故障切换流程（核心原理） 假设架构是：Master(A) -\u0026gt; Slave(B), Slave(C)。当 Master(A) 宕机时：\n侦测与确认： Manager 发现 Master(A) 连不上，多次重试确认。\n选主（Election）： 检查 Slave(B) 和 Slave(C)，谁的 Relay Log 最完整（数据最新），谁就当新主。\n数据补全（差异日志补全）：\n如果 Master SSH 还能连：MHA 会登录到死掉的 Master 上，把还没来得及发给 Slave 的最新 Binlog 截取并应用到新主上。数据 0 丢失。 如果 Master 物理损坏：对比各 Slave 的 Relay Log，把差异补齐。 提升新主与重构拓扑： 对新主执行 STOP SLAVE，解除只读模式；告诉其他 Slave 执行 CHANGE MASTER TO 指向新主。\nVIP 漂移： 通过钩子脚本将 VIP 从旧 Master 漂移到新 Master 上。\nMHA 的优缺点 优点 缺点 数据一致性高（SSH 可达时数据不丢失） Perl 语言编写，维护困难 切换速度快（30 秒内） VIP 配置复杂，需自己写脚本 对现有架构侵入小 脑裂风险（需配置 fencing 脚本） 成熟稳定 MHA Manager 自身是单点 MySQL Group Replication (MGR) MySQL Group Replication (MGR) 是 MySQL 官方在 5.7.17 版本正式推出的高可用与高扩展解决方案。它引入了分布式系统中最核心的 Paxos 协议，从而实现了数据库集群的强一致性和原生高可用。\n核心特点：为什么它比传统主从牛？ 数据不丢失： 任何一个事务想要提交，必须经过集群中**大多数（N/2 + 1）**节点的同意。 原子性： 一个事务要么在所有节点都生效，要么都不生效。 自动脑裂防御： 如果发生网络分区，只有拥有大多数节点的那个分区能对外提供服务，少数派分区会自动锁死。 两种运行模式 模式 特点 适用场景 单主模式 (Single-Primary) 只有一个节点可以写，其他节点只读。Primary 挂掉时自动选新主 推荐/主流，几乎没有冲突检测开销 多主模式 (Multi-Primary) 所有节点都可以同时处理写请求 冲突检测复杂，同时修改同一行数据会报错回滚 MGR 的工作原理 假设有 3 个节点（A, B, C），Client 向 A 发送了一条 UPDATE：\n执行阶段： 节点 A 先在本地内存里预执行这个事务，但不提交。生成一个写集 (Write Set)。\n广播与共识 (Paxos)： 节点 A 把写集广播给整个小组。只要有 2 个收到并排序成功，协议就达成。\n冲突检测 (Certification)： 所有节点都会拿着这个写集，去跟自己内存里正在处理的其他事务比对。如果有冲突，后到的事务直接回滚。\n提交 (Commit)： 通过认证后，事务真正写入 Binlog 和磁盘。\nMGR 的硬性限制 必须是 InnoDB 引擎 每张表必须有主键 (Primary Key)：MGR 靠主键的 Hash 来判断写冲突 必须开启 GTID 网络要求高：节点间通信非常频繁 节点数量限制： 最多支持 9 个节点 MGR vs MHA 对比 维度 MHA MGR 核心机制 外部脚本监控 + 异步/半同步复制 数据库内核插件 + Paxos 协议 数据一致性 理论上可能有丢失 强一致性（Quorum 机制保证不丢） 脑裂保护 需额外配置 fencing 脚本 原生自带 故障切换 需要 VIP 漂移脚本配合 自动选主 多点写入 不支持 支持（多主模式） MySQL InnoDB Cluster 这是一个全家桶解决方案：\nMGR（底层）： 负责数据复制和强一致性 MySQL Router（中间件）： 负责流量转发，自动识别谁是主节点 MySQL Shell（工具）： 一键部署和管理 MGR 集群 公式： InnoDB Cluster = MGR + MySQL Router + MySQL Shell\nRedis 的中心化集群架构 在 Redis 的生态演进中，提到\u0026quot;中心化\u0026quot;架构，通常指的是两种形态：\n高可用层面： Redis Sentinel（哨兵模式） 分片/代理层面： Codis 或 Twemproxy 与之相对的是 Redis Cluster（官方集群），它是典型的**去中心化（P2P）**架构。\nRedis Sentinel（哨兵模式） 这是 Redis 官方推荐的**高可用（HA）**解决方案。\n架构拓扑 数据节点： 1 个 Master（负责写）+ N 个 Slave（负责读） 管理节点（Sentinel）： 一组独立的 Redis 进程（建议至少 3 个），互相通信，同时监控所有数据节点 核心功能 功能 说明 监控 (Monitoring) 不断 Ping Master 和 Slave，看它们是否还活着 通知 (Notification) 发现节点挂了，可以通过 API 通知管理员 自动故障转移 (Automatic Failover) Master 挂了，哨兵投票选出新 Master，指挥其他 Slave 连向新老大 配置中心 (Configuration Provider) 客户端连接 Sentinel，Sentinel 告诉客户端当前 Master 的地址 故障切换流程 主观下线 (SDOWN)： 一个哨兵 Ping 不通 Master，它认为 Master 挂了（主观觉得）。 客观下线 (ODOWN)： 超过半数（Quorum）的哨兵都说连不上，坐实 Master 挂了。 选举领头哨兵： 哨兵们内部选出一个\u0026quot;领头哨兵\u0026quot;来执行切换操作。 选新主： 领头哨兵根据规则（优先级、复制偏移量）选出一个 Slave 升级为 Master。 广播： 通知其余 Slave 和客户端切换到新地址。 优缺点 优点 缺点 官方原生，自动化 HA 写性能无法扩展（只有一个 Master） 解决了单点故障问题 存储无法扩展（内存容量受限于单机） Proxy 架构（Codis / Twemproxy） 这是一种中心化分片架构。在 Redis Cluster 普及之前，这是处理海量数据的主流方案。\n架构拓扑 1 Client \u0026lt;---\u0026gt; Proxy (Codis/Twemproxy) \u0026lt;---\u0026gt; Redis Group 1, Group 2, ... 核心原理 中心入口： 客户端只连接 Proxy，感觉就像连接一个巨大的单机 Redis。 数据分片： Proxy 内部维护了路由表（Slot 映射）。当你 SET key value 时，Proxy 计算 key 的 Hash 值，转发给后端的某一台 Redis。 扩容： Codis 提供了 Dashboard，可以动态地迁移数据（Slot），对客户端透明。 优缺点 优点 缺点 客户端简单（无需改代码） 多了一层网络转发，增加延迟 支持超大容量 架构复杂，需要部署 ZooKeeper/Etcd - 逐渐被边缘化（Redis Cluster 成熟后） 对比：Redis Cluster 是\u0026quot;去中心化\u0026quot; 没有 Proxy： 客户端直接连任何一个 Redis 节点 没有中心 Master： 集群被切分成 16384 个槽（Slots），分配给多个主节点 Gossip 协议： 节点之间互相对话 客户端智能： 请求错了节点，节点会返回 MOVED 错误，告诉客户端正确的 IP LSM Tree 是什么 LSM Tree (Log-Structured Merge-tree) 是一种为高吞吐量写入而优化的数据结构，它是现代 NoSQL 数据库（如 HBase, Cassandra, LevelDB, RocksDB）和部分 NewSQL 数据库（如 TiDB）的存储引擎核心。\n核心思想： 将离散的随机写请求，转换成批量的顺序写请求，以换取极致的写入性能。\n为什么要发明 LSM Tree？ 在传统的 B+ 树（MySQL InnoDB 使用）中，当我们要写入一条数据时，需要先找到它在磁盘 B+ 树中的具体叶子节点位置，然后做原地更新。\n痛点： 如果写入的主键是无序的，这会产生大量的磁盘随机 I/O。对于机械硬盘甚至 SSD 来说，随机写比顺序写慢得多。\nLSM Tree 的解决思路： 不管你写什么，我先不急着存到磁盘的具体位置，而是像写日志一样，**追加（Append）**到文件末尾。追加是顺序写，速度极快。\nLSM Tree 的三大核心组件 1. MemTable（内存表） 位置： 内存（RAM） 结构： 通常是一个有序的数据结构（如跳表 SkipList 或红黑树） 作用： 所有新的写入请求首先都进入 MemTable。因为是在内存中操作，速度极快 2. Immutable MemTable（不可变内存表） 位置： 内存 作用： 当 MemTable 写满后，它会瞬间变成\u0026quot;不可变\u0026quot;状态，并生成一个新的 MemTable 接收新写入。这个不可变的表会在后台被刷盘（Flush）到磁盘 3. SSTable (Sorted String Table) 位置： 磁盘 结构： 内部有序的键值对文件 特点： 不可变（Immutable）。一旦写入磁盘，就不会再被修改 分层（Level）： 磁盘上的 SSTable 通常分为 Level 0, Level 1, Level 2\u0026hellip; 多层 4. WAL (Write Ahead Log) 作用： 为了防止断电导致内存里的 MemTable 数据丢失，每次写 MemTable 之前，会先顺序写入磁盘的 WAL 日志 工作流程详解 写入流程（Write） —— 极快 写 WAL（保证持久性） 写 MemTable（内存操作，O(logN)） 结束。（对客户端来说，写入已经完成了） 后台动作： 当 MemTable 满了，转为 Immutable MemTable，然后 Flush 到磁盘成为 Level 0 的 SSTable。\n读取流程（Read） —— 稍慢 因为数据可能散落在内存和磁盘的不同层级中，读取需要分层查找：\n查 MemTable 查 Immutable MemTable 查 L0 层 SSTable（文件间 Key 可能重叠，需要遍历） 查 L1, L2\u0026hellip; 层 SSTable 优化： 使用布隆过滤器 (Bloom Filter)。在打开一个 SSTable 文件前，先问布隆过滤器：\u0026ldquo;这个 Key 可能在这里吗？\u0026ldquo;如果回答\u0026quot;不在\u0026rdquo;，就直接跳过该文件。\n核心机制：Compaction（合并/压缩） LSM Tree 需要在后台运行 Compaction 进程：\nMerge： 把多个小的、重叠的 SSTable 读取出来 Sort： 进行归并排序 Clean： 丢弃旧版本数据，物理删除带有\u0026quot;墓碑标记\u0026quot;的数据 Write： 写入新的、更大的、更有序的 Level+1 层 SSTable LSM Tree vs B+ Tree 特性 LSM Tree B+ Tree 典型代表 RocksDB, HBase, Cassandra, TiKV MySQL (InnoDB), PostgreSQL 写入性能 极高 (顺序写) 一般 (随机写，需维护树结构平衡) 读取性能 一般 (可能需要查多个文件) 极高 (索引直接定位) 空间利用率 高 (SSTable 紧凑排列，无碎片) 低 (页分裂导致碎片) 适用场景 写多读少，海量数据日志、监控 读多写少，强一致性事务 MySQL Buffer Pool 和 TiDB 缓存对比 MySQL 的 Buffer Pool 和 TiDB 的缓存机制存在显著差异，这主要源于它们底层存储引擎结构的不同（B+ 树 vs LSM 树）。\nMySQL：InnoDB Buffer Pool 在哪里？ 物理位置： MySQL 服务器的**内存（RAM）**中 归属： 属于 InnoDB 存储引擎 内容： 缓存数据页、索引页、插入缓冲（Change Buffer）、自适应哈希索引、锁信息等 怎么运作的？ MySQL 的 Buffer Pool 是典型的 Page Cache（页缓存） 机制，默认页大小为 16KB。\n读操作：\n命中（Hit）：直接返回，无需读盘（极快） 未命中（Miss）：从磁盘加载该页到 Buffer Pool，然后再返回 写操作（Write Back 策略）：\n直接修改内存中的页，将其标记为\u0026quot;脏页（Dirty Page）\u0026rdquo; 同时写入 Redo Log 保证持久性 后台线程异步将脏页刷回磁盘 怎么\u0026quot;使用\u0026quot;？（调优） 核心参数： innodb_buffer_pool_size 建议配置： 在专用数据库服务器上，通常设置为物理内存的 50% ~ 75% 切记： 留给操作系统和其他进程一些内存，不要设得太满导致 Swap TiDB：多层级缓存架构 TiDB 是存算分离架构，缓存分为两部分：TiDB Server（计算层）和 TiKV（存储层）。\nTiKV 层（存储层 - 核心数据缓存） TiKV 底层使用 RocksDB（LSM Tree 架构），缓存机制与 MySQL 大不相同。\nBlock Cache（读缓存）：\n在 TiKV 节点的内存中 用于缓存磁盘上的 SSTable 数据块（Block） 数据是只读的，不存在\u0026quot;脏页\u0026quot;的概念 MemTable（写缓存）：\n在 TiKV 节点的内存中 新数据直接写入 MemTable，写满后 Flush 到磁盘成为 SSTable 写入完全不经过 Block Cache。\nTiDB 层（计算层 - 结果缓存） Coprocessor Cache： 缓存下推给 TiKV 计算的中间结果 Plan Cache（执行计划缓存）： 缓存 SQL 的解析和优化结果 核心对比总结 特性 MySQL (InnoDB Buffer Pool) TiDB (TiKV RocksDB Block Cache) 数据结构 B+ Tree 页 (Page, 16KB) LSM Tree 块 (Block, 4KB~) 缓存内容 数据 + 索引 主要是 SSTable 的数据块 写入方式 原地更新：直接修改缓存页，标记为脏页 追加写：写入单独的 MemTable，不修改 Block Cache 脏页处理 需要 Checkpoint 刷盘 无脏页概念 (SSTable 是不可变的) 内存分配 建议给 50-75% 物理内存 建议给 45% 左右 (需预留给 OS Cache) TiDB 的读取速度会不会慢很多？ TiKV 的底层完全基于 RocksDB，使用的就是 LSM Tree 结构。\n答案是： 理论上单次查询会有轻微延迟（Read Amplification，读放大），但在实际生产和高并发场景下，通常感觉不到慢，甚至在某些场景下更快。\n为什么 LSM Tree 这种\u0026quot;原本读取慢\u0026quot;的结构，在 TiDB 里跑得飞快？ 1. 布隆过滤器 (Bloom Filter) —— 快速排除 RocksDB 给每个 SSTable 文件都配了一个布隆过滤器。它能以 O(1) 的速度告诉你：\u0026ldquo;这个文件里绝对没有这个 Key\u0026rdquo; 或者 \u0026ldquo;可能有\u0026rdquo;。\n效果： 绝大多数不包含该数据的文件会被瞬间排除，根本不需要发生磁盘 I/O。\n2. Block Cache —— 内存命中 热点数据（Hot Data）通常已经被加载到了内存的 Block Cache 中。如果缓存命中，读取速度就等同于读内存。\n3. Compaction (合并) —— 保持层级扁平 RocksDB 会在后台不断进行 Compaction，把多层的小文件合并成一层的大文件。保证读取时需要查找的文件层数非常少。\n4. TiKV 的杀手锏：Coprocessor (计算下推) 这是 TiDB 架构上最大的优势。\nMySQL 的做法： \u0026ldquo;把数据全搬到 Server 层，Server 再过滤。\u0026rdquo; TiDB 的做法： \u0026ldquo;计算下推\u0026rdquo;。TiDB Server 告诉 TiKV 节点：\u0026ldquo;你帮我数一下 age \u0026gt; 20 的有多少，直接告诉我结果。\u0026rdquo; 效果： 虽然 LSM Tree 读单行可能稍慢，但 TiDB 利用多节点并行计算 + 减少网络传输，使得整体查询响应速度往往反超单机 MySQL。\n性能对比实话实说 场景 MySQL (B+ Tree) TiDB (LSM Tree) 谁赢？ 点查询 select * from t where id=1 极快 (O(logN) 稳定索引查找) 稍慢 (可能要查 MemTable+BlockCache) MySQL 险胜（但高并发下 TiDB 吞吐量更大） 范围查询 select * from t where id \u0026gt; 100 快 (叶子节点链表) 很快 (SSTable 内部本身就是有序的) 平手 / TiDB 胜 写入性能 一般 (随机 I/O，页分裂) 极快 (顺序追加写) TiDB 完胜 复杂分析 (OLAP) 聚合、Group By 慢 (单机 CPU 瓶颈) 极快 (MPP 架构，多节点并行计算) TiDB 完胜 结论 TiDB 的\u0026quot;慢\u0026quot;主要体现在极低延迟要求的\u0026quot;单点查询\u0026quot;上（比如 MySQL 能做到 0.5ms，TiDB 可能是 1-2ms）。\n但在绝大多数业务场景下，得益于缓存和布隆过滤器，这个差异是可以忽略的。而它带来的写入吞吐量巨大提升和海量数据扩展能力，是 B+ Tree 架构难以比拟的。\nTiDB 如何使用联合索引（KV 结构如何模拟 B+ 树索引） TiDB 底层 TiKV 是一个巨大的 Map（Key-Value），看起来是平铺的。那怎么用扁平的 KV 来模拟立体的\u0026quot;联合索引\u0026quot;呢？\n答案就在于 \u0026ldquo;Key 的编码规则（Key Encoding）\u0026quot;。\nTiDB 并没有真的建立一棵 B+ 树，而是巧妙地把\u0026quot;索引列的值\u0026quot;直接编码到了 KV 的 Key 里面。因为 TiKV（RocksDB）是按 Key 的字节序有序存储的，所以只要设计好 Key 的格式，就能利用\u0026quot;Key 的顺序\u0026quot;来模拟\u0026quot;B+ 树的顺序\u0026rdquo;。\n场景假设 假设你有一张表 user，有一个联合索引 idx_name_age (name, age)。\n1 2 3 4 5 6 7 8 9 10 CREATE TABLE user ( id INT PRIMARY KEY, name VARCHAR(20), age INT, KEY idx_name_age (name, age) ); INSERT INTO user VALUES (1, \u0026#39;Alice\u0026#39;, 18); INSERT INTO user VALUES (2, \u0026#39;Bob\u0026#39;, 20); INSERT INTO user VALUES (3, \u0026#39;Alice\u0026#39;, 19); TiDB 是怎么把它们变成 KV 的？ 存\u0026quot;行数据\u0026quot; (Row) 1 2 Key: t{表ID}_r{行ID} Value: [Alice, 18, ...] (整行数据) 存\u0026quot;联合索引\u0026quot; (Index) —— 重点！ TiDB 会按照 (TableID, IndexID, IndexColumnValues) 的格式构造 Key：\n逻辑上的 Key 结构 Value 解释 t10_i1_Alice_18_1 null Alice(18岁) 对应 ID=1 t10_i1_Alice_19_3 null Alice(19岁) 对应 ID=3 t10_i1_Bob_20_2 null Bob(20岁) 对应 ID=2 Key 的设计玄机：\n前缀相同： 大家都是 t10_i1（同一个表，同一个索引），所以它们在磁盘上是物理挨在一起的 顺序排列： RocksDB 会自动把 Key 排序。Alice_18 排在 Alice_19 前面，Alice_xxx 全部都排在 Bob_xxx 前面 联合索引如何生效？（查询过程） 场景 1：最左前缀匹配 1 SELECT * FROM user WHERE name = \u0026#39;Alice\u0026#39;; TiDB 动作：\n构造一个扫描范围：从 t10_i1_Alice 开始 TiKV 直接定位到 t10_i1_Alice_18_1 接着往下读，读到 t10_i1_Alice_19_3 再往下读，发现是 Bob 了，停止 结果： 拿到了 ID 1 和 3。这和 B+ 树的范围查找完全一样！\n场景 2：联合查询 1 SELECT * FROM user WHERE name = \u0026#39;Alice\u0026#39; AND age = 19; TiDB 动作：直接构造精确的 Key 前缀 t10_i1_Alice_19，TiKV 直接 Seek 定位。\n场景 3：索引失效（跳过最左前缀） 1 SELECT * FROM user WHERE age = 19; 索引 Key 是按 name 排序的。age=19 的数据并不是挨在一起的，没办法 Scan，只能全表扫描。这和 MySQL 的索引失效原理完全一致。\n总结 TiDB 并没有像 MySQL 那样维护复杂的树指针，它用了一种\u0026quot;降维打击\u0026quot;的方式：\n映射： 把多维的\u0026quot;联合索引 (a, b, c)\u0026quot; 扁平化映射成一维的 Key ..._a_b_c 排序： 利用底层 RocksDB/LSM Tree 对 Key 的天然有序性 扫描： 把 SQL 的范围查询转换成 KV 存储的 Prefix Scan（前缀扫描） 所以，你在 MySQL 里学的索引原则（最左前缀、索引覆盖、索引下推），在 TiDB 里 100% 适用。\nTiDB 多个索引是否要多存几份表？ 你的理解是对的，但有一个关键的定语需要修正： 并不是\u0026quot;多存几份表\u0026quot;，而是\u0026quot;多存几份索引列的数据\u0026quot;。\n这是数据库领域最核心的交换法则：空间换时间（Space for Time）。\n并没有存\u0026quot;整张表\u0026quot;，只存了\u0026quot;路标\u0026quot; 假设你的 user 表非常宽，有很多列：id, name, age, address, bio, photo_url, create_time...\n第一份：主键/行数据 (Row Data) —— 它是真身 1 2 Key: t10_r1 (主键 ID) Value: {name:Alice, age:18, address:北京, bio:..., photo:..., ...} (整行所有数据都在这) 大小： 假设这一行有 1KB。\n第二份：联合索引 (Secondary Index) —— 它是影子 假设你建了索引 idx_name_age (name, age)。\n1 2 Key: t10_i1_Alice_18_1 (索引 ID + 索引列的值 + 主键 ID) Value: null (几乎不占空间) 它只复制了 name(\u0026quot;Alice\u0026quot;) 和 age(18) 这两个字段，加上一个主键 ID(1)。其他的 address、bio、photo 统统不存。\n大小： 这一行 KV 可能只有 50 Bytes。\n回表（Back to Table）：因为没存整表 正因为索引 KV 里只有 name 和 age，没有 address，所以：\n查询 1（索引覆盖）： SELECT name, age FROM user WHERE name='Alice'\n只需要读索引 KV，拿到 \u0026ldquo;Alice\u0026rdquo; 和 18，任务结束。速度极快。 查询 2（回表）： SELECT address FROM user WHERE name='Alice'\n读索引 KV，找到 name='Alice' 对应的主键 ID = 1 拿着 ID = 1，再去读\u0026quot;主键/行数据\u0026quot;那份 KV，把 address 拿出来 这就是所谓的**\u0026ldquo;回表\u0026rdquo;**代价 TiDB 相比 MySQL 的\u0026quot;空间\u0026quot;优势 虽然逻辑上 TiDB 和 MySQL 都要存这些索引副本，但在物理存储上，TiDB（RocksDB）有一个巨大的优势：前缀压缩（Prefix Compression）。\n在 TiDB (LSM Tree) 中，RocksDB 会利用 Delta Encoding 和 Block Compression (Zstd/Lz4)：\n它不会傻傻地把 \u0026ldquo;Alice\u0026rdquo; 存 1 万遍 它会记：\u0026ldquo;跟上一行比，前缀有 15 个字节是一样的，只有最后的主键 ID 不一样\u0026rdquo; 实测结果： 同样的数据量和索引量，迁移到 TiDB 后，磁盘占用通常只有 MySQL 的 30% ~ 50%。\nTiDB 的索引查找是否需要遍历？ 绝对不是\u0026quot;每一次都遍历\u0026quot;。\n虽然 TiKV 底层是 KV 结构，但它支持一种核心操作叫 Seek(key)。这个操作的复杂度是 O(log N)，和 MySQL 的 B+ 树查找效率是同一个量级的。\n宏观层面：它是分区的（Region） PD (Placement Driver) 知道 name='Alice' 对应的数据在哪个 Region 上，请求直接发给对应节点。\n微观层面：文件内部是有\u0026quot;目录\u0026quot;的 SSTable 文件内部自带索引（Index Block），查找时：\n布隆过滤器： 先看一眼文件头，如果过滤器说\u0026quot;这里面没有 Alice\u0026quot;，直接跳过整个文件 查索引块： 发现 Alice 应该在第 0~10KB 这个块里 二分查找： 只把这个小块加载到内存，然后做一次二分查找 结论： 无论文件有多大，找到 Alice 只需要读取极少量的元数据块，然后做一次精准跳转。\nTomcat 拥有的是线程池还是连接池 直接回答： Tomcat 两者都有，但\u0026quot;默认连接数\u0026quot;通常指的是它作为 Web 服务器处理 HTTP 请求的能力。\n对外：Tomcat 作为 Web 服务器 这里指的是浏览器（Client）连接到 Tomcat。在这个层面，Tomcat 主要维护的是线程池（Thread Pool）和连接数（Connections）。\n默认值（关键知识点） 参数 默认值 含义 maxThreads 200 最大工作线程数，Tomcat 能同时并行处理多少个请求 maxConnections 10,000 (NIO) / 8,192 (Spring Boot) 最大连接数，Tomcat 能同时维持多少个 TCP Socket 连接 acceptCount 100 排队队列，当 maxConnections 也满了，操作系统层面还允许多少个新的 TCP 连接排队 为什么连接数比线程数大这么多？\n因为用了 NIO (Non-blocking IO)！Tomcat 用少量的线程（Poller Thread）就能挂起成千上万个空闲的 TCP 连接。只有当连接真正要读写数据、处理业务时，才会分配那 200 个 maxThreads 中的一个去干活。\n总结： Tomcat 默认能 hold 住 10,000 个连接，但同一时刻只能全力跑 200 个业务代码。\n对内：Tomcat 作为数据库连接池提供者 这里指的是你的 Java 代码连接 MySQL。\nTomcat 确实自带了一个组件叫 tomcat-jdbc，这是一个 JDBC 数据库连接池。\n但是： 在 Spring Boot 2.0 之后，默认换成了性能更强悍的 HikariCP。\n图解 Tomcat 处理流程 (NIO) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 用户请求 (浏览器) | v [ TCP 连接 (Socket) ] \u0026lt;--- 限制由 maxConnections (10000) 控制 | | (IO多路复用, Epoll 监听) v [ Poller 线程 ] (极少，负责搬运数据) | | (数据读取完毕，准备执行业务) v [ Worker 线程池 ] \u0026lt;--- 限制由 maxThreads (200) 控制 | | (执行 Java 代码: Controller -\u0026gt; Service -\u0026gt; Dao) v [ DB 连接池 (HikariCP) ] \u0026lt;--- 限制由 max-size (10) 控制 | v MySQL 常见误区纠正 误区： \u0026ldquo;把 maxThreads 加到 10000，Tomcat 就能处理 10000 高并发。\u0026rdquo;\n真相： 可能会死机。\n线程是昂贵的资源 开启 10000 个 Java 线程，光上下文切换就会把 CPU 吃光 调优建议： 对于计算密集型，maxThreads 设小点；对于 IO 密集型，可以适当调大到 500~800，但很少超过 1000。\nJava 17 下 Tomcat 的线程限制与虚拟线程 Java 17 能用到默认的 maxThreads: 200 和 maxConnections: 10000 吗？ 是的，完全可以。 Java 版本（JDK 17）本身不会改变 Tomcat 的这些默认参数配置。这些参数是由 Tomcat 的版本以及你使用的框架（如 Spring Boot）决定的。\n如果你使用的是 Spring Boot（最常见的情况），默认配置如下：\n参数 默认值 说明 server.tomcat.threads.max 200 同一时刻最多只有 200 个线程在全力处理业务逻辑 server.tomcat.max-connections 8192 可以同时维持 8000 多个 TCP 连接 server.tomcat.accept-count 100 排队队列 Java 17 在这里的\u0026quot;尴尬\u0026quot;地位 在 Java 17 下，这 200 个线程是真正的**\u0026ldquo;重量级系统线程\u0026rdquo; (Platform Threads)**。\n这意味着：\n硬上限： 你很难把这个值调得特别大（比如调到 10,000）。因为 Java 17 的线程直接对应操作系统内核线程，开几千个线程会导致内存爆炸和 CPU 疯狂切换上下文。\nIO 阻塞痛点： 如果你的业务里有大量的 Thread.sleep、外部 API 调用、慢 SQL 查询，这 200 个线程很容易被占满（Block 住）。一旦 200 个全被占住，第 201 个请求进来就得去队列里排队。\n对比 Java 21+： 如果你升级到 Java 21 使用虚拟线程，这 maxThreads: 200 的限制就不存在了。虚拟线程模式下，Tomcat 甚至不使用传统的线程池，而是为每个请求创建一个全新的虚拟线程，轻松支持 10 万+ 并发。\n如何在 Java 17 下调优？ 既然不能用虚拟线程，如果你的并发量上来，觉得 200 不够用，可以在 application.yml 中适当调大：\n1 2 3 4 5 6 7 server: tomcat: threads: max: 500 # 建议值：IO密集型任务可调至 500-800 min-spare: 50 # 最小空闲线程，保证有任务来能立马干活 max-connections: 10000 # 如果并发连接确实很高，可以改回 10000 甚至 20000 accept-count: 200 # 稍微排长一点队 AI 生成场景（2分钟长连接）的特殊考量 如果你的服务是 AI 生成，且和客户端的连接一次都是在 2 分钟左右，这种情况下：\nJava 17 (平台线程) 会直接暴毙：\n用户 A 进来了，开始 AI 生成。他占用了一个线程，持续时间 2 分钟 这个线程在这 2 分钟里，虽然 99% 的时间在睡觉（等 GPU），但它死死抱住茅坑不拉屎 只要有 200 个用户同时在生成，你的服务器就满载了 虚拟线程 (Java 21) 能轻松拿捏：\n虚拟线程发起读取 LLM 数据的请求时，JVM 会把这个虚拟线程从 CPU 上拿下来，挂到堆内存里（只占几 KB 内存） 载体线程空出来了，可以立马去服务第 201、202\u0026hellip; 第 10000 个用户 一台 4 核 8G 的机器，可以轻松维持数万个这种 2 分钟的长连接 Java 17 的解决方案：\n彻底的异步非阻塞 (Spring WebFlux / Netty)：代码难写，但性能和虚拟线程一样强 集群 + 增加配置：调大 maxThreads，上多台机器通过 Nginx 负载均衡 升级 Java 21：成本最低、收益最高 常见的内存溢出（OOM）类型 在 Java 开发中，java.lang.OutOfMemoryError (OOM) 是最令开发者头疼的问题之一。根据发生区域的不同，OOM 主要分为以下 6 种常见类型。\n1. 堆内存溢出 (Heap Space) —— 最常见 报错信息： java.lang.OutOfMemoryError: Java heap space\n原因： 堆（Heap）是存放对象实例的地方。当创建的对象太多，且 GC 无法回收（对象一直被引用），堆满了就会报错。\n常见场景：\n内存泄漏： 比如一个 static List 不断往里 add 对象，但从来不删 大对象： 一次性从数据库查询了 100 万条数据全部加载到内存中 流量激增： 并发太高，瞬间产生的对象超过了 -Xmx 设置的上限 解决：\n调大堆内存：-Xms 和 -Xmx 分析 Dump 文件：使用 MAT (Memory Analyzer Tool) 查看是哪个对象占满了内存 2. 元空间溢出 (Metaspace) 报错信息： java.lang.OutOfMemoryError: Metaspace\n原因： 元空间主要存储类的元数据（Class Metadata），即类的信息、方法信息等。\n常见场景：\n动态代理泛滥： 使用 CGLib、Spring AOP、MyBatis 等框架时，程序在运行期间动态生成了大量的代理类 热部署： 频繁进行热部署，旧的 ClassLoader 没有被卸载，导致类元数据堆积 解决：\n调大元空间：-XX:MaxMetaspaceSize 检查代码中是否有死循环生成动态类的逻辑 3. GC 开销超限 (GC Overhead Limit Exceeded) 报错信息： java.lang.OutOfMemoryError: GC overhead limit exceeded\n原因： JVM 发现系统处于\u0026quot;垂死挣扎\u0026quot;状态：CPU 花了 98% 的时间在做 GC，但只回收了不到 2% 的内存。为了防止 CPU 一直空转做无用功，JVM 抛出这个错误终止程序。\n常见场景： 通常伴随着 Heap Space 问题出现。由于堆快满了，GC 拼命回收但收不回来。\n解决： 同\u0026quot;堆内存溢出\u0026quot;的排查思路。\n4. 无法创建新的本地线程 (Unable to create new native thread) 报错信息： java.lang.OutOfMemoryError: unable to create new native thread\n原因： Java 的线程直接映射到操作系统的内核线程。创建一个线程需要消耗操作系统的内存资源（主要是线程栈 Stack）。\n公式： (物理内存 - JVM堆 - 元空间) / 每个线程栈大小(-Xss) = 最大线程数\n或者触碰到了 Linux 系统的最大进程/线程数限制 (ulimit)。\n常见场景：\n线程池泄露： 代码里不断 new Thread() 却不销毁 高并发： 每个线程栈设置太大（如 1MB），导致物理内存不够创建更多线程 解决：\n减小线程栈：调整 -Xss 参数（如从 1M 减到 256k） 增加系统限制：修改 Linux 的 /etc/security/limits.conf 中的 nproc 使用线程池：禁止直接 new Thread() 5. 栈溢出 (Stack Overflow) 报错信息： java.lang.StackOverflowError\n（严格来说是 Error，不属于 OOM，但常被混淆）\n原因： 方法调用链太深，把线程栈（Stack）压爆了。\n常见场景：\n死递归： 方法 A 调用 A，没有退出条件 方法间循环调用： A 调用 B，B 调用 A 解决：\n检查递归逻辑 临时调大 -Xss（治标不治本） 6. 直接内存溢出 (Direct Buffer Memory) 报错信息： java.lang.OutOfMemoryError: Direct buffer memory\n原因： 使用了 ByteBuffer.allocateDirect() 分配堆外内存（Off-Heap Memory）。这部分内存不受 JVM 堆大小限制，但受物理内存限制。如果申请太快，GC 来不及释放堆外内存，就会报错。\n常见场景： Netty 数据传输频繁，或者没有显式调用 ReferenceCountUtil.release() 释放 ByteBuf。\n解决：\n调整参数：-XX:MaxDirectMemorySize 检查 Netty 代码是否有内存泄漏 OOM 排查神技 遇到 OOM，不要瞎猜，请配置以下 JVM 参数，让它在死之前留下一份\u0026quot;遗书\u0026quot;（Dump 文件）：\n1 2 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof 有了这份 .hprof 文件，配合 MAT (Memory Analyzer Tool) 或 JProfiler，你可以清楚地看到是哪个对象占用了 90% 的内存。\nTomcat 线程池与自定义线程池的关系 Tomcat 的 200 个线程是用来做什么的？ 是用来\u0026quot;执行业务逻辑\u0026quot;的。\nTomcat 底层（NIO 模型）其实有两波线程：\n线程类型 数量 职责 Poller/Acceptor 线程 极少（1-2 个） 负责在门口\u0026quot;处理网络请求的连接和数据传输\u0026quot;，把 socket 里的数据读出来，打包成 Request 对象 Worker 线程 默认 200 个 负责调用你的 Controller、Service、访问数据库，直到生成 Response 返回 结论： 你的 Java 代码（业务逻辑）完全运行在这 200 个 Worker 线程上。\nSpring Boot 的高并发是否就靠这 200 个线程？ 对于传统的 Spring MVC（阻塞式 I/O）来说，是的。\n高并发的公式：QPS = 线程数 / 单次请求耗时\n场景 单次请求耗时 理论 QPS 结论 传统 CRUD 0.05 秒 200 / 0.05 = 4000 QPS 单机也能抗几千 QPS AI 流式生成 120 秒 200 / 120 ≈ 1.6 QPS 系统完全瘫痪 自己创建的线程池算在 Tomcat 的 200 个里面吗？ 不算。 这是完全独立的两块资源。\nTomcat 线程池： 归 Tomcat 管，默认 max=200 你的线程池： 归 JVM 管，大小由你自己 new ThreadPoolExecutor 时指定 关键互动流程：\n1 2 3 4 5 6 7 8 9 @GetMapping(\u0026#34;/ai-chat\u0026#34;) public void chat() { // 1. 此时占用 1 个 Tomcat 线程 myCustomThreadPool.submit(() -\u0026gt; { // 2. 这里的代码在你的自定义线程池里跑，不占用 Tomcat 线程 doHeavyAiWork(); }); // 3. 关键点：Tomcat 线程是释放了，还是得等着？ } 两种情况：\n做法 Tomcat 线程状态 并发效果 傻等（Future.get()） 被占用 并发没提升 异步响应（DeferredResult / SseEmitter） 立即释放 并发大幅提升 SseEmitter 异步模式详解 正确的做法： Tomcat 线程池 + SseEmitter + 自定义异步线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @GetMapping(\u0026#34;/ai-stream\u0026#34;) public SseEmitter stream() { SseEmitter emitter = new SseEmitter(5 * 60 * 1000L); // 5分钟超时 // Tomcat 线程只做这一件事：创建 emitter，扔给后台，立即返回 aiTaskExecutor.submit(() -\u0026gt; { try { // 这里在自定义线程池里跑，不占用 Tomcat 线程 doAiStreamWork(emitter); } catch (Exception e) { emitter.completeWithError(e); } }); return emitter; // Tomcat 线程瞬间释放（2~5ms） } 效果：\nTomcat 线程池不再是瓶颈，QPS 恢复到几千甚至上万 压力转移到：自定义线程池 和 Tomcat 的 maxConnections（8192） 针对 Java 17 的优化建议 1. 调整自定义线程池配置 1 2 3 4 5 6 7 8 9 10 @Bean(\u0026#34;aiTaskExecutor\u0026#34;) public Executor aiTaskExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(200); // 常驻并发量 executor.setMaxPoolSize(2000); // 同时服务的上限（Java 17 单机极限） executor.setQueueCapacity(500); // 超过 2000 人时的排队数量 executor.setThreadNamePrefix(\u0026#34;AI-Stream-\u0026#34;); executor.initialize(); return executor; } 2. 调整 JVM 线程栈大小 因为后台线程主要是\u0026quot;搬运工\u0026quot;（读 InputStream 写 OutputStream），不需要很深的调用栈：\n1 -Xss256k # 默认 1MB，改成 256k 后 2000 个线程只占 500MB 内存 3. 优雅处理超时 1 2 3 SseEmitter emitter = new SseEmitter(5 * 60 * 1000L); // 5分钟超时 emitter.onCompletion(() -\u0026gt; { /* 清理资源 */ }); emitter.onTimeout(() -\u0026gt; { /* 超时处理 */ }); 总结 方案 Tomcat 线程 并发能力 适用场景 直接阻塞 被占满 极低（200 并发） 快速接口（\u0026lt;100ms） SseEmitter + 自定义线程池 立即释放 高（受自定义线程池限制） AI 流式、长连接 Java 21 虚拟线程 自动调度 极高（数万并发） 终极方案 TiDB 新节点发现与数据调度 新 TiKV 是如何被发现的？（节点注册） 当你在新机器上启动一个 TiKV 实例时，它是**主动向集群\u0026quot;报到\u0026quot;**的。核心调度者是 PD (Placement Driver)，而不是 TiDB Server。\n流程：\n读取配置： 新 TiKV 读取配置文件，找到 PD 节点的地址（pd-endpoints） 发送心跳： 新 TiKV 向 PD 发送 RPC 请求，告诉 PD：\u0026ldquo;我是新来的，我的 IP 是多少，我的磁盘容量是多少\u0026rdquo; PD 注册： PD 为新节点分配一个全局唯一的 Store ID，将其状态标记为 Up 注：TiDB Server 此时可能还不知道新节点，它只有在读写数据时发现路由变化，才会更新本地的 Region Cache。\n什么时候把数据存过去？（调度与平衡） 数据基于 Region（数据分片） 为单位，通过 Raft 协议 逐步迁移，完全由 PD 的调度器控制。\n流程：\n信息收集： 所有 TiKV 节点定期（默认每 10 秒）向 PD 发送 Store Heartbeat\n旧节点汇报：我有 1000 个 Region，磁盘使用了 80% 新节点汇报：我有 0 个 Region，磁盘使用了 1% 生成调度策略： PD 的 balance-region-scheduler 发现新节点分数极低，决定把旧节点的一些 Region 搬运过去\n下发操作指令： PD 生成 MovePeer Operator\nAdd Peer：在新节点上增加一个副本 Remove Peer：数据同步完成后，删掉旧节点上多余的副本 执行搬运（Raft）：\nLeader 向新节点发送 Snapshot（快照数据） 快照期间的新写入通过 Raft Log 同步 新节点数据追平后，正式成为 Raft Group 成员 TiDB Server 是怎么感知到的？ TiDB Server 在这个过程中是被动的：\n缓存失效： TiDB Server 维护了 Region Cache（Region ID -\u0026gt; TiKV 地址的映射） 请求重试： 数据迁移后，旧 TiKV 会返回 Region Error 重新拉取： TiDB Server 向 PD 询问最新路由信息 TiKV 的 Raft Log TiKV 用来同步主从（Leader 和 Follower）副本的日志是 Raft Log。\n核心定义 TiKV 是一个基于 Raft 一致性算法 的分布式存储系统。在 Raft 协议中，所有的写操作首先都会被转化为一条日志条目（Log Entry）。\nLeader 的职责： 接收写入请求，把指令追加到自己的 Raft Log 中，然后复制给 Followers Follower 的职责： 接收 Leader 发来的 Log，追加到自己的 Log 中，并告诉 Leader \u0026ldquo;我收到了\u0026rdquo; 达成一致（Commit）： 当**大多数节点（Majority）**都收到了这条 Log，Leader 才会把它应用到状态机 物理存储 Raft Log 在 TiKV 内部是作为 KV 数据存储在 RocksDB 里的。\nTiKV 内部有两个 RocksDB 实例：\n实例 存储内容 RocksDB-KV (kvdb) 真正的用户数据（State Machine） RocksDB-Raft (raftdb) Raft Log 写入流程：\n用户写入 Key=\u0026quot;A\u0026quot;, Value=\u0026quot;1\u0026quot; TiKV Leader 将操作封装成 Log Entry，写入 raftdb（落盘） Leader 通过网络把 Log Entry 发给 Followers Followers 收到后，也写入自己的 raftdb 达成共识后，Leader 和 Followers 再把数据写入 kvdb（这步叫 Apply） 旧的 Raft Log 会被清理（Log Compaction） Raft Log vs MySQL 日志对比 特性 TiKV Raft Log MySQL Redo Log MySQL Binlog 主要用途 多副本之间的数据同步、故障恢复 单机引擎的故障恢复 主从同步、数据归档 共识机制 强一致性（Raft 协议，必须多数派成功） 无（单机写盘） 弱一致性/半同步 存储方式 存储在 RocksDB (LSM-Tree) 中 循环写的物理日志文件 追加写的逻辑日志文件 内容 操作指令 + 索引 + 任期 物理页的修改 SQL 语句或行级数据变化 LSM Tree vs B+ 树的读写性能对比 写入速度：LSM Tree 碾压 B+ 树 差距：1 个数量级以上（10x ~ 100x）\n引擎 写入方式 问题 B+ 树（MySQL） 随机写（Random Write） 修改一行数据，需要把整个 16KB Page 读出来、修改、写回去；Page 满了还要分裂 LSM Tree（TiDB） 顺序写（Sequential Write） 不管改哪行数据，都直接追加到内存和 WAL 末尾 磁盘特性： 机械硬盘的顺序写速度是随机写的 100 倍；即使是 NVMe SSD，顺序写也能跑满带宽。\n读取速度：B+ 树稳赢，但 LSM 也没输太惨 B+ 树： 高度为 3，根节点和第二层索引通常在内存里，查询 = 1 次物理 I/O。稳得可怕。\nLSM Tree： 数据可能在 MemTable、L0、L1\u0026hellip;L6。理论上需要多次 I/O，但有两个\u0026quot;作弊神器\u0026quot;：\n神器一：布隆过滤器 (Bloom Filter) 每个 SSTable 文件都附带一个 Bloom Filter：\n回答\u0026quot;绝对没有\u0026quot; → 直接跳过这个文件，0 次磁盘 I/O 回答\u0026quot;可能有\u0026quot; → 才去读这个文件 效果： 能过滤掉 99% 不包含目标 Key 的 SSTable 文件。\n神器二：Block Cache 热点数据的 SSTable Block 会被缓存在内存中，命中时等同于读内存。\n实测对比 场景 MySQL (B+ Tree) TiDB (LSM Tree) 点查（Point Lookup） 极度稳定，约 1 次 I/O 最好 0 次（MemTable 命中），普通 1-2 次，最坏多次（Bloom Filter 误判） 范围查询（Range Scan） 叶子节点有双向链表，顺序读极快 需要在多个层级做归并排序，消耗 CPU SSD 改变了战局 硬件 顺序读写 随机读写 差距 机械硬盘 (HDD) 100MB/s 1MB/s 100 倍 固态硬盘 (SSD) 2000MB/s 500MB/s 4~5 倍 SSD 的随机读能力非常强，这在一定程度上削弱了 LSM Tree 顺序写的优势，同时也掩盖了 LSM Tree 多次随机读的劣势。\n一句话总结 如果没有布隆过滤器，LSM Tree 的读取速度可能是 B+ 树的 1/10；但加上布隆过滤器和 SSD 后，两者的点查性能差距通常在 10%~20% 以内，而 LSM 却换来了 10 倍 的写入性能提升。\n多层 SSTable 结构详解（Leveled Compaction） TiKV 默认配置是 7 层（Level 0 到 Level 6），每一层的容量通常是上一层的 10 倍。\n各层职责 Level 0 (L0) —— \u0026ldquo;无序的乱流区\u0026rdquo; 来源： MemTable 写满后直接 Flush 成为 L0 的一个 SSTable 文件 特点： Key 是重叠的（Overlapping），因为按时间顺序生成，没有经过合并 读取代价： 必须遍历 L0 层的所有文件 控制： TiKV 严格控制 L0 的文件数量（通常只有几个），一旦多了马上触发 Compaction Level 1 ~ Level 6 —— \u0026ldquo;有序的图书馆\u0026rdquo; 来源： 由上一层的数据经过 Compaction（合并排序）下沉而来 特点： 全局有序，互不重叠 读取优势： 通过 Key 可以直接定位到唯一的一个 SSTable 文件（支持二分查找） Compaction 机制（数据下沉） L0 -\u0026gt; L1 (Major Compaction) 当 L0 文件太多（例如超过 4 个），系统把 L0 的文件和 L1 里 Key 范围有重叠的文件一起读取 在内存中进行多路归并排序（Merge Sort） 生成新的、无重叠的 SSTable 文件，放回 L1 注：这一步最耗费 CPU，因为 L0 是乱序的。\nL1 -\u0026gt; L2 -\u0026gt; \u0026hellip; -\u0026gt; L6 当某层大小超过阈值，挑选一个文件，找到下一层中和它范围重叠的文件，合并、排序、去重、删除（处理墓碑），写入下一层。\n查询路径 当 TiDB 发起一个查询 Get(Key=\u0026quot;user_1\u0026quot;)：\nMemTable： 先看内存里有没有最新的（速度最快） Immutable MemTable： 看准备刷盘的那块内存 L0 SSTables： 依次查询每一个文件（按时间倒序）—— 这里最慢 L1 SSTables： 根据 Key 范围定位到唯一的一个文件，问 Bloom Filter L2 \u0026hellip; L6： 同上，每一层只读 1 个文件 总结 L0 层： 是写性能的缓冲区，允许乱序，写入极快，但读取慢（必须全扫） L1-L6 层： 是读性能的保障区，严格有序，读取快（二分查找），但写入需要付出 Compaction 的代价 LSM Tree 是\u0026quot;用后台的 CPU 和 I/O 资源（做 Compaction），来换取前台的极速写入和较好的读取性能\u0026quot;。\n布隆过滤器（Bloom Filter）详解 布隆过滤器是计算机科学中设计最巧妙的数据结构之一。\n核心逻辑： 如果布隆过滤器说\u0026quot;没有\u0026quot;，那就是 100% 没有；如果它说\u0026quot;有\u0026quot;，那是**\u0026ldquo;可能有\u0026rdquo;**。\n工作原理 想象一个非常长的位数组（Bit Array），初始全都是 0，同时有几个哈希函数。\n写入数据（存入 \u0026ldquo;TiKV\u0026rdquo;） 用 3 个哈希函数计算：Hash1(\u0026quot;TiKV\u0026quot;)=3, Hash2(\u0026quot;TiKV\u0026quot;)=5, Hash3(\u0026quot;TiKV\u0026quot;)=8 把位数组中下标为 3、5、8 的格子全都置为 1 查询数据 情况 A：绝对不存在\n查 \u0026ldquo;MySQL\u0026rdquo;：Hash1=3, Hash2=6, Hash3=8 第 6 位是 0 → 绝对从来没被存进去过 情况 B：可能存在（误判）\n查 \u0026ldquo;Oracle\u0026rdquo;：Hash1=3, Hash2=8, Hash3=5 第 3、5、8 位全都是 1 → 系统说\u0026quot;可能存在\u0026quot; 真相： 其实从来没存过 \u0026ldquo;Oracle\u0026rdquo;，这是哈希碰撞导致的假阳性（False Positive） 在 TiKV 中的作用 TiKV 的磁盘上存了成千上万个 SSTable 文件。当你要找 Key = 10086 时：\nTiKV 拿到 SSTable 文件头部的 Bloom Filter（通常缓存在内存里） 问 Bloom Filter：\u0026ldquo;在这个文件里有 10086 吗？\u0026rdquo; \u0026ldquo;绝对没有\u0026rdquo; → 直接跳过，节省一次磁盘 I/O \u0026ldquo;可能有\u0026rdquo; → 去磁盘加载这个 SSTable 的数据块 核心价值： 能帮数据库过滤掉 99% 以上不包含目标 Key 的文件。\n优缺点 优点 缺点 极其节省空间： 存 10 亿个 Key 可能只需要几百 MB 存在误判（False Positive）： 会把\u0026quot;没有\u0026quot;说成\u0026quot;有\u0026quot; 极快： 查询和插入都是 O(k)，跟数据量无关 不支持删除： 不能简单地把位还原成 0 绝无\u0026quot;漏网之鱼\u0026quot;： 说\u0026quot;没有\u0026quot;就绝对没有 - 一句话总结 布隆过滤器是一个**\u0026ldquo;内存很小、不说谎但偶尔会看走眼\u0026rdquo;**的看门大爷。他能极其高效地告诉你：\u0026ldquo;这人肯定不在屋里，别进去找了\u0026rdquo;，从而省下了无数次推门进去（读磁盘）的力气。\nTiDB 查询 L0 层的真实流程 TiDB 在 L0 上不是对文件内容的\u0026quot;全量顺序扫描\u0026quot;，而是对 L0 层所有文件的**\u0026ldquo;逐个排查\u0026rdquo;**。\n查询流程还原 假设 L0 层有 4 个 SSTable 文件（File A, B, C, D），按时间顺序生成（A 最新）。查询 Key = 100：\n第 1 步：查 File A\n元数据检查（内存）：Key 范围是 200~300 判断：100 不在范围内 → 直接跳过 第 2 步：查 File B\n元数据检查：Key 范围是 0~150，命中 Bloom Filter 检查（内存）：回答\u0026quot;没有\u0026quot; → 跳过 第 3 步：查 File C\n元数据检查：范围 50~200，命中 Bloom Filter 检查：回答\u0026quot;可能有\u0026quot; 文件内部查找（读取磁盘）： SSTable 内部也是有序的，有 Index Block 二分查找定位到具体的 Data Block（通常 4KB） 只加载那个 Data Block，解析出来 结果：找到了！返回 Value 第 4 步：查 File D\n因为在 File C 里已经找到了，File D 不需要看了 为什么 L0 还是慢？ 虽然用到了二分查找和布隆过滤器，但 L0 的机制依然比 L1~L6 慢：\n问题 说明 必须 Loop 每一个文件 L1 层可以直接定位到唯一的一个文件，L0 层必须一个个问 多次 I/O 的风险 Bloom Filter 误判或范围查询时，可能需要读取多个文件 查询 L1~L6： 最多读 1 个文件 查询 L0： 最坏情况可能读 N 个文件\n范围查询（Range Scan） 如果是 SELECT * FROM t WHERE id \u0026gt; 100 AND id \u0026lt; 200：\nTiKV 打开 L0 层所有涉及该范围的文件 同时建立多个迭代器（Iterator） 在内存中对比这些迭代器当前指的值，谁最小选谁（还要处理覆盖逻辑） 这个过程非常消耗 CPU，因为要不断地比较、推进迭代器。\nMemTable 刷盘到 L0 的过程 排序：其实早已完成 MemTable 的底层数据结构通常是 SkipList（跳表），这是一种天然有序的数据结构。\n当你往 TiKV 写数据时，它在插入的那一瞬间，就已经被安插到了正确的位置上 刷盘时，Flush 线程只需要从头到尾遍历这个 SkipList，按顺序把数据拿出来写到磁盘上即可 不需要再进行一次耗时的排序算法 元数据生成：边写边算 在把数据从内存顺序写入磁盘文件的过程中，TiKV 会同时计算并生成大量元数据，追加到 SSTable 文件的末尾（Footer）：\n元数据 作用 Min/Max Key 记录文件里的最小和最大 Key，用于快速判断\u0026quot;不在本文件\u0026quot; Bloom Filter 把文件里所有的 Key 都算一遍哈希，生成布隆过滤器的位图 Index Block 记录数据块的位置，支持文件内部的二分查找 L0 SSTable 的双重性质 维度 特点 内部（Internally） 绝对完美有序，带有完整的索引和布隆过滤器 外部（Globally） 和其他 L0 文件是\u0026quot;乱序/重叠\u0026quot;的 这就导致了\u0026quot;必须逐个检查 L0 文件\u0026quot;的问题。\nSSTable 二分查找 vs B+ 树多次随机 I/O 核心纠正 SSTable 的\u0026quot;二分查找\u0026quot;并不是在磁盘上跳来跳去的二分查找。如果真的在磁盘上做标准的二分查找，SSTable 会慢到令人发指。\nSSTable 的真实查找流程 假设一个 SSTable 文件有 256MB，查询 Key = 100：\n第 1 步：查 Index Block（内存操作）\nSSTable 的末尾有一个索引块，通常缓存在内存里 在索引里二分查找，发现 Key = 100 在第 5 个数据块（Block 5），位置是 Offset: 16KB, Length: 4KB 第 2 步：精准 I/O（磁盘操作）\nTiKV 只读取这 4KB 的数据，而不是 256MB 的整个文件 第 3 步：块内搜索（内存操作）\n把这 4KB 数据解压到内存 在这个 4KB 的小范围内做二分查找 总结： SSTable 的查找 = 0 次磁盘二分 + 1 次磁盘精准读取\nMySQL B+ 树的查找流程 假设查 ID = 100：\n查根节点（Root Page）： 通常常驻内存 查分支节点（Internal Page）： 如果内存里有直接查，没有就读磁盘 查叶子节点（Leaf Page）： 把 16KB 整个加载到 Buffer Pool 页内搜索： 通过 Page Directory 进行二分查找 终极对比 特性 TiDB (SSTable) MySQL (B+ Tree) 最小读取单位 Block (通常 4KB) Page (通常 16KB) 如何定位目标块？ 依靠计算和索引： Bloom Filter 确认存在 → Index Block 算出 Offset 依靠指针： 父节点记录了子节点的 Page ID，一层层跳过去 磁盘 I/O 行为 跳跃式： 直接算出位置，空降过去读取 寻路式： 如果父节点不在内存，可能要读多次盘 一句话概括 TiDB 像是有 GPS 坐标： Bloom Filter 确认你在，Index 告诉我你在第几排第几列，我直接空降过去拿那一本书（Block） MySQL 像是查路标： 先看路口的牌子（Root），往左走；再看路口的牌子（Internal），往右走；最后走到房子门口（Leaf），进去拿那一页（Page） 为什么 TiDB 选择 LSM Tree 而不是 B+ 树 TiDB 的定位是**\u0026ldquo;分布式\u0026rdquo;且\u0026ldquo;支持海量数据写入\u0026rdquo;**的数据库。在这个定位下，B+ 树有几个致命的弱点。\n原因一：写入性能的鸿沟 引擎 问题 B+ 树 当数据量达到 TB 级别，且写入是随机的（如 UUID 主键），需要不断地把磁盘上的 Page 读出来、修改、写回去。更糟糕的是页分裂（Page Split），会导致大量的磁盘操作和锁竞争。这被称为**\u0026ldquo;写墙\u0026rdquo;（Write Wall）** LSM Tree 不管改哪个 Key，对于磁盘来说永远都是 Append Only。顺序写磁盘的速度是随机写的几十倍甚至上百倍 场景： TiDB 经常被用来应对\u0026quot;双11\u0026quot;这种流量洪峰，或者日志类数据的海量插入。\n原因二：分布式架构下的\u0026quot;数据迁移\u0026quot; TiDB 是分布式的，数据会在不同的 TiKV 节点之间搬来搬去（Rebalance）。\n引擎 迁移难度 B+ 树 是一个原地更新的复杂结构。迁移数据需要从复杂的树结构里拆出一部分，锁定，传输，再在另一台机器上重建树结构。非常复杂且难以保证一致性 LSM Tree SSTable 文件是**不可变（Immutable）**的。快照极快，只需要直接把文件通过网络发过去就行了（Send File） 原因三：存储成本（压缩率） 引擎 空间利用率 B+ 树 Page 通常不会填满（为了预留空间给 Update），典型空间利用率只有 50%~70%。而且很难做高压缩 LSM Tree SSTable 是一次性生成的，数据紧紧挨在一起。前缀压缩效果极好 实测数据： 同样的数据存入 TiDB，通常只占用 MySQL 磁盘空间的 30%~50%。\n原因四：站在巨人的肩膀上（RocksDB） TiDB 团队并没有从零手写存储引擎，而是直接利用经过工业界大规模验证的 RocksDB 作为底层，把精力花在处理 Raft 共识协议和分布式事务上。\n总结对比 维度 B+ 树 (MySQL) LSM Tree (TiDB) 谁赢？ 读性能 极好（稳定 1 次 IO） 稍弱（依赖 Cache/Bloom Filter） B+ 树赢 写性能 一般（随机 IO 瓶颈） 极强（顺序写） LSM 赢（关键） 空间利用率 一般（有碎片） 极高（压缩好） LSM 赢（省钱） 扩容/迁移 困难（修改复杂结构） 容易（直接发文件） LSM 赢（分布式核心） 一句话总结 TiDB 并不是为了\u0026quot;找麻烦\u0026quot;才选复杂的 LSM Tree，而是因为在分布式和海量写入的场景下，B+ 树\u0026quot;撑不住\u0026quot;了。LSM Tree 虽然读取逻辑复杂一点，但它换来了十倍的写入吞吐量和极高的压缩率，这对分布式数据库来说是最划算的交易。\n","date":"2025-12-02T13:40:39+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A13.0/","title":"面试八股3.0"},{"content":"","date":"2025-12-01T14:11:07+08:00","permalink":"https://LuciusWan.github.io/p/%E5%9C%BA%E6%99%AF/","title":"场景"},{"content":"智识神工实习经历 - 面试话术指南 一、实习整体介绍（30秒版本） \u0026ldquo;我在智识神工实习期间，负责心理医生知识库项目的后端开发。这是一个 AI 驱动的心理健康服务平台，核心功能是让用户可以和 AI 进行心理咨询对话。\n我主要做了几件事：\nAI 大模型集成：用 Spring AI 封装了通义、Ollama 等多个大模型的统一调用接口 RAG 混合检索：基于 ElasticSearch 实现了语义+关键词的混合检索，召回率提升 40% 对话历史优化：用时间游标分页解决了深分页性能问题，百万级数据查询从 2.1 秒降到 0.7 秒 接口限流：用 Redisson + AOP 实现了令牌桶限流，保护 AI 接口 这段实习让我对 RAG 系统、大模型应用开发、性能优化 有了深入的实践经验。\u0026rdquo;\n二、八股文融合速查表 八股知识点 项目中的应用场景 引出话术 ElasticSearch 原理 RAG 混合检索 \u0026ldquo;ES 的倒排索引原理是\u0026hellip;\u0026rdquo; 向量检索 语义匹配 \u0026ldquo;向量相似度计算用的是余弦相似度\u0026hellip;\u0026rdquo; MySQL 深分页 对话历史查询 \u0026ldquo;深分页问题的本质是\u0026hellip;\u0026rdquo; 游标分页 时间游标优化 \u0026ldquo;游标分页避免了 OFFSET 的问题\u0026hellip;\u0026rdquo; 复合索引 查询优化 \u0026ldquo;我建了联合索引\u0026hellip;\u0026rdquo; 令牌桶算法 接口限流 \u0026ldquo;令牌桶和漏桶的区别是\u0026hellip;\u0026rdquo; AOP 原理 限流注解 \u0026ldquo;我用 AOP 实现了声明式限流\u0026hellip;\u0026rdquo; Redis 分布式 Redisson 限流 \u0026ldquo;Redisson 的 RRateLimiter 底层是\u0026hellip;\u0026rdquo; 策略模式 多模型切换 \u0026ldquo;我用策略模式封装了多个大模型\u0026hellip;\u0026rdquo; Rerank 机制 检索结果排序 \u0026ldquo;Rerank 是二次排序，用交叉编码器\u0026hellip;\u0026rdquo; 三、核心亮点一：AI 大模型集成 问题背景 \u0026ldquo;我们的系统需要对接多个大模型：通义千问用于生产环境，Ollama 本地模型用于开发测试。\n问题是：每个模型的 API 格式不一样，如果在业务代码里写一堆 if-else，代码会很乱，而且每次加新模型都要改业务代码。\u0026rdquo;\n技术方案 \u0026ldquo;我用 Spring AI + 策略模式 解决：\n定义统一的 AiModelService 接口 每个模型实现一个策略类 用 Spring 的 Map\u0026lt;String, Interface\u0026gt; 注入自动收集所有实现 业务代码只调用统一接口，根据配置切换模型\u0026rdquo; 🎯 融合八股：策略模式 面试官追问：为什么用策略模式？\n回答：\u0026ldquo;策略模式的核心是把算法封装成独立的类，让它们可以互相替换。好处是：\n开闭原则：加新模型只需新增策略类，不改原有代码 消除 if-else：不用写条件判断 易于测试：每个策略可以独立单元测试\u0026rdquo; 四、核心亮点二：RAG 混合检索 问题背景 \u0026ldquo;心理咨询场景有个特点：用户问题很口语化，比如\u0026rsquo;我最近心情不好\u0026rsquo;，但知识库里是专业术语\u0026rsquo;抑郁情绪\u0026rsquo;。\n纯关键词检索：词不一样，匹配不上 纯向量检索：能匹配语义，但可能召回不相关内容\n所以需要混合检索，结合两者优点。\u0026rdquo;\n技术方案 \u0026ldquo;我设计了三阶段检索架构：\n第一阶段：混合召回\n关键词检索：ES 的 BM25 算法 向量检索：ES 的 kNN 搜索 两路结果合并去重 第二阶段：Rerank 精排\n用交叉编码器对召回结果重新打分 第三阶段：Top-K 截断\n取 Top 5 拼接到 Prompt\u0026rdquo; 效果数据 \u0026ldquo;- 召回率提升 40%\nNDCG 提升 35% 响应时间 \u0026lt; 0.2 秒\u0026rdquo; 🎯 融合八股：ES 倒排索引 面试官追问：ES 检索原理是什么？\n回答：\u0026ldquo;ES 底层用 Lucene，核心是倒排索引。\n传统数据库是正排：文档 ID → 内容 倒排索引反过来：词 → 包含这个词的文档列表\n比如：'抑郁' → [doc1, doc3, doc7]\n搜索时取列表的交集或并集，就能快速找到相关文档。\nBM25 在此基础上计算相关性分数，考虑词频、逆文档频率、文档长度。\u0026rdquo;\n🎯 融合八股：向量检索 面试官追问：向量检索怎么实现？\n回答：\u0026ldquo;核心是把文本转成向量，计算相似度。\nEmbedding：用预训练模型把文本转成 1024 维向量 相似度：余弦相似度 cos(A,B) = A·B / (|A|*|B|) ES kNN：底层用 HNSW 算法，时间复杂度 O(log n)\u0026rdquo;\n🎯 融合八股：Rerank 机制 面试官追问：Rerank 和初次检索的区别？\n回答：\u0026ldquo;初次检索用双塔模型：Query 和 Document 分别编码，快但精度一般。\nRerank 用交叉编码器：Query 和 Document 拼接输入，精度高但慢。\n策略是：双塔快速召回 Top 100，交叉编码器精排出 Top 5。\u0026rdquo;\n五、核心亮点三：对话历史查询优化 问题背景 \u0026ldquo;用户的对话历史会越来越多，产品要求支持分页查看历史记录。\n问题：传统的 LIMIT offset, size 在深分页时性能很差。比如查第 10000 页，MySQL 要先扫描前 10000*20 条记录，再丢弃，非常慢。\n测试数据：百万级数据，查第 5000 页，耗时 2.1 秒，完全不能接受。\u0026rdquo;\n技术方案 \u0026ldquo;我用时间游标分页替代传统分页：\n传统分页：SELECT * FROM chat_history WHERE user_id = ? ORDER BY timestamp DESC LIMIT 100000, 20\n游标分页：SELECT * FROM chat_history WHERE user_id = ? AND timestamp \u0026lt; ? ORDER BY timestamp DESC LIMIT 20\n区别是：游标分页不用 OFFSET，直接从上一页最后一条记录的时间戳开始查，走索引，性能稳定。\u0026rdquo;\n索引设计 \u0026ldquo;我建了复合索引：(user_id, timestamp, session_id)\n为什么这个顺序？\nuser_id 放最前面，因为每次查询都带这个条件 timestamp 放第二，用于游标定位和排序 session_id 放最后，用于覆盖索引，避免回表\u0026rdquo; 效果数据 \u0026ldquo;- 查询性能提升 3 倍\n百万级数据响应时间从 2.1 秒降到 0.7 秒 无论查第几页，性能都稳定\u0026rdquo; 🎯 融合八股：MySQL 深分页问题 面试官追问：深分页为什么慢？\n回答：\u0026ldquo;深分页的本质问题是 OFFSET 需要扫描并丢弃大量数据。\nLIMIT 100000, 20 的执行过程：\n从索引中找到符合条件的记录 扫描前 100020 条 丢弃前 100000 条 返回最后 20 条 OFFSET 越大，扫描的数据越多，性能越差。这是 MySQL 的机制决定的，无法优化。\u0026rdquo;\n🎯 融合八股：游标分页原理 面试官追问：游标分页为什么快？\n回答：\u0026ldquo;游标分页用 WHERE 条件替代 OFFSET。比如上一页最后一条的时间戳是 2024-01-01 12:00:00，下一页查询 WHERE timestamp \u0026lt; '2024-01-01 12:00:00' LIMIT 20。这样 MySQL 直接从索引定位到这个时间点，往前取 20 条，不需要扫描前面的数据。时间复杂度：传统分页 O(offset + limit)，游标分页 O(limit)。\u0026rdquo;\n🎯 融合八股：复合索引最左前缀 面试官追问：为什么索引顺序是 (user_id, timestamp, session_id)？\n回答：\u0026ldquo;遵循最左前缀原则。\n这个索引可以支持：\nWHERE user_id = ? ✅ WHERE user_id = ? AND timestamp \u0026lt; ? ✅ WHERE user_id = ? AND timestamp \u0026lt; ? ORDER BY timestamp ✅ 但不支持：\nWHERE timestamp \u0026lt; ? ❌（没有 user_id） WHERE session_id = ? ❌（跳过了前两列） 我的查询条件是 user_id = ? AND timestamp \u0026lt; ?，正好匹配索引前两列，可以走索引。\u0026rdquo;\n六、核心亮点四：接口限流 问题背景 \u0026ldquo;AI 接口调用大模型，成本很高（按 Token 计费），而且响应慢。如果不限流：\n恶意用户可能刷接口，造成巨额费用 大量请求可能打垮服务\u0026rdquo; 技术方案 \u0026ldquo;我用 Redisson RRateLimiter + Spring AOP 实现了声明式限流，底层用 Redisson 的 RRateLimiter，基于 Redis 实现分布式限流。\u0026rdquo;\n1 2 3 4 @RateLimit(key = \u0026#34;ai:chat\u0026#34;, limit = 10, window = 60) // 每分钟10次 public String chat(String prompt) { return aiService.chat(prompt); } 🎯 融合八股：令牌桶 vs 漏桶 面试官追问：令牌桶和漏桶有什么区别？\n回答：\u0026ldquo;两者都是限流算法，但特性不同：\n漏桶：\n请求进入桶中，以固定速率流出 特点是平滑流量，无论请求多快，处理速度恒定 缺点是无法应对突发流量 令牌桶：\n以固定速率往桶里放令牌，请求需要拿到令牌才能执行 特点是允许突发，桶里有令牌就能立即执行 可以设置桶的容量，控制突发上限 我选令牌桶是因为 AI 接口允许一定的突发，比如用户连续问几个问题。\u0026rdquo;\n🎯 融合八股：Redisson 分布式限流 面试官追问：为什么用 Redisson 而不是本地限流？\n回答：\u0026ldquo;因为我们是分布式部署，多个实例。\n本地限流（如 Guava RateLimiter）只能限制单个实例，3 个实例就是 3 倍的限流额度。\nRedisson RRateLimiter 基于 Redis，所有实例共享同一个限流器，能实现全局限流。\n底层原理是用 Redis 的 Lua 脚本实现令牌桶，保证原子性。\u0026rdquo;\n🎯 融合八股：AOP 实现原理 面试官追问：限流注解是怎么生效的？\n回答：\u0026ldquo;通过 Spring AOP 实现。\n定义 @RateLimit 注解 写一个切面类，用 @Around 拦截带注解的方法 在切面里调用 Redisson 限流器 限流通过则执行原方法，否则抛异常 Spring AOP 底层用动态代理：\n如果目标类实现了接口，用 JDK 动态代理 否则用 CGLIB 生成子类\u0026rdquo; 七、核心亮点五：可观测性建设 问题背景 \u0026ldquo;AI 应用有个特点：大模型是黑盒，出了问题很难排查。比如用户反馈回答不好，我们需要知道：\n检索到了哪些文档？ Prompt 是什么？ 大模型返回了什么？ Token 消耗了多少？\u0026rdquo; 技术方案 \u0026ldquo;我搭建了完整的可观测性体系：\n监控告警：ARMS（阿里云应用监控）\n接口响应时间、错误率 JVM 内存、GC 情况 自定义指标：Prometheus + Grafana\n大模型 Token 用量 检索召回率 限流触发次数 日志追踪：\n每次请求记录完整的 RAG 链路 检索结果、Prompt、响应都落日志\u0026rdquo; 🎯 融合八股：Prometheus 指标类型 面试官追问：Prometheus 有哪些指标类型？\n回答：\u0026ldquo;四种：\nCounter：只增不减的计数器，如请求总数 Gauge：可增可减的仪表盘，如当前连接数 Histogram：直方图，统计分布，如响应时间分布 Summary：摘要，计算分位数，如 P99 响应时间 我用 Counter 统计 Token 用量，用 Histogram 统计响应时间分布。\u0026rdquo;\n八、口语化面试话术（完整版） 公式：业务背景 → 技术选型原因 → 核心难点实现 → 遇到的坑与解决 → 未来优化方向\n【话术一】RAG 混合检索系统 1️⃣ 业务背景（30秒） \u0026ldquo;我们做的是一个心理咨询 AI，用户可以和 AI 聊天，AI 会根据专业知识库给出回答。\n核心问题是检索：用户说\u0026rsquo;我最近心情不好睡不着\u0026rsquo;，但知识库里写的是\u0026rsquo;失眠症状\u0026rsquo;、\u0026lsquo;抑郁情绪\u0026rsquo;这种专业术语。\n如果用传统的关键词搜索，根本搜不到，因为词不一样。但如果纯用向量语义搜索，又可能召回一些不太相关的内容。\n所以我需要设计一个混合检索方案，把关键词匹配和语义匹配结合起来。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我调研了几种方案：\n方案一：纯 ES 关键词检索\n用 BM25 算法匹配关键词 问题是：用户口语化表达和专业术语对不上 方案二：纯向量检索\n用 Embedding 模型把文本转成向量，计算余弦相似度 问题是：可能召回语义相近但实际不相关的内容 方案三：混合检索 + Rerank（我最终选的）\n关键词和向量两路召回，合并结果 用 Rerank 模型二次排序，提高精度 选这个方案是因为它结合了两者的优点：关键词保证精确匹配，向量保证语义理解，Rerank 保证排序质量。\u0026rdquo;\n3️⃣ 核心难点实现（2分钟） \u0026ldquo;整个检索分三个阶段：\n第一阶段：混合召回\n我在 ES 里同时存了原文和向量。查询时并行执行两个搜索：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 // 关键词检索 - BM25 List\u0026lt;Doc\u0026gt; keywordResults = es.search(matchQuery(\u0026#34;content\u0026#34;, query)); // 向量检索 - kNN float[] vector = embeddingModel.embed(query); List\u0026lt;Doc\u0026gt; vectorResults = es.knnSearch(\u0026#34;embedding\u0026#34;, vector, k); // 合并去重 Set\u0026lt;Doc\u0026gt; merged = new LinkedHashSet\u0026lt;\u0026gt;(); merged.addAll(keywordResults); merged.addAll(vectorResults); \u0026ldquo;第二阶段：Rerank 精排\n召回的结果可能有几十条，但给大模型的 context 不能太长。我用交叉编码器重新打分：\u0026rdquo;\n1 2 // Rerank - 交叉编码器 List\u0026lt;Doc\u0026gt; reranked = rerankModel.rerank(query, merged); \u0026ldquo;交叉编码器和双塔模型的区别是：双塔模型分别编码 query 和 doc，交叉编码器把两者拼在一起编码，能捕捉更细粒度的交互，精度更高。\n第三阶段：构建 Prompt\n取 Top 5 的文档，拼接到 Prompt 里：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 你是一个专业的心理咨询师。根据以下参考资料回答用户问题： 【参考资料】 1. {doc1} 2. {doc2} ... 【用户问题】 {query} 4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：向量维度不匹配\n一开始用的 Embedding 模型输出 768 维，后来换了个模型输出 1024 维，ES 里的旧数据就查不了了。\n解决：重新建索引，写了个迁移脚本，把旧数据重新 Embedding 一遍。以后换模型前先评估维度兼容性。\n坑二：Rerank 太慢\n交叉编码器精度高但是慢，100 条文档 Rerank 要 500ms。\n解决：控制召回数量，两路各召回 50 条，去重后大概 70-80 条，Rerank 时间控制在 200ms 以内。\n坑三：ES 向量检索版本问题\nES 7.x 的向量检索是插件形式，不太稳定。\n解决：升级到 ES 8.x，原生支持 kNN 搜索，性能和稳定性都好很多。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. Query 改写：用大模型把用户口语化的问题改写成专业术语，提高关键词召回率 2. 多路召回融合：除了关键词和向量，还可以加知识图谱召回 3. 在线学习：根据用户反馈调整 Rerank 模型的权重\u0026rdquo;\n【话术二】对话历史分页优化 1️⃣ 业务背景（30秒） \u0026ldquo;用户和 AI 的对话历史需要持久化，产品要求支持分页查看历史记录。\n问题是：用户聊得越多，数据越多。有的用户聊了几千条，用传统的 LIMIT offset, size 分页，翻到后面特别慢。\n我测了一下，百万级数据查第 5000 页，要 2.1 秒，用户体验完全不能接受。\u0026rdquo;\n2️⃣ 技术选型原因（30秒） \u0026ldquo;深分页慢的根本原因是 OFFSET 需要扫描并丢弃大量数据。\nLIMIT 100000, 20 实际上要扫描 100020 条，丢弃前 100000 条，只返回最后 20 条。\n解决方案有两种：\n子查询优化：先查出 ID，再根据 ID 查数据。能优化一些，但还是要扫描 游标分页：用 WHERE 条件替代 OFFSET，彻底避免扫描 我选了游标分页，因为它无论查第几页，性能都是恒定的。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;游标分页的核心思想是：记住上一页最后一条记录的位置，下一页从这个位置开始查。\n传统分页：\u0026rdquo;\n1 2 3 4 SELECT * FROM chat_history WHERE user_id = 123 ORDER BY timestamp DESC LIMIT 100000, 20 \u0026ldquo;游标分页：\u0026rdquo;\n1 2 3 4 SELECT * FROM chat_history WHERE user_id = 123 AND timestamp \u0026lt; \u0026#39;2024-01-01 12:00:00\u0026#39; ORDER BY timestamp DESC LIMIT 20 \u0026ldquo;关键是要建好索引：(user_id, timestamp, session_id)\n这个索引可以：\n通过 user_id 快速定位到这个用户的数据 通过 timestamp 快速定位到游标位置 session_id 作为覆盖索引，避免回表\u0026rdquo; 4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：同一时间戳有多条记录\n如果两条记录的 timestamp 完全相同，游标分页可能会漏数据或重复。\n解决：游标改成 (timestamp, id) 组合。先按 timestamp 排序，timestamp 相同时按 id 排序。查询条件改成：\u0026rdquo;\n1 WHERE (timestamp \u0026lt; ?) OR (timestamp = ? AND id \u0026lt; ?) 5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 缓存热点数据：最近的对话记录访问频率高，可以缓存到 Redis 2. 冷热分离：超过 30 天的历史数据迁移到归档表，减少主表数据量 3. ES 检索：如果要支持全文搜索历史记录，可以同步到 ES\u0026rdquo;\n【话术三】接口限流设计 1️⃣ 业务背景（30秒） \u0026ldquo;AI 接口调用大模型，按 Token 计费，成本很高。而且大模型响应慢，如果不限流：\n恶意用户刷接口，一天能刷出几千块的账单 大量请求堆积，正常用户也用不了\u0026rdquo; 2️⃣ 技术选型原因（30秒） \u0026ldquo;限流算法有几种：\n固定窗口：简单但有临界问题 滑动窗口：平滑但内存占用大 漏桶：平滑流量但不能应对突发 令牌桶：允许突发，适合我的场景\n我选令牌桶，因为用户可能连续问几个问题，需要允许一定的突发。\n实现上用 Redisson RRateLimiter，因为我们是分布式部署，需要全局限流。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;我用 AOP 实现了声明式限流：\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 自定义注解 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface RateLimit { String key(); int limit(); // 令牌数 int window(); // 时间窗口（秒） } // 切面 @Around(\u0026#34;@annotation(rateLimit)\u0026#34;) public Object around(ProceedingJoinPoint point, RateLimit rateLimit) { String key = buildKey(rateLimit); // 拼接用户ID RRateLimiter limiter = redisson.getRateLimiter(key); // 初始化限流器（只执行一次） limiter.trySetRate(RateType.OVERALL, rateLimit.limit(), rateLimit.window(), RateIntervalUnit.SECONDS); // 尝试获取令牌 if (!limiter.tryAcquire()) { throw new RateLimitException(\u0026#34;操作过于频繁\u0026#34;); } return point.proceed(); } \u0026ldquo;使用时只需要加注解：\u0026rdquo;\n1 2 @RateLimit(key = \u0026#34;ai:chat\u0026#34;, limit = 10, window = 60) public String chat(String prompt) { ... } 4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：限流器初始化重复执行\ntrySetRate 每次请求都调用，虽然 Redisson 内部做了幂等，但还是有性能开销。\n解决：用一个 Set 记录已初始化的 key，只有第一次才调用 trySetRate。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 动态限流：根据系统负载动态调整限流阈值 2. 分级限流：VIP 用户限流阈值更高 3. 熔断降级：大模型响应慢时自动降级，返回缓存的通用回答\u0026rdquo;\n九、常见追问及回答 Q1: 为什么选择 ElasticSearch 而不是专门的向量数据库？ \u0026ldquo;我对比了几个方案：\n方案 优点 缺点 ES 8.x 同时支持关键词和向量，运维成熟 向量检索性能不如专业向量库 Milvus 向量检索性能好 不支持关键词检索，需要两套系统 Pinecone 托管服务，省心 成本高，数据出境问题 我选 ES 是因为：\n我需要混合检索，ES 一套系统搞定 公司已有 ES 集群，运维成本低 我的数据量不大（几十万条），ES 性能够用\u0026rdquo; Q2: Rerank 模型用的是什么？ \u0026ldquo;我用的是 bge-reranker-base，是智源开源的中文 Rerank 模型。\n选它的原因：\n中文效果好，专门针对中文优化 模型不大，推理速度可以接受 开源免费，可以本地部署\u0026rdquo; Q3: 游标分页的缺点是什么？ \u0026ldquo;游标分页有两个限制：\n不能跳页：只能上一页、下一页，不能直接跳到第 100 页 需要稳定的排序字段：如果数据会更新，排序可能变化 对于我的场景，对话历史是按时间顺序的，用户也不需要跳页，所以这两个限制可以接受。\u0026rdquo;\nQ4: 限流被触发后怎么处理？ \u0026ldquo;我做了几层处理：\n友好提示：返回\u0026rsquo;操作过于频繁，请稍后重试\u0026rsquo;，不是冷冰冰的错误码 重试建议：告诉用户多久后可以重试 监控告警：限流触发次数超过阈值时告警，可能是有人在刷接口 日志记录：记录被限流的用户 ID 和 IP，方便排查\u0026rdquo; Q5: 实习期间最大的收获是什么？ \u0026ldquo;最大的收获是学会了从 0 到 1 做一个完整的功能。\n以前在学校做项目，主要是实现功能。实习之后发现，功能只是一部分，还要考虑：\n性能：能不能扛住线上流量 成本：AI 接口调用费用怎么控制 可观测性：出了问题怎么排查 兼容性：新功能上线会不会影响老功能 这些是在实际工作中才能学到的。\u0026rdquo;\n十、面试前 Checklist 必须能脱口而出的 实习 30 秒介绍 RAG 混合检索的三阶段架构 深分页为什么慢，游标分页为什么快 令牌桶和漏桶的区别 为什么用 Redisson 而不是本地限流 召回率提升 40%、NDCG 提升 35% 这些数据 最好能说清楚的 ES 倒排索引原理 BM25 算法 向量检索和余弦相似度 Rerank 交叉编码器 vs 双塔模型 MySQL 复合索引最左前缀原则 AOP 动态代理原理 加分项 遇到的坑和解决方案 未来优化方向 技术选型的对比和权衡 可观测性建设的思路 十一、实习经历软性问题（必问） 这部分问题考察的不是技术，而是你的工作态度、团队协作、抗压能力。即使实际经历不多，也要准备好合理的回答。\nQ1: 实习期间加班多吗？怎么看待加班？ 参考回答：\n\u0026ldquo;实习期间加班不算特别多，但也有过几次。\n印象比较深的一次是 RAG 检索功能要上线前，发现召回率不达标，我主动留下来和 mentor 一起排查问题。最后发现是 Embedding 模型的版本问题，换了模型后效果好了很多。那次大概加班到晚上 10 点多。\n我对加班的看法是：\n如果是因为项目紧急、技术攻关，我觉得是可以接受的，毕竟这也是学习和成长的机会 但如果是因为效率低或者流程问题导致的常态化加班，我觉得应该反思和优化 我会尽量在工作时间内高效完成任务，减少不必要的加班\u0026rdquo; Q2: 你的代码是怎么上线的？经历过完整的上线流程吗？ 参考回答：\n\u0026ldquo;经历过，我们的上线流程大概是这样的：\n1. 开发阶段\n在本地开发，用 Ollama 本地模型测试 写完后提交到 Git，发起 Merge Request 2. Code Review\nmentor 会 review 我的代码，提出修改意见 我印象比较深的是，mentor 指出我的一个 SQL 没有走索引，让我加了复合索引 3. 测试环境\n代码合并到 develop 分支后，自动部署到测试环境 测试同学会做功能测试，我也会自测 4. 预发布环境\n测试通过后，部署到预发布环境 预发布环境连的是生产数据库的从库，可以验证真实数据 5. 生产发布\n一般是晚上低峰期发布 我参与过一次发布，主要是在旁边看 mentor 操作，学习发布流程 发布后会观察监控，确认没有异常 我学到的是：上线不只是把代码部署上去，还要考虑灰度发布、回滚方案、监控告警这些。\u0026rdquo;\nQ3: 和同事/mentor 是怎么协作的？ 参考回答：\n\u0026ldquo;我们团队大概 5-6 个人，我主要和 mentor 还有另一个后端同事协作比较多。\n日常协作方式：\n每天早上有个 15 分钟的站会，同步昨天做了什么、今天计划做什么、有没有阻塞 有问题会先在飞书群里问，复杂的问题会拉个小会讨论 代码通过 GitLab 的 Merge Request 协作，互相 review 印象比较深的一次协作： 做 RAG 混合检索的时候，需要和算法同学配合。他负责调 Rerank 模型，我负责工程实现。我们一起定义了接口格式，他把模型封装成 HTTP 服务，我这边调用。中间遇到过返回格式不一致的问题，我们一起 debug 解决的。\n我学到的是：\n提前对齐接口和预期，能减少很多返工 遇到问题及时沟通，不要自己闷头搞 文档很重要，接口文档、设计文档都要写清楚\u0026rdquo; Q4: 遇到过和同事意见不一致的情况吗？怎么处理的？ 参考回答：\n\u0026ldquo;有过一次。\n背景是：我在做对话历史分页的时候，想用游标分页，但 mentor 一开始建议用传统的 LIMIT OFFSET，因为实现简单。\n我的处理方式：\n我没有直接反驳，而是先写了个测试，用百万级数据测了两种方案的性能 测试结果显示，深分页时传统方案要 2 秒多，游标分页只要 0.7 秒 我把测试结果和分析发给 mentor，说明游标分页虽然实现复杂一点，但性能好很多 mentor 看了数据后同意了我的方案，还夸我做事有理有据 我学到的是：\n意见不一致很正常，关键是用数据和事实说话 不要情绪化，要尊重对方的经验 最终目标是把事情做好，不是证明谁对谁错\u0026rdquo; Q5: 实习期间遇到过什么困难？怎么解决的？ 参考回答：\n\u0026ldquo;遇到过几个困难：\n技术上的困难： 刚开始做 RAG 的时候，对向量检索完全不懂，不知道 Embedding 是什么，kNN 是什么。\n我的解决方式：\n先看了几篇入门文章，了解基本概念 然后看 ES 官方文档，学习怎么用 ES 做向量检索 不懂的地方问 mentor，他给我推荐了几篇论文 最后自己写 demo 验证，边做边学 工作节奏上的困难： 刚开始不太适应，不知道怎么估时间，经常低估任务复杂度，导致 delay。\n我的解决方式：\n后来学会了把大任务拆成小任务，每个小任务单独估时间 估时间的时候会乘以 1.5 的系数，留一些 buffer 如果发现要 delay，提前和 mentor 沟通，而不是等到 deadline 才说 我学到的是：遇到困难很正常，关键是主动学习、主动沟通，不要等着别人来帮你。\u0026rdquo;\nQ6: mentor 对你的评价怎么样？ 参考回答：\n\u0026ldquo;mentor 对我的评价总体是正面的。\n他肯定的地方：\n学习能力强，新技术上手快 做事有责任心，交给我的任务都能按时完成 代码质量不错，review 的时候问题比较少 他给我的建议：\n要更主动地沟通，有问题早点说，不要自己闷头搞 技术深度还要加强，不能只停留在会用的层面，要理解原理 可以多参与技术分享，锻炼表达能力 我的改进： 后来我确实更主动了，每周会主动找 mentor 聊一次，同步进度和问题。技术上也开始看源码、看论文，不只是看教程。\u0026rdquo;\nQ7: 为什么从上一家公司离职/实习结束？ 参考回答：\n\u0026ldquo;主要是因为实习期到了，要回学校准备毕业的事情。\n这段实习我收获很大：\n技术上，学会了 RAG、大模型应用开发、性能优化 工作方式上，学会了怎么和团队协作、怎么做 code review、怎么上线 认知上，知道了企业级开发和学校项目的区别 如果有机会，我还是很愿意继续在这个方向深耕的，所以现在在找相关的工作机会。\u0026rdquo;\nQ8: 实习期间有没有主动做过什么事情？ 参考回答：\n\u0026ldquo;有的，我主动做了几件事：\n1. 写了技术文档 RAG 检索模块做完后，我主动写了一份技术文档，包括架构设计、接口说明、部署方式。后来新来的实习生就是看我的文档上手的。\n2. 优化了一个慢查询 有一次我在看监控的时候，发现有个接口响应时间很长，排查后发现是 SQL 没走索引。我主动提了优化方案，加了索引后响应时间从 2 秒降到了 200ms。\n3. 分享了一次技术 实习快结束的时候，我在组内做了一次技术分享，讲的是游标分页的原理和实践。虽然有点紧张，但反馈还不错。\n我觉得：主动做事不仅能学到更多，也能让 mentor 和团队看到你的价值。\u0026rdquo;\nQ9: 你觉得自己在实习中有什么不足？ 参考回答：\n\u0026ldquo;有几个不足：\n1. 技术深度不够 很多技术只停留在会用的层面，比如 ES 我会用，但底层的 Lucene 原理不太清楚。后来我开始有意识地看源码和论文。\n2. 沟通不够主动 刚开始遇到问题会自己闷头搞很久，后来才学会及时问 mentor。现在我会设一个时间限制，比如一个问题卡了 2 小时还没解决，就去问人。\n3. 全局视角不够 我主要关注自己负责的模块，对整个系统的架构了解不多。后来我会主动看其他模块的代码，了解上下游是怎么配合的。\n我在持续改进，比如现在会定期复盘，看看哪些地方可以做得更好。\u0026rdquo;\nQ10: 你对这份工作有什么期望？ 参考回答：\n\u0026ldquo;我的期望主要有三点：\n1. 技术成长 希望能接触到有挑战的项目，比如高并发、大数据、AI 应用这些方向。我不怕难，怕的是没有成长。\n2. 团队氛围 希望团队氛围是开放的，大家可以互相学习、互相帮助。我在实习的时候很喜欢和 mentor 讨论技术问题，这种感觉很好。\n3. 业务价值 希望做的事情是有价值的，能真正帮助到用户。我在实习的时候做的心理咨询 AI，虽然是 toB 的产品，但想到能帮助到有心理困扰的人，还是很有成就感的。\n总的来说，我希望找一个能让我快速成长、做有价值的事情的平台。\u0026rdquo;\n十二、软性问题回答技巧 回答公式：STAR 法则 S（Situation）：背景是什么 T（Task）：你的任务是什么 A（Action）：你采取了什么行动 R（Result）：结果怎么样 几个原则 诚实但有技巧：不用编造经历，但可以把普通经历讲得有亮点 具体比抽象好：说\u0026quot;我优化了一个 SQL，响应时间从 2 秒降到 200ms\u0026quot;比\u0026quot;我做了性能优化\u0026quot;好 展示成长：即使是不足，也要说你怎么改进的 正面积极：不要抱怨前公司、前同事，即使有不好的经历也要正面表达 避免的雷区 ❌ \u0026ldquo;我没怎么加班\u0026rdquo; → 显得不够投入 ❌ \u0026ldquo;我就是按 mentor 说的做\u0026rdquo; → 显得没有主动性 ❌ \u0026ldquo;前公司/mentor 不好\u0026rdquo; → 显得情商低 ❌ \u0026ldquo;我没遇到什么困难\u0026rdquo; → 显得经历太浅 ❌ \u0026ldquo;我什么都会\u0026rdquo; → 显得不够谦虚 ","date":"2025-11-28T10:18:09+08:00","permalink":"https://LuciusWan.github.io/p/%E5%AE%9E%E4%B9%A0%E7%BB%8F%E5%8E%86%E8%AF%9D%E6%9C%AF/","title":"实习经历话术"},{"content":"高统简答题 1. 什么情况下需要进行估计 f ? 在统计学习中，我们将输入 X 和输出 Y 的关系假设为 $Y = f(X) + \\epsilon$。我们需要估计 f 通常出于以下两个主要目的：\n预测 (Prediction)：当我们可以很容易获得输入 X，但很难获得输出 Y 时。我们希望通过$ \\hat{Y} = \\hat{f}(X)$ 来预测结果，此时我们只关心预测的准确性，而不太关心 $\\hat{f}$ 的具体形式（它可以是一个黑盒）。\n推断 (Inference)：当我们想理解 X 是如何影响 Y 时。我们需要确切知道 f 的形式，比如哪些特征最重要？它们与 Y 是正相关还是负相关？此时我们不能把 f 当作黑盒。\n2. Y 作为预测，其精确度依赖于哪些量？ 预测的精确度（通常用 $E(Y - \\hat{Y})^2$ 衡量）依赖于两部分误差：\n可约误差 (Reducible Error)：来自于 $\\hat{f}$ 对真实 f 的估计不完美。通过改进模型算法可以减少这部分误差。\n不可约误差 (Irreducible Error)：来自于 $\\epsilon$（误差项）。因为 Y 本身包含无法通过 X 解释的变异，即使我们完美估计了 f，这部分误差依然存在。\n3. 如何区分推断和预测？ 这是 ISLR 的核心思想之一：\n预测关注的是：给一个新的 $X$，$\\hat{Y}$ 能有多准？ 我们不在乎模型内部看起来是什么样（哪怕它是复杂的神经网络）。\n推断关注的是：X 和 Y 之间的关系是什么？ 我们需要模型具有可解释性 (Interpretability)。通常，线性模型适合推断，而非线性模型（如 Boosting、SVM）适合预测。\n4. 推断中常用的基本问题有哪些？ 在进行推断时，我们通常问以下三个问题：\n哪些预测变量（predictors, X）与响应变量（response, Y）相关？（特征选择问题）\n预测变量与响应变量之间的关系是什么？（正相关还是负相关？）\n这种关系能够用线性方程总结吗，还是更复杂的非线性关系？\n5. 如何利用均方误差 (MSE) 计算可约误差和不可约误差？ 数学期望形式的分解如下（这是第二章最重要的公式）：\n$E(Y - \\hat{Y})^2 = [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon)$\n$[f(X) - \\hat{f}(X)]^2$：这是可约误差（即偏差和方差的组合）。\n$Var(\\epsilon)$：这是不可约误差（数据的固有噪声）。\n6. 估计 f 的方法有哪些？ 主要分为两大类：\n参数方法 (Parametric Methods)：\n假设 f 的函数形状（例如：假设它是线性的）。\n利用训练数据拟合参数（例如：最小二乘法）。\n优点：简化问题，需要的样本量较少。\n缺点：如果假设的形状错误，偏差很大。\n非参数方法 (Non-parametric Methods)：\n不假设 f 的明确形状，而是追求尽可能接近数据点（例如：样条、KNN）。\n优点：可以适应各种形状的 f。\n缺点：需要大量的观测数据，且容易过拟合。\n7. 半指导学习 (Semi-supervised Learning) 的适用的数据模型为哪些？ ISLR 对此提及较少，但其定义是：\n适用于只有少量数据有标签 (Y)，但有大量数据只有输入 (X) 而没有标签的情况。这介于监督学习和无监督学习之间。\n8. 模型的拟合效果如何评价（针对回归类模型）？ 最常用的指标是 均方误差 (MSE, Mean Squared Error)：\n$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2$\n我们更关注测试 MSE (Test MSE) 而非训练 MSE，因为我们希望模型在未见数据上表现良好。 9. 描述曲线光滑度 (Smoothness) 的量是什么？ 在统计学习语境下，这通常指的是灵活性 (Flexibility) 或 自由度 (Degrees of Freedom)。\n低自由度（如线性回归）：曲线非常“硬”，是一条直线，不光滑（或者说极其平滑以至于没有波动）。\n高自由度（如 KNN 当 K=1 时）：曲线非常“摆动 (wiggly)”，紧贴每个数据点。\n(注：在平滑样条中，有一个专门的惩罚参数 $\\lambda$ 控制光滑度，\\lambda 越大越光滑/平直)。\n10. 光滑度 (Flexibility) 和偏差、方差的关系？ 这是经典的 偏差-方差权衡 (Bias-Variance Trade-off)：\n光滑度/灵活性 增加（模型变复杂）：\n偏差 (Bias) 降低（模型能更好地拟合真实关系）。\n方差 (Variance) 升高（模型对训练数据的微小变化非常敏感）。\n光滑度/灵活性 降低（模型变简单）：\n偏差 升高。\n方差 降低。\n目标：找到一个中间点，使 $Bias^2 + Variance$最小。\n11. 分类模型最常用的估计精度的方法是什么？ 错误率 (Error Rate) 或 误分类率 (Misclassification Rate)：\n$\\frac{1}{n} \\sum_{i=1}^{n} I(y_i \\neq \\hat{y}_i)$\n即：分类错误的样本数占总样本数的比例。\n12. 贝叶斯错误率 (Bayes Error Rate) 如何计算？ 贝叶斯错误率是理论上最低的可能错误率（类似于回归中的不可约误差）。\n策略：对于给定的 x，将样本分到 Pr(Y=j|X=x) 最大的那一类。\n计算：$1 - E(\\max_j Pr(Y=j|X))$。\n意思是：1 减去我们在每个点上做出最佳选择时的平均概率。 13. KNN (K-最近邻) 算法的实现步骤？ KNN 是一种非参数方法：\n选定 K 值（例如 K=3）。\n对于一个新的观测点 x_0，在训练数据中找到距离它最近的 K 个点（通常使用欧氏距离）。\n分类决策：这 K 个点中，哪个类别的占比最高（投票），就将 x_0 归为哪一类。\n(注：对于概率，$Pr(Y=j|X=x_0) = \\frac{1}{K} \\sum_{i \\in N_0} I(y_i = j))$。 第一部分：核心推断与评估 (Inference \u0026amp; Evaluation) 1. 估计参数测量接近程度的常用方法是什么？\n标准误 (Standard Error, SE)。\n它衡量了我们的估计值 \\hat{\\beta} 与真实值 \\beta 之间的平均偏离程度。\n总体均值的标准误 vs 残差的标准误？ 这是一个易混淆点：\n总体均值 \\hat{\\mu} 的标准误：$SE(\\hat{\\mu}) = \\frac{\\sigma}{\\sqrt{n}}$。衡量的是样本均值估计总体的准确度。\n残差标准误 (RSE, Residual Standard Error)：RSE = $\\sqrt{\\frac{RSS}{n-2}}$。衡量的是模型预测值偏离真实数据点的平均距离（即 \\epsilon 的标准差估计）。\n3. 置信区间 (Confidence Interval) 如何计算？(95%, 99%)\n通式：$\\hat{\\beta}1 \\pm t{\\alpha/2, n-2} \\times SE(\\hat{\\beta}_1)$。\n95% 置信区间：大约是 $\\hat{\\beta}_1 \\pm 2 \\cdot SE(\\hat{\\beta}_1)$。\n这意味着：如果我们重复取样并计算区间，95% 的区间会包含真实的 \\beta_1。\n4. 如何判断预测变量和响应变量之间存在相关性？\n看 p 值 (p-value)。如果 p \u0026lt; 0.05（通常标准），则拒绝原假设 ($H_0: \\beta_1 = 0$)，认为存在相关性。 判断线性回归拟合质量的标准？ 两个核心指标：\nRSE (残差标准误)：越小越好。衡量绝对误差。\n$R^2$ (决定系数)：越接近 1 越好。衡量模型解释了数据变异的百分比 $(1 - RSS/TSS)$。\n6. 为什么有些变量在简单回归中显著，在多元回归中变得不显著？\n这是因为预测变量之间存在相关性 (Collinearity)。\n在简单回归中，X_1 可能只是代理了 X_2 的作用（因为它们相关）。\n在多元回归中，我们控制了 X_2，此时 X_1 纯粹的、额外的贡献可能就为零了。\n第二部分：多元回归与模型选择 (Multiple Regression) 7. 如何判断多个响应变量和预测变量之间有关系？(多元分析)\n这里通常指判断整体模型是否显著，使用 F-统计量 (F-statistic)。\n即使所有单个变量的 p 值都不显著，F 统计量依然可能显著（对抗多重检验问题）。\n8. 如何选择重要的变量？(变量选择方法)\n向前选择 (Forward Selection)：从零开始，逐个加显著变量。\n向后选择 (Backward Selection)：先包含所有变量，逐个剔除不显著的（p值最大）。\n混合选择 (Mixed Selection)：结合上述两者。\n9. 拒绝向后选择 (Backward Selection) 的条件有哪些？\n硬性条件：当样本量 n 小于变量数 p 时 (n \u0026lt; p)，无法使用向后选择（因为无法拟合包含所有变量的初始模型）。此时只能用向前选择。 第三部分：定性变量与模型假设 (Categorical \u0026amp; Assumptions) 10. 哑变量 (Dummy Variables) 和水平数 (Levels) 的关系？什么是基准水平？\n如果一个定性变量有 K 个水平（Level），我们需要创建 K-1 个哑变量。\n基准水平 (Baseline)：就是那个没有对应哑变量的水平。所有的系数 \\beta 都是相对于这个基准水平的差异。\n11. 线性模型的假设有哪些？(经典考题)\n线性 (Linearity)：X 和 Y 是线性关系。\n独立性 (Independence)：误差项 \\epsilon_i 之间互不相关（针对时间序列数据很重要）。\n正态性 (Normality)：误差项服从正态分布。\n同方差性 (Homoscedasticity)：误差项的方差 \\sigma^2 是常数，不随 X 变化。\n12. 线性模型存在的问题？(诊断)\n数据的非线性 (Non-linearity)。\n误差项自相关 (Correlation of error terms)。\n异方差性 (Non-constant variance of error terms)。\n异常值 (Outliers)。\n高杠杆点 (High Leverage points)。\n共线性 (Collinearity)。\n13. 如何去除可加性假设？什么是实验分层原则 (Hierarchy Principle)？\n去除可加性：引入 交互项 (Interaction Term)，例如 $X_1 \\times X_2$。这意味着 X_1 对 Y 的影响取决于 X_2 的取值。\n分层原则 (Hierarchy Principle)：如果模型中包含了交互项$X_1 \\times X_2$，那么必须同时也包含主效应 X_1 和 X_2，即使它们的主效应 p 值不显著。\n14. 如何去除线性假设？\n引入 多项式回归 (Polynomial Regression)，例如加入 X^2, X^3。 第四部分：预测与 KNN (Prediction \u0026amp; KNN) 15. 如何精确地估计某一个预测变量对响应变量的影响？\n使用 置信区间 (Confidence Interval)。它告诉我们 \\hat{f}(x) 的平均值在哪里。 16. 如何判断未来的预测精度呢？\n使用 预测区间 (Prediction Interval)。\n注意：预测区间总是比置信区间宽，因为它不仅要考虑参数估计的不确定性（可约误差），还要包含单个点的随机误差 \\epsilon（不可约误差）。\n17. KNN 回归和分类的具体区别？\nKNN 分类：输出是邻居类别的众数 (Majority Vote)。\nKNN 回归：输出是邻居 Y 值的平均数 (Average)。\n第一部分：逻辑回归 (Logistic Regression) 为什么定性变量的回归问题不能使用线性回归？ 主要有两个原因：\n编码没有自然顺序：如果响应变量 Y 有三个类别（如：狗、猫、鸟），编码为 1, 2, 3。线性回归会假设 1 \u0026lt; 2 \u0026lt; 3 且 (2-1) = (3-2)，这意味着“狗和猫的差距”等于“猫和鸟的差距”，这在逻辑上通常是不成立的。\n概率越界：如果是二分类问题（编码 0 和 1），线性回归预测的 Y 值可能小于 0 或大于 1，这作为“概率”是没有意义的。\n2. 逻辑斯蒂函数表达式以及对数发生比 (Log-odds) 的构造？其含义？\nLogistic 函数（确保输出在 [0,1] 之间）：\n$p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}$\n对数发生比 $(Log-odds / Logit)$：\n$\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1 X$\n含义：X 每增加一个单位，对数发生比增加 \\beta_1。注意：p(X) 与 X 的关系是非线性的，所以不能简单说概率增加了 \\beta_1。\n3. 估计系数的基本方法？\n最大似然估计 (Maximum Likelihood Estimation, MLE)。\n我们寻找一组 \\beta，使得观测到的数据出现的概率（似然函数）最大化。与之相对，线性回归使用的是最小二乘法 (Least Squares)。\n第二部分：线性判别分析 (LDA) 与 QDA 不使用逻辑斯蒂回归的原因？(即：什么时候 LDA 优于 Logistic？) 这是 ISLR 的经典考点，LDA 在以下情况更好：\n类与类分得特别开：逻辑回归的参数估计会不稳定，而 LDA 很稳定。\n样本量 n 较小 且 X 近似正态分布：LDA 比逻辑回归更稳健。\n多分类问题 (K \u0026gt; 2)：LDA 处理多分类更自然。\n线性判别分析实现的“基本步骤”？\nLDA 的核心是贝叶斯定理：\n假设每一类观测值 f_k(x) 服从正态分布 (Gaussian)。\n假设所有类别的方差 (或协方差矩阵) 相等 ($\\sigma_1^2 = \\dots = \\sigma_k^2 = \\sigma^2$)。\n利用贝叶斯公式计算后验概率 Pr(Y=k|X=x)。\n将观测分给后验概率（或线性判别分数 \\delta_k(x)）最大的一类。\n6. 贝叶斯分类器的分类结果如何表达？\n它将观测点 x_0 分配给使得 Pr(Y=j|X=x_0) 最大 的那个类别 j。\n这也是理论上错误率最低的分类器。\n7. 为什么 LDA 的灵敏度 (Sensitivity) 这么低？\nLDA 默认使用 0.5 (50%) 作为后验概率的阈值进行分类。\n如果样本严重不平衡（例如：欺诈交易只占 1%），为了最大化整体准确率 (Accuracy)，模型会倾向于把所有人都预测为“正常”。这导致整体准确率很高（99%），但几乎没抓到一个坏人，所以灵敏度 (Sensitivity) 极低。\n解决方法：降低阈值（例如，只要 P(Default|X) \u0026gt; 0.2 就判为违约）。\n8. QDA 在实现过程中和 LDA 存在哪些不同？\n假设不同：LDA 假设所有类别的协方差矩阵相同 (\\Sigma_k = \\Sigma)；QDA 假设每一类有自己的协方差矩阵 (\\Sigma_k)。\n边界形状：LDA 是线性的 (Linear)；QDA 是二次的 (Quadratic)，曲线更弯曲。\n权衡：QDA 灵活性更高（低偏差），但需要估计更多参数（高方差），需要更多的数据。\n第三部分：模型评估 (Evaluation) 灵敏度、特异度、召回率和精确度的计算？ 假设：Positive (P) 是我们要检测的关注类（如患病），Negative (N) 是正常类。\n灵敏度 (Sensitivity) / 召回率 (Recall)：$\\frac{TP}{TP + FN}$ (所有真病人中，抓出来多少？)\n特异度 (Specificity)：$\\frac{TN}{TN + FP}$ (所有健康人中，排除了多少？)\n精确度 (Precision)：$\\frac{TP}{TP + FP}$ (我预测为有病的人里，多少是真的有病？)\n10. 第一类错误和第二类错误的区分？\n第一类错误 (Type I Error)：假阳性 (False Positive)。没病说有病（拒真）。\n第二类错误 (Type II Error)：假阴性 (False Negative)。有病说没病（取伪）。\n11. ROC 图像的基本使用？\n横轴：1 - 特异度 (False Positive Rate)。\n纵轴：灵敏度 (True Positive Rate)。\n用法：ROC 曲线展示了在所有可能的阈值下模型的表现。\nAUC (Area Under Curve)：曲线下的面积。AUC 越大（接近 1），模型越好。AUC = 0.5 相当于瞎猜。\n第四部分：KNN 12. K 近邻算法需要输入的多组参数有哪些？K 值对分类的影响？\n输入参数：\n训练数据 X 和标签 Y。\n测试点 x_0。\nK 值 (邻居数量)。\nK 的影响：\nK 很小 (e.g., K=1)：决策边界非常扭曲、复杂，低偏差，高方差（容易过拟合）。\nK 很大：决策边界接近线性，非常平滑，高偏差，低方差。\n这张图片涉及 ISLR 第五章：重抽样方法 (Resampling Methods)。\n这一章非常重要，因为它是现代统计学习中模型选择 (Model Selection) 和 模型评估 (Model Assessment) 的基石。如果没有交叉验证，我们就无法客观地选择最优模型。\n作为统计学大师，我将为你逐一解答这些问题，重点解释 LOOCV 与 k-fold 的偏差-方差权衡，这是考试必考的难点。\n第一部分：验证集方法 (The Validation Set Approach) 1. 交叉验证常用的误差估计方法？\n对于回归问题：均方误差 (MSE)。\n对于分类问题：误分类率 (Error Rate)。\n验证集方法存在的问题有哪些？ 这是最原始的方法（将数据随机分为 50% 训练，50% 测试），主要有两个大缺陷：\n高方差 (High Variability)：测试误差的估计非常依赖于你是如何分割数据的。换一个随机种子，切分结果不同，评估结果可能波动很大。\n高偏差 (Overestimation of Error)：因为你只用了原本数据的一半 (n/2) 来训练模型。我们知道数据越少模型越差，所以这个方法会高估模型在完整数据集上的错误率。\n第二部分：留一交叉验证 (LOOCV) 3. 留一交叉验证 (LOOCV) 的测试误差估计的均值如何计算？\n步骤：\n总共有 n 个样本。\n拿出第 1 个样本作为测试集，用剩余 n-1 个训练，算 MSE_1。\n拿出第 2 个样本作为测试集，用剩余 n-1 个训练，算 MSE_2。\n\u0026hellip;重复 n 次。\n计算：\n$CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} MSE_i$\n大师提示（图里提到的那个线性回归特例）：在线性回归中，LOOCV 其实不需要训练 n 次，只要训练一次就可以算出来：$CV_{(n)} = \\frac{1}{n} \\sum (\\frac{y_i - \\hat{y}_i}{1-h_i})^2$，其中 h_i 是杠杆值。\n4. 留一交叉验证和验证集方法的比较？\n偏差 (Bias)：LOOCV 更低。因为它用了 n-1 个数据训练（几乎是全部），非常接近在这个数据集上能达到的最好效果。\n随机性：LOOCV 没有随机性（总是切那一个），结果是确定的；验证集方法有随机性。\n第三部分：k 折交叉验证 (k-fold CV) —— 核心考点 5. 使用交叉验证的目的是什么？是对 MSE 的真值感兴趣吗？\n目的：\n模型评估 (Model Assessment)：估计模型在未知数据上的表现。\n模型选择 (Model Selection)：在多个模型（不同灵活性）中选最好的那个。\n关于真值：我们通常不是特别关心 MSE 的绝对真值是多少，而是关心哪个模型的 MSE 最小。我们需要的是 MSE 曲线的最小值位置（用于确定模型复杂度，如 KNN 的 K 值或 Lasso 的 \\lambda）。\nLOOCV 方法和 k 折方法的异同点？如何进行偏差-方差的均衡？(重点!) 这是 ISLR 第五章最深刻的理论部分：\n计算成本：LOOCV 极其昂贵（跑 n 次）；k-fold 便宜（通常 k=5 或 10，只跑 5 或 10 次）。\n偏差 (Bias)：LOOCV 偏差更低。因为它用的训练数据 (n-1) 比 k-fold (n - n/k) 更多，更接近真实分布。\n方差 (Variance)：k-fold 方差更低（这是反直觉的，请仔细看）：\nLOOCV 的 n 个模型是在几乎完全相同的数据上训练的（重叠度极高），导致这 n 个预测结果高度相关。对高度相关的量取平均，方差减少得很少。\nk-fold 的 k 个模型之间重叠度较低，相关性较低。\n结论：k-fold (k=5 or 10) 通常是偏差-方差权衡的最佳选择。它既不会像验证集那样高偏差，也不会像 LOOCV 那样高方差。\n7. 对于分类问题，交叉验证的评判标准是什么？\n依然是 误分类率 (Error Rate)：\n$CV_k = \\frac{1}{k} \\sum_{i=1}^{k} Err_i$\n其中 Err_i 是第 i 折里的错误比例。\n第四部分：实际应用与自助法 (Bootstrap) 8. 使用 KNN 分类器时，使用训练错误率还是交叉验证错误率对 K 值进行选择？为什么？\n必须使用交叉验证错误率 (CV Error)。\n原因：\n训练错误率具有误导性。随着 K 变小（模型变复杂），训练错误率会单调下降直到 0。但这并不代表模型好，而是过拟合。\nCV 错误率会呈现 U 型曲线。它能捕捉到过拟合，帮助我们找到偏差和方差平衡的那个最优 K。\n9. 自助法 (Bootstrap) 适用的条件？\n适用场景：当我们想衡量估计量的不确定性（如标准误 SE、置信区间）时，特别是当这些估计量的理论公式很复杂或不存在时（比如中位数的中位数，或者非线性模型的参数）。\n核心思想：从原始数据集中有放回地 (with replacement) 重复采样，生成多个“假”的数据集，计算参数，然后看这些参数的分布。\n注意：Bootstrap 一般不用于评估模型的预测精度（因为有放回采样导致某些样本出现多次，某些不出现，会造成训练集和测试集重叠，严重低估误差）。\n第一部分：最小二乘法的问题与扩展 (OLS Issues \u0026amp; Extensions) 1. p 和 n 的大小会对最小二乘 (OLS) 的结果产生怎样的影响？最小二乘是如何减小计量方差的？\n影响：\n当 $n \\gg p$ 时：OLS 表现良好，具有低方差和低偏差。\n当 p 接近 n 时：OLS 容易过拟合，方差 (Variance) 剧增。\n当 p \u0026gt; n 时：OLS 无法通过唯一解（方程数少于未知数），方差无穷大。\n如何减小方差：\n通过 约束 (Constraining) 或 收缩 (Shrinking) 估计系数（如 Ridge/Lasso）。\n这会引入少量偏差 (Bias)，但能大幅降低方差，从而降低整体 MSE。\n对线性回归模型的拓展方法有哪些？基本原理是什么？ 主要有三类：\n子集选择 (Subset Selection)：挑出一部分最好的变量来拟合。\n收缩方法 (Shrinkage/Regularization)：保留所有变量，但把系数往 0 压缩（Ridge, Lasso）。\n降维方法 (Dimension Reduction)：将 p 个变量组合成 M 个新变量 (M \u0026lt; p)，然后进行回归（PCR, PLS）。\n第二部分：子集选择 (Subset Selection) 3. 最优子集方法 (Best Subset Selection) 的构建过程是怎样的？\n这是一个穷举过程：\n拟合 M_0 (零模型)。\n对于 $k=1, 2, \\dots, p$：拟合所有可能的 C_p^k 个模型，挑出 RSS 最小（或 R^2 最大）的那个作为 M_k。\n最后在 $M_0, \\dots, M_p$ 中，利用交叉验证、AIC 或 BIC 选出唯一的最优模型。\n4. 子集选择方法结果的评判标准是什么？\n训练误差不足以作为标准（因为变量越多，训练 RSS 必然越小）。\n间接估算：C_p, AIC, BIC, 调整 R^2 (Adjusted R^2)。这些指标会对变量数量 d 进行惩罚。\n直接估算：验证集误差 (Validation Set Error) 或 交叉验证误差 (Cross-Validation Error)。\n5. 逐步选择 (Stepwise) 相较于最优子集的优点？\n计算效率：最优子集需要拟合 2^p 个模型，当 p\u0026gt;20 时计算量爆炸。逐步选择只需拟合约 p^2 个模型。\n统计稳定性：当 p 很大时，最优子集搜索空间太大，容易在训练数据上过拟合（找到纯粹由噪声构成的“好”模型）。逐步选择搜索空间小，方差更低。\n6. 向前选择和向后选择实现过程？\n向前选择 (Forward)：从空模型开始，每次加一个能使 RSS 下降最多的变量，直到加满。\n向后选择 (Backward)：从全模型开始，每次剔除一个 p 值最大（最不重要）的变量，直到为空。\n7. 为什么向后选择在 n \u0026lt; p 的情况下不成立？\n因为向后选择的第一步是拟合包含所有变量的全模型。\n当 n \u0026lt; p 时，全模型无法拟合（自由度不够，矩阵不可逆），所以无法启动。\n注：向前选择在 n \u0026lt; p 时依然可用。\n8. 最优模型选择的方法有哪些？\n$C_p, AIC, BIC$（偏向选简单模型）, Adjusted R^2。\n一倍标准误准则 (One-Standard-Error Rule)：在交叉验证中，不一定选误差最小的点，而是选在最小误差的一个标准误范围内，模型最简单（变量最少）的那个点。\n第三部分：正则化/收缩方法 (Ridge \u0026amp; Lasso) —— 核心重难点 9. 岭回归 (Ridge) 中为什么不对 \\beta_0 进行惩罚？\n\\beta_0 是截距项，代表当所有 X=0 时 Y 的平均值。\n如果惩罚 \\beta_0，就会强制回归线经过原点（或接近原点），但这取决于数据的测量单位和位置，没有实际物理意义。我们只希望压缩变量的影响力，不希望改变数据的基准水平。\n10. 为什么在使用岭回归之前需要对数据进行标准化处理？标准化公式？\n原因：岭回归的惩罚项$\\lambda \\sum \\beta_j^2$ 对变量的尺度 (Scale) 非常敏感。如果 X_1 是“米”，X_2 是“毫米”，X_1 的系数会很大，受到更多惩罚。标准化让所有变量处于公平的起跑线。\n公式：$\\tilde{x}{ij} = \\frac{x{ij}}{\\sqrt{\\frac{1}{n} \\sum (x_{ij} - \\bar{x}_j)^2}}$（即除以标准差，使其方差为1）。\n11. 为什么岭回归优化了最小二乘的结果？\n偏差-方差权衡 (Bias-Variance Trade-off)：\n随着 \\lambda 增大，岭回归系数减小（偏离真实值），偏差略微增加。\n但同时，模型对训练数据的噪声不再那么敏感，方差大幅下降。\n只要方差下降的幅度超过偏差上升的幅度，整体 MSE 就会下降。\n12. 为什么提出 Lasso 回归？(Lasso vs Ridge)\nRidge 的缺点是：最终模型包含所有 p 个变量（系数趋向于 0 但不等于 0）。这使得模型难以解释。\nLasso 的优点是：它可以将部分系数完全压缩为 0，从而实现变量选择 (Variable Selection)，得到稀疏模型。\n13. 为什么 Lasso 可以将系数估计完全缩为 0？(几何解释)\n几何解释：Lasso 的约束区域是菱形$(Diamond, | \\beta_1 | + | \\beta_2 | \\leq s)$，有尖角。RSS 的等高线很容易在尖角处（即坐标轴上）与约束区域相切。在坐标轴上意味着某个 \\beta = 0。\nRidge 的约束区域是圆形 $(\\beta_1^2 + \\beta_2^2 \\leq s)$，没有尖角，切点几乎不可能刚好在坐标轴上。\n14. 岭回归和 Lasso 回归的不同适用条件？\nLasso：适用于只有少数几个变量真正起作用，其他变量都是噪声的情况（稀疏信号）。\nRidge：适用于大部分变量都对 Y 有贡献，且贡献度差不多大的情况（密集信号）。\n15. 岭回归的贝叶斯解释中对应的密度函数是什么？Lasso 呢？\nRidge：假设系数 \\beta 的先验分布服从 高斯分布 (Normal/Gaussian Distribution)。\nLasso：假设系数 \\beta 的先验分布服从 拉普拉斯分布 (Laplace / Double-Exponential Distribution)（这种分布在 0 处有尖峰）。\n第四部分：降维方法 (Dimension Reduction) 16. 降维方法是如何实现的呢？\n我们不直接用 X_1, \\dots, X_p 回归。\n而是构造 Z_1, \\dots, Z_M (M \u0026lt; p)，其中每个 Z_m 都是原始 X 的线性组合 (\\sum \\phi_{jm} X_j)。\n然后用 Y 对 Z 进行最小二乘回归。\n17. 降维常用的方法有哪些？\n主成分回归 (PCR, Principal Components Regression)：无监督地构造 Z，只看 X 的方差，不看 Y。\n偏最小二乘 (PLS, Partial Least Squares)：有监督地构造 Z，同时利用 X 和 Y 的信息，寻找既能解释 X 变异又能解释 Y 的方向。\n18. 主成分分析法需要进行标准化处理吗？偏最小二乘呢？\n必须标准化。\n如果不标准化，方差大的变量（单位大的变量）会主导主成分的构造，导致降维结果偏向于单位大的变量，而非真正重要的结构。\n第一部分：基础非线性模型 (Polynomials \u0026amp; Step Functions) 非线性回归有哪些类型？ ISLR 第七章主要介绍了以下几种：\n多项式回归 (Polynomial Regression)：引入 X^2, X^3 等。\n阶梯函数 (Step Functions)：将 X 切分为不同的区间，每个区间拟合一个常数。\n回归样条 (Regression Splines)：分段多项式 + 节点约束。\n光滑样条 (Smoothing Splines)：RSS + 平滑惩罚项。\n局部回归 (Local Regression)：只利用邻近点进行加权拟合。\n广义可加模型 (GAMs)：将上述方法扩展到多个预测变量。\n2. 多项式回归最高阶数？为什么这样设置？\n最高阶数：通常不超过 3 或 4 (d=3, 4)。\n原因：\n尾部震荡：高阶多项式在数据的边界（头部和尾部）会产生剧烈的震荡（Runge现象），导致极高的方差。\n解释性差：很难解释 X^8 到底代表什么物理意义。\n第二部分：样条 (Splines) —— 核心考点 3. 三次样条 (Cubic Splines) 的自由度是多少？\n公式：df = 4 + K。\n解释：\n一个没有任何约束的三次多项式有 4 个参数 (\\beta_0, \\beta_1, \\beta_2, \\beta_3)。\n每增加一个节点 (Knot)，为了保持平滑（连续、一阶导连续、二阶导连续），我们实际上增加了一个自由度（或者说截断幂基函数）。\n所以如果有 K 个节点，自由度就是 4+K。\n注意：如果不加截距项，有时会被记为 3+K+1 或直接说用了 K+4 个基函数。\n三次样条函数的基本形式是什么？ 使用截断幂基 (Truncated Power Basis) 表示：\n$y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3 + \\sum_{k=1}^K \\beta_{k+3} h(x_i, \\xi_k) + \\epsilon_i$\n其中 h(x, \\xi) 是截断函数：当 x \u0026gt; \\xi 时为 (x - \\xi)^3，否则为 0。这一项确保了在节点 \\xi_k 处的平滑连接。\n5. 为什么使用自然样条 (Natural Spline)？\n问题：普通的三次样条在边界区域（第一个节点之前和最后一个节点之后）方差非常大，预测很不稳定。\n解决：自然样条强制要求函数在边界区域是线性的（二阶导为0）。\n结果：牺牲了一点点偏差，换取了边界区域方差的大幅降低，预测更稳定。\n6. 拟合样条的节点位置如何确定？节点的数量如何确定呢？\n位置 (Location)：\n简单方法：等距分布。\n常用方法：根据分位数分布。数据密集的地方节点多，数据稀疏的地方节点少。\n数量 (Number)：\n使用 交叉验证 (Cross-Validation)。尝试不同的节点数 K，画出 CV 误差曲线，选误差最小的那个。 相较于多项式回归，样条拟合的优点在哪？ 这是一个经典的对比题：\n多项式回归是全局的：为了适应局部的一个弯曲，整个函数（包括远处）都会受到影响并剧烈波动。要增加灵活性必须增加次数 d，导致全局不稳定。\n样条是局部的：它可以保持低阶数（比如 3 阶），通过增加节点 K 来增加灵活性。增加一个节点只会影响该节点附近的拟合，不会导致整个曲线乱动。样条更稳健。\n第三部分：光滑样条 (Smoothing Splines) 如何理解光滑样条中的惩罚项？ 目标函数：\n$\\sum_{i=1}^{n} (y_i - g(x_i))^2 + \\lambda \\int g\u0026rsquo;\u0026rsquo;(t)^2 dt$\n第一项：拟合程度（RSS）。使曲线靠近数据点。\n第二项 (惩罚项)：光滑程度。g\u0026rsquo;\u0026rsquo;(t) 衡量曲线的曲率（弯曲程度）。\n\\lambda 的作用：\n\\lambda = 0：完全不惩罚，曲线会穿过所有点（过拟合）。\n\\lambda \\to \\infty：惩罚无限大，不允许任何弯曲，结果变成一条直线（最小二乘回归）。\n9. 为什么光滑样条更加注重有效自由度 (df_\\lambda)？\n在光滑样条中，我们不选“节点数量”（实际上它在每个数据点都设了节点，有 n 个节点）。\n我们调节的是 \\lambda。但 \\lambda 是个抽象的数字（比如 0.005），很难直观理解模型的复杂度。\n所以我们将 \\lambda 转换为 有效自由度 (Effective Degrees of Freedom)。比如 df_\\lambda = 8 意味着这个平滑样条的灵活性相当于一个有 8 个参数的多项式。这让我们能直观地量化模型复杂度。\n第四部分：局部回归与 GAM 10. 局部回归 (Local Regression) 的实现步骤？\n选点：对于要预测的目标点 x_0。\n找邻居：找到离 x_0 最近的 k 个点（占据总数据的比例 s）。\n赋权重：离 x_0 越近的点权重越大，远的权重小。\n拟合：利用这些加权的点，拟合一个加权最小二乘回归（通常是线性的）。\n预测：根据拟合出的线计算 \\hat{f}(x_0)。\nGAM 模型 (Generalized Additive Models) 的优缺点？\nGAM 允许我们把非线性结合到多元回归中：Y = \\beta_0 + f_1(X_1) + f_2(X_2) + \\dots + \\epsilon。\n优点：\n非线性：能自动拟合每个变量的非线性关系。\n可加性/可解释性：因为是相加关系，我们可以单独把 f_1(X_1) 画出来，观察 X_1 如何独立影响 Y（控制其他变量不变）。\n缺点：\n忽略交互作用：默认假设变量之间没有交互。如果 X_1 和 X_2 有交互效应，GAM 会漏掉（除非你手动加入交互项 f(X_1, X_2)）。 第一部分：基础决策树 (Decision Trees) 1. 回归树的建立过程？\n采用 自上而下、贪婪 (Greedy) 的递归二叉分裂 (Recursive Binary Splitting)。\n自上而下：从包含所有观测的根节点开始。\n贪婪：在每一步，只考虑当前最好的分裂，不考虑这一步对未来分裂的影响。\n过程：遍历所有预测变量 X_j 和所有可能的切分点 s，找到能使产生的两个区域的 RSS (残差平方和) 最小 的那个切分 (j, s)。\n2. 为什么要引入树的剪枝 (Pruning)？本书采用的哪一种剪枝方式？\n原因：如果不剪枝，树会长得非常茂盛（每个叶子节点甚至只有一个样本），导致过拟合，模型极其复杂，方差极高。\n方法：代价复杂性剪枝 (Cost Complexity Pruning)，也叫最弱连接剪枝$(Weakest Link Pruning)$。\n原理：我们在最小化 RSS 的同时，对树的终端节点数量 |T| 进行惩罚。\n$\\text{Minimize } \\sum_{m=1}^{|T|} \\sum_{i \\in R_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha |T|$\n3. 代价复杂度剪枝是如何实现的？相关的系数 \\alpha 如何求解？\n\\alpha 是一个调节参数，控制树的复杂度与拟合优度之间的权衡。\n求解 \\alpha：我们无法直接算出最优的 \\alpha，而是使用 K 折交叉验证 (K-fold Cross-Validation)。选取使交叉验证误差最小的那个 \\alpha 值，然后返回对应的那棵子树。\n4. 回归树终端节点的判断条件是什么？\n对于回归树，终端节点（叶子）的预测值是该区域内所有训练观测值的平均值 (Mean)。\n分裂停止条件通常是：节点包含的观测数少于某个阈值（如 5 个），或者 RSS 下降幅度不再显著。\n5. 分类树和回归树的评价标准是什么？\n回归树：RSS (残差平方和)。\n分类树：基尼系数 (Gini Index) 或 交叉熵 (Cross-Entropy)。也可以用分类错误率，但它对树的生长不够敏感。\n6. 基尼系数的大小对分类树的影响？互熵呢？\n这两个指标都是衡量节点纯度 (Node Purity) 的。\n值越小，纯度越高。如果一个节点里的样本全属于同一类，基尼系数和熵都为 0。\n在构建树时，我们总是寻找能让基尼系数或熵下降最多的分裂点。\n第二部分：树的优缺点与对比 7. 线性回归和决策树的适用情况？\n线性回归：适用于真实边界是线性的（Linear）。\n决策树：适用于真实关系高度非线性或复杂的（Complex/Non-linear）。\n(考试技巧：如果问哪个更好，答案永远是“取决于数据特征”。)\n8. 树方法相较于传统方法的优点？\n易于解释：可视化效果好，甚至比线性回归更直观（像人类做决策的过程）。\n处理定性变量：不需要像线性回归那样先生成哑变量 (Dummy Variables)。\n可视化：可以画出漂亮的树图。\n9. 树方法相较于其他回归和分类方法的缺点是什么？\n预测准确性较低：单棵树通常打不过线性回归或样条。\n方差高 (High Variance)：这是最大的痛点。数据稍微改动一点点，生成的树可能完全不同。\n第三部分：装袋法 (Bagging) 与 随机森林 (Random Forest) 10. 装袋法实现的基本原理？定性变量如何处理呢？\n原理：Bootstrap Aggregation。利用 Bootstrap 从原数据集中有放回地抽取 B 个样本集，训练 B 棵树（不剪枝），然后取平均。\n降低方差：平均化多个独立（虽然不是完全独立）的模型可以降低方差。\n定性变量（分类问题）：对于分类，装袋法采用多数投票 (Majority Vote)——所有树中预测最多的那个类别作为最终结果。\n11. 随机森林方法的实现过程？\n随机森林是装袋法的升级版，目的是降低树之间的相关性 (Decorrelate the trees)。\n过程：在构建树的每一步分裂时，只允许从随机抽取的 m 个预测变量中选择（而不是所有 p 个）。\n通常选择$m \\approx \\sqrt{p}$。\n这强制让树彼此长得不一样，从而进一步降低方差。\n第四部分：提升法 (Boosting) 12. 应用提升法的回归树的构建过程？\nBoosting 是串行 (Sequential) 的，不是并行的。\n步骤：\n先初始化 f(x) = 0, r_i = y_i。\n拟合一棵树 $\\hat{f}^1$ 到残差 r 上（而不是 Y 上）。\n更新模型：$\\hat{f} \\leftarrow \\hat{f} + \\lambda \\hat{f}^1。$\n更新残差：$r \\leftarrow r - \\lambda \\hat{f}^1。$\n重复 B 次。\n核心思想：每棵新树都在修补上一棵树犯的错。\n13. 提升法的三个重要的调整参数？\n树的数量 (B)：Boosting 会过拟合（不像 Bagging），所以 B 不能无限大，需要通过交叉验证选择。\n收缩参数 (\\lambda, Shrinkage/Learning Rate)：控制学习速度。通常很小（0.01 或 0.001）。这意味着我们需要很多棵树来逐步逼近。\n树的深度 (d, Interaction Depth)：控制每棵树的复杂度（交互作用）。通常 d 很小（1 到 4）。如果 d=1，称为树桩 (Stump)。\n14. 提升法应用的函数是什么？\n它应用的是慢速学习 (Slow Learning) 的概念。\n通过将每一步的学习结果乘以 \\lambda，让模型一点一点地从残差中提取信息，而不是一次性拟合所有数据。这使得模型在预测时更稳健。\n第一部分：基础概念与最大间隔分类器 (MMC) 1. 超平面 (Hyperplane) 是如何定义的？\n在 $p$ 维空间中，超平面是一个 $p-1$ 维 的平坦仿射子空间。\n数学定义：满足以下方程的点 $X = (X_1, \\dots, X_p)^T$ 的集合：\n$$ \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p = 0 $$$$\n2. 对于分隔超平面，其具有哪些性质？\n它将空间一分为二。\n符号性质：\n如果观测点 $x_i$ 属于第一类 ($y_i = 1$)，则 $f(x_i) \u0026gt; 0$。\n如果观测点 $x_i$ 属于第二类 ($y_i = -1$)，则 $f(x_i) \u0026lt; 0$。\n即 $y_i \\cdot (\\beta_0 + \\beta_1 x_{i1} + \\dots) \u0026gt; 0$ 对所有观测成立。\n3. 如何构造最大分类器 (Maximal Margin Classifier)？即它的约束条件有哪些？\n目标：寻找一个超平面，使得数据点到平面的最小距离（间隔 Margin, $M$）最大化。\n优化问题：\n最大化 $M$。\n约束 1 (单位向量)：$\\sum_{j=1}^{p} \\beta_j^2 = 1$（为了确定系数的尺度）。\n约束 2 (正确分类且在间隔外)：$y_i(\\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}) \\ge M$。\n这意味着所有点不仅要在正确的一侧，而且距离超平面的距离至少为 $M$。\n第二部分：软间隔与支持向量分类器 (SVC) 4. 什么是软间隔 (Soft Margin)？\n背景：现实数据通常是线性不可分的，或者即使分开，受个别噪声点影响，最大间隔会很窄且不稳定。\n定义：我们允许部分观测点违反间隔限制（即落在间隔内部，甚至落在错误的一侧）。这被称为“软”间隔。\n引入松弛变量 (Slack Variables, $\\epsilon_i$) 来量化这种违反程度。\n5. 最大分类器和支持向量分类器 (Support Vector Classifier) 的支持向量相同吗？为什么？\n不相同。\n最大间隔分类器：支持向量仅是那些正好落在间隔边界上的点（数量通常很少）。\n支持向量分类器：支持向量包括：\n正好在间隔边界上的点。\n违反间隔的点（落在间隔内部或错误一侧的点）。\n为什么：因为 SVC 的超平面位置是由这些“难分类”的点决定的，所有违反间隔的点都会对超平面产生影响，所以它们也是支持向量。\n如何区分最大间隔分类器、支持向量分类器以及支持向量机？(核心考点) 这是一个层层递进的关系：\n最大间隔分类器 (MMC)：\n线性边界。\n硬间隔 (Hard Margin)：不允许任何错误，要求数据线性可分。\n支持向量分类器 (SVC)：\n线性边界。\n软间隔 (Soft Margin)：允许部分错误，适用于线性不可分或有噪声的数据。\n支持向量机 (SVM)：\n非线性边界。\n通过核函数 (Kernel) 扩展了 SVC。\n第三部分：支持向量机 (SVM) 与 核函数 7. 对于非线性分类情况，如何利用支持向量机进行分类？\n利用 核技巧 (Kernel Trick)。\n我们不直接在原始空间计算，而是将特征空间升维（例如引入 $X^2, X^3$），在高维空间中寻找线性超平面。\n在计算时，我们不需要真的算出高维坐标，只需计算样本间的内积 $K(x_i, x_i\u0026rsquo;)$。\n常用核函数：多项式核 (Polynomial Kernel) 和 径向基核 (Radial Kernel / RBF)。\n第四部分：多分类与参数 (Multi-class \u0026amp; Cost) 支持向量机如何处理多分类问题？ SVM 本质上是二分类器。处理多分类 ($K\u0026gt;2$) 主要有两种策略：\n一对一 (One-versus-One, OVO)。\n一对多 (One-versus-All, OVA)。\n9. 一对一、一对多分别需要多少模型参与？具体的实现过程是怎样的呢？\n一对一 (One-versus-One)：\n模型数量：$\\binom{K}{2} = \\frac{K(K-1)}{2}$ 个（两两组合）。\n过程：比如有 3 类，我们训练“1 vs 2”、“1 vs 3”、“2 vs 3”。\n预测：将新数据放入所有模型，看哪个类别得票最多。\n一对多 (One-versus-All)：\n模型数量：$K$ 个。\n过程：训练“第 1 类 vs 其他”、“第 2 类 vs 其他”\u0026hellip;\n预测：将新数据放入 $K$ 个模型，计算 $f(x)$ 的值，选取值最大（即距离超平面最远且为正）的那个类别。\n","date":"2025-11-27T21:58:42+08:00","permalink":"https://LuciusWan.github.io/p/%E9%AB%98%E7%BB%9F/","title":"高统"},{"content":"EduAgentX 项目面试话术指南 一、项目整体介绍（30秒版本） \u0026ldquo;我做的是一个智能教育管理系统 EduAgentX，核心功能包括 AI 智能题目生成、高并发抢课系统 和 RAG 知识库检索。技术栈是 Spring Boot 3 + Spring AI + Redis + RocketMQ，同时我还完成了从单体到微服务的架构演进，使用 Spring Cloud Alibaba + Dubbo + Nacos + Higress 网关。项目中我重点解决了三个技术难题：抢课系统的高并发防超卖、AI 工作流的流式输出、以及 热点数据的缓存优化。\u0026rdquo;\n零、八股文融合速查表 八股知识点 项目中的应用场景 引出话术 Redis 单线程模型 Lua 脚本原子性 \u0026ldquo;Lua 能保证原子性是因为 Redis 单线程\u0026hellip;\u0026rdquo; Redis 数据结构 Hash 存储库存/抢课状态 \u0026ldquo;我用 Hash 而不是 String，因为\u0026hellip;\u0026rdquo; Redis 持久化 抢课数据可靠性 \u0026ldquo;我配置了 AOF 持久化，防止宕机丢数据\u0026hellip;\u0026rdquo; 线程池参数 异步工作流执行 \u0026ldquo;我自定义了线程池，核心线程数设置为\u0026hellip;\u0026rdquo; CAS 与原子类 HeavyKeeper 计数器 \u0026ldquo;我用 AtomicInteger 保证计数的线程安全\u0026hellip;\u0026rdquo; ConcurrentHashMap 热点 Key 存储 \u0026ldquo;我用 ConcurrentHashMap 而不是 HashMap\u0026hellip;\u0026rdquo; 阻塞队列 消息缓冲区 \u0026ldquo;我用 ConcurrentLinkedQueue 无锁队列\u0026hellip;\u0026rdquo; AOP 原理 限流切面、性能监控 \u0026ldquo;我用 AOP 实现了限流，原理是动态代理\u0026hellip;\u0026rdquo; Spring 事务 批量写入数据库 \u0026ldquo;我用 TransactionTemplate 编程式事务\u0026hellip;\u0026rdquo; MySQL 索引 抢课记录查询优化 \u0026ldquo;我给 student_id + subject_id 建了联合索引\u0026hellip;\u0026rdquo; MySQL 锁 纯 MySQL 抢课方案 \u0026ldquo;我还实现了一版用悲观锁的方案\u0026hellip;\u0026rdquo; 消息队列 异步削峰 \u0026ldquo;我用 RocketMQ 实现异步，选它是因为\u0026hellip;\u0026rdquo; 设计模式 题目生成模块 \u0026ldquo;我用了策略模式、模板方法、工厂模式\u0026hellip;\u0026rdquo; JVM 内存模型 ThreadLocal 存储 SSE \u0026ldquo;我用 ThreadLocal 存储 Emitter，避免\u0026hellip;\u0026rdquo; 序列化 Redis 序列化配置 \u0026ldquo;我配置了 Jackson 序列化，解决了\u0026hellip;\u0026rdquo; 分布式锁 防止重复抢课 \u0026ldquo;除了 Lua，我还可以用 Redisson 分布式锁\u0026hellip;\u0026rdquo; CAP 理论 缓存一致性策略 \u0026ldquo;我选择了 AP，保证可用性，最终一致\u0026hellip;\u0026rdquo; 限流算法 滑动窗口限流 \u0026ldquo;我实现了滑动窗口限流，用 Redis ZSet\u0026hellip;\u0026rdquo; 遇到的问题与解决方式 大纲生成 1. 背景 (Situation) “这个故事发生在我们的比赛决赛夏令营期间。当时我们有机会面对面和几位行业内的专家评委交流。 专家们对我们的‘课程大纲自动生成’功能很感兴趣，但在实测后，一位专家犀利地指出了一个问题：‘你们生成的每一个字我都认识，但感觉跟上传的这个课件关系不大，像是在一本正经地胡说八道。’ 这就是典型的 RAG 幻觉问题。生成的每一章都看似专业，但其实是大模型用自己的训练数据编的，丢失了用户上传文档的特异性。”\n2. 归因分析 (Analysis) “我当时非常焦虑，回去立刻排查。 当时受限于学生服务器的算力（可能只有几核CPU，没有显卡），我们没法部署重型的 Re-rank（重排序）模型，也没法搭建 Elasticsearch 做混合检索（当时还没想到利用 Redis 的全文检索或是云端知识库）。 我们只用了最基础的向量检索（Vector Search）。 问题就出在切片上。把一份逻辑严密的教材切成碎片后，向量检索只能搜到‘关键词相似’的片段，丢失了整本书的目录结构和章节逻辑。大模型拿不到宏观结构，只能瞎编。”\n3. 解决方案 (Action) —— 专家的建议与落地 “当时专家给了一个非常巧妙的思路，我们称之为LLM 导读模式（或者叫 Map-Reduce 思想），完全避开了复杂的检索算法：\n第一步：全库浏览，提取目录（Map）。 对于几十页的文档，我们不再切片，而是让长窗口模型（Long-Context LLM）先快速通读全文，让它只做一件事：生成一份带页码的详细目录。\n第二步：让模型自主决策（Agentic Decision）。 当需要生成大纲时，我们把这份‘目录’扔给大模型，问它：‘你要写大纲，需要参考哪几部分内容？’ 大模型会根据目录判断：‘我需要第 1-5 页的简介，和第 20-25 页的核心算法。’\n第三步：精准投喂（Fetch \u0026amp; Generate）。 程序根据大模型返回的页码，直接去原始 PDF 里把这几页的完整文本提取出来，原封不动地喂给模型。 这样，模型看到的是完整的上下文，而不是破碎的片段。”\n4. 结果 (Result) “改用这个方案后，虽然我们没有增加任何硬件成本，但生成效果有了质的飞跃。大纲的每一级标题都能精确对应到文档的具体章节，幻觉率几乎降到了零。这次经历也让我明白，解决 RAG 问题不一定非要靠堆算力，**数据处理的逻辑（Workflow）**往往比模型本身更重要。”\n题目生成 背景与挑战（起头：先说遇到的尴尬） “我想讲讲我在做那个 AI 出题项目时遇到的一个的挑战。 当时项目差不多写完了，离比赛交稿还有一周左右，我们找了自己的高中老师来试用我们的项目。结果老师们的反馈让我们挺意外的。 他们说：‘你们的 AI 很严谨，生成的题目完全没有科学性错误，也没有歧义，但是太水了。’ 简单说就是，题目太简单，干扰项（错误选项）设计得太假，学生根本不用动脑子，一看就知道哪个是错的，用排除法直接就选对了。这对考察学生能力根本没用。我们当时问他们有没有切换一下难度选项，当时我们设置了3个难度等级，简单，中等，困难，他们切换了一下，结果发现结果没啥变化，还是比较简单”\n2. 归因分析（过渡：我是怎么排查的） “我当时就去扒我们的 Prompt 和工作流，发现主要有两个坑： 第一，干扰项太随意。AI 纯粹是为了凑四个选项，正确答案可能是知识库文档的内容，错误选项就是随便更改了知识库文档的一两个词语，根本没有设计什么‘思维陷阱’，甚至AI会出一些显而易见的错误来。 第二，我们给的例子（Example）不好。给大模型的参考案例太简单了，三个难度用的是同一套案例，导致AI认为案例就是对应的难度了，AI 就照葫芦画瓢，出的题也简单。\n3. 解决方案（高光：我是怎么修的——重点记这三招） “为了解决这个，我主要做了三件事：\n第一，改干扰项的逻辑。 我改了 Prompt，中等和困难题目强制要求 AI ‘站在学生的易错点上去出题’。比如故意模拟一些计算错误或者逻辑漏洞作为选项。这样学生想做对，就必须真的懂，光靠蒙是不行的。\n第二，把‘样题’升级了。 我把提示词里的参考案例全换成了那种需要深度思考的应用题，告诉大模型：‘这种有难度的题，才是我想要的’。\n第三，这也是最关键的一步，我加了个AI 质检员 先让普通模型出题，然后引入一个更厉害的模型Gemini2.5Pro当‘审核员’，以前的质检节点只是检查题目有没有问题，如果没有问题就去生成下一道或者结束任务了，现在AI会把生成题目的问题放入上下文中，然后让AI根据问题进行重新生成。直到审核通过，才会发给用户。并且还加了个兜底机制，既然普通模型（学生）教了 3 遍还不会，那就让高级模型（Gemini 2.5 Pro，老师）直接亲自上手改写，而不是只给意见了。”\n4. 结果（收尾：最后效果咋样） “改完后，老师们的态度立马变了。他们说现在的题目有嚼头了，能真正考察学生会不会用知识，而不是死记硬背。后来这种生成-审核-修改的闭环模式，也成了我们项目的一个标准做法。”\n二、核心亮点详细话术（融合八股版） 亮点一：高并发抢课系统（Redis + Lua + RocketMQ） 问题背景 \u0026ldquo;在抢课场景下，我们面临的核心问题是 高并发下的库存超卖 和 数据库压力过大。比如一门课只有100个名额，但可能有1000个学生同时点击抢课，如果处理不当就会出现超卖，或者数据库直接被打挂。\u0026rdquo;\n技术方案 \u0026ldquo;我的解决方案分三层：\n第一层：Redis + Lua 脚本保证原子性\n把课程库存预热到 Redis 的 Hash 结构中 使用 Lua 脚本实现原子性的「检查库存 → 扣减库存 → 记录抢课状态」 这样即使万级并发，也不会出现超卖 第二层：RocketMQ 异步削峰\nRedis 操作成功后，不直接写数据库，而是发送消息到 RocketMQ 消费者批量消费（每批1000条或10秒），批量写入 MySQL 这样把瞬时高并发转化为平稳的数据库写入 第三层：失败回滚机制\n如果消息发送失败，立即执行 Redis 回滚脚本 保证 Redis 和最终数据库的数据一致性\u0026rdquo; 代码亮点（可以主动提） \u0026ldquo;Lua 脚本的核心逻辑是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 -- 1. 检查是否已抢课 if redis.call(\u0026#39;HEXISTS\u0026#39;, studentSnatchKey, subjectId) == 1 then return -1 -- 已抢课 end -- 2. 检查并扣减库存（原子操作） local capacity = redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, -1) if capacity \u0026lt; 0 then redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, 1) -- 回滚 return -2 -- 库存不足 end -- 3. 记录抢课状态 redis.call(\u0026#39;HSET\u0026#39;, studentSnatchKey, subjectId, 1) return 1 -- 成功 整个过程在 Redis 单线程中执行，天然保证原子性。\u0026rdquo;\n性能数据 \u0026ldquo;优化后，抢课接口的 QPS 从原来纯 MySQL 的 500 提升到 2000+，响应时间从 200ms 降到 50ms 以内。\u0026rdquo;\n🎯 融合八股：Redis 单线程模型 面试官追问：为什么 Lua 脚本能保证原子性？\n回答：\u0026ldquo;这要从 Redis 的线程模型说起。Redis 6.0 之前是纯单线程模型，所有命令都在一个线程中串行执行。虽然 6.0 引入了 IO 多线程（处理网络读写），但命令执行仍然是单线程的。\nLua 脚本在执行期间，Redis 不会执行其他命令，相当于把多个操作打包成一个原子操作。这和数据库事务不同——数据库是通过锁来保证隔离性，而 Redis 是通过单线程串行执行来保证原子性。\n需要注意 Lua 脚本不能太长，否则会阻塞其他请求。我的脚本只有几行，执行时间在微秒级。\u0026rdquo;\n🎯 融合八股：Redis 数据结构选择 面试官追问：为什么用 Hash 存储库存，而不是 String？\n回答：\u0026ldquo;我用 Hash 有几个考虑：\n内存效率：如果用 String，每个课程一个 Key（如 capacity:1、capacity:2），会有大量的 Key 元数据开销。用 Hash（subject:capacity → {1: 100, 2: 50}），多个字段共享一个 Key 的元数据，内存更省。\n原子操作：HINCRBY 可以原子性地对某个字段加减，配合 Lua 脚本很方便。\n批量操作：HGETALL 可以一次获取所有课程的库存，方便做缓存预热。\nRedis 的 Hash 底层是 ziplist（小数据量）或 hashtable（大数据量），当字段数超过 hash-max-ziplist-entries（默认512）时会转换。我的场景课程数不多，用 ziplist 更省内存。\u0026rdquo;\n🎯 融合八股：消息队列对比 面试官追问：为什么选 RocketMQ 而不是 Kafka？\n回答：\u0026ldquo;我对比了几个主流消息队列：\n特性 RocketMQ Kafka RabbitMQ 吞吐量 10万级 百万级 万级 延迟 ms级 ms级 us级 事务消息 ✅ 支持 ❌ 不支持 ❌ 不支持 延迟消息 ✅ 支持 ❌ 不支持 ✅ 插件支持 消息回溯 ✅ 支持 ✅ 支持 ❌ 不支持 选择 RocketMQ 的原因：\n事务消息：可以保证本地事务和消息发送的一致性 延迟消息：未来可以做延迟退课提醒 消息回溯：出问题时可以重新消费历史消息 阿里生态：和 Spring Cloud Alibaba 集成更好\u0026rdquo; 🎯 融合八股：MySQL 悲观锁 vs 乐观锁 面试官追问：如果不用 Redis，纯 MySQL 怎么实现？\n回答：\u0026ldquo;我其实还实现了一版纯 MySQL 的方案，用的是悲观锁：\n1 2 3 4 -- 悲观锁：SELECT FOR UPDATE SELECT * FROM snatch_subject WHERE subject_id = ? FOR UPDATE; -- 检查库存后更新 UPDATE snatch_subject SET stock_remain = stock_remain - 1 WHERE subject_id = ?; 悲观锁 vs 乐观锁的选择：\n悲观锁：适合写多读少、冲突概率高的场景，但会阻塞其他事务 乐观锁：适合读多写少、冲突概率低的场景，通过版本号实现 抢课场景冲突概率高，所以用悲观锁更合适。但悲观锁的问题是性能差（QPS 只有 500），所以最终选择了 Redis 方案。\u0026rdquo;\n亮点二：AI 工作流引擎（LangGraph4j + SSE 流式输出） 问题背景 \u0026ldquo;AI 生成题目是一个耗时操作，可能需要 10-30 秒。如果用传统的同步请求，用户体验很差，而且容易超时。另外，题目生成涉及多个步骤：知识检索 → 任务拆分 → 题目生成 → 质量检查，需要一个灵活的工作流来编排。\u0026rdquo;\n技术方案 \u0026ldquo;我使用了 LangGraph4j 作为工作流引擎，配合 SSE（Server-Sent Events） 实现流式输出：\n工作流设计：\nRAG 知识检索节点 - 从向量数据库检索相关知识点 任务列表节点 - 根据题目数量创建生成任务队列 题目生成节点 - 调用大模型生成题目 质量检查节点 - 验证题目格式和逻辑 条件路由 - 质检不通过则重新生成，通过则继续下一题 流式输出实现：\n使用 ThreadLocal 存储 SseEmitter，避免序列化问题 工作流异步执行，每个节点完成后实时推送结果 前端通过 EventSource 监听，实时展示生成进度\u0026rdquo; 代码亮点 \u0026ldquo;条件路由的实现是这样的：\n1 2 3 4 5 6 7 .addConditionalEdges(\u0026#34;ques_parse_check_node\u0026#34;, edge_async(this::routeAfterCheck), Map.of( \\\u0026#34;continue_generate\\\u0026#34;, \\\u0026#34;ques_generate_node\\\u0026#34;, // 继续生成下一题 \\\u0026#34;retry_generate\\\u0026#34;, \\\u0026#34;ques_generate_node\\\u0026#34;, // 重新生成当前题 \\\u0026#34;finish\\\u0026#34;, END // 完成 )) 这样就实现了一个带重试机制的循环工作流。\u0026rdquo;\n设计模式应用 \u0026ldquo;在题目生成模块，我还应用了多种设计模式：\n策略模式：不同题型（选择题、填空题、大题）使用不同的生成策略 模板方法模式：题目存储流程统一，但具体存储逻辑由子类实现 工厂模式：根据题型创建对应的生成器 门面模式：AIQuestionFacade 统一对外接口\u0026rdquo; 🎯 融合八股：ThreadLocal 原理与内存泄漏 面试官追问：为什么用 ThreadLocal 存储 SseEmitter？\n回答：\u0026ldquo;因为 SseEmitter 不能序列化，不能放到工作流上下文中传递。我用 ThreadLocal 存储，每个线程有自己的副本。\n1 2 3 4 5 6 7 public static final ThreadLocal\u0026lt;SseEmitter\u0026gt; SSE_EMITTER_HOLDER = new ThreadLocal\u0026lt;\u0026gt;(); // 异步执行前设置 SSE_EMITTER_HOLDER.set(emitter); // 执行完毕后清理（重要！） SSE_EMITTER_HOLDER.remove(); ThreadLocal 原理：每个 Thread 内部有一个 ThreadLocalMap，Key 是 ThreadLocal 对象（弱引用），Value 是存储的值。\n内存泄漏问题：如果不调用 remove()，在线程池场景下，线程会被复用，ThreadLocalMap 中的 Entry 不会被清理，导致内存泄漏。所以我在 finally 块中一定会调用 remove()。\u0026rdquo;\n🎯 融合八股：线程池参数配置 面试官追问：异步执行用的什么线程池？\n回答：\u0026ldquo;我用的是 CompletableFuture.runAsync()，默认使用 ForkJoinPool.commonPool()。但在生产环境，我会自定义线程池：\n1 2 3 4 5 6 7 8 ThreadPoolExecutor executor = new ThreadPoolExecutor( 4, // 核心线程数 = CPU核心数 8, // 最大线程数 = 2 * CPU核心数 60, TimeUnit.SECONDS, // 空闲线程存活时间 new LinkedBlockingQueue\u0026lt;\u0026gt;(1000), // 有界队列，防止OOM new ThreadFactoryBuilder().setNameFormat(\\\u0026#34;ai-workflow-%d\\\u0026#34;).build(), new CallerRunsPolicy() // 拒绝策略：调用者执行 ); 参数设置原则：\nCPU 密集型：核心线程数 = CPU 核心数 IO 密集型：核心线程数 = CPU 核心数 * 2（或更多） AI 生成是 IO 密集型（等待 API 响应），所以可以设置多一些线程 拒绝策略选择：\nAbortPolicy：直接抛异常（默认） CallerRunsPolicy：调用者线程执行（我选这个，保证任务不丢失） DiscardPolicy：静默丢弃 DiscardOldestPolicy：丢弃最老的任务\u0026rdquo; 🎯 融合八股：设计模式详解 面试官追问：能详细说说策略模式怎么用的吗？\n回答：\u0026ldquo;以题目生成为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 1. 策略接口 public interface QuestionGenerator { Question generate(String knowledge, String difficulty); } // 2. 具体策略 @Component(\\\u0026#34;multipleChoice\\\u0026#34;) public class MultipleChoiceGenerator implements QuestionGenerator { ... } @Component(\\\u0026#34;fillBlank\\\u0026#34;) public class FillBlankGenerator implements QuestionGenerator { ... } // 3. 策略选择（配合 Spring 容器） @Resource private Map\u0026lt;String, QuestionGenerator\u0026gt; generatorMap; // Spring 自动注入所有实现 public Question generate(String type, String knowledge) { QuestionGenerator generator = generatorMap.get(type); return generator.generate(knowledge, difficulty); } 策略模式的好处：\n开闭原则：新增题型只需添加新的策略类，不修改原有代码 消除 if-else：避免大量的条件判断 易于测试：每个策略可以独立测试\u0026rdquo; 亮点三：热点数据缓存优化（HeavyKeeper + 二级缓存） 问题背景 \u0026ldquo;在抢课高峰期，某些热门课程会被大量访问，形成热点 Key。如果每次都访问 Redis，会造成 Redis 压力过大，响应时间从正常的 5ms 飙升到 200ms+。\u0026rdquo;\n技术方案 \u0026ldquo;我实现了一套 热点检测 + 二级缓存 的方案：\n热点检测（AsyncHeavyKeeper）：\n使用 HeavyKeeper 算法实时检测 Top K 热点 Key 核心优化：将耗时操作异步化，add() 方法耗时从 5ms 降到 \u0026lt;1ms 使用 ConcurrentLinkedQueue 无锁队列，后台线程批量处理 二级缓存架构：\nL1 缓存：Caffeine 本地缓存，容量 10000，过期时间 60 秒 L2 缓存：Redis 分布式缓存 读操作：先查 L1 → 未命中查 L2 → 写入 L1 写操作：直接写 Redis（保证一致性），不走本地缓存\u0026rdquo; 关键设计决策 \u0026ldquo;这里有一个重要的设计决策：写操作不使用本地缓存。\n原因是：抢课是写操作，需要强一致性。如果用本地缓存，在分布式环境下会出现数据不一致。比如 A 服务器的本地缓存显示还有库存，但实际 Redis 中已经没了。\n所以我的策略是：\n写操作（抢课/退课）：直接走 Redis Lua 脚本 读操作（查询库存/状态）：走二级缓存，提升性能\u0026rdquo; 🎯 融合八股：ConcurrentHashMap 原理 面试官追问：热点 Key 存储为什么用 ConcurrentHashMap？\n回答：\u0026ldquo;因为热点检测是多线程并发访问的场景。\nHashMap 的问题：\n非线程安全，多线程 put 可能导致死循环（JDK7 的头插法）或数据丢失 ConcurrentHashMap 的优势（JDK8+）：\n使用 CAS + synchronized 保证线程安全 锁粒度是单个 Node，而不是整个 Map 读操作完全无锁（volatile 保证可见性） 1 2 3 4 5 6 // 我的代码中 private final ConcurrentHashMap\u0026lt;String, AtomicInteger\u0026gt; hotKeyMap; // computeIfAbsent 是原子操作 AtomicInteger counter = hotKeyMap.computeIfAbsent(key, k -\u0026gt; new AtomicInteger(0)); counter.addAndGet(increment); // AtomicInteger 也是线程安全的 为什么不用 Hashtable？\nHashtable 用 synchronized 锁整个表，性能差 ConcurrentHashMap 锁粒度更细，并发性能更好\u0026rdquo; 🎯 融合八股：CAS 与原子类 面试官追问：AtomicInteger 怎么保证线程安全的？\n回答：\u0026ldquo;AtomicInteger 底层使用 CAS（Compare And Swap） 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // AtomicInteger.addAndGet 的底层实现 public final int addAndGet(int delta) { return U.getAndAddInt(this, VALUE, delta) + delta; } // Unsafe.getAndAddInt public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); // 读取当前值 } while (!compareAndSwapInt(o, offset, v, v + delta)); // CAS 更新 return v; } CAS 原理：比较内存值和预期值，相等则更新，不相等则重试。\nCAS 的问题：\nABA 问题：值从 A→B→A，CAS 认为没变化。解决：AtomicStampedReference（带版本号） 自旋开销：高并发时大量线程自旋，CPU 开销大 只能保证单个变量：多个变量需要用锁 在我的场景中，计数器更新冲突概率不高，CAS 很合适。\u0026rdquo;\n🎯 融合八股：阻塞队列选择 面试官追问：为什么用 ConcurrentLinkedQueue 而不是 LinkedBlockingQueue？\n回答：\u0026ldquo;两者的区别：\n特性 ConcurrentLinkedQueue LinkedBlockingQueue 实现 CAS 无锁 ReentrantLock 加锁 阻塞 非阻塞 支持阻塞 容量 无界 可设置有界 性能 高并发下更好 中等 我选择 ConcurrentLinkedQueue 的原因：\n生产者不阻塞：add() 方法要求极快返回，不能等待 高并发：无锁实现，性能更好 消费者轮询：后台线程用 poll() 非阻塞获取，配合 sleep 避免空转 如果需要阻塞等待，比如生产者-消费者模式，我会用 LinkedBlockingQueue。\u0026rdquo;\n亮点四：微服务架构演进 问题背景 \u0026ldquo;随着业务发展，单体应用出现了几个问题：\nAI 生成任务占用大量资源，影响其他业务 抢课高并发场景无法独立扩展 部署时间长，发布风险高\u0026rdquo; 技术方案 \u0026ldquo;我完成了从单体到微服务的架构演进：\n服务拆分（7个微服务）：\nUser Service - 用户认证 Course Service - 课程管理 Snatch Service - 抢课服务（独立扩展） Question Service - 题目管理 File Service - 文件存储 RAG Service - 知识库检索 AI-Workflow Service - AI 工作流（独立部署，可配 GPU） 技术选型：\n服务注册与配置：Nacos 服务间调用：Dubbo（Triple 协议，性能比 HTTP 高 10 倍） API 网关：Higress（基于 Envoy，支持 Dubbo 协议转换） 消息队列：RocketMQ 分布式事务：Seata（Saga 模式） Session 共享：Spring Session + Redis\u0026rdquo; 为什么选择 Dubbo 而不是 Feign？ \u0026ldquo;主要是性能考虑。Feign 基于 HTTP，每次调用都要经过 HTTP 协议栈，序列化/反序列化开销大。Dubbo 使用 Triple 协议（兼容 gRPC），基于 HTTP/2，支持多路复用，性能是 Feign 的 10 倍以上。\n在抢课这种高并发场景下，服务间调用的性能差异会被放大，所以选择 Dubbo 更合适。\u0026rdquo;\n🎯 融合八股：Spring 事务传播机制 面试官追问：批量写入数据库的事务怎么处理的？\n回答：\u0026ldquo;我用的是 TransactionTemplate 编程式事务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Resource private TransactionTemplate transactionTemplate; private void batchHandleSnatchEvents(List\u0026lt;SnatchEvent\u0026gt; events) { transactionTemplate.execute(status -\u0026gt; { try { // 1. 批量插入抢课记录 snatchMapper.batchInsertSnatch(snatchList); // 2. 批量更新课程容量 snatchSubjectMapper.decrementCapacityBatch(subjectId, count); return true; } catch (Exception e) { status.setRollbackOnly(); // 手动回滚 throw e; } }); } 为什么用编程式事务而不是 @Transactional？\n消费者方法不是 Spring 代理调用，@Transactional 可能失效 编程式事务更灵活，可以精确控制事务边界 事务传播机制（常问）：\nREQUIRED（默认）：有事务就加入，没有就新建 REQUIRES_NEW：总是新建事务，挂起当前事务 NESTED：嵌套事务，可以独立回滚 SUPPORTS：有事务就加入，没有就非事务执行\u0026rdquo; 🎯 融合八股：分布式事务 Seata 面试官追问：跨服务的事务怎么处理？\n回答：\u0026ldquo;我用的是 Seata 的 Saga 模式：\nSeata 的几种模式：\n模式 原理 优点 缺点 AT 自动补偿，基于 undo_log 无侵入 需要数据库支持 TCC Try-Confirm-Cancel 性能好 侵入性强，需要写三个方法 Saga 正向操作 + 补偿操作 长事务友好 最终一致性 XA 两阶段提交 强一致 性能差 我选择 Saga 的原因：\n抢课流程是长事务（Redis → MQ → MySQL） 可以接受最终一致性 补偿逻辑简单（回滚 Redis 操作） Saga 的实现：\n1 2 3 4 5 6 7 // 正向操作 redisService.decrStock(); mqService.sendMessage(); // 补偿操作（失败时调用） redisService.incrStock(); // 回滚库存 ```\u0026#34; 🎯 融合八股：CAP 理论 面试官追问：你的系统是 CP 还是 AP？\n回答：\u0026ldquo;我的系统选择了 AP（可用性 + 分区容错性），牺牲强一致性，保证最终一致性。\nCAP 理论：\nC（Consistency）：所有节点数据一致 A（Availability）：每个请求都能得到响应 P（Partition tolerance）：网络分区时系统仍能工作 分布式系统必须保证 P，所以只能在 C 和 A 之间选择。\n我的选择：\n抢课场景对可用性要求高（用户不能等太久） 可以接受最终一致性（Redis 和 MySQL 短暂不一致） 通过补偿机制保证数据最终一致 如果选择 CP：\n每次抢课都要等 MySQL 写入成功才返回 性能会很差，用户体验不好\u0026rdquo; 三、常见追问及回答 Q1: Redis 和 MySQL 数据一致性怎么保证？ \u0026ldquo;我采用的是 最终一致性 方案：\nRedis 先行：抢课操作先在 Redis 完成，保证高性能 消息队列异步同步：成功后发送 RocketMQ 消息 批量写入 MySQL：消费者批量消费，写入数据库 失败回滚：消息发送失败时，立即回滚 Redis 补偿机制：定时任务对比 Redis 和 MySQL 数据，修复不一致 这样既保证了高性能，又保证了最终数据一致。\u0026rdquo;\nQ2: 如果 RocketMQ 消息丢失怎么办？ \u0026ldquo;我做了多层保障：\n生产者确认：使用同步发送，确保消息到达 Broker 消息持久化：RocketMQ 配置同步刷盘 消费者确认：处理成功后才 ACK，失败会重试 补偿任务：定时任务扫描 Redis 中的抢课记录，对比 MySQL，补偿漏掉的数据 即使极端情况下消息丢失，补偿任务也能保证数据最终一致。\u0026rdquo;\nQ3: Lua 脚本为什么能保证原子性？ \u0026ldquo;Redis 是单线程模型，所有命令都是串行执行的。Lua 脚本在执行期间，不会被其他命令打断，相当于一个原子操作。\n这和数据库的事务不同，数据库事务是通过锁来保证隔离性，而 Redis Lua 是通过单线程串行执行来保证原子性。\n需要注意的是，Lua 脚本不能太长，否则会阻塞其他请求。我的脚本只有几行，执行时间在微秒级。\u0026rdquo;\nQ4: 为什么用 SSE 而不是 WebSocket？ \u0026ldquo;SSE 和 WebSocket 的选择取决于场景：\nSSE：单向通信（服务器 → 客户端），基于 HTTP，实现简单，自动重连 WebSocket：双向通信，需要额外的握手和心跳机制 AI 生成场景是典型的单向推送，用户发起请求后，服务器持续推送生成结果，不需要客户端再发消息。所以 SSE 更合适，实现也更简单。\u0026rdquo;\nQ5: HeavyKeeper 算法原理是什么？ \u0026ldquo;HeavyKeeper 是一种概率数据结构，用于在有限内存下找出 Top K 热点元素。\n核心思想是：\n使用多层 Bucket 数组，每层用不同的 Hash 函数 每个 Bucket 存储一个 Key 的指纹和计数 新元素到来时，如果指纹匹配则计数+1，否则以一定概率衰减原计数 衰减到 0 时，用新元素替换 这样高频元素会稳定占据 Bucket，低频元素会被逐渐淘汰。\n我的优化是把计数更新和清理操作异步化，主线程只做快速的 Bucket 更新，耗时操作放到后台线程。\u0026rdquo;\nQ6: 微服务拆分的原则是什么？ \u0026ldquo;我遵循的原则是：\n业务边界清晰：按领域划分，用户、课程、抢课各自独立 高内聚低耦合：服务内部高内聚，服务间通过接口通信 独立部署：每个服务可以独立部署和扩展 数据独立：每个服务有自己的数据库，避免跨库查询 渐进式拆分：先拆独立性高的服务（用户、文件），再拆有依赖的服务 比如抢课服务，它是高并发场景，需要独立扩展，所以单独拆出来。AI 服务是计算密集型，可能需要 GPU，也单独拆出来。\u0026rdquo;\n四、项目难点与解决方案总结 难点 问题描述 解决方案 效果 高并发超卖 1000人同时抢100个名额 Redis Lua 原子操作 零超卖 数据库压力 瞬时高并发写入 RocketMQ 异步削峰 数据库 QPS 降低 90% AI 生成超时 生成耗时 10-30 秒 SSE 流式输出 + 异步工作流 用户实时看到进度 热点 Key Redis 响应从 5ms 飙到 200ms HeavyKeeper + 二级缓存 响应稳定在 10ms 单体瓶颈 无法独立扩展 微服务拆分 抢课服务可独立扩容 五、面试加分项 1. 主动提及的技术深度 \u0026ldquo;我还研究了Redis 的 IO 多线程优化，在 Redis 6.0+ 可以配置 io-threads 提升性能\u0026rdquo; \u0026ldquo;Lua 脚本我做了优化，把多次 Redis 操作合并，减少网络往返\u0026rdquo; \u0026ldquo;消息队列我对比了 RocketMQ 和 Kafka，选择 RocketMQ 是因为它支持事务消息和延迟消息\u0026rdquo; 2. 可以展示的监控意识 \u0026ldquo;我在关键路径加了性能监控切面，记录每个方法的执行时间\u0026rdquo; \u0026ldquo;Redis 慢查询我配置了告警，超过 50ms 就会记录日志\u0026rdquo; \u0026ldquo;消息队列的消费延迟我也做了监控，防止消息堆积\u0026rdquo; 3. 可以提及的扩展思考 \u0026ldquo;如果并发量再大 10 倍，我会考虑 Redis Cluster 分片\u0026rdquo; \u0026ldquo;如果要支持秒杀场景，可以加入令牌桶限流\u0026rdquo; \u0026ldquo;未来可以考虑用 Serverless 部署 AI 服务，按需扩缩容\u0026rdquo; 六、更多八股融合场景 🎯 AOP 原理（限流切面） 项目应用：我用 AOP 实现了接口限流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Aspect @Component public class RateLimitAspect { @Around(\u0026#34;@annotation(rateLimit)\u0026#34;) public Object around(ProceedingJoinPoint point, RateLimit rateLimit) { // 滑动窗口限流（Redis ZSet 实现） Long remaining = redisTemplate.execute(RATE_LIMIT_SCRIPT, ...); if (remaining \u0026lt; 0) { throw new BusinessException(\u0026#34;操作过于频繁\u0026#34;); } return point.proceed(); } } AOP 原理：\nSpring AOP 基于动态代理实现 JDK 动态代理：目标类实现接口时使用，基于反射 CGLIB 代理：目标类没有接口时使用，基于字节码生成子类 @Around 的执行顺序：\n1 2 3 4 5 6 @Around 前置逻辑 → @Before → 目标方法 → @AfterReturning / @AfterThrowing → @Around 后置逻辑 → @After 🎯 限流算法（滑动窗口） 项目应用：我实现了滑动窗口限流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- Redis ZSet 实现滑动窗口 local key = KEYS[1] local window = ARGV[1] -- 窗口大小（秒） local limit = ARGV[2] -- 限制次数 local now = ARGV[3] -- 当前时间戳 -- 移除窗口外的请求 redis.call(\u0026#39;ZREMRANGEBYSCORE\u0026#39;, key, 0, now - window * 1000) -- 统计窗口内的请求数 local count = redis.call(\u0026#39;ZCARD\u0026#39;, key) if count \u0026lt; limit then redis.call(\u0026#39;ZADD\u0026#39;, key, now, now) -- 记录本次请求 return limit - count - 1 -- 返回剩余次数 else return -1 -- 限流 end 常见限流算法对比：\n算法 原理 优点 缺点 固定窗口 固定时间段计数 简单 临界问题（窗口边界突发） 滑动窗口 滑动时间段计数 平滑 内存占用大 漏桶 固定速率流出 平滑流量 无法应对突发 令牌桶 固定速率生成令牌 允许突发 实现复杂 我选择滑动窗口是因为它能平滑限流，避免固定窗口的临界问题。\n🎯 MySQL 索引优化 项目应用：抢课记录查询优化\n1 2 3 4 5 -- 查询某学生是否抢过某课程 SELECT * FROM snatch WHERE student_id = ? AND subject_id = ?; -- 我建了联合索引 CREATE INDEX idx_student_subject ON snatch(student_id, subject_id); 索引原理（B+ 树）：\n非叶子节点只存索引，叶子节点存数据 叶子节点用链表连接，支持范围查询 树高一般 3-4 层，查询复杂度 O(log n) 联合索引的最左前缀原则：\n(student_id, subject_id) 索引可以支持： WHERE student_id = ? ✅ WHERE student_id = ? AND subject_id = ? ✅ WHERE subject_id = ? ❌（不走索引） 索引失效场景：\n对索引列使用函数：WHERE YEAR(create_time) = 2024 隐式类型转换：WHERE student_id = '123'（student_id 是 int） LIKE 左模糊：WHERE name LIKE '%张' OR 条件：WHERE student_id = 1 OR name = '张三' 🎯 Redis 序列化问题 项目应用：我配置了两个 RedisTemplate\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 1. 通用 RedisTemplate（Jackson 序列化） @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate() { template.setValueSerializer(new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(...)); return template; } // 2. Lua 专用 RedisTemplate（String 序列化） @Bean public RedisTemplate\u0026lt;String, String\u0026gt; luaRedisTemplate() { template.setValueSerializer(new StringRedisSerializer()); return template; } 为什么要两个？\nJackson 序列化会在值前面加类型信息，Lua 脚本处理不了 Lua 脚本需要纯字符串，所以用 StringRedisSerializer 常见序列化方式：\nJdkSerializationRedisSerializer：Java 原生序列化，可读性差 StringRedisSerializer：字符串，简单但只能存字符串 Jackson2JsonRedisSerializer：JSON，可读性好，需要配置类型信息 GenericJackson2JsonRedisSerializer：JSON + 类型信息，通用性好 🎯 Spring Bean 生命周期 项目应用：消费者启动和关闭\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Component public class SnatchEventConsumer { @PostConstruct // Bean 初始化后执行 public void start() { // 启动消费线程 new Thread(this::consumeLoop).start(); } @PreDestroy // Bean 销毁前执行 public void shutdown() { // 优雅关闭：处理完剩余消息 flushBatch(); scheduler.shutdown(); } } Bean 生命周期：\n实例化（new） 属性注入（@Autowired） Aware 接口回调（BeanNameAware、ApplicationContextAware） BeanPostProcessor.postProcessBeforeInitialization @PostConstruct InitializingBean.afterPropertiesSet init-method BeanPostProcessor.postProcessAfterInitialization 使用中\u0026hellip; @PreDestroy DisposableBean.destroy destroy-method 🎯 JVM 内存模型与可见性 项目应用：后台线程的停止标志\n1 2 3 4 5 6 7 8 9 10 11 12 13 private final AtomicBoolean running = new AtomicBoolean(true); // 后台线程 private void processQueue() { while (running.get()) { // 需要保证可见性 // 处理逻辑 } } // 关闭方法 public void shutdown() { running.set(false); // 其他线程能立即看到 } 为什么用 AtomicBoolean 而不是普通 boolean？\n普通 boolean 没有可见性保证，其他线程可能看不到修改 AtomicBoolean 底层用 volatile，保证可见性 volatile 的作用：\n可见性：一个线程修改后，其他线程立即可见 禁止指令重排序：防止编译器和 CPU 优化导致的乱序 volatile 不能保证原子性：\ncount++ 不是原子操作（读-改-写） 需要原子性用 AtomicInteger 或 synchronized 七、一句话总结 \u0026ldquo;这个项目让我深入理解了 高并发系统设计（Redis + Lua + MQ）、AI 应用开发（LangGraph4j + RAG + SSE）、以及 微服务架构演进（Spring Cloud Alibaba + Dubbo）。最大的收获是学会了如何在 性能、一致性、可用性 之间做权衡。\u0026rdquo;\n八、面试话术模板 开场白 \u0026ldquo;我做的是一个智能教育管理系统，主要有三个技术亮点：高并发抢课、AI 工作流、微服务架构。您想先听哪个？\u0026rdquo;\n引出八股的过渡句 \u0026ldquo;说到这个，其实涉及到 Redis 的单线程模型\u0026hellip;\u0026rdquo; \u0026ldquo;这里我用了 ConcurrentHashMap，它的原理是\u0026hellip;\u0026rdquo; \u0026ldquo;为了保证线程安全，我用了 AtomicInteger，它底层是 CAS\u0026hellip;\u0026rdquo; \u0026ldquo;事务这块我用的是编程式事务，因为 @Transactional 有个坑\u0026hellip;\u0026rdquo; 展示深度的句式 \u0026ldquo;我还对比了几种方案\u0026hellip;\u0026rdquo; \u0026ldquo;这里有个细节需要注意\u0026hellip;\u0026rdquo; \u0026ldquo;我踩过一个坑是\u0026hellip;\u0026rdquo; \u0026ldquo;如果并发量再大 10 倍，我会考虑\u0026hellip;\u0026rdquo; 结束语 \u0026ldquo;这个项目让我对高并发和分布式有了更深的理解，也让我养成了从性能、一致性、可用性多角度思考问题的习惯。\u0026rdquo;\n九、口语化面试话术（完整版） 公式：业务背景 → 技术选型原因 → 核心难点实现（手撕逻辑） → 遇到的坑与解决 → 未来优化方向\n【话术一】高并发抢课系统 1️⃣ 业务背景（30秒） \u0026ldquo;我们这个系统有一个抢课功能，就是学生选课的时候，热门课程可能几百上千人同时抢。\n核心问题有两个：\n第一是超卖，比如课程只有100个名额，结果抢了120个人，这肯定不行 第二是数据库扛不住，如果每个请求都直接打到MySQL，瞬时1000个并发，数据库直接就挂了 所以我需要设计一个既能防超卖、又能扛住高并发的方案。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我调研了几种方案：\n方案一：纯MySQL + 悲观锁\n用 SELECT FOR UPDATE 锁住库存记录 问题是性能太差，测下来只有500 QPS，而且锁竞争严重 方案二：MySQL + 乐观锁\n用版本号控制，UPDATE ... WHERE version = ? 问题是高并发下大量重试，成功率低 方案三：Redis + Lua + 消息队列（我最终选的）\nRedis 单线程，天然防并发问题 Lua 脚本保证原子性，不会超卖 消息队列异步写数据库，削峰填谷 选 Redis 的核心原因是：它的单线程模型天然保证了操作的原子性，不需要加锁就能防止并发问题。\u0026rdquo;\n3️⃣ 核心难点实现（2分钟，可手撕） \u0026ldquo;核心就是这个 Lua 脚本，我给您讲一下逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 第一步：检查这个学生是不是已经抢过了 local hasSnatch = redis.call(\u0026#39;HEXISTS\u0026#39;, studentKey, subjectId) if hasSnatch == 1 then return -1 -- 已经抢过，直接返回 end -- 第二步：扣减库存（原子操作） local newCapacity = redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, -1) if newCapacity \u0026lt; 0 then -- 库存不够，要回滚 redis.call(\u0026#39;HINCRBY\u0026#39;, capacityKey, subjectId, 1) return -2 -- 库存不足 end -- 第三步：记录抢课状态 redis.call(\u0026#39;HSET\u0026#39;, studentKey, subjectId, 1) return 1 -- 成功 为什么能防超卖？\n关键在于 Redis 是单线程执行命令的。这个 Lua 脚本在执行期间，不会有其他命令插进来。所以「检查库存 → 扣减库存 → 记录状态」这三步是一个原子操作，不可能出现两个人同时扣减最后一个库存的情况。\n数据怎么落库？\nRedis 操作成功后，我不是直接写 MySQL，而是发一条消息到 RocketMQ。消费者那边批量消费，比如攒够1000条或者等10秒，然后批量 INSERT。这样数据库的压力就从瞬时1000 QPS 变成了平稳的每秒几十次批量写入。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;我踩过几个坑：\n坑一：Redis 序列化问题\n一开始我用 Jackson 序列化，结果 Lua 脚本执行报错。因为 Jackson 会在值前面加类型信息，Lua 处理不了。\n解决：我配了两个 RedisTemplate，一个用 Jackson 给业务用，一个用纯 String 序列化专门给 Lua 脚本用。\n坑二：消息发送失败数据不一致\nRedis 扣减成功了，但是消息发送失败了，这时候 Redis 和 MySQL 数据就不一致了。\n解决：我加了回滚机制。消息发送失败时，立即执行一个回滚的 Lua 脚本，把库存加回去，把抢课状态删掉。\n坑三：热点 Key 导致 Redis 响应变慢\n压测的时候发现，热门课程的 Key 被大量访问，Redis 响应时间从5ms飙到200ms。\n解决：我实现了一个热点检测 + 本地缓存的方案。用 HeavyKeeper 算法检测热点 Key，检测到之后把数据缓存到本地 Caffeine，减少 Redis 访问。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;如果并发量再大10倍，我会考虑：\nRedis Cluster 分片：把不同课程的库存分散到不同节点，避免单点瓶颈 令牌桶预热：抢课开始前，先发放令牌，没有令牌的请求直接拒绝，减少无效请求 本地预扣减：在应用层先做一次本地库存预扣减，过滤掉大部分请求，只有预扣减成功的才去访问 Redis\u0026rdquo; 【话术二】AI 智能题目生成 1️⃣ 业务背景（30秒） \u0026ldquo;我们系统有一个 AI 出题功能，老师输入知识点和题目数量，系统自动生成选择题、填空题、大题。\n核心问题：\nAI 生成很慢，一道题可能要5-10秒，生成10道题就要1-2分钟 如果用传统的同步请求，用户要等很久，体验很差，而且容易超时 生成的题目质量参差不齐，需要有质检和重试机制\u0026rdquo; 2️⃣ 技术选型原因（1分钟） \u0026ldquo;我选了 LangGraph4j + SSE 流式输出 的方案：\n为什么用 LangGraph4j？\n它是一个工作流引擎，可以把复杂的 AI 任务拆成多个节点 支持条件路由，比如质检不通过可以自动重试 节点之间可以传递上下文，方便管理状态 为什么用 SSE 而不是 WebSocket？\nSSE 是单向通信，服务器推送给客户端，正好符合我的场景 基于 HTTP，实现简单，不需要额外的握手和心跳 自动重连，断了会自己连回来 为什么不用轮询？\n轮询会产生大量无效请求 实时性差，用户体验不好\u0026rdquo; 3️⃣ 核心难点实现（2分钟） \u0026ldquo;我设计了一个四节点的工作流：\n1 2 3 开始 → RAG知识检索 → 任务拆分 → 题目生成 → 质量检查 → 结束 ↑ ↓ ←← 重试 ←←← 节点一：RAG 知识检索\n根据老师输入的知识点，从向量数据库检索相关的教学文档 这样生成的题目更贴合教材内容 节点二：任务拆分\n把「生成10道选择题」拆成10个独立的任务 每个任务生成一道题 节点三：题目生成\n调用大模型，传入知识点和检索到的文档 生成题目、选项、答案、解析 节点四：质量检查\n检查 JSON 格式是否正确 检查选项数量是否符合要求 检查答案是否在选项中 条件路由的实现：\n1 2 3 4 5 6 7 .addConditionalEdges(\u0026#34;质检节点\u0026#34;, edge_async(this::routeAfterCheck), Map.of( \u0026#34;continue\u0026#34;, \u0026#34;生成节点\u0026#34;, // 质检通过，继续下一题 \u0026#34;retry\u0026#34;, \u0026#34;生成节点\u0026#34;, // 质检失败，重新生成 \u0026#34;finish\u0026#34;, END // 全部完成 )) SSE 流式输出：\n每生成一道题，就立即推送给前端，用户可以实时看到进度。我用 ThreadLocal 存储 SseEmitter，避免序列化问题。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：ThreadLocal 内存泄漏\n一开始我忘了清理 ThreadLocal，结果在线程池场景下，线程被复用，ThreadLocal 里的对象一直不释放，内存越来越大。\n解决：在 finally 块里一定要调用 remove()。\n坑二：异步线程拿不到 ThreadLocal\n工作流是异步执行的，但是异步线程和主线程不是同一个，拿不到主线程的 ThreadLocal。\n解决：在异步任务开始时，重新 set 一次 SseEmitter。\n坑三：大模型返回格式不稳定\n有时候大模型返回的 JSON 格式不对，解析失败。\n解决：我在 prompt 里加了严格的格式要求，并且在质检节点做了格式校验，不通过就重试，最多重试3次。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 并行生成：现在是串行生成10道题，可以改成并行，开10个线程同时生成 2. 缓存相似题目：如果知识点相似，可以从缓存里取，不用每次都调大模型 3. 模型微调：用我们自己的题库数据微调模型，提高生成质量\u0026rdquo;\n【话术三】微服务架构演进 1️⃣ 业务背景（30秒） \u0026ldquo;项目一开始是单体架构，后来遇到了几个问题：\n资源竞争：AI 生成任务很吃 CPU 和内存，一跑起来其他接口都变慢了 无法独立扩展：抢课高峰期，只有抢课模块需要扩容，但单体架构只能整体扩容，浪费资源 发布风险高：改一行代码要重新部署整个应用，万一出问题影响所有功能 所以我决定做微服务拆分。\u0026rdquo;\n2️⃣ 技术选型原因（1分钟） \u0026ldquo;我选的是 Spring Cloud Alibaba + Dubbo + Nacos + Higress 这套：\n为什么选 Dubbo 而不是 Feign？\nFeign 基于 HTTP，每次调用都要经过完整的 HTTP 协议栈，开销大 Dubbo 用的是 Triple 协议，基于 HTTP/2，支持多路复用，性能是 Feign 的10倍 在抢课这种高并发场景，服务间调用的性能差异会被放大 为什么选 Nacos？\n同时支持服务注册和配置中心，不用部署两套 和 Spring Cloud Alibaba 生态集成好 性能比 Eureka 和 Consul 都好 为什么选 Higress 网关？\n基于 Envoy，性能很高 原生支持 Dubbo 协议转换，外部 HTTP 请求可以直接转成 Dubbo 调用 和 Nacos 无缝集成\u0026rdquo; 3️⃣ 核心难点实现（1分钟） \u0026ldquo;我拆成了7个服务：\n服务 职责 为什么单独拆 User 用户认证 基础服务，被所有服务依赖 Course 课程管理 业务独立 Snatch 抢课 高并发，需要独立扩展 Question 题目管理 业务独立 File 文件存储 IO 密集，独立部署 RAG 知识库检索 向量计算，资源隔离 AI-Workflow AI 工作流 CPU 密集，可能要 GPU 服务间调用：用 Dubbo RPC，定义了统一的接口模块 EduAgentX-Client，所有服务都依赖它。\nSession 共享：用 Spring Session + Redis，所有服务共享同一个 Session 存储。\u0026rdquo;\n4️⃣ 遇到的坑与解决（1分钟） \u0026ldquo;坑一：循环依赖\nCourse 服务要调用 User 服务获取教师信息，User 服务又要调用 Course 服务获取用户的课程列表，形成了循环依赖。\n解决：重新梳理服务边界，把「用户的课程列表」这个功能放到 Course 服务，User 服务只负责用户基本信息。\n坑二：分布式事务\n抢课成功后要同时更新 Redis、发消息、写数据库，跨了多个服务。\n解决：用 Seata 的 Saga 模式，定义正向操作和补偿操作。失败时自动执行补偿，保证最终一致性。\n坑三：服务调用超时\nAI 服务生成题目很慢，默认的 Dubbo 超时时间是3秒，经常超时。\n解决：针对 AI 服务单独配置超时时间为60秒，其他服务保持3秒。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 服务网格：引入 Istio，把服务治理下沉到基础设施层 2. 容器化：用 Kubernetes 部署，实现自动扩缩容 3. Serverless：AI 服务可以用 Serverless 部署，按调用量付费，降低成本\u0026rdquo;\n【话术四】热点缓存优化 1️⃣ 业务背景（30秒） \u0026ldquo;压测的时候发现一个问题：热门课程被大量访问，Redis 响应时间从正常的5ms飙升到200ms，严重影响了抢课接口的性能。\n分析原因是：所有请求都打到 Redis 的同一个 Key 上，形成了热点 Key，Redis 单线程处理不过来。\u0026rdquo;\n2️⃣ 技术选型原因（30秒） \u0026ldquo;我的方案是 热点检测 + 本地缓存：\n用 HeavyKeeper 算法 实时检测哪些 Key 是热点 检测到热点后，把数据缓存到本地 Caffeine 后续请求先查本地缓存，命中就不用访问 Redis 了 为什么用 HeavyKeeper？因为它是概率数据结构，内存占用小，可以在有限内存下找出 Top K 热点元素。\u0026rdquo;\n3️⃣ 核心难点实现（1分钟） \u0026ldquo;HeavyKeeper 的原理是：\n维护一个多层的 Bucket 数组 每个 Bucket 存一个 Key 的指纹和计数 新请求来了，如果指纹匹配就计数+1 如果不匹配，以一定概率衰减原来的计数 衰减到0就用新 Key 替换 我做的优化：\n原始实现的 add() 方法要5ms，太慢了。我改成了异步版本：\n1 2 3 4 5 6 7 8 9 10 11 public AddResult add(String key, int increment) { // 1. 快速更新 Bucket（分段锁，\u0026lt;1ms） int maxCount = updateBuckets(key, increment); // 2. 如果是热点，放入队列（不阻塞） if (maxCount \u0026gt;= threshold) { updateQueue.offer(new UpdateTask(key, maxCount)); } return result; } 耗时操作（清理过期数据、统计 Top K）都放到后台线程异步处理，主线程只做快速的计数更新。优化后 add() 耗时从5ms降到了0.1ms。\u0026rdquo;\n4️⃣ 遇到的坑与解决（30秒） \u0026ldquo;坑：本地缓存数据不一致\n本地缓存和 Redis 数据可能不一致，比如 A 服务器的本地缓存显示还有库存，但 Redis 里已经没了。\n解决：我的策略是写操作不走本地缓存。抢课、退课这种写操作，直接走 Redis Lua 脚本。本地缓存只用于读操作（查询库存、查询状态），而且设置了60秒过期时间，保证最终一致性。\u0026rdquo;\n5️⃣ 未来优化方向（30秒） \u0026ldquo;1. 多级缓存：可以再加一层进程内缓存，形成 L1（进程内）→ L2（本地 Caffeine）→ L3（Redis）的三级缓存 2. 缓存预热：抢课开始前，提前把热门课程的数据加载到本地缓存 3. Redis Cluster：如果热点 Key 太多，可以用 Redis Cluster 分散到多个节点\u0026rdquo;\n十、万能应对话术 当面试官问「还有什么要补充的吗」 \u0026ldquo;我想补充一点，这个项目让我最大的收获不是学会了某个技术，而是学会了怎么做技术选型。\n比如抢课系统，我一开始想用分布式锁，后来发现 Lua 脚本更简单高效；消息队列我对比了 Kafka 和 RocketMQ，最后选了 RocketMQ 因为它支持事务消息。\n我觉得做技术选型最重要的是理解每个方案的优缺点和适用场景，而不是盲目追求新技术。\u0026rdquo;\n当面试官问「这个项目有什么不足」 \u0026ldquo;有几个地方我觉得可以做得更好：\n监控不够完善：目前只有基础的日志，缺少完整的链路追踪和性能监控大盘 测试覆盖率不够：单元测试写得比较少，主要靠手工测试 文档不够完善：接口文档有，但是架构设计文档和运维文档比较欠缺 如果有机会重新做，我会在项目初期就把这些基础设施搭建好。\u0026rdquo;\n当面试官问「你在团队中的角色」 \u0026ldquo;我是这个项目的主要开发者，负责核心模块的设计和实现：\n抢课系统的高并发方案是我设计的 AI 工作流引擎是我从零搭建的 微服务拆分的架构设计也是我主导的 遇到技术难题时，我会先自己调研，然后和团队讨论，最后形成方案文档，评审通过后再实施。\u0026rdquo;\n当面试官深挖某个技术细节你不太确定时 \u0026ldquo;这个细节我不太确定，但是我的理解是\u0026hellip;（说你的理解）。回去之后我会再深入研究一下，确认一下是不是这样。\u0026rdquo;\n千万不要：\n瞎编一个答案 说「我不知道」然后沉默 十一、面试前 Checklist 必须能脱口而出的 项目30秒介绍 三个核心亮点的业务背景 Lua 脚本的核心逻辑（能手写） 为什么选 Redis 不选 MySQL 为什么选 RocketMQ 不选 Kafka 为什么选 Dubbo 不选 Feign ThreadLocal 内存泄漏怎么解决 分布式事务用的什么方案 最好能说清楚的 Redis 单线程模型 ConcurrentHashMap 原理 线程池参数怎么配置 AOP 的实现原理 Spring 事务传播机制 CAP 理论，你的系统是 CP 还是 AP 加分项 性能优化的具体数据（QPS 从多少到多少） 踩过的坑和解决方案 未来的优化方向 对比过哪些技术方案 EduAgentX 项目面试问答文档 本文档针对EduAgentX智能教育平台项目，整理了面试中可能被深入追问的技术细节，帮助你应对二面技术拷问。\n目录 一、Redis技术细节 二、微服务架构 三、高并发抢课系统 四、AI工作流系统 五、数据库与ORM 六、安全与认证 七、RocketMQ消息队列 八、阿里云OSS文件存储 九、上线运维 十、异常处理与全局响应 十一、技术栈选型 一、Redis技术细节 1.1 Redis序列化方式 Q: 你的项目中Redis使用了什么序列化方式？为什么这样选择？\nA: 项目中配置了两个RedisTemplate，使用不同的序列化策略：\n通用RedisTemplate - 使用Jackson2JsonRedisSerializer序列化Value Lua脚本专用RedisTemplate - 使用StringRedisSerializer全字符串序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(connectionFactory); // 使用 Jackson2JsonRedisSerializer 序列化值 ObjectMapper objectMapper = new ObjectMapper(); objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; serializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(objectMapper, Object.class); // Key 使用 String 序列化 template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(serializer); template.setHashKeySerializer(new StringRedisSerializer()); template.setHashValueSerializer(serializer); return template; } @Bean public RedisTemplate\u0026lt;String, String\u0026gt; luaRedisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate\u0026lt;String, String\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(connectionFactory); // 全部使用 String 序列化，用于Lua脚本 StringRedisSerializer stringSerializer = new StringRedisSerializer(); template.setKeySerializer(stringSerializer); template.setValueSerializer(stringSerializer); template.setHashKeySerializer(stringSerializer); template.setHashValueSerializer(stringSerializer); return template; } } 选择原因：\nJackson2JsonRedisSerializer: 支持复杂对象序列化，可读性好，便于调试 StringRedisSerializer: Lua脚本中需要纯字符串操作，避免JSON前缀导致的类型转换问题 Key统一用String: 避免Key带有序列化前缀，便于在Redis客户端直接查看 深入追问：\nQ: 为什么不用JDK序列化？ A: JDK序列化存在以下问题：\n序列化后的数据包含类信息，体积大 可读性差，无法在Redis客户端直接查看 存在安全漏洞（反序列化攻击） 跨语言兼容性差 Q: activateDefaultTyping的作用是什么？ A: 启用类型信息记录，序列化时会在JSON中包含@class字段，反序列化时能正确还原对象类型。这对于存储多态对象很重要。\n1.2 Lua脚本原子操作 Q: 抢课系统中的Lua脚本是怎么设计的？如何保证原子性？\nA: 抢课使用Lua脚本实现原子性操作，一次网络往返完成：检查→扣减→记录。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public static final RedisScript\u0026lt;Long\u0026gt; SNATCH_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(\u0026#34;\u0026#34;\u0026#34; local tempSnatchKey = KEYS[1] local studentSnatchKey = KEYS[2] local subjectCapacityKey = KEYS[3] local studentId = ARGV[1] local subjectId = ARGV[2] -- 1. 检查是否已抢课 local hasSnatch = redis.call(\u0026#39;HEXISTS\u0026#39;, studentSnatchKey, subjectId) if hasSnatch == 1 then return -1 -- 已抢课 end -- 2. 原子性扣减库存 local newCapacity = redis.call(\u0026#39;HINCRBY\u0026#39;, subjectCapacityKey, subjectId, -1) if newCapacity \u0026lt; 0 then redis.call(\u0026#39;HINCRBY\u0026#39;, subjectCapacityKey, subjectId, 1) -- 回滚 return -2 -- 库存不足 end -- 3. 批量写入 local hashKey = studentId .. \u0026#39;:\u0026#39; .. subjectId redis.call(\u0026#39;HINCRBY\u0026#39;, tempSnatchKey, hashKey, 1) redis.call(\u0026#39;HSET\u0026#39;, studentSnatchKey, subjectId, 1) return 1 -- 成功 \u0026#34;\u0026#34;\u0026#34;, Long.class); 原子性保证机制：\nRedis单线程执行: Lua脚本在Redis中原子执行，不会被其他命令打断 HINCRBY原子操作: 扣减库存使用原子递减，避免超卖 失败回滚: 库存不足时立即回滚，保证数据一致性 返回值设计：\n-1: 已抢课，不能重复抢 -2: 课程容量不足 1: 抢课成功 深入追问：\nQ: 为什么用HINCRBY而不是先HGET再HSET？ A: 在Lua脚本内部，两者的原子性是等价的（因为整个Lua脚本本身就是原子执行的）。选择HINCRBY的原因是：\n代码简洁：一条命令完成读取+计算+写入 避免类型转换：HGET返回字符串，需要tonumber()转换后再计算，HINCRBY直接操作数值 直接返回新值：HINCRBY返回操作后的新值，方便判断库存是否为负 Q: 那HINCRBY的原子性优势体现在哪里？ A: 如果不用Lua脚本，而是在Java代码中分别调用HGET和HSET，那就会有并发问题。HINCRBY的原子性优势体现在单独使用时，而不是在Lua脚本内部。\nQ: Lua脚本有什么限制？ A:\n不能使用随机函数（影响主从复制） 执行时间不宜过长（阻塞其他请求） 所有Key必须在同一个Redis节点（集群模式需要用Hash Tag） 1.3 多级缓存架构 Q: 项目中的多级缓存是怎么设计的？\nA: 采用 Caffeine本地缓存 + Redis分布式缓存 的两级架构：\n1 2 3 4 5 6 7 8 9 10 11 @Component public class CacheManager { @Bean public Cache\u0026lt;String, Object\u0026gt; localCache() { return Caffeine.newBuilder() .maximumSize(10000) // 最大缓存10000条 .expireAfterWrite(60, TimeUnit.SECONDS) // 60秒过期 .recordStats() // 启用统计 .build(); } } 缓存查询流程：\n1 2 请求 → 本地缓存(Caffeine) → Redis → 数据库 ↑ 命中返回 ↑ 命中返回 ↑ 查询并缓存 实际使用代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public Integer getSubjectCapacityWithCache(Long subjectId) { String cacheKey = \u0026#34;capacity:\u0026#34; + subjectId; // 1. 先查本地缓存 Object cached = localCache.getIfPresent(cacheKey); if (cached != null) { return (Integer) cached; } // 2. 查询Redis Object capacityObj = luaRedisTemplate.opsForHash() .get(capacityKey, subjectId.toString()); // 3. 热Key检测，决定是否缓存到本地 AddResult addResult = hotKeyDetector.add(buildCacheKey(subjectId), 1); if (addResult.isHotKey()) { localCache.put(cacheKey, capacityValue); } return capacityValue; } 深入追问：\nQ: 本地缓存和Redis缓存的数据一致性怎么保证？ A:\n本地缓存设置较短过期时间（60秒） 写操作时主动失效本地缓存 对于强一致性场景，直接查Redis Q: 为什么选择Caffeine而不是Guava Cache？ A: Caffeine是Guava Cache的升级版，性能更好：\n使用Window TinyLFU淘汰算法，命中率更高 异步加载支持更好 统计功能更完善 1.4 HeavyKeeper热Key检测 Q: 热Key检测是怎么实现的？\nA: 使用HeavyKeeper算法实现热Key检测，这是一种概率数据结构，能在有限内存下高效识别高频访问的Key。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public class HeavyKeeper implements TopK { private final int k; // Top K private final int width; // 桶宽度 private final int depth; // 桶深度 private final double[] lookupTable; // 衰减查找表 private final Bucket[][] buckets; // 计数桶 private final PriorityQueue\u0026lt;Node\u0026gt; minHeap; // 最小堆维护TopK public HeavyKeeper(int k, int width, int depth, double decay, int minCount) { this.k = k; // 监控Top 100 this.width = width; // 100000 this.depth = depth; // 5 this.minCount = minCount; // 最小出现3次 // 预计算衰减表 for (int i = 0; i \u0026lt; 256; i++) { lookupTable[i] = Math.pow(decay, i); } } @Override public AddResult add(String key, int increment) { // 1. 计算指纹 long itemFingerprint = hash(key.getBytes()); int maxCount = 0; // 2. 更新多层桶 for (int i = 0; i \u0026lt; depth; i++) { int bucketNumber = Math.abs(hash(key.getBytes())) % width; Bucket bucket = buckets[i][bucketNumber]; synchronized (bucket) { if (bucket.fingerprint == itemFingerprint) { bucket.count += increment; maxCount = Math.max(maxCount, bucket.count); } else { // 概率衰减 double decay = lookupTable[Math.min(bucket.count, 255)]; if (random.nextDouble() \u0026lt; decay) { bucket.count--; if (bucket.count == 0) { bucket.fingerprint = itemFingerprint; bucket.count = increment; } } } } } // 3. 更新TopK堆 // ... return new AddResult(expelled, isHot, key); } } 配置参数：\n1 2 3 4 5 6 7 hotKeyDetector = new HeavyKeeper( 100, // 监控Top 100 Key 100000, // 宽度 5, // 深度 0.92, // 衰减系数 3 // 最小出现3次才记录 ); 深入追问：\nQ: HeavyKeeper相比Count-Min Sketch有什么优势？ A:\nCount-Min Sketch只能估计频率，不能直接获取TopK HeavyKeeper结合了Count-Min Sketch和Space-Saving算法 内存效率更高，误差更小 Q: 为什么需要定时fading？ A: 防止历史热Key长期占据TopK位置，通过定期衰减让新的热Key有机会进入。\n二、微服务架构 2.1 Dubbo配置与调用 Q: 项目中Dubbo是怎么配置的？用的什么协议？\nA: 使用Apache Dubbo 3.x，配置Triple协议 + Nacos注册中心：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # application.yml dubbo: registry: address: nacos://127.0.0.1:8848?username=nacos\u0026amp;password=nacos register-mode: instance protocol: name: tri # Triple协议（基于gRPC） port: 50052 consumer: timeout: 60000 # 60秒超时 check: false # 启动时不检查服务提供者 retries: 2 # 失败重试2次 provider: timeout: 60000 application: qos-port: 22222 metadata-type: remote metadata-report: address: nacos://127.0.0.1:8848?username=nacos\u0026amp;password=nacos Triple协议选择原因：\n基于HTTP/2，支持流式传输 兼容gRPC，跨语言调用更方便 性能优于传统Dubbo协议 支持应用级服务发现 深入追问：\nQ: check: false是什么意思？ A: 启动时不检查服务提供者是否存在。在微服务场景下，服务可能还没启动完成，设置false避免启动失败。\nQ: retries: 2会不会导致重复请求？ A: 会的，所以对于非幂等接口（如抢课），需要在业务层做幂等处理，比如先检查是否已抢课，或者查询信息（幂等性的信息适合使用重复请求）。\n在代码中通过注解对“查询接口”单独开启：\n1 2 3 // 只有查询接口，才手动指定重试次数 @DubboReference(retries = 2, timeout = 3000) private UserQueryService userQueryService; 2.2 服务拆分策略 Q: 项目拆分成了哪些微服务？拆分原则是什么？\nA: 项目按业务领域拆分为以下微服务：\n1 2 3 4 5 6 7 8 9 10 11 EduAgentX-MicroService/ ├── EduAgentX-User # 用户服务 (端口8124) ├── EduAgentX-Course # 课程服务 (端口8125) ├── EduAgentX-Question # 题目服务 (端口8126) ├── EduAgentX-Snatch # 抢课服务 (端口8127) ├── EduAgentX-File # 文件服务 (端口8128) ├── EduAgentX-RagService # RAG服务 (端口8129) ├── EduAgentX-AI-Workflow # AI工作流服务 (端口8130) ├── EduAgentX-Client # 内部调用接口定义 ├── EduAgentX-Common # 公共模块 └── EduAgentX-Model # 数据模型 拆分原则：\n单一职责: 每个服务只负责一个业务领域 高内聚低耦合: 服务内部高度内聚，服务间通过接口通信 独立部署: 每个服务可以独立部署、扩容 数据隔离: 每个服务有自己的数据库表（逻辑隔离） 深入追问：\nQ: 为什么抢课服务要单独拆出来？ A: 抢课是高并发场景，需要独立扩容。拆分后可以：\n单独优化Redis连接池 独立限流配置 不影响其他服务稳定性 2.3 跨服务调用设计 Q: 微服务之间是怎么调用的？\nA: 通过定义InnerService接口 + @DubboService实现：\n接口定义（EduAgentX-Client模块）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public interface InnerUserService { List\u0026lt;User\u0026gt; listByIds(Collection\u0026lt;? extends Serializable\u0026gt; ids); User getById(Serializable id); UserVO getUserVO(User user); // 静态方法，避免跨服务调用 static User getLoginUser(HttpServletRequest request) { Object userObj = request.getSession().getAttribute(USER_LOGIN_STATE); User currentUser = (User) userObj; if (currentUser == null || currentUser.getId() == null) { throw new BusinessException(ErrorCode.NOT_LOGIN_ERROR); } return currentUser; } } 服务实现（EduAgentX-Snatch模块）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @DubboService public class InnerSnatchSubjectServiceImpl implements InnerSnatchSubjectService { @Resource private SnatchSubjectService snatchSubjectService; @Override public void initSubjectCapacityToRedis(Long subjectId) { snatchSubjectService.initSubjectCapacityToRedis(subjectId); } @Override public SnatchSubject getBySubjectId(Long subjectId) { return snatchSubjectService.getBySubjectId(subjectId); } } 调用方使用：\n1 2 3 4 5 6 @DubboReference private InnerUserService innerUserService; public void someMethod() { User user = innerUserService.getById(userId); } 深入追问：\nQ: 为什么getLoginUser用静态方法？ A: 获取登录用户需要HttpServletRequest，这个对象无法跨服务传递。使用静态方法在本地从Session获取，避免RPC调用。\n2.4 分布式Session Q: 微服务之间Session是怎么共享的？\nA: 使用Spring Session + Redis实现分布式Session：\n1 2 3 4 5 6 spring: session: store-type: redis timeout: 2880m # 48小时 redis: namespace: spring:session 工作原理：\n用户登录后，Session存储到Redis 所有微服务连接同一个Redis 请求携带JSESSIONID，从Redis获取Session Session存储结构：\n1 2 3 4 5 spring:session:sessions:{sessionId} ├── creationTime ├── lastAccessedTime ├── maxInactiveInterval └── sessionAttr:USER_LOGIN_STATE # 用户登录信息 深入追问：\nQ: Session过期时间为什么设置48小时？ A: 教育场景下用户可能长时间使用，设置较长过期时间提升体验。同时Redis会自动清理过期Session。\nQ: 如果Redis挂了怎么办？ A:\n短期：用户需要重新登录 长期：可以考虑Redis集群或哨兵模式保证高可用 2.5 Dubbo底层原理深入 Q: Dubbo的服务调用过程是怎样的？从发起调用到收到响应经历了哪些步骤？\nA: 完整的调用链路如下：\n1 2 3 4 5 Consumer端: 1. Proxy代理 → 2. Filter链 → 3. Invoker → 4. Directory → 5. Router → 6. LoadBalance → 7. Invoker → 8. Protocol → 9. Exchanger → 10. Transporter(Netty) Provider端: 1. Transporter(Netty) → 2. Exchanger → 3. Protocol → 4. Filter链 → 5. Invoker → 6. 实际服务实现 详细流程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 1. 代理层：生成代理对象 UserService proxy = Proxy.getProxy(UserService.class); // 2. 调用时，代理对象调用InvokerInvocationHandler public Object invoke(Object proxy, Method method, Object[] args) { // 3. 构建RpcInvocation RpcInvocation invocation = new RpcInvocation(method, args); // 4. 通过Directory获取所有可用Invoker List\u0026lt;Invoker\u0026gt; invokers = directory.list(invocation); // 5. Router过滤（标签路由、条件路由等） invokers = router.route(invokers, invocation); // 6. LoadBalance选择一个Invoker Invoker invoker = loadBalance.select(invokers, invocation); // 7. 发起远程调用 Result result = invoker.invoke(invocation); return result.getValue(); } Q: Dubbo的Invoker是什么？为什么说它是核心模型？\nA: Invoker是Dubbo的核心抽象，代表一个可执行体：\n1 2 3 4 5 public interface Invoker\u0026lt;T\u0026gt; { Class\u0026lt;T\u0026gt; getInterface(); // 服务接口 URL getUrl(); // 服务地址 Result invoke(Invocation invocation); // 执行调用 } Invoker的类型：\n本地Invoker：直接调用本地实现 远程Invoker：封装了网络通信逻辑 集群Invoker：封装了负载均衡、容错逻辑 为什么是核心：\n统一了本地调用和远程调用的抽象 所有的Filter、Router、LoadBalance都围绕Invoker工作 服务暴露和引用的最终产物都是Invoker Q: Dubbo的Filter机制是怎样的？如何自定义Filter？\nA: Filter是Dubbo的拦截器机制，类似于Servlet Filter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 自定义Filter示例 @Activate(group = {CommonConstants.CONSUMER, CommonConstants.PROVIDER}) public class LogFilter implements Filter { @Override public Result invoke(Invoker\u0026lt;?\u0026gt; invoker, Invocation invocation) throws RpcException { long startTime = System.currentTimeMillis(); String methodName = invocation.getMethodName(); try { // 前置处理 log.info(\u0026#34;调用方法: {}\u0026#34;, methodName); // 执行调用 Result result = invoker.invoke(invocation); // 后置处理 long cost = System.currentTimeMillis() - startTime; log.info(\u0026#34;方法 {} 耗时: {}ms\u0026#34;, methodName, cost); return result; } catch (Exception e) { log.error(\u0026#34;调用异常: {}\u0026#34;, e.getMessage()); throw e; } } } 配置文件（META-INF/dubbo/org.apache.dubbo.rpc.Filter）：\n1 logFilter=com.lucius.eduAgentX.filter.LogFilter 内置Filter：\nConsumerContextFilter：设置调用上下文 FutureFilter：处理异步调用 MonitorFilter：监控统计 TimeoutFilter：超时处理 ExceptionFilter：异常处理 Q: Dubbo的Directory和Router有什么区别？\nA:\nDirectory（服务目录）：\n存储所有可用的服务提供者列表 监听注册中心变化，动态更新列表 类似于\u0026quot;电话簿\u0026rdquo; 1 2 3 public interface Directory\u0026lt;T\u0026gt; { List\u0026lt;Invoker\u0026lt;T\u0026gt;\u0026gt; list(Invocation invocation); // 获取所有Invoker } Router（路由器）：\n对Directory返回的列表进行过滤 实现条件路由、标签路由等 类似于\u0026quot;筛选器\u0026quot; 1 2 3 public interface Router { List\u0026lt;Invoker\u0026lt;?\u0026gt;\u0026gt; route(List\u0026lt;Invoker\u0026lt;?\u0026gt;\u0026gt; invokers, Invocation invocation); } 路由规则示例：\n1 2 3 4 5 6 7 8 # 条件路由：北京机房的消费者只调用北京机房的提供者 conditions: - \u0026#34;host = 192.168.1.* =\u0026gt; host = 192.168.1.*\u0026#34; # 标签路由：灰度发布 tags: - name: gray addresses: [192.168.1.100, 192.168.1.101] Q: Dubbo的服务暴露过程是怎样的？\nA: 服务暴露的核心流程：\n1 2 @DubboService注解 → ServiceBean → ServiceConfig.export() → Protocol.export() → 启动Server → 注册到注册中心 详细步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 1. Spring扫描@DubboService注解，创建ServiceBean @DubboService public class UserServiceImpl implements UserService { } // 2. ServiceConfig.export() public void export() { // 2.1 检查配置 checkAndUpdateSubConfigs(); // 2.2 构建URL URL url = new URL(protocol, host, port, path, parameters); // 2.3 通过Protocol暴露服务 Exporter\u0026lt;?\u0026gt; exporter = protocol.export(invoker); // 2.4 注册到注册中心 registry.register(url); } // 3. Protocol.export() - 以Triple协议为例 public \u0026lt;T\u0026gt; Exporter\u0026lt;T\u0026gt; export(Invoker\u0026lt;T\u0026gt; invoker) { // 启动HTTP/2 Server openServer(url); return new TripleExporter\u0026lt;\u0026gt;(invoker); } Q: Dubbo的服务引用过程是怎样的？\nA: 服务引用的核心流程：\n1 2 @DubboReference注解 → ReferenceBean → ReferenceConfig.get() → Protocol.refer() → 创建代理对象 详细步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 1. Spring扫描@DubboReference注解 @DubboReference private UserService userService; // 2. ReferenceConfig.get() public T get() { // 2.1 从注册中心订阅服务 List\u0026lt;URL\u0026gt; urls = registry.lookup(url); // 2.2 创建Invoker Invoker\u0026lt;T\u0026gt; invoker = protocol.refer(type, url); // 2.3 创建代理对象 return proxyFactory.getProxy(invoker); } 2.6 Dubbo高级特性 Q: Dubbo如何实现服务分组和多版本？\nA: 通过group和version参数实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 服务提供者 - 不同分组 @DubboService(group = \u0026#34;primary\u0026#34;) public class PrimaryUserServiceImpl implements UserService { } @DubboService(group = \u0026#34;backup\u0026#34;) public class BackupUserServiceImpl implements UserService { } // 服务消费者 - 指定分组 @DubboReference(group = \u0026#34;primary\u0026#34;) private UserService primaryUserService; // 多版本共存 @DubboService(version = \u0026#34;1.0.0\u0026#34;) public class UserServiceV1Impl implements UserService { } @DubboService(version = \u0026#34;2.0.0\u0026#34;) public class UserServiceV2Impl implements UserService { } // 消费者指定版本 @DubboReference(version = \u0026#34;2.0.0\u0026#34;) private UserService userService; // 消费者随机调用任意版本 @DubboReference(version = \u0026#34;*\u0026#34;) private UserService userService; 使用场景：\n分组：同一接口的不同实现（如主备、读写分离） 版本：接口升级时的灰度发布 Q: Dubbo的隐式参数传递是怎么实现的？\nA: 通过RpcContext传递隐式参数：\n1 2 3 4 5 6 7 8 9 10 // Consumer端设置 RpcContext.getClientAttachment().setAttachment(\u0026#34;traceId\u0026#34;, \u0026#34;123456\u0026#34;); RpcContext.getClientAttachment().setAttachment(\u0026#34;userId\u0026#34;, \u0026#34;1001\u0026#34;); // 调用服务 userService.getById(1L); // Provider端获取 String traceId = RpcContext.getServerAttachment().getAttachment(\u0026#34;traceId\u0026#34;); String userId = RpcContext.getServerAttachment().getAttachment(\u0026#34;userId\u0026#34;); 应用场景：\n分布式链路追踪（TraceId传递） 用户身份信息传递 灰度标签传递 Q: Dubbo如何实现本地存根（Stub）和本地伪装（Mock）？\nA:\n本地存根（Stub）- 在Consumer端做预处理：\n如果校验不通过，直接返回，而不是去调用rpc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 存根实现 public class UserServiceStub implements UserService { private final UserService userService; public UserServiceStub(UserService userService) { this.userService = userService; } @Override public User getById(Long id) { // 前置校验 if (id == null || id \u0026lt;= 0) { return null; } // 调用远程服务 return userService.getById(id); } } // 配置 @DubboReference(stub = \u0026#34;com.lucius.eduAgentX.stub.UserServiceStub\u0026#34;) private UserService userService; 本地伪装（Mock）- 服务降级：\n如果服务炸了，返回默认字符串，如”服务繁忙“，或者可以不管服务器好坏，直接降级返回\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Mock实现 public class UserServiceMock implements UserService { @Override public User getById(Long id) { // 返回默认值或从缓存获取 User user = new User(); user.setId(id); user.setUserName(\u0026#34;默认用户\u0026#34;); return user; } } // 配置 - 失败时Mock @DubboReference(mock = \u0026#34;com.lucius.eduAgentX.mock.UserServiceMock\u0026#34;) private UserService userService; // 配置 - 强制Mock（不调用远程） @DubboReference(mock = \u0026#34;force:com.lucius.eduAgentX.mock.UserServiceMock\u0026#34;) private UserService userService; Q: Dubbo的连接控制是怎样的？\nA: Dubbo支持多种连接控制策略：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dubbo: #作为服务端的时候 provider: # 服务端最大连接数 accepts: 1000 # 每个服务的线程数 threads: 200 # 线程池类型 threadpool: fixed #作为客户端的时候，和服务端建立的连接数量取决于端口数 consumer: # 每个服务的连接数，这里指的是一个服务和一个客户端之间最大连接数 connections: 1 # 是否共享连接 shareconnections: true 连接模式：\n单一长连接（默认）：所有请求复用一个连接 多连接：每个服务建立多个连接，提高并发 1 2 3 // 为特定服务配置多连接 @DubboReference(connections = 10) private UserService userService; Q: Dubbo如何处理大数据量传输？\nA:\n1. 分页查询：\n1 2 3 4 // 避免一次返回大量数据 public interface UserService { Page\u0026lt;User\u0026gt; listByPage(int pageNum, int pageSize); } 2. 流式传输（Triple协议支持）：\n1 2 3 4 // 服务端流 public interface UserService { StreamObserver\u0026lt;User\u0026gt; listAllUsers(StreamObserver\u0026lt;User\u0026gt; responseObserver); } 3. 调整payload限制：\n1 2 3 dubbo: protocol: payload: 8388608 # 8MB，默认是8MB 4. 压缩传输：\n1 2 3 4 5 6 7 dubbo: provider: payload: 8388608 protocol: # 启用压缩 parameters: compressor: gzip Q: Dubbo的服务治理有哪些功能？\nA:\n1. 动态配置：\n1 2 3 4 // 通过Admin或API动态修改配置 ConfigCenterConfig config = new ConfigCenterConfig(); config.setAddress(\u0026#34;nacos://127.0.0.1:8848\u0026#34;); // 动态修改超时时间、权重等 2. 服务降级：\n1 2 3 4 5 # 通过规则配置降级 override: - service: com.lucius.eduAgentX.service.UserService parameters: mock: force:return null 3. 访问控制：\n1 2 3 4 5 # 黑白名单 accesslog: - service: com.lucius.eduAgentX.service.UserService whitelist: [192.168.1.*] blacklist: [192.168.2.*] 4. 权重调整：\n1 2 3 4 5 6 # 动态调整权重 override: - service: com.lucius.eduAgentX.service.UserService address: 192.168.1.100 parameters: weight: 200 Q: Dubbo 3.x相比2.x有哪些重要变化？\nA:\n特性 Dubbo 2.x Dubbo 3.x 服务发现 接口级 应用级（默认） 协议 Dubbo协议 Triple协议（默认） 注册中心 Zookeeper为主 Nacos/Zookeeper 云原生 不支持 支持K8s、Service Mesh 性能 高 更高 应用级服务发现的优势：\n1 2 3 4 5 6 7 接口级：每个接口都注册一条记录 - UserService → provider1, provider2 - OrderService → provider1, provider2 应用级：每个应用只注册一条记录 - user-service → provider1, provider2 - 元数据单独存储 减少注册中心压力 更适合大规模微服务 与K8s服务发现模型一致 Q: 如何排查Dubbo调用问题？\nA:\n1. 开启访问日志：\n1 2 3 dubbo: provider: accesslog: true # 或指定文件路径 2. 查看调用统计：\n1 2 3 4 // 通过QoS命令 telnet localhost 22222 \u0026gt; ls // 列出服务 \u0026gt; count UserService // 查看调用统计 3. 链路追踪：\n1 2 // 集成SkyWalking或Zipkin // 通过Filter传递TraceId 4. 常见问题排查：\n1 2 3 4 5 6 7 8 9 10 11 12 13 问题：No provider available 排查： 1. 检查服务是否启动 2. 检查注册中心连接 3. 检查group/version是否匹配 4. 检查网络是否通畅 问题：Timeout 排查： 1. 检查Provider处理时间 2. 检查网络延迟 3. 调整timeout配置 4. 检查线程池是否满了 三、高并发抢课系统 3.1 抢课核心流程 Q: 抢课系统的核心流程是怎样的？\nA: 采用 Redis预扣库存 + 异步落库 的架构：\n1 2 3 4 5 用户请求 → 限流检查 → Lua脚本原子操作 → 返回结果 ↓ 临时数据写入Redis ↓ 定时任务批量同步到MySQL 核心代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Override public BaseResponse\u0026lt;Boolean\u0026gt; snatchTheSubject(SnatchRequest request, HttpServletRequest httpRequest) { User loginUser = userService.getLoginUser(httpRequest); Long studentId = loginUser.getId(); Long subjectId = request.getSubjectId(); // 1. 检查Redis中是否有课程容量数据 Integer capacity = snatchCacheService.getSubjectCapacityWithCache(subjectId); if (capacity == null) { snatchSubjectService.initSubjectCapacityToRedis(subjectId); } // 2. 执行Lua脚本抢课 Long result = snatchCacheService.snatchWithCache(studentId, subjectId); // 3. 处理返回结果 if (result == -1) { throw new BusinessException(ErrorCode.OPERATION_ERROR, \u0026#34;已抢课，不能重复抢课\u0026#34;); } if (result == -2) { throw new BusinessException(ErrorCode.OPERATION_ERROR, \u0026#34;课程余量不足\u0026#34;); } if (result == 1) { return ResultUtils.success(true); } throw new BusinessException(ErrorCode.SYSTEM_ERROR, \u0026#34;抢课失败\u0026#34;); } Redis数据结构设计：\n1 2 3 4 5 6 7 8 9 10 11 subject:capacity # Hash: 课程容量 ├── 1 → 100 └── 2 → 50 snatch:{studentId} # Hash: 学生已抢课程 ├── 1 → 1 └── 3 → 1 snatch:temp:{timeSlice} # Hash: 临时抢课数据 ├── 1001:1 → 1 # 学生1001抢了课程1 └── 1002:1 → -1 # 学生1002退了课程1 深入追问：\nQ: 为什么不直接写MySQL？ A:\nMySQL单机QPS约1000，无法支撑高并发 Redis单机QPS可达10万+ 异步落库减少数据库压力 3.2 数据一致性保证 Q: Redis和MySQL的数据一致性怎么保证？\nA: 通过 定时任务 + 补偿机制 保证最终一致性：\n定时同步任务（每10秒执行）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Scheduled(fixedRate = 10000) @Transactional(rollbackFor = Exception.class) public void run() { String lastTimeSlice = RedisKeyUtil.getLastTimeSlice(); syncSnatch2DBByTimeSlice(lastTimeSlice); } public void syncSnatch2DBByTimeSlice(String timeSlice) { String tempSnatchKey = RedisKeyUtil.getTempSnatchKey(timeSlice); Map\u0026lt;Object, Object\u0026gt; allTempSnatchMap = redisTemplate.opsForHash().entries(tempSnatchKey); List\u0026lt;Snatch\u0026gt; snatchListToInsert = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Snatch\u0026gt; snatchListToDelete = new ArrayList\u0026lt;\u0026gt;(); for (Object key : allTempSnatchMap.keySet()) { String[] parts = key.toString().split(\u0026#34;:\u0026#34;); Long studentId = Long.valueOf(parts[0]); Long subjectId = Long.valueOf(parts[1]); Integer snatchType = Integer.valueOf(allTempSnatchMap.get(key).toString()); if (snatchType == 1) { // 抢课 snatchListToInsert.add(new Snatch(studentId, subjectId)); } else if (snatchType == -1) { // 退课 snatchListToDelete.add(new Snatch(studentId, subjectId)); } } // 批量操作 if (!snatchListToInsert.isEmpty()) { snatchService.saveBatch(snatchListToInsert); } // ... } 补偿任务（每天凌晨2点）：\n1 2 3 4 5 6 7 @Scheduled(cron = \u0026#34;0 0 2 * * *\u0026#34;) public void run() { Set\u0026lt;String\u0026gt; snatchKeys = redisTemplate.keys(\u0026#34;snatch:temp:*\u0026#34;); for (String timeSlice : extractTimeSlices(snatchKeys)) { syncSnatch2DBJob.syncSnatch2DBByTimeSlice(timeSlice); } } 时间片设计：\n1 2 3 4 5 6 7 public static String getCurrentTimeSlice() { Date now = new Date(); int second = DateUtil.second(now); int alignedSecond = (second / 10) * 10; // 向下取整到10的倍数 return DateUtil.format(now, \u0026#34;HH:mm:\u0026#34;) + String.format(\u0026#34;%02d\u0026#34;, alignedSecond); } // 例如：14:30:00, 14:30:10, 14:30:20... 3.3 限流实现 Q: 接口限流是怎么实现的？\nA: 使用 Redis + Lua脚本 实现滑动窗口限流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Aspect @Component public class RateLimitAspect { private static final DefaultRedisScript\u0026lt;Long\u0026gt; RATE_LIMIT_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(\u0026#34;\u0026#34;\u0026#34; local key = KEYS[1] local window = tonumber(ARGV[1]) local limit = tonumber(ARGV[2]) local current = tonumber(ARGV[3]) -- 移除窗口外的记录 redis.call(\u0026#39;ZREMRANGEBYSCORE\u0026#39;, key, 0, current - window * 1000) -- 统计当前窗口内的请求数 local currentCount = redis.call(\u0026#39;ZCARD\u0026#39;, key) if currentCount \u0026lt; limit then -- 未超限，记录本次请求 redis.call(\u0026#39;ZADD\u0026#39;, key, current, current) redis.call(\u0026#39;EXPIRE\u0026#39;, key, window) return limit - currentCount - 1 -- 返回剩余次数 else return -1 -- 超限 end \u0026#34;\u0026#34;\u0026#34;, Long.class); @Around(\u0026#34;@annotation(rateLimit)\u0026#34;) public Object around(ProceedingJoinPoint point, RateLimit rateLimit) throws Throwable { String limitKey = buildLimitKey(rateLimit); Long remaining = redisTemplate.execute( RATE_LIMIT_SCRIPT, Collections.singletonList(limitKey), rateLimit.window(), rateLimit.limit(), System.currentTimeMillis() ); if (remaining != null \u0026amp;\u0026amp; remaining \u0026lt; 0) { throw new BusinessException(ErrorCode.OPERATION_ERROR, \u0026#34;操作过于频繁，请稍后重试\u0026#34;); } return point.proceed(); } } 使用方式：\n1 2 3 4 5 @RateLimit(key = \u0026#34;snatch\u0026#34;, window = 1, limit = 5, type = \u0026#34;user\u0026#34;) @PostMapping(\u0026#34;/save\u0026#34;) public BaseResponse\u0026lt;Boolean\u0026gt; snatchTheSubject(@RequestBody SnatchRequest request) { // ... } 深入追问：\nQ: 为什么用滑动窗口而不是固定窗口？ A: 固定窗口在窗口边界会有突刺问题。比如限制每秒5次，在0.9秒请求5次，1.1秒又请求5次，实际0.2秒内请求了10次。滑动窗口能更平滑地限流。\n3.4 性能优化措施 Q: 抢课系统做了哪些性能优化？\nA: 主要优化措施：\n1. 连接池优化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spring: data: redis: lettuce: pool: max-active: 100 # 最大连接数 max-idle: 50 min-idle: 10 datasource: hikari: maximum-pool-size: 50 minimum-idle: 10 server: tomcat: threads: max: 500 min-spare: 50 max-connections: 10000 2. Lua脚本优化：\n减少Redis操作次数（原来5次→现在3次） 使用HINCRBY原子操作 3. 批量SQL优化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 使用CASE WHEN批量更新 @Update(\u0026#34;\u0026#34;\u0026#34; UPDATE snatch_subject SET capacity = CASE subject_id \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34;\u0026gt; WHEN #{item.subjectId} THEN capacity + #{item.change} \u0026lt;/foreach\u0026gt; END WHERE subject_id IN \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; open=\u0026#34;(\u0026#34; separator=\u0026#34;,\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{item.subjectId} \u0026lt;/foreach\u0026gt; \u0026#34;\u0026#34;\u0026#34;) void batchUpdateSubjectCapacity(@Param(\u0026#34;list\u0026#34;) List\u0026lt;SubjectCapacityChangeDTO\u0026gt; list); 4. 异步热Key检测：\nHeavyKeeper的add()操作异步执行 不阻塞主流程 性能对比：\n指标 优化前 优化后 QPS 500 2000+ 响应时间 100ms \u0026lt;50ms Redis连接数 10 100 四、AI工作流系统 4.1 LangGraph4j工作流 Q: AI出题的工作流是怎么设计的？\nA: 使用LangGraph4j构建有向图工作流，支持条件路由和循环：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 private CompiledGraph\u0026lt;MessagesState\u0026lt;String\u0026gt;\u0026gt; createQuestionWorkflow() { return new MessagesStateGraph\u0026lt;String\u0026gt;() // 添加节点 .addNode(\u0026#34;ques_knowledge_result_node\u0026#34;, QuesKnowledgeResultNode.create()) .addNode(\u0026#34;ques_task_list_node\u0026#34;, QuesTaskListNode.create()) .addNode(\u0026#34;ques_generate_node\u0026#34;, QuesGenerateNode.create()) .addNode(\u0026#34;ques_parse_check_node\u0026#34;, QuesParseCheckNode.create()) // 添加边 .addEdge(START, \u0026#34;ques_knowledge_result_node\u0026#34;) .addEdge(\u0026#34;ques_knowledge_result_node\u0026#34;, \u0026#34;ques_task_list_node\u0026#34;) .addEdge(\u0026#34;ques_task_list_node\u0026#34;, \u0026#34;ques_generate_node\u0026#34;) .addEdge(\u0026#34;ques_generate_node\u0026#34;, \u0026#34;ques_parse_check_node\u0026#34;) // 条件路由 .addConditionalEdges(\u0026#34;ques_parse_check_node\u0026#34;, edge_async(this::routeAfterCheck), Map.of( \u0026#34;continue_generate\u0026#34;, \u0026#34;ques_generate_node\u0026#34;, \u0026#34;retry_generate\u0026#34;, \u0026#34;ques_generate_node\u0026#34;, \u0026#34;finish\u0026#34;, END )) .compile(); } private String routeAfterCheck(MessagesState\u0026lt;String\u0026gt; state) { QuestionGenerateContext context = QuestionGenerateContext.getContext(state); Boolean checkResult = context.getCheckResult(); if (checkResult == null || !checkResult) { return \u0026#34;retry_generate\u0026#34;; // 质检未通过，重新生成 } context.setCurrentQuestionIndex(context.getCurrentQuestionIndex() + 1); if (context.getQuestionNum() \u0026gt; 0) { return \u0026#34;continue_generate\u0026#34;; // 继续生成下一题 } return \u0026#34;finish\u0026#34;; // 完成 } 工作流图：\n1 2 3 4 5 6 7 8 graph LR START --\u0026gt; 知识点检索 知识点检索 --\u0026gt; 任务列表生成 任务列表生成 --\u0026gt; 题目生成 题目生成 --\u0026gt; 质检解析 质检解析 --\u0026gt;|通过且有剩余| 题目生成 质检解析 --\u0026gt;|未通过| 题目生成 质检解析 --\u0026gt;|完成| END 4.2 设计模式应用 Q: AI出题系统用了哪些设计模式？\nA: 主要使用了三种设计模式：\n1. 外观模式（Facade）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Service public class AIQuestionFacade { @Resource private QuestionMakerService questionMakerService; @Resource private ExplanationExecutor explanationExecutor; @Resource private ScoreStandardExecutor scoreStandardExecutor; public QuestionGenerateContext generateAndParseQuestion( SseEmitter emitter, QuestionGenerateContext context, String prompt, QuestionTypeEnum questionTypeEnum) { return switch (questionTypeEnum) { case MULTIPLE_CHOICE_QUESTION -\u0026gt; { var result = questionMakerService.multipleChoiceQuestion(prompt, subjectId, emitter); yield processQuestionStream(context, result, questionTypeEnum, emitter); } case FILL_BLANK_QUESTION -\u0026gt; { var result = questionMakerService.fillBlankQuestion(subjectId, prompt, emitter); yield processQuestionStream(context, result, questionTypeEnum, emitter); } case BIG_QUESTION -\u0026gt; { var result = questionMakerService.bigQuestion(prompt, emitter, subjectId); yield processQuestionStream(context, result, questionTypeEnum, emitter); } }; } } 2. 模板方法模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class ParseCheckStorageExecutor { @Resource private MultipleChoiceStorageTemplate multipleChoiceStorageTemplate; @Resource private FillBlankStorageTemplate fillBlankStorageTemplate; @Resource private BigStorageTemplate bigStorageTemplate; public QuestionGenerateContext executeParseCheckAndStorage( Object questionResult, QuestionGenerateContext context, QuestionTypeEnum questionTypeEnum) { return switch (questionTypeEnum) { case MULTIPLE_CHOICE_QUESTION -\u0026gt; multipleChoiceStorageTemplate.saveQuestion((MultipleChoiceQuestionBO) questionResult, context); case FILL_BLANK_QUESTION -\u0026gt; fillBlankStorageTemplate.saveQuestion((FillBlankQuestionBO) questionResult, context); case BIG_QUESTION -\u0026gt; bigStorageTemplate.saveQuestion((BigQuestionBO) questionResult, context); }; } } 3. 策略模式：\n不同题型使用不同的生成策略 不同题型使用不同的解析策略 不同题型使用不同的评分标准生成策略 4.3 SSE实时推送 Q: AI生成过程中的实时推送是怎么实现的？\nA: 使用SSE（Server-Sent Events）+ ThreadLocal存储Emitter：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Service public class WorkFlowServiceImpl implements WorkFlowService { public static final ThreadLocal\u0026lt;SseEmitter\u0026gt; SSE_EMITTER_HOLDER = new ThreadLocal\u0026lt;\u0026gt;(); @Override public Boolean generateQuestionWorkFlow(..., SseEmitter emitter) { SSE_EMITTER_HOLDER.set(emitter); try { // 发送初始消息 JSONObject jsonObject = new JSONObject(); jsonObject.put(WorkFlowTagEnum.START.getValue(), \u0026#34;工作流开始执行...\u0026#34;); emitter.send(SseEmitter.event() .name(WorkFlowTagEnum.START.getValue()) .data(jsonObject.toString())); CompiledGraph\u0026lt;MessagesState\u0026lt;String\u0026gt;\u0026gt; workflow = createQuestionWorkflow(); // 异步执行工作流 CompletableFuture.runAsync(() -\u0026gt; { SSE_EMITTER_HOLDER.set(emitter); // 异步线程重新设置 try { for (NodeOutput\u0026lt;MessagesState\u0026lt;String\u0026gt;\u0026gt; step : workflow.stream(initialState)) { // 节点内部实时发送SSE消息 } emitter.complete(); } catch (Exception e) { emitter.completeWithError(e); } finally { SSE_EMITTER_HOLDER.remove(); } }); } finally { // 主线程不清理，异步任务会重新设置 } return true; } } 节点中发送消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class QuesGenerateNode { public static AsyncNodeAction\u0026lt;MessagesState\u0026lt;String\u0026gt;\u0026gt; create() { return node_async(state -\u0026gt; { SseEmitter emitter = SSE_EMITTER_HOLDER.get(); JSONObject jsonObject = new JSONObject(); jsonObject.put(WorkFlowTagEnum.ALERT.getValue(), \u0026#34;题目生成节点\u0026#34;); emitter.send(SseEmitter.event() .name(WorkFlowTagEnum.ALERT.getValue()) .data(jsonObject.toString())); // 生成题目... return QuestionGenerateContext.saveContext(context); }); } } 深入追问：\nQ: 为什么用ThreadLocal存储SseEmitter？ A:\nSseEmitter不能序列化，无法放入工作流状态 ThreadLocal可以在同一线程的不同节点间共享 异步线程需要重新设置 4.4 RAG检索增强 Q: RAG是怎么实现的？\nA: 使用Spring AI + Redis向量存储：\n1 2 3 4 5 6 7 8 9 spring: ai: openai: base-url: ${spring.ai.openai.base-url} api-key: ${spring.ai.openai.api-key} embedding: options: model: text-embedding-v3 dimensions: 1024 文档处理流程：\n1 2 3 4 5 6 7 8 9 10 11 public interface RagService { // 1. 文档上传并向量化 Long documentPush(MultipartFile file, String category, String subjectId, HttpServletRequest request) throws IOException; // 2. 检索相关内容 RagResultVO getRagResult(RagPromptRequest request); // 3. 删除文档 boolean deleteDocumentByFileId(Long id); } 支持的文档格式：\nPDF（使用spring-ai-pdf-document-reader） DOCX（使用Apache POI） 五、数据库与ORM 5.1 MyBatis-Flex使用 Q: 为什么选择MyBatis-Flex而不是MyBatis-Plus？\nA: MyBatis-Flex是MyBatis-Plus的轻量级替代：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // QueryWrapper使用 public QueryWrapper getQueryWrapper(UserQueryRequest request) { return QueryWrapper.create() .eq(\u0026#34;id\u0026#34;, request.getId()) .eq(\u0026#34;userRole\u0026#34;, request.getUserRole()) .like(\u0026#34;userAccount\u0026#34;, request.getUserAccount()) .like(\u0026#34;userName\u0026#34;, request.getUserName()) .orderBy(request.getSortField(), \u0026#34;ascend\u0026#34;.equals(request.getSortOrder())); } // 条件更新 QueryWrapper query = QueryWrapper.create() .where(User::getId).eq(loginUser.getId()); userMapper.updateByQuery(updateUser, query); 对比MyBatis-Plus： | 特性 | MyBatis-Flex | MyBatis-Plus | |\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;| | 依赖大小 | 更小 | 较大 | | Lambda支持 | 支持 | 支持 | | 多表关联 | 更好 | 一般 | | 学习成本 | 低 | 低 |\n5.2 批量操作优化 Q: 批量更新是怎么优化的？\nA: 使用CASE WHEN语句一次SQL更新多条记录：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;update id=\u0026#34;batchUpdateSubjectCapacity\u0026#34;\u0026gt; UPDATE snatch_subject SET capacity = CASE subject_id \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34;\u0026gt; WHEN #{item.subjectId} THEN capacity + #{item.change} \u0026lt;/foreach\u0026gt; END WHERE subject_id IN \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; open=\u0026#34;(\u0026#34; separator=\u0026#34;,\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{item.subjectId} \u0026lt;/foreach\u0026gt; \u0026lt;/update\u0026gt; 对比逐条更新：\n逐条更新：N次网络往返 + N次SQL解析 批量更新：1次网络往返 + 1次SQL解析 5.3 连接池配置 Q: HikariCP是怎么配置的？\nA:\n1 2 3 4 5 6 7 8 spring: datasource: hikari: maximum-pool-size: 50 # 最大连接数 minimum-idle: 10 # 最小空闲连接 connection-timeout: 30000 # 连接超时30秒 idle-timeout: 600000 # 空闲超时10分钟 max-lifetime: 1800000 # 最大生命周期30分钟 参数调优原则：\nmaximum-pool-size: 根据并发量和数据库承载能力设置 minimum-idle: 保持一定空闲连接，减少创建开销 max-lifetime: 小于数据库的wait_timeout 5.4 事务管理 Q: 事务是怎么管理的？\nA:\n1 2 3 4 5 6 @Scheduled(fixedRate = 10000) @Transactional(rollbackFor = Exception.class) public void run() { // 批量插入、删除、更新 // 任何异常都会回滚 } rollbackFor = Exception.class的作用：\n默认只对RuntimeException回滚 设置后对所有Exception都回滚 六、安全与认证 6.1 密码加密 Q: 密码是怎么加密的？\nA: 使用MD5 + 盐值加密：\n1 2 3 4 5 6 7 @Override public String getEncryptPassword(String userPassword) { final String SALT = \u0026#34;lucius\u0026#34;; return DigestUtils.md5DigestAsHex( (userPassword + SALT).getBytes(StandardCharsets.UTF_8) ); } 深入追问：\nQ: MD5安全吗？有什么改进方案？ A: MD5已不够安全，可以改进为：\nBCrypt（推荐） PBKDF2 Argon2 6.2 权限控制 Q: 权限控制是怎么实现的？\nA: 使用AOP切面 + 自定义注解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Aspect @Component public class AuthInterceptor { @Around(\u0026#34;@annotation(authCheck)\u0026#34;) public Object doInterceptor(ProceedingJoinPoint joinPoint, AuthCheck authCheck) throws Throwable { String mustRole = authCheck.mustRole(); HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest(); User loginUser = userService.getLoginUser(request); UserRoleEnum mustRoleEnum = UserRoleEnum.getEnumByValue(mustRole); if (mustRoleEnum == null) { return joinPoint.proceed(); // 不需要权限 } UserRoleEnum userRoleEnum = UserRoleEnum.getEnumByValue(loginUser.getUserRole()); if (!mustRoleEnum.equals(userRoleEnum)) { throw new BusinessException(ErrorCode.NO_AUTH_ERROR); } return joinPoint.proceed(); } } 使用方式：\n1 2 3 4 5 @AuthCheck(mustRole = \u0026#34;admin\u0026#34;) @GetMapping(\u0026#34;/list\u0026#34;) public BaseResponse\u0026lt;List\u0026lt;User\u0026gt;\u0026gt; listUsers() { // 只有admin角色可以访问 } 七、RocketMQ消息队列 7.1 MQ选型对比 Q: 为什么选择RocketMQ？\nA: 对比三种主流MQ：\n特性 RocketMQ Kafka RabbitMQ 吞吐量 高 最高 中等 延迟 毫秒级 毫秒级 微秒级 可靠性 高 高 高 事务消息 支持 不支持 不支持 顺序消息 支持 支持 支持 运维复杂度 中等 高 低 选择RocketMQ原因：\n阿里开源，国内社区活跃 支持事务消息（抢课场景可能需要） 性能和可靠性平衡好 7.2 生产者/消费者配置 Q: RocketMQ是怎么配置的？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 rocketmq: name-server: 192.168.5.4:8081 topic: snatch-topic producer: group: snatch-producer-group send-message-timeout: 3000 retry-times-when-send-failed: 2 consumer: group: snatch-consumer-group batch-size: 1000 # 批量消费 batch-timeout: 10 # 批次超时 pull-batch-size: 100 consume-thread-min: 5 consume-thread-max: 20 八、阿里云OSS文件存储 8.1 OSS配置 Q: OSS是怎么配置的？\nA:\n1 2 3 4 5 6 edu: alioss: endpoint: ${edu.alioss.endpoint} access-key-id: ${edu.alioss.access-key-id} access-key-secret: ${edu.alioss.access-key-secret} bucket-name: ${edu.alioss.bucket-name} 敏感信息管理：\n使用环境变量或配置中心 不在代码中硬编码 8.2 文件上传流程 Q: 文件上传是怎么实现的？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Override public Boolean updateUserAvatar(MultipartFile file, HttpServletRequest request) { User loginUser = getLoginUser(request); // 1. 生成唯一文件名 String originalFilename = file.getOriginalFilename(); String extension = originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); String snowId = IdUtil.getSnowflake().nextIdStr(); String objectName = \u0026#34;user-avatar/\u0026#34; + snowId + extension; // 2. 上传到OSS String filePath = aliOssUtil.upload(file.getBytes(), objectName); // 3. 更新数据库 User updateUser = new User(); updateUser.setUserAvatar(filePath); userMapper.updateByQuery(updateUser, QueryWrapper.create().where(User::getId).eq(loginUser.getId())); return true; } 雪花ID的作用：\n保证文件名全局唯一 避免文件覆盖 九、上线运维 9.1 多环境配置 Q: 多环境是怎么管理的？\nA: 使用Spring Profiles：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # application.yml spring: profiles: active: local # 或 prod # application-local.yml (开发环境) spring: datasource: url: jdbc:mysql://localhost:3306/eduagentxnew username: root password: 123456 # application-prod.yml (生产环境) spring: datasource: url: jdbc:mysql://localhost:3306/eduagentxnew username: eduagentxnew password: ${DB_PASSWORD} # 从环境变量读取 9.2 健康检查 Q: 健康检查接口是怎么设计的？\nA:\n1 2 3 4 5 6 7 8 @RestController @RequestMapping(\u0026#34;/health\u0026#34;) public class HealthController { @GetMapping(\u0026#34;/\u0026#34;) public BaseResponse\u0026lt;String\u0026gt; healthCheck() { return ResultUtils.success(\u0026#34;ok\u0026#34;); } } 用途：\n负载均衡健康探测 K8s存活探针 监控系统检测 9.3 缓存监控 Q: 缓存监控是怎么实现的？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @RestController @RequestMapping(\u0026#34;/admin/cache\u0026#34;) public class AdminCacheMonitorController { @GetMapping(\u0026#34;/stats\u0026#34;) public BaseResponse\u0026lt;CacheStatsVO\u0026gt; getCacheStats() { CacheStats stats = localCache.stats(); CacheStatsVO vo = new CacheStatsVO(); vo.setHitCount(stats.hitCount()); vo.setMissCount(stats.missCount()); vo.setHitRate(stats.hitRate()); vo.setEvictionCount(stats.evictionCount()); vo.setCacheSize(localCache.estimatedSize()); return ResultUtils.success(vo); } @GetMapping(\u0026#34;/hot-subjects\u0026#34;) public BaseResponse\u0026lt;List\u0026lt;Item\u0026gt;\u0026gt; getHotSubjects() { return ResultUtils.success(snatchCacheService.getHotSubjects()); } } 9.4 系统初始化 Q: 应用启动时做了什么初始化？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Component public class SnatchInitializer { @Resource private SnatchSubjectService snatchSubjectService; @PostConstruct public void init() { try { log.info(\u0026#34;开始初始化抢课系统...\u0026#34;); snatchSubjectService.initAllSubjectCapacityToRedis(); log.info(\u0026#34;抢课系统初始化完成\u0026#34;); } catch (Exception e) { log.error(\u0026#34;抢课系统初始化失败\u0026#34;, e); } } } 初始化内容：\n将所有课程容量加载到Redis 预热本地缓存 十、异常处理与全局响应 10.1 统一响应格式 Q: 接口响应格式是怎么统一的？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Data public class BaseResponse\u0026lt;T\u0026gt; implements Serializable { private int code; private T data; private String message; } public class ResultUtils { public static \u0026lt;T\u0026gt; BaseResponse\u0026lt;T\u0026gt; success(T data) { return new BaseResponse\u0026lt;\u0026gt;(0, data, \u0026#34;ok\u0026#34;); } public static BaseResponse\u0026lt;?\u0026gt; error(ErrorCode errorCode, String message) { return new BaseResponse\u0026lt;\u0026gt;(errorCode.getCode(), null, message); } } 10.2 全局异常处理 Q: 全局异常是怎么处理的？\nA:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RestControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(BusinessException.class) public BaseResponse\u0026lt;?\u0026gt; businessExceptionHandler(BusinessException e) { log.error(\u0026#34;BusinessException\u0026#34;, e); return ResultUtils.error(e.getCode(), e.getMessage()); } @ExceptionHandler(RuntimeException.class) public BaseResponse\u0026lt;?\u0026gt; runtimeExceptionHandler(RuntimeException e) { log.error(\u0026#34;RuntimeException\u0026#34;, e); return ResultUtils.error(ErrorCode.SYSTEM_ERROR, \u0026#34;系统错误\u0026#34;); } } 十一、技术栈选型 11.1 核心版本 技术 版本 Spring Boot 3.5.4 Java 17/21 MyBatis-Flex 1.11.1 Spring AI 1.0.0-M7 LangGraph4j 1.6.0-rc2 Caffeine 3.1.8 Jedis 5.2.0 11.2 依赖选型原因 依赖 选择原因 Hutool 全能工具库，减少重复代码 Knife4j 美观的API文档，支持调试 Caffeine 高性能本地缓存 LangGraph4j Java版LangGraph，构建AI工作流 HikariCP 最快的JDBC连接池 总结 本文档覆盖了EduAgentX项目的核心技术细节，建议面试前：\n重点掌握：Redis Lua脚本、多级缓存、Dubbo配置 理解原理：HeavyKeeper算法、滑动窗口限流、异步落库 熟悉代码：能够手写关键代码片段 准备追问：每个技术点都要想好深入追问的答案 祝面试顺利！🎉\n","date":"2025-11-27T20:08:45+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E8%AF%9D%E6%9C%AF/","title":"面试话术"},{"content":"面试八股/场景2.0 介绍一下RDB和AOF Redis 是一个基于内存的数据库，为了防止服务器宕机导致数据丢失，Redis 提供了两种主要的持久化机制：RDB (Redis Database) 和 AOF (Append Only File)。\n这两者分别代表了两种不同的思路：快照（Snapshotting） 和 日志（Logging）。\n1. RDB (Redis Database) —— 快照模式 RDB 是 Redis 默认的持久化方式。它会在指定的时间间隔内，将内存中的数据集快照写入磁盘。\n工作原理 触发方式： 可以通过配置文件（如 save 900 1，表示900秒内有1个key变动则触发）自动触发，也可以手动执行 SAVE 或 BGSAVE 命令。\n核心流程（BGSAVE）：\nRedis 主进程 fork 一个子进程。\n子进程共享主进程的内存数据（利用操作系统的 Copy-on-Write / 写时复制 技术）。\n子进程将数据写入到一个临时的 RDB 文件中。\n写入完成后，用新文件替换旧的 RDB 文件。\n✅ 优点 恢复速度快： RDB 是一个紧凑的二进制文件，非常适合用于灾难恢复和备份。Redis 加载 RDB 文件恢复数据的速度远快于 AOF。\n文件体积小： 相比 AOF，RDB 文件更小，节省磁盘空间。\n性能影响小： 父进程在 fork 子进程后继续处理请求，持久化工作由子进程完成，最大化了 Redis 的性能。\n❌ 缺点 数据丢失风险较高： RDB 是间隔执行的（例如每5分钟一次）。如果 Redis 在两次快照之间宕机，这期间产生的数据将会丢失。\n大数据集下的停顿： 当数据集非常大（如几十 GB）时，fork 子进程的操作可能会比较耗时，导致 Redis 主进程出现毫秒级甚至秒级的阻塞。\n2. AOF (Append Only File) —— 日志模式 AOF 记录了服务器接收到的每一个写操作（查询操作不记录）。服务器启动时，通过重新执行这些命令来还原数据。\n工作原理 命令追加： 所有的写命令会先追加到 AOF 缓冲区。\n同步策略（fsync）： 根据配置将缓冲区内容同步到磁盘：\nappendfsync always：每次写操作都同步（最安全，但性能最差）。\nappendfsync everysec：每秒同步一次（默认推荐，兼顾性能与安全）。\nappendfsync no：由操作系统决定何时同步（性能最好，但不可控）。\nAOF 重写（Rewrite）： 随着时间推移，AOF 文件会越来越大（例如：SET a 1, SET a 2 其实最终只是 a=2）。Redis 会在后台对 AOF 文件进行重写，只保留恢复当前数据所需的最小命令集。\n✅ 优点 数据安全性高： 使用 everysec 策略，最坏情况下也只会丢失 1 秒的数据。\n可读性强： AOF 文件是纯文本格式，如果误执行了 FLUSHALL，只要 AOF 文件未被重写，可以手动删掉文件末尾的该命令来挽救数据。\n❌ 缺点 文件体积大： 记录所有写命令，导致 AOF 文件通常比 RDB 文件大得多。\n恢复速度慢： 恢复数据时需要“重放”所有命令，速度比加载 RDB 二进制快照要慢。\n写性能稍低： 根据 fsync 策略，AOF 对写性能有一定影响（通常 everysec 影响很小）。\n3. RDB vs AOF 核心对比 特性 RDB (快照) AOF (日志) 数据安全性 较低 (可能丢失最后几分钟数据) 高 (默认通常只丢1秒) 恢复速度 非常快 较慢 (需重放命令) 文件体积 小 (二进制压缩) 大 (文本记录) 资源消耗 CPU 高 (Fork 过程), I/O 低 CPU 低, I/O 高 (持续追加) 启动优先级 低 (若开启 AOF，优先加载 AOF) 高 (因为数据更全) Redis 是一个基于内存的数据库，为了防止服务器宕机导致数据丢失，Redis 提供了两种主要的持久化机制：RDB (Redis Database) 和 AOF (Append Only File)。\n这两者分别代表了两种不同的思路：快照（Snapshotting） 和 日志（Logging）。\n以下是两者的详细对比与解析：\n1. RDB (Redis Database) —— 快照模式 RDB 是 Redis 默认的持久化方式。它会在指定的时间间隔内，将内存中的数据集快照写入磁盘。\n工作原理 触发方式： 可以通过配置文件（如 save 900 1，表示900秒内有1个key变动则触发）自动触发，也可以手动执行 SAVE 或 BGSAVE 命令。\n核心流程（BGSAVE）：\nRedis 主进程 fork 一个子进程。\n子进程共享主进程的内存数据（利用操作系统的 Copy-on-Write / 写时复制 技术）。\n子进程将数据写入到一个临时的 RDB 文件中。\n写入完成后，用新文件替换旧的 RDB 文件。\n✅ 优点 恢复速度快： RDB 是一个紧凑的二进制文件，非常适合用于灾难恢复和备份。Redis 加载 RDB 文件恢复数据的速度远快于 AOF。\n文件体积小： 相比 AOF，RDB 文件更小，节省磁盘空间。\n性能影响小： 父进程在 fork 子进程后继续处理请求，持久化工作由子进程完成，最大化了 Redis 的性能。\n❌ 缺点 数据丢失风险较高： RDB 是间隔执行的（例如每5分钟一次）。如果 Redis 在两次快照之间宕机，这期间产生的数据将会丢失。\n大数据集下的停顿： 当数据集非常大（如几十 GB）时，fork 子进程的操作可能会比较耗时，导致 Redis 主进程出现毫秒级甚至秒级的阻塞。\n2. AOF (Append Only File) —— 日志模式 AOF 记录了服务器接收到的每一个写操作（查询操作不记录）。服务器启动时，通过重新执行这些命令来还原数据。\n工作原理 命令追加： 所有的写命令会先追加到 AOF 缓冲区。\n同步策略（fsync）： 根据配置将缓冲区内容同步到磁盘：\nappendfsync always：每次写操作都同步（最安全，但性能最差）。\nappendfsync everysec：每秒同步一次（默认推荐，兼顾性能与安全）。\nappendfsync no：由操作系统决定何时同步（性能最好，但不可控）。\nAOF 重写（Rewrite）： 随着时间推移，AOF 文件会越来越大（例如：SET a 1, SET a 2 其实最终只是 a=2）。Redis 会在后台对 AOF 文件进行重写，只保留恢复当前数据所需的最小命令集。\n✅ 优点 数据安全性高： 使用 everysec 策略，最坏情况下也只会丢失 1 秒的数据。\n可读性强： AOF 文件是纯文本格式，如果误执行了 FLUSHALL，只要 AOF 文件未被重写，可以手动删掉文件末尾的该命令来挽救数据。\n❌ 缺点 文件体积大： 记录所有写命令，导致 AOF 文件通常比 RDB 文件大得多。\n恢复速度慢： 恢复数据时需要“重放”所有命令，速度比加载 RDB 二进制快照要慢。\n写性能稍低： 根据 fsync 策略，AOF 对写性能有一定影响（通常 everysec 影响很小）。\n3. RDB vs AOF 核心对比 特性 RDB (快照) AOF (日志) 数据安全性 较低 (可能丢失最后几分钟数据) 高 (默认通常只丢1秒) 恢复速度 非常快 较慢 (需重放命令) 文件体积 小 (二进制压缩) 大 (文本记录) 资源消耗 CPU 高 (Fork 过程), I/O 低 CPU 低, I/O 高 (持续追加) 启动优先级 低 (若开启 AOF，优先加载 AOF) 高 (因为数据更全) 4. 最佳实践：混合持久化 (Redis 4.0+) 在 Redis 4.0 之前，通常建议同时开启 RDB（做备份）和 AOF（保数据）。\nRedis 4.0 引入了混合持久化（Hybrid Persistence）：\n这是目前的推荐配置。它结合了 RDB 和 AOF 的优点：\n机制： 在进行 AOF 重写时，Redis 会将当前内存的数据以 RDB 格式 写入 AOF 文件的开头，随后的增量写操作继续以 AOF 文本格式 追加到文件末尾。\n结果： AOF 文件前半部分是 RDB（加载快、体积小），后半部分是增量日志（数据全）。\n效果： 既保证了快速启动（加载 RDB 部分），又保证了数据不丢失（加载 AOF 增量部分）。\n进程和线程的区别 用一句话概括：进程是资源分配的最小单位，线程是 CPU 调度的最小单位。\n核心区别详解 1. 资源的拥有权（Resource Ownership） 进程： 拥有独立的内存空间（代码段、数据段、堆等）和系统资源（文件描述符等）。不同进程之间的资源是隔离的。\n线程： 线程本身不拥有系统资源，只拥有很少的运行中必不可少的资源（如程序计数器、栈、寄存器）。同一进程内的所有线程共享该进程的内存空间（堆、全局变量）和文件资源。\n2. 调度与开销（Overhead \u0026amp; Switching） 进程： 切换成本高。当操作系统切换进程时，需要保存当前进程的上下文（内存页表、CPU 状态等）并加载新进程的上下文，这会导致 CPU 缓存失效，开销较大。\n线程： 切换成本低。同一进程内的线程切换，不需要切换内存页表，只需要保存和恢复少量的寄存器内容和栈信息，速度很快。\n3. 通信方式（Communication） 进程间通信 (IPC)： 困难。因为内存隔离，进程间需要通过特殊机制通信，如：管道 (Pipe)、消息队列、共享内存、信号量、Socket 等。\n线程间通信： 容易。因为共享内存（堆），线程之间可以直接读写同一变量来进行通信。\n注意： 虽然通信容易，但带来了**线程安全（同步）**问题，需要使用锁（Lock）或 CAS 等机制来防止数据错乱。 4. 健壮性与隔离性（Stability） 进程： 健壮性强。一个进程崩溃通常不会影响其他进程（因为内存是隔离的）。例如：Chrome 浏览器的一个标签页（进程）崩了，通常不会导致整个浏览器崩溃。\n线程： 健壮性弱。一个线程出现致命错误（如非法内存访问），可能会导致整个进程崩溃，进而导致该进程内的所有线程都挂掉。\n对比总结表 维度 进程 (Process) 线程 (Thread) 本质 资源分配的最小单位 CPU 调度的最小单位 内存空间 独立（互不干扰） 共享（同一进程内） 切换开销 大 (涉及虚拟内存、页表切换) 小 (不涉及内存地址空间切换) 通信难度 难 (IPC：管道、Socket等) 易 (直接读写共享变量) 稳定性 进程间隔离，一个崩了不影响其他 一个线程崩了可能搞挂整个进程 并发性 也可以并发，但资源消耗大 并发性高，资源消耗小 Redis的内存淘汰机制 当 Redis 的内存使用量达到在 redis.conf 中配置的 maxmemory 上限时，为了能继续接收新的写入请求，Redis 必须根据配置的策略删除一部分数据。这就是 Redis 的内存淘汰机制。\nRedis 提供了 8 种 淘汰策略（Redis 4.0 之后），我们可以从**“淘汰范围”和“淘汰算法”**两个维度来理解。\n1. 两个核心维度 在记忆这些策略之前，先理解两个概念，这样就不需要死记硬背了：\n淘汰范围（也就是“去哪里选”）：\nallkeys：从所有键中筛选（不管有没有设置过期时间）。通常用于把 Redis 当纯缓存用的场景。\nvolatile：只从**设置了过期时间（TTL）**的键中筛选。通常用于把 Redis 当数据库用，同时又想缓存一部分临时数据的场景。\n淘汰算法（也就是“怎么选”）：\nLRU (Least Recently Used)：最近最少使用。\nLFU (Least Frequently Used)：最不经常使用（Redis 4.0+）。\nRandom：随机。\nTTL：快过期的。\nRedis 的 LRU 是真的 LRU 吗？ 不是。 Redis 使用的是近似 LRU 算法（Approximated LRU）。\n原因： 严格的 LRU 需要维护一个巨大的双向链表，每访问一次 key 就要移动节点，这非常消耗内存且影响性能。\n实现： Redis 采用随机采样的方式。当需要淘汰时，它随机抽取 N 个 key（默认 5 个，由 maxmemory-samples 配置），然后淘汰这 N 个里面最久没被访问的那一个。\n效果： 虽然是近似的，但在 Redis 3.0 优化后，效果已经非常接近严格 LRU 了。\nRedis的各种淘汰策略 策略前缀 策略后缀 (算法) 含义 适用场景 noeviction - 不淘汰，写请求报错 纯数据存储，数据不能丢 allkeys -lru 所有Key + 最近最少使用 通用缓存 (推荐) allkeys -lfu 所有Key + 最不经常使用 即使最近被访问过，总体访问频率低也被淘汰 allkeys -random 所有Key + 随机 极少使用 volatile -lru 过期Key + 最近最少使用 混合存储，只淘汰缓存部分 volatile -lfu 过期Key + 最不经常使用 同上 volatile -random 过期Key + 随机 极少使用 volatile -ttl 过期Key + 剩余时间最短 让快过期的先走 Java的双亲委派模型是什么？ 双亲委派模型（Parent Delegation Model） 是 Java 类加载机制的核心设计思想。\n虽然名字听起来有点高大上（甚至有点拗口），但它的核心逻辑非常简单，用一句话概括就是：“这也是为了你好：有事儿先找你爹，你爹搞不定你再自己来。”\n下面我从结构、流程、作用和例外四个方面为你拆解。\n1. 谁是“双亲”？（类加载器的层级） 在 Java 中，类加载器（ClassLoader）是有层级关系的。并不是真的有两个亲戚（“双亲”这个翻译其实有点误导，它指的是 Parent，即父级）。\n主要的类加载器有三层：\n启动类加载器 (Bootstrap ClassLoader)\n地位： 老祖宗，最顶层。\n职责： 负责加载 Java 的核心类库（如 java.lang.String, rt.jar 等）。它是用 C++ 写的，在 Java 代码里拿不到它的引用（也就是 null）。\n它负责加载 Java 运行时环境（JRE）中最核心的库。这些类位于 $JAVA_HOME/jre/lib 目录下，通常打包在 rt.jar (Runtime Jar) 中。\n💡 具体例子： 只要是 java.* 开头的几乎都是它加载的。\n基础类型包装类： java.lang.Integer, java.lang.Double, java.lang.String\n集合框架： java.util.ArrayList, java.util.HashMap, java.util.HashSet\nIO 流： java.io.File, java.io.FileInputStream\n并发包： java.util.concurrent.ConcurrentHashMap\n线程： java.lang.Thread\n🧐 现象： 如果你在代码里打印 String.class.getClassLoader()，你会得到 null。这不是因为没加载，而是因为 Bootstrap 是用 C++ 写的，Java 代码无法获取它的引用。\n扩展类加载器 (Extension ClassLoader)\n地位： 中间层。\n职责： 负责加载 Java 的扩展库（JAVA_HOME/lib/ext 目录下的 jar 包）。\n它负责加载 $JAVA_HOME/jre/lib/ext 目录下的类库，或者被 java.ext.dirs 系统变量所指定的路径。它是对 Java 核心功能的补充。\n💡 具体例子： 这些类通常平时用得少一点，多涉及一些加密、特殊网络协议或 XML 解析等。\n加密库： com.sun.crypto.provider.SunJCE (Java 加密扩展，做 AES/DES 加密时会用到)\nDNS 相关： sun.net.spi.nameservice.dns.DNSNameService (某些 JDK 版本下的 DNS 解析服务)\nJavaScript 引擎： jdk.nashorn.api.scripting.NashornScriptEngine (Java 8 中内置的 JS 引擎)\n应用程序类加载器 (Application ClassLoader)\n地位： 最底层（系统默认）。\n职责： 负责加载我们自己写的代码（ClassPath 下的类）和第三方 Jar 包。\n这是我们接触最多的加载器。它负责加载 CLASSPATH 环境变量或系统属性 java.class.path 指定的类库。\n💡 具体例子： 凡是你自己在工程里写的，或者在 pom.xml / build.gradle 里引用的，都归它管。\n你写的业务代码：\ncom.example.project.UserController\ncom.example.project.MyUtils\n你的 Main 启动类\n第三方开源框架（Maven 依赖）：\nSpring 全家桶： org.springframework.boot.SpringApplication, org.springframework.context.ApplicationContext\n数据库驱动： com.mysql.cj.jdbc.Driver (注意：虽然 Driver 接口是核心的，但 MySQL 的实现类是 App 加载的)\n中间件客户端： org.apache.rocketmq.client.producer.DefaultMQProducer (RocketMQ), com.alibaba.dubbo.config.ApplicationConfig (Dubbo)\n工具类： com.alibaba.fastjson.JSON, org.apache.commons.lang3.StringUtils\n此外，还可以有自定义类加载器 (Custom ClassLoader)，挂在应用程序类加载器下面。\n2. 委派流程（怎么工作？） 当一个类加载器收到了类加载的请求时，它不会自己立即去加载，而是遵循以下步骤：\n向上委托： 它会把这个请求委托给父类加载器去执行。\n层层传递： 父类加载器如果还有父类，就继续向上委托，直到传到最顶层的 Bootstrap ClassLoader。\n向下尝试：\nBootstrap 尝试加载，如果找到了（比如是 String），就直接返回。\n如果 Bootstrap 没找到（也就是它管辖的范围里没有这个类），就告诉子类（Extension）：“我搞不定，你来吧”。\nExtension 尝试加载，如果没找到，再往下交给 Application。\nApplication 尝试加载，如果也没找到，就会抛出 ClassNotFoundException。\n3. 为什么要这么设计？（核心作用） 双亲委派模型主要解决了两个大问题：\n✅ 1. 安全性 (Security) —— 防止核心 API 被篡改 假设黑客写了一个恶意的类，名字也叫 java.lang.String，并且放在了你的 ClassPath 下。 如果没有双亲委派，系统就会加载这个恶意的 String 类，你的密码、数据全都会被黑客截获。 有了双亲委派： 系统在加载 String 时，会一直往上找，最终由 Bootstrap ClassLoader 加载了 JDK 自带的那个正版 String。黑客写的那个类永远没有机会被加载。\n✅ 2. 避免重复加载 (Uniqueness) Java 类在内存中的唯一性是由 “类加载器 + 类全名” 共同决定的。 如果同一个 System 类被两个不同的加载器各加载了一次，JVM 会认为它们是两个完全不同的类，这会导致类型转换异常，系统会乱套。 双亲委派保证了核心类永远只由顶层的加载器加载一次。\n4. 什么时候需要打破双亲委派？ 虽然双亲委派很好，但在某些特殊场景下，它反而成了阻碍，我们需要“打破”它（即：不让父类先加载，而是自己先加载，或者绕过父类）。\n经典案例：\nTomcat (Web 容器)：\nTomcat 上可能部署了两个 Web 应用，一个用 Spring 4，一个用 Spring 5。\n如果用默认的双亲委派，Spring 类库只能加载一份，会导致冲突。\n解决： Tomcat 自定义了类加载器，优先加载 Web 应用自己 WEB-INF/lib 下的类，打破了“向上委托”的规则（先自己找，找不到再问爸爸）。\nJDBC (SPI 机制)：\nJava 核心包提供了 java.sql.Driver 接口（在 Bootstrap 层加载）。\n但是具体的实现（如 MySQL 驱动）是第三方厂商提供的（在 ClassPath 下，由 App 层加载）。\n这里出现了一个悖论：Bootstrap 层的代码需要去调用 App 层的代码。父加载器是看不到子加载器的类的。\n解决： 使用 线程上下文类加载器 (Thread Context ClassLoader)，让父级加载器“走后门”拿到子级加载器去加载类。\nHashMap与ConcurentHashMap的区别 HashMap 和 ConcurrentHashMap (CHM) 的核心区别在于：线程安全性和底层实现机制\n简单来说：\nHashMap 是非线程安全的，性能极高，适合单线程。\nConcurrentHashMap 是线程安全的，高并发下性能依然优秀，适合多线程。\n核心区别详解 ① 线程安全性 (Thread Safety) HashMap:\n不安全。 如果多个线程同时写入 HashMap，可能会导致数据覆盖（Data Race）。\n严重问题： 在 JDK 1.7 中，多线程并发扩容（Resize）时甚至会导致链表成环，造成 Infinite Loop（死循环），CPU 飙升 100%。虽然 JDK 1.8 修复了死循环问题，但依然会有数据丢失风险。\nConcurrentHashMap:\n安全。 它是专门为并发设计的。内部使用了非常精妙的锁机制和 CAS 操作，保证了多线程下的数据一致性。 ② 锁的粒度 (Locking Granularity) —— 性能的关键 HashMap: 没有锁。\nHashtable (反面教材): 使用 synchronized 锁住整个 Map（一把大锁）。只要有一个线程在写，其他线程无论是读还是写都得排队，效率极低。\nConcurrentHashMap:\nJDK 1.7: 使用 分段锁 (Segment Locking)。将数据分成一段一段（默认 16 段），每次只锁住被修改的那一段。\nJDK 1.8 (优化): 抛弃了分段锁，采用 CAS + synchronized。锁的粒度更细，只锁住哈希桶的头节点。这意味着只要两个线程操作的 Key 不在同一个桶（Hash冲突），它们就可以完全并行，互不干扰！\n能用无锁（CAS）解决的就用无锁，解决不了的再用锁（synchronized），而且锁本身也做了巨大的优化\n1. CAS (Compare And Swap) —— 冲锋在前的“轻骑兵” CAS 是一种乐观锁机制。它的核心思想是：“我认为没人跟我抢，所以我直接尝试更新。如果真的有人抢（比较失败），我再重试或放弃。”\n在 JDK 1.8 的 CHM 中，CAS 主要用于无竞争场景和状态设置，它的速度非常快，因为它直接对应 CPU 的一条原子指令（cmpxchg）。\nCAS 在哪里用？ 插入新节点（最关键的路径）： 当 put 一个数据时，如果计算出的 Hash 槽位（Bucket）是空的（没有发生哈希冲突），CHM 不会加锁，而是直接用 CAS 尝试把新节点放入该位置。\n代码逻辑： casTabAt(tab, i, null, new Node(...))\n优势： 这种情况在哈希散列良好的情况下非常常见，完全避免了加锁的开销。\n初始化数组： 在 initTable 方法中，通过 CAS 修改 sizeCtl 变量（将其设为 -1），来抢占“初始化数组”的权利。只有一个线程能 CAS 成功，其他的线程会 yield 让出 CPU。\n计数更新： 在 addCount 方法中，利用类似 LongAdder 的机制（Cells 数组），通过 CAS 累加元素的数量。\nCAS 的潜在问题： ABA 问题：（虽然在 CHM 的节点插入中通常不涉及，但在其他并发场景需注意）。\n自旋开销： 如果竞争太激烈，CAS 一直失败重试（自旋），会白白浪费 CPU 资源。\n2. Synchronized —— 坐镇后方的“重装卫士” 在 JDK 1.6 之前，synchronized 是重量级锁，性能很差。但在 JDK 1.8 中，它是经过武装牙齿的“新式重甲”。\nSynchronized 在哪里用？ 仅在发生哈希冲突时使用。\n当 put 数据时，如果发现目标槽位已经有节点了（Hash 冲突），CAS 就搞不定了（因为要操作链表或红黑树，涉及多个指针的变动，CAS 很难保证原子性）。 此时，CHM 会用 synchronized 锁住该槽位的头节点。\n底层实现深度对比 (JDK 1.7 vs JDK 1.8) 这是面试中最能体现深度的部分，重点关注 ConcurrentHashMap 的演进。\nHashMap JDK 1.7: 数组 + 链表。\nJDK 1.8: 数组 + 链表 + 红黑树。当链表长度 \u0026gt; 8 且数组长度 \u0026gt; 64 时，链表会转为红黑树，将查询复杂度从 $O(n)$ 优化到 $O(\\log n)$。\nConcurrentHashMap (进化史) 特性 JDK 1.7 (分段锁) JDK 1.8 (CAS + Synchronized) 核心结构 Segment 数组 + HashEntry 数组 + 链表 Node 数组 + 链表 + 红黑树 锁机制 ReentrantLock (Segment 继承自它) CAS (乐观锁) + synchronized 锁粒度 粗。锁住一个 Segment (默认含多个 Hash 桶) 细。只锁住当前 Hash 桶的头节点 并发度 受限于 Segment 个数 (默认 16) 理论上等于 Hash 桶的数量 (数组长度) 读操作 volatile 保证可见性，无锁 volatile 保证可见性，无锁 JDK 1.8 为什么要放弃分段锁？\n内存占用： 每个 Segment 都要继承 ReentrantLock，通过 AQS 维护队列，内存开销大。\n锁粒度不够细： 即使分了 16 段，依然可能存在多个线程竞争同一个段的情况。\n效率提升： JDK 1.6 之后 JVM 对 synchronized 做了大量优化（偏向锁、轻量级锁），在低竞争下性能已经非常好了，没必要维护复杂的 ReentrantLock。\n3. 总结对比表 维度 HashMap ConcurrentHashMap 线程安全 ❌ 否 ✅ 是 Null Key/Value ✅ 允许 ❌ 不允许 原理 (JDK8) 数组 + 链表 + 红黑树 数组 + 链表 + 红黑树 + CAS + synchronized 扩容机制 新建数组 -\u0026gt; 迁移数据 能够支持多线程并发协助扩容 (这是 CHM 1.8 的黑科技) 应用场景 局部变量、单线程环境 全局缓存、高并发环境 为什么要用synchronized去处理hash冲突 CAS 的“射程”只有 1 个变量 (One Word) 这是核心原因。 CAS 只能保证对“内存中某一个地址”的更新是原子的。\n没有冲突时（put 到空槽位）： 只需要把 Node 放入数组的 tab[i] 位置。这就只涉及一个变量（数组的一个坑位）的修改。\nCAS(tab, i, null, newNode) -\u0026gt; 搞得定！ ✅ 有冲突时（链表/红黑树）： 这就不是改一个变量的事了，这是一个复合操作（Compound Operation）。\n场景一：链表追加 你需要先遍历链表找到最后一个节点 Tail，然后把 Tail.next 指向 NewNode。 看似只改了 Tail.next 一个变量，但在并发环境下，你必须保证从你找到 Tail 到你修改 Tail 的这段时间里，Tail 没有被别人删掉，也没有别人在后面先插了一脚。如果要用 CAS 解决这个问题，必须极其复杂的自旋重试，代码复杂度指数级上升。\n场景二：红黑树旋转 (最致命的) 红黑树插入节点后，为了保持平衡，可能需要变色和旋转。 一次旋转（左旋/右旋）往往涉及到 3 到 5 个指针的同时修改（父节点指向子节点、子节点指向孙节点、父节点指向新的子节点\u0026hellip;）。 CAS 一次只能改 1 个指针，无法同时原子性地修改 3 个指针。 如果你用 3 次 CAS 分别去改，那在第 1 次和第 2 次之间，树的结构是断裂的。其他线程读到这个断裂的树，程序直接崩了。\n结论： synchronized 锁住的是**“一段代码逻辑”（原子性范围大），而 CAS 锁住的是“一个变量”**（原子性范围小）。处理复杂数据结构变动，必须用大范围的锁。\nRedis挂了RocketMQ挂了都怎么处理 Redis 挂了怎么处理？ Redis 挂了，最大的风险是大量流量瞬间击穿缓存，直接打到数据库（MySQL），导致数据库宕机，引发“缓存雪崩”。\n1. 架构层面（事前：别让它挂） 生产环境绝对不能用单机版（Standalone）Redis。\n哨兵模式 (Sentinel)： 此时如果主节点挂了，哨兵会自动选举一个从节点变成主节点。业务层感知很小。\n集群模式 (Cluster)： 数据分片。某一个分片的主节点挂了，该分片的从节点上位。\n2. 应用层面（事中：挂了怎么办） 这是开发最需要关心的。如果 Redis 真的全挂了，代码必须有降级策略。\n方案 A：二级缓存（本地缓存）兜底\n策略： 请求先查 Redis -\u0026gt; Redis 挂了/没数据 -\u0026gt; 查本地缓存 (如 Caffeine/Guava) -\u0026gt; 本地也没 -\u0026gt; 查数据库。\n作用： 本地缓存虽然容量小，但能扛住短期的高热点流量，给数据库争取喘息时间。\n方案 B：熔断与限流（Circuit Breaker \u0026amp; Rate Limiting）\n工具： Sentinel (阿里), Hystrix, Resilience4j。\n逻辑： 当监测到访问 Redis 的异常率飙升（比如连接超时），直接熔断 Redis 调用。\n后续： 请求不再去连 Redis（防止卡死线程），而是直接限流访问数据库。比如平时 10000 QPS，Redis 挂了，限制只有 200 QPS 能打到数据库，剩下的请求直接报错或返回默认值。\n目的： 保住数据库！ 只要数据库还活着，服务就还有救；数据库挂了，整个系统就完了。\n方案 C：服务降级\n如果是非核心业务（比如“猜你喜欢”、“热搜榜”），Redis 挂了直接返回空数据或静态的默认数据，不要去查数据库。 3. 关于分布式锁 如果你的系统依赖 Redis 做分布式锁（Redisson），Redis 挂了会导致锁失效或无法加锁。\n处理： 这种情况下通常需要业务报错（Fail Fast），或者降级为数据库乐观锁（Version字段），但并发性能会大打折扣。\nMQ (消息队列) 挂了怎么处理？ MQ (如 RocketMQ, Kafka, RabbitMQ) 挂了，最大的风险是上下游解耦失败，导致核心链路断开（如下单成功了，但扣库存/发积分的消息发不出去了），或者数据丢失。\n1. 架构层面（事前：别让它挂） 集群部署： 无论是 Kafka 还是 RocketMQ，都是主从/多副本机制。\n多机房/多Broker： 确保一个 Broker 挂了，Producer 可以自动重连到其他 Broker 发送消息。\n2. 应用层面（事中：生产者发不出去怎么办？） 这是最关键的。如果 MQ 彻底连不上了，生产者（Producer）必须有备选方案。\n方案 A：本地消息表（Local Message Table）—— 最稳妥方案\n原理： 既然 MQ 连不上，那就把消息写到本地数据库的一张表里（和业务数据在同一个事务中）。\n流程：\n开启数据库事务。\n执行业务 SQL（如下单）。\n执行插入 SQL：INSERT INTO local_msg_table ... status='PENDING'。\n提交事务。\n恢复： 启动一个定时任务（Timer），轮询这张本地消息表，把状态是 \u0026lsquo;PENDING\u0026rsquo; 的消息尝试重新发给 MQ。一旦发送成功，从表中删除或更新状态。\n方案 B：写入本地磁盘/文件\n原理： 如果数据库压力也很大，可以将消息内容追加写入服务器的本地日志文件。\n恢复： 后续写个脚本读取日志文件，重新灌入 MQ。\n方案 C：同步直连（极端降级）\n如果业务允许，当 MQ 挂了，消费者（Consumer）提供一个 HTTP/RPC 接口。生产者发现 MQ 发送失败，直接调用消费者的 RPC 接口（将异步变同步）。\n缺点： 失去了削峰填谷的作用，消费者可能扛不住压力。\n3. 应用层面（事中：消费者收不到怎么办？） 积压处理： MQ 挂了期间，消息无法消费。等 MQ 恢复后，可能会有海量消息涌入。\n策略： 消费者需要评估是否增加线程数，或者临时起一套只负责“搬运”的消费者，把消息快速落库，然后再慢慢处理，防止消费者被压垮。\n介绍TiDB的计算与存储分离，和MySQL的区别是什么 一句话概括：TiDB 把“处理 SQL 的脑子”和“存数据的肚子”彻底分开了，中间通过网络（RPC）通信。\n一、 TiDB 的计算与存储分离架构 TiDB 的架构主要由三大组件组成，完美体现了这种分离：\n1. 计算层：TiDB Server（无状态的“大脑”） 职责： 负责接收客户端的 SQL 请求，进行 SQL 解析、语法检查、制定查询计划（Optimizer）、生成执行器。\n特点： 它是无状态的（Stateless）。 它不存储任何实际的数据。\n扩展性： 如果你发现 SQL 解析慢了，或者并发连接数太高了，只需要加几台 TiDB Server 机器就行，完全不需要进行数据迁移。\n2. 存储层：TiKV（分布式的“肚子”） 职责： 负责存储真正的数据。底层是一个巨大的、分布式的、有序的 Key-Value Map。\n实现： 内部使用 RocksDB 存储引擎。数据被切分成很多个 Region（默认 96MB），通过 Raft 协议（类似 Paxos）保证多副本一致性。\n扩展性： 如果你发现硬盘满了，或者磁盘 I/O 扛不住了，只需要加几台 TiKV 机器，数据会自动均衡过去。\n3. 调度层：PD (Placement Driver)（“总指挥”） 职责： 存储元数据（哪个 Key 在哪个 TiKV 上），负责给 TiDB Server 提供路由信息，同时指挥 TiKV 进行数据搬迁和负载均衡。 二、 TiDB 与 MySQL 的核心区别 我们将传统 MySQL（单机或主从架构）与 TiDB 进行深度对比：\n维度 MySQL (传统架构) TiDB (存算分离架构) 架构模式 紧耦合 (Monolithic) 松耦合 (Microservices-like) 进程结构 SQL 解析器和 InnoDB 引擎在同一个进程 (mysqld) 中。 SQL 解析在 TiDB 进程，数据存储在 TiKV 进程，通常部署在不同机器上。 通信方式 内存函数调用 (Function Call)，极快。 网络 RPC 调用 (gRPC)，有网络延迟开销。 扩展能力 (Scaling) 垂直扩展 (Vertical)：买更好的 CPU/内存。\n分库分表：需要中间件，运维极其痛苦。 水平扩展 (Horizontal)：计算不足加 TiDB，存储不足加 TiKV，完全透明，业务无感知。 查询执行 数据在哪，计算就在哪。 分布式计算：TiDB 生成计划，分发给多个 TiKV 并行处理。 事务限制 受限于单机内存和磁盘，大事务容易导致主从延迟。 基于 Percolator 模型 (Google) 的两阶段提交 (2PC)，支持跨行跨表分布式事务。 高可用 需依赖 MHA/Orchestrator，主从切换可能丢数据或需人工介入。 基于 Raft 协议，自动选主，强一致性，RPO = 0（数据不丢）。 为什么lua脚本能保证原子性？ 简单直接的答案是：因为 Redis 的主工作线程是单线程的，且 Lua 脚本在执行时是“排他”的。\n我们可以把 Redis 想象成一个只开了一个窗口的办事大厅，而 Lua 脚本就是一份必须一次性办完的复杂文件。\n以下是深度的技术原理拆解，帮助你在面试中不仅能答对，还能答出深度：\n1. 核心机制：单线程 + 独占模式 Redis 的核心命令执行器是单线程的（Event Loop）。\n普通命令（如 SET/GET）： Redis 会从队列里一个个取出来执行。A 客户端发一个 SET，B 客户端发一个 GET，它们是排队轮流执行的。\nLua 脚本（EVAL）： 当 Redis 读到 EVAL 命令（执行 Lua 脚本）时，它会进入一种独占模式。\nRedis 会暂停处理所有其他客户端发来的请求。\n它把整个 Lua 脚本作为一个整体交给 Lua 解释器执行。\n只有当脚本执行结束（或者超时），Redis 才会恢复去处理请求队列里排队的下一个命令。\n结论： 在 Lua 脚本执行期间，绝对不会有其他客户端的命令插队。这就从物理上保证了脚本内的操作是不可分割的（Indivisible），也就是原子性。\n面试高阶陷阱：此“原子性”非彼“原子性” 这是面试官最喜欢挖的坑，一定要主动指出来：\nRedis Lua 脚本的“原子性”是指“隔离性 (Isolation)”，而不是数据库事务中的“原子性 (Atomicity，要么全做要么全不做)”。\nSQL 事务： 如果中间报错，会回滚 (Rollback)，像什么都没发生过一样。\nRedis Lua： 如果脚本里有 3 条命令，执行到第 2 条报错了：\n第 1 条已经生效的数据不会回滚！\n第 2 条报错停止。\n第 3 条不会执行。\n脚本结束。\n面试话术：\n“Redis 的 Lua 脚本保证的是执行过程不被其他客户端打断，保证了操作的原子隔离性。但是，Redis 不支持回滚 (Rollback)。如果脚本内部逻辑抛出错误，之前执行成功的写操作是无法撤销的。所以在编写 Lua 脚本时，必须保证代码逻辑的健壮性。”\n我的简历中使用了 Redisson 的 RRateLimiter ，这个组件的底层就是纯 Lua 脚本实现的。\n可以这样举例：\n“比如我在项目中使用的令牌桶限流。\n我需要查询当前令牌够不够（GET）。\n如果够，我就要扣减一个令牌（DECR）。\n这两个操作如果分开执行，在高并发下会出现‘超卖’（两个线程同时看到令牌剩余 1 个，结果都扣减了，变成 -1）。 而 Redisson 将这两个动作封装在一个 Lua 脚本里发给 Redis，因为 Lua 的原子性，这两个动作瞬间完成，中间没缝隙，绝对不会出现超卖。”\n为什么这比 Redis原生事务更强？ Redis 原生事务（MULTI/EXEC）存在一个痛点：CAS (Check-And-Set) 问题。\nRedis 事务流程： 你必须先 GET 一个值到客户端，判断一下（Check），然后再发 SET 命令（Set）。\n竞态条件： 在你 GET 之后、SET 之前，因为网络延迟，另一个客户端可能修改了这个值。虽然 WATCH 可以监控变化并取消事务，但这意味着你需要写重试逻辑，高并发下失败率极高。\nLua 的优势： 逻辑直接在服务端运行。GET 和 SET 之间没有网络通信延迟，且中间没有其他命令插入。你可以放心地读取一个值，修改它，再写回去，完全不用担心期间被别人改了。\n介绍一下虚拟内存 虚拟内存 (Virtual Memory)，一言以蔽之，是操作系统对所有进程撒的一个弥天大谎。\n它给每个进程（比如你的 Java 程序）营造了一个美丽的幻觉：\n“兄弟，这整个电脑的内存全是你的！是连续的！是独占的！你想怎么用怎么用，不用管别人。”\n但实际上，物理内存（RAM）可能早就被碎尸万段，甚至塞满了，部分数据都被赶到硬盘上去了。\n在很久以前（DOS 时代），确实没有虚拟内存。程序直接操作物理地址。 这会导致三个严重问题：\n打架（地址冲突）：\nQQ 说：“我要住 101 号房间。”\n微信说：“我也要住 101 号房间。”\n崩了。程序员必须小心翼翼地规划，谁用哪块地。\n偷窥（不安全）：\nQQ 住 101，微信住 102。\n微信稍微伸个头，就能看到 QQ 在 101 房间里的隐私（读取内存数据）。恶意程序可以随意修改操作系统的核心数据。\n不够用（内存不足）：\n你有 4GB 内存，GTA5 游戏要 8GB。直接报错退出，玩不了。 二、 虚拟内存的机制（怎么圆这个谎？） 为了解决上面的问题，操作系统引入了中间商。\n1. 核心道具：页表 (Page Table) \u0026amp; MMU 虚拟地址 (Virtual Address)：进程手里拿到的房卡号（比如 0x001）。这是假的。\n物理地址 (Physical Address)：内存条上真正的存储单元地址（比如 0x8F3）。这是真的。\n映射表 (Page Table)：记录“假房号”对应“真房号”的小本本。\nMMU (Memory Management Unit)：CPU 里专门负责查表的一个硬件单元。\n2. 工作流程 当你的 Java 程序执行指令 int a = 10 (假设要把 10 写到地址 0x001)：\n进程发出指令：“我要往 0x001 写数据！”（这是虚拟地址）。\nMMU 拦截：“稍等，我查一下表。”\nMMU 查页表发现：进程 A 的 0x001 对应物理内存的 0x8F3。 硬件执行：CPU 把数据写到了物理内存的 0x8F3。\n妙在哪里？\nQQ 往 0x001 写数据 -\u0026gt; 映射到物理地址 0x800。\n微信 往 0x001 写数据 -\u0026gt; 映射到物理地址 0x900。\n虽然他们用的虚拟地址一样，但物理上完全隔离，互不干扰！\n缺页中断 (Page Fault) —— “空手套白狼” 这是虚拟内存最骚的操作。 你的 Java 程序申请了 1GB 内存（比如 new byte[1024*1024*1024]）。 操作系统直接答应：“好，给你 1GB！”（虚拟内存里划给你了）。 但实际上，物理内存里 1KB 都没给你分配。\n当你真正开始写数据时：\nCPU 拿着虚拟地址去查表。\nMMU 发现：“夷？这个页在物理内存里不存在（Valid 位是 0）。”\n触发 缺页中断 (Page Fault)。\n操作系统内核醒来：“哎呀，这小子来真的了。”\n操作系统赶紧找一块空闲的物理内存，分配给这个页，更新映射表。\n让 CPU 重新执行刚才的写入指令。\n这就是为什么 Java 启动时申请大内存很快，但实际占用（RES）是随着运行慢慢涨上去的。\n交换 (Swap) —— 硬盘来凑数 如果物理内存真满了（比如开了几十个 Chrome 标签页），怎么办？\n动作：操作系统会把那些很久没用的页（冷数据），从物理内存里踢出来，写到硬盘上（Swap 分区 / pagefile.sys）。\n腾地：物理内存腾出来了，给当前急用的程序用。\n换回：当你突然切回那个很久没用的 Chrome 标签页，操作系统会再触发缺页中断，把硬盘里的数据读回物理内存（这时候你会感觉电脑卡了一下，硬盘灯狂闪）。\n操作系统中有很多内存淘汰策略，比如LRU，LFU，CLOCK，增强CLOCK等\n进程切换和线程切换的区别? 1.进程切换:进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大。 2.线程切换:线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小。\n线程切换为什么比进程切换快，节省了什么资源? 线程切换比进程切换快是因为线程共享同一进程的地址空间和资源，线程切换时只需切换堆栈和程序计数器等少量信息，而不需要切换地址空间，避免了进程切换时需要切换内存映射表等大量资源的开销，从而节省了时间和系统资源。\nJNI 是什么？ 它在 Java 编程中是一个非常重要的机制，主要用于解决 Java 应用程序需要与本地代码（Native Code）交互的问题。\nJNI 的核心概念与作用 1. 核心定义 JNI 是一套编程接口，它允许运行在 Java 虚拟机（JVM） 上的 Java 代码与用其他语言（如 C、C++ 等）编写的本地应用程序和库进行交互。\n2. 主要作用 调用本地库 (Calling Native Libraries): 允许 Java 程序调用操作系统底层功能、硬件设备驱动程序，或者使用已经存在的、用 C/C++ 等语言编写的高性能库。\n提高性能 (Performance Enhancement): 对于对性能要求极高或需要直接操作硬件的代码块，可以将其用 C/C++ 实现，并通过 JNI 在 Java 中调用，以提升执行效率。\n复用现有代码 (Reusing Existing Code): 允许开发者在 Java 项目中重用大量的现有 C/C++ 代码库，而无需将其完全重写成 Java。\nJNI 的缺点 虽然 JNI 很强大，但它也有一些缺点：\n失去跨平台性： 一旦使用 JNI，你的 Java 程序就依赖于特定的本地库文件，从而失去了 Java “一次编译，到处运行” 的跨平台优势。\n开发复杂性： JNI 的开发过程比纯 Java 复杂，需要处理 C/C++ 代码、头文件生成、本地内存管理和垃圾回收的交互等问题。\n安全和稳定性风险： 本地代码不受 JVM 内存管理和安全机制的保护。如果本地代码有内存泄漏或越界访问等错误，可能导致整个 JVM 崩溃。\nSpringBoot程序的JDBC连接到了MySQL，用的是UDS，请问流程是什么 场景准备 主角 A (Spring Boot)：位于 Linux 系统的一个进程（假设 PID=100）。\n主角 B (MySQL)：位于 Linux 系统的另一个进程（假设 PID=200）。\n秘密通道 (UDS 文件)：MySQL 在启动时，会在硬盘上创建一个特殊文件，通常位于 /var/lib/mysql/mysql.sock（这个路径在 my.cnf 里配置）。\n配置上的不同（这是关键第一步）： 平时你连数据库，URL 写的是 jdbc:mysql://127.0.0.1:3306/...。 用 UDS 时，你的 JDBC URL 会变得很奇怪，大概长这样（取决于具体的驱动实现，通常需要引入 junixsocket 等库配合）：\nProperties\n1 2 # 意思就是：别走 TCP 了，帮我去连这个文件！ jdbc:mysql:///?socketFactory=org.newsclub.net.mysql.AFUNIXDatabaseSocketFactory\u0026amp;socket=/var/lib/mysql/mysql.sock 二、 详细连接流程（从发起请求到拿到数据） 假设你的 Controller 收到一个请求，要查 SELECT * FROM users。\n第一阶段：建立连接（握手） Java 发起系统调用：\nSpring Boot (JDBC 驱动) 解析 URL，发现要用 UDS。\n它不再调用 TCP 的 connect(ip, port)，而是调用针对文件的系统调用 socket(AF_UNIX, ...) 和 connect(\u0026quot;/var/lib/mysql/mysql.sock\u0026quot;)。\n操作系统（内核）介入：\n内核看到 Java 想连 /var/lib/mysql/mysql.sock。\n权限检查：内核检查运行 Java 进程的用户（比如 app_user）有没有对这个 sock 文件的读写权限。如果没有，直接报错 Permission denied。\n查找绑定：内核查看记录表，发现这个 sock 文件正被 PID=200 (MySQL) 监听（Listen）着。\n建立通道：\n内核在内存里，直接在 PID=100 (Java) 和 PID=200 (MySQL) 之间搭了一根“虚拟管子”。\n分配句柄：\n给 Java 进程发一个文件句柄（FD），比如 FD=8。\n给 MySQL 进程发一个文件句柄（FD），比如 FD=12。\n此时，连接建立完成。不需要 TCP 的三次握手（SYN, SYN-ACK, ACK），只有文件系统的查找开销。\n第二阶段：发送 SQL（写数据） Java 写数据：\nSpring Boot 把 SQL 语句 SELECT * FROM users 转成字节流。\n调用系统调用 write(FD=8, \u0026quot;SELECT...\u0026quot;)。\n内核搬运（最快的部分）：\n没有协议栈：内核不需要给数据包加 TCP 头、IP 头、不需要算校验和，也不需要路由查找。\n直接拷贝：内核直接把 Java 进程 发送缓冲区 里的数据，拷贝到 MySQL 进程的 接收缓冲区 里。\nMySQL 那个监听的 FD=12 变得“可读”。\nMySQL 读数据：\nMySQL 被唤醒，调用 read(FD=12)，拿到了 SQL 语句。 第三阶段：返回结果（读数据） MySQL 处理：\nMySQL 解析 SQL，查自己的 B+ 树，找到了 10 条用户数据。 MySQL 写回：\nMySQL 调用 write(FD=12, [用户数据])。 内核再次搬运：\n内核把数据直接从 MySQL 的内存搬运到 Java 的内存缓冲区。 Java 拿到结果：\nSpring Boot 从 read(FD=8) 中苏醒，拿到 ResultSet，封装成对象返回给 Controller。 如果用 TCP (127.0.0.1) 流程有啥区别？ 为了让你更直观地看到 UDS 省了啥，我们看看普通的 Localhost TCP 连接多了哪些步骤：\n打包：Java 把 SQL 加上 TCP 头（源端口、目标端口）、IP 头（源IP 127.0.0.1、目标IP 127.0.0.1）。\n计算：CPU 计算 TCP 校验和。\n路由：内核网络层查路由表，发现是回环地址（Loopback）。\n伪装发送：数据包虽然不出网卡，但要在内核的协议栈里走一圈“虚拟出网再入网”的流程（MTU检查、防火墙规则检查 iptables 等）。\n拆包：MySQL 端收到后，去掉 IP 头、去掉 TCP 头，校验数据的完整性。\n总结差异：\nTCP 方式：就像你写了一封信，虽然寄给同一个办公室的同事，但你还是把它扔进了楼下的邮局信箱。邮局（内核网络栈）盖戳、分拣、再投递回同一个办公室。\nUDS 方式：你直接站起来，把信放在了同事的桌子上。\nRedis把数据从内核内存区拷贝到用户内存的过程 详细流程图解（从 Socket 到 Redis） 假设一个客户端发来了 GET user:1。\n第一步：数据到达内核 网卡接收到光信号/电信号，转成数据包。\nDMA (直接内存访问) 把数据包拷贝到内核的内存（Socket 接收缓冲区）。\n内核检查这根 Socket 对应的句柄（FD），发现 Redis 之前通过 epoll_ctl 关注了它的“可读事件”。\n内核动作：把这个 FD 加入到 就绪链表 (Ready List) 中。\n第二步：Redis 醒来 Redis 主线程一直在跑一个死循环（aeMain）。\n循环里调用了 epoll_wait。\n刚才数据一到，epoll_wait 立刻返回，告诉 Redis：“嘿，FD=5 是可读的！”\n第三步：读取与执行 Redis 根据 FD=5，找到对应的处理函数（通常是 readQueryFromClient）。\n系统调用 read：把数据从内核搬运到 Redis 的用户态 Buffer。\n协议解析：解析 RESP 协议，知道你要执行 GET。\n查字典：在内存的 HashMap 里找到 user:1 的值。\n准备回复：把结果写入到客户端对象的发送缓冲区。\n第四步：回复客户端 如果发送缓冲区很小，Redis 直接当场就调用 write 发回去了。\n如果发送缓冲区满了（或者内核的写缓冲区满了），Redis 会向 epoll 注册一个 “写事件”。\n等下次内核告诉 Redis “这个 Socket 可以写了”，Redis 再继续把剩下的数据发完。\n操作系统的IO多路复用select，poll，epoll poll和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。\nepoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过epoll_ctl0 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是O(logn)。而 select/poll 内核里没有类似 epol 红黑树这种保存所有待检测的 socket 的数据结构，所以select/pol 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。\nepoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait0 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。\n我们来看一个最经典的场景：Redis 怎么把数据发给客户端？ 假设 Redis 要发送字符串 \u0026quot;Hello\u0026quot;。\n1. 物理位置 字符串 \u0026ldquo;Hello\u0026rdquo;：一开始在 Redis 的用户内存里。\nSocket 对象：在操作系统的内核内存里。\n2. 发送过程 (write) Redis 调用 write(fd, \u0026quot;Hello\u0026quot;) 系统调用。\n步骤 A：跨界拷贝（CPU Copy） CPU 暂停 Redis 的用户态运行，切换到内核态。 CPU 把 \u0026ldquo;Hello\u0026rdquo; 从 Redis 的用户内存 复制到 Socket 的发送缓冲区（内核内存）。 注意：这时候数据其实还在内存里，没出去呢！\n步骤 B：DMA 拷贝 操作系统看“发送缓冲区”里有货了，就命令 网卡（硬件）： “喂，把这块内存里的数据拿走发出去。” 网卡的 DMA 控制器直接把数据从内核内存搬运到网卡硬件上，然后变成电信号发走。\n3. 接收过程 (read) 客户端发来了一条命令 \u0026quot;GET\u0026quot;。\n步骤 A：硬件接收 网卡收到电信号，转成数据包，通过 DMA 搬运到 Socket 的接收缓冲区（内核内存）。 此时，Redis 还不知道数据来了。\n步骤 B：通知与唤醒 (Epoll) 内核发现这个 Socket 的接收缓冲区有数据了，于是通过 Epoll 告诉 Redis：“FD=5 有读事件了！”\n步骤 C：跨界拷贝（CPU Copy） Redis 醒来，调用 read(fd)。 CPU 把数据从 Socket 的接收缓冲区（内核内存） 复制到 Redis 的用户内存。 现在，Redis 终于可以在自己的变量里看到 \u0026quot;GET\u0026quot; 这三个字母了。\n内核内存和Socket是什么？ 内核内存 (Kernel Memory) —— “皇宫禁地” 在 Linux 操作系统中，物理内存（RAM）被逻辑上划分为两块：\n用户空间 (User Space)：\n谁在住？ 你的 Java 程序、Chrome 浏览器、QQ 等所有应用程序。\n地位：平民百姓。权力有限，想干大事（读硬盘、发网络包）必须打报告（系统调用）。\n特点：如果你的 Java 程序崩了，只是这块地盘乱了，不会影响整个电脑。\n内核空间 (Kernel Space) / 内核内存：\n谁在住？ 操作系统内核（Linux Kernel）、硬件驱动程序。\n地位：皇宫禁地（VIP）。拥有最高权限，可以随意操作 CPU、硬盘、网卡。\n特点：Socket 就存放在这里！ 还有页表、进程表等核心数据。如果这里崩了，电脑直接蓝屏或重启。\n为什么要有“内核内存”？ 主要是为了安全和隔离。防止你写了一个只有 bug 的代码，直接把操作系统的核心数据给改了，导致系统瘫痪。\nSocket 是什么？—— “插座与缓冲区” “Socket” 翻译过来叫“插座”或“套接字”。 但这个翻译太抽象了。在内核内存的视角里，Socket 到底是什么？\n本质上，Socket 就是内核内存里的两个缓冲区（Buffer）结构体。\n当你用 Java new Socket() 创建一个连接时，内核会在内核内存里划出一小块地盘，专门维护这个连接。这块地盘里主要包含两部分：\n接收缓冲区 (Recv Buffer)：\n像一个收件箱。\n网卡收到网线传来的数据，会先扔进这个箱子，等着你的 Java 程序来取。\n发送缓冲区 (Send Buffer)：\n像一个发件箱。\n你的 Java 程序想发数据，先把数据扔进这个箱子，然后由操作系统择机发给网卡。\n传统的Java17，是用户级线程和内核级线程一对一处理 在 Java 19（虚拟线程/协程）普及之前，Java 17 及更早版本，采用的确实是经典的 1:1 线程模型。\n这意味着：每一个 Java 线程（User Thread），在底层都死死绑定着一个操作系统的内核线程（Kernel Thread）。\n一、 核心关系：傀儡与真身 在 1:1 模型中，Java 线程和内核线程的关系，就像是 “皮影戏的傀儡” 和 “幕后的操纵者”。\nJava 线程 (User Thread)：\n这是你在代码里 new Thread() 创建出来的对象。\n它只是一个傀儡（皮影）。它有名字、有属性（ID、Priority），但它自己是没有生命的，动不起来。\n它生活在 JVM 的堆内存 里（用户态）。\n内核线程 (Kernel Thread / KLT)：\n这是操作系统（Linux/Windows）真正创建出来的工人。\n它是幕后的操纵者。只有它才能被 CPU 调度，只有它才有资格进 CPU 干活。\n它生活在 内核空间 里。\n所谓 1:1 映射：就是当你调用 thread.start() 时，JVM 会通过系统调用（System Call），向操作系统申请一个内核线程，然后把这个 Java 线程对象和那个内核线程**“绑死”**在一起。此后，这个 Java 线程的一举一动，其实都是那个内核线程在干活。\n二、 它们怎么“通信”？（控制权传递） 你问的“通信”，其实不是像发微信那样发消息，而是指令下达和状态同步。这一切都是通过 JNI (Java Native Interface) 和 系统调用 (System Call) 完成的。\n我们可以把这想象成牵线的过程。\n1. 启动指令：start() Java 层：你喊了一句 t1.start()。\n通信过程：\nJava 方法调用 private native void start0()。\n这就触碰到了 JVM 的 C++ 代码。\nJVM 向操作系统发起系统调用：clone() (Linux) 或 CreateThread (Windows)。\n操作系统：收到请求，创建一个真正的内核线程。\n绑定：JVM 把这个内核线程的 ID 记在 Java 线程对象里（建立了 1:1 关系）。\n2. 行为控制：sleep() / yield() / park() 场景：你在 Java 代码里写了 Thread.sleep(1000)。\n通信过程：\nJava 线程（傀儡）说：“我要睡一秒。”\nJVM 识别到这是个 Native 方法。\nJVM 发起系统调用，告诉内核：“喂，把你手里控制这个 Java 线程的那个内核线程挂起（Suspend）1秒。”\n操作系统：把对应的内核线程从 CPU 上也就是“运行队列”里拿下来，扔到“等待队列”里。\n结果：Java 线程看起来停了，其实是背后的内核线程停了。\n3. 阻塞同步：IO 操作 场景：你读取文件 fis.read()。\n通信过程：\nJava 代码执行到读取指令。\n因为读取硬盘是特权操作，Java 线程自己干不了，必须陷入内核态。\n对应的内核线程发起 IO 请求，然后被操作系统阻塞（因为它要等硬盘转圈圈）。\n反馈：内核线程不动了，Java 线程的状态也就变成了 BLOCKED 或 RUNNABLE (但在等待 syscall 返回)。\n三、 它们怎么调度？（谁说了算？） 这是最关键的：JVM 完全不管调度！JVM 是没有资格分配 CPU 时间片的。\n在 1:1 模型下，Java 线程的调度完全交给操作系统的调度器（Scheduler）。\n1. 调度者：OS 调度器（比如 Linux 的 CFS） JVM 就像一个劳务派遣公司，它把人（线程）招进来，交给政府（OS）去管理。至于谁先干活、谁后干活、干多久，全看政府的心情。\n2. 调度方式：抢占式 (Preemptive) 操作系统是个独裁者，它采用**“抢占式”**调度。\n时间片（Time Slice）：\nOS 给每个内核线程分配一小段 CPU 时间（比如 10ms - 100ms）。\n时间一到，CPU 内部的时钟中断响铃。\nOS 强行把当前线程踢下来（哪怕你代码还没跑完），换下一个线程上。\n上下文切换 (Context Switch) —— 昂贵的代价： 这就是 1:1 模型最大的痛点。当 OS 决定切换线程时：\n保存现场：把当前内核线程的寄存器值、程序计数器（跑到哪一行了）全部存回内存。\n刷新缓存：因为换人了，CPU L1/L2 缓存里的数据大部分都废了，需要重新加载。\n恢复现场：把下一个要运行的内核线程的信息读进寄存器。\n3. Java 优先级的尴尬 Java 里有 Thread.setPriority(1-10)。\n现实：这玩意儿基本是个心理安慰。\n原因：Java 的优先级只是给 OS 一个“建议”。由于不同操作系统对优先级的定义不同（Linux 甚至可能忽略它），JVM 传过去之后，OS 可能会说：“好的我知道了，但我还是按我的规则办。”\nsynchronized的底层原理 第一层：数据结构层 —— Mark Word 的比特位舞步 在 64 位 JVM 中，对象头（Object Header）里的 Mark Word 是 8 个字节（64 bit）。synchronized 的所有状态流转，本质上就是在修改这 64 个 bit。\n我们需要关注最后 2 位（锁标志位）和倒数第 3 位（偏向锁位）：\n锁状态 25 bit (未使用) 31 bit (HashCode) 1 bit (未用) 4 bit (分代年龄) 1 bit (偏向锁位) 2 bit (锁标志位) 无锁 \u0026hellip; HashCode 0 age 0 01 偏向锁 ThreadID (54bit) Epoch (2bit) \u0026hellip; age 1 01 轻量级锁 指向栈中 Lock Record 的指针 (62bit) \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 00 重量级锁 指向互斥量（Monitor）的指针 (62bit) \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 10 GC 标记 \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 11 底层细节：\n当锁是 轻量级锁 (00) 时，前 62 位不再存 HashCode，而是存一个内存地址指针，指向持有锁线程的栈帧。\n当锁是 重量级锁 (10) 时，前 62 位指向堆内存中 C++ 定义的 ObjectMonitor 对象。\n第二层：栈帧层 —— Lock Record (锁记录) 在轻量级锁阶段，JVM 并不想直接请求操作系统，它玩了一个“偷梁换柱”的把戏。\n开辟空间：当代码进入 synchronized 块，如果当前是无锁状态，JVM 会在当前线程的栈帧中创建一个名为 Lock Record 的空间。\nDisplaced Mark Word：JVM 把对象头里原本的 Mark Word 拷贝一份到这个 Lock Record 中（为了保存原本的 HashCode 和分代年龄，等锁释放了还得还回去）。\nCAS 争抢：JVM 尝试用 CAS (Compare And Swap) 指令，将对象头里的 Mark Word 替换为指向 Lock Record 的指针。\n成功：对象头变成了“指针 + 00”，代表抢锁成功。\n失败：说明有竞争，或者已经锁了。JVM 会检查对象头的指针是不是指向我自己的栈？如果是，说明是重入锁，只需在栈里再放一个空的 Lock Record 记录重入次数即可。\n第三层：JVM 实现层 —— C++ 里的 ObjectMonitor 当竞争升级为重量级锁，JVM 会去堆中申请一个 C++ 对象：ObjectMonitor。\n在 OpenJDK 的 HotSpot 源码中 (src/share/vm/runtime/objectMonitor.hpp)，它的核心结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 class ObjectMonitor { ... void * volatile _owner; // 指向当前持有锁的线程 (The King) volatile jlong _recursions; // 锁的重入次数 volatile int _count; // 抢锁计数器 // 核心等待队列 ObjectWaiter * volatile _cxq; // (Contention Queue) 竞争队列，单向链表 ObjectWaiter * volatile _EntryList; // 等待队列，双向链表 (阻塞状态的线程) ObjectWaiter * volatile _WaitSet; // 等待集合 (调用wait()后的线程) ... } 底层竞争流程（硬核版）：\nCAS 抢占：线程尝试通过 CAS 将 _owner 指针指向自己。成功则执行。\n自旋失败，入队：如果抢不到，线程被封装成 ObjectWaiter 对象。\n进入 cxq：线程首先通过 CAS 尝试把节点插入 _cxq 队列的头部（LIFO 策略，为了减少尾部维护开销）。\nOnDeck 机制：JVM 不会把所有人都唤醒，而是通过策略挑选一个继承人（Heir），称为 OnDeck，只有这个线程会去竞争锁，避免“惊群效应”。\n第四层：操作系统与硬件层 —— Futex 与 内存屏障 这是最底下的地基，也是为什么重量级锁慢的原因。\n1. 操作系统：Mutex 与 Futex 当线程在 ObjectMonitor 里抢不到锁，需要“阻塞（Block）”时，JVM 会调用操作系统的内核函数。\nLinux 环境下：\n早期：直接用 pthread_mutex_lock，这需要从用户态（User Mode）切换到内核态（Kernel Mode）。这个切换涉及到保存 CPU 寄存器上下文、刷新 CPU 缓存（L1/L2 Cache 失效）等，开销极大。\n现代优化 (Futex)：Linux 提供了 futex (Fast Userspace muTEX)。\n它先在用户态尝试通过 CAS 修改一个整数。\n只有当 CAS 失败（确实有竞争），才会调用系统调用（System Call）陷入内核态去执行 sem_wait 让线程挂起。\npark()：Java 中的 LockSupport.park() 底层就是调用了 futex 相关的系统调用。\n2. CPU 硬件：内存语义 (JMM) synchronized 不仅仅是锁，它还保证了 内存可见性。\nLock (monitorenter)：\n底层会插入一个 LoadBarrier（或类似的刷新指令）。\n强制让当前线程的工作内存（CPU Cache）失效，必须从主内存重新读取变量。\nUnlock (monitorexit)：\n底层会插入一个 StoreBarrier（写屏障）。\n强制将工作内存中的最新修改立即刷新回主内存，确保别的线程能看到。\n确保每次都能读到业务的最新的缓存信息，比如剩余票数还剩1个，把之前获取锁之前获取到的2给删了，重新更新为最新值，然后在把剩余票数变为0个。\n总结：一条线程的“黑化”之路 如果一个 Java 线程去抢 synchronized：\nCPU 指令层：先尝试 CAS 修改对象头。\n栈帧层：如果失败，检查是否是自己锁的（重入），或者尝试把 Mark Word 复制到自己栈帧（轻量级锁）。\nC++ 对象层：还失败？去堆里找 ObjectMonitor，把自己包装成 ObjectWaiter 节点，拼命往 _cxq 队列头挤。\nOS 内核层：挤不进去？调用 futex 系统调用，请求操作系统把自己挂起（Sleep），交出 CPU 时间片，从用户态跌落内核态，等待被唤醒。\n介绍一下Java里的volatile volatile 是 Java 虚拟机（JVM）提供的一种轻量级的同步机制。在并发编程中，它通常被用来修饰变量。\n理解 volatile，核心要抓住这三大特性：可见性、有序性，以及它不保证原子性。\n以下是详细的拆解：\n1. 核心特性 A. 保证可见性 (Visibility) 这是 volatile 最主要的作用。\n问题背景： 在 Java 内存模型 (JMM) 中，每个线程都有自己的工作内存 (Working Memory，对应 CPU 缓存)，变量存储在主内存 (Main Memory) 中。线程操作变量时，会先将变量从主内存拷贝到自己的工作内存中。如果线程 A 修改了变量，线程 B 可能还在读取自己缓存中的旧值，导致数据不一致。\nvolatile 的作用：\n当一个线程修改了 volatile 变量的值，新值会立即刷新到主内存。\n同时，会强制让其他线程工作内存中该变量的缓存失效。\n当其他线程需要读取该变量时，必须重新从主内存读取最新值。\nB. 禁止指令重排序 (Ordering) 问题背景： 为了提高性能，编译器和处理器通常会对指令进行重排序（即代码执行顺序可能与编写顺序不同），只要不影响单线程下的结果即可。但在多线程环境下，重排序可能导致严重的逻辑错误（例如：对象初始化了一半就被另一个线程使用了）。\nvolatile 的作用： JVM 会通过插入内存屏障 (Memory Barrier) 来禁止特定类型的指令重排序，从而保证有序性。\n经典案例： 单例模式的“双重检查锁”（Double-Checked Locking）。如果不加 volatile，可能导致拿到一个未完全初始化的对象。 C. 不保证原子性 (No Atomicity) 这是面试和开发中最大的坑。\n现象： volatile 不能替代 synchronized 或 Lock。\n例子： 对一个 volatile int count 执行 count++ 操作。\ncount++ 包含三个步骤：读值 -\u0026gt; 加 1 -\u0026gt; 写回。\n如果两个线程同时读到了 100，都加 1，然后都写回 101。最终结果是 101，而不是期望的 102。\n结论： 对于复合操作（Read-Modify-Write），volatile 无法保证线程安全。\n3. 什么时候使用 volatile？ 由于 volatile 比 synchronized 开销小（因为它不会引起线程上下文切换），在满足以下两个条件时，推荐使用：\n对变量的写操作不依赖于当前值（例如：不是 i++，而是 flag = true）。\n该变量没有包含在具有其他变量的不变式中。\n常见场景 1：状态标记量 (Flag) 用于控制线程停止或状态切换。\n1 2 3 4 5 6 7 8 9 10 11 volatile boolean shutdownRequested; public void shutdown() { shutdownRequested = true; } public void doWork() { while (!shutdownRequested) { // 执行业务逻辑 } } 常见场景 2：单例模式 (Double-Checked Locking) 这是 volatile 防重排最经典的应用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Singleton { // 必须加 volatile，防止指令重排导致 instance 指向未初始化的内存 private volatile static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); // new 操作并非原子，分为3步： // 1. 分配内存 // 2. 初始化对象 // 3. 将 instance 指向内存地址 // 若发生重排(1-\u0026gt;3-\u0026gt;2)，其他线程可能拿到非空的但未初始化的对象。 } } } return instance; } } 4. 总结：volatile vs synchronized 特性 volatile synchronized 可见性 保证 保证 有序性 保证 保证 原子性 不保证 保证 线程阻塞 不会阻塞线程 会阻塞线程 适用范围 仅变量 方法、代码块 性能 较高 (轻量级) 较低 (重量级，尽管已有优化) 一句话总结： volatile 是 Java 提供的轻量级同步机制，它主要用于保证多线程下的变量可见性和禁止指令重排，但它不能保证原子性，因此不能完全替代锁。\n它保证的“顺序”：禁止内部瞎优化（指令重排） CPU 和编译器为了快，有时候会把你写的代码顺序打乱（只要单线程下逻辑通顺就行）。\nVolatile 的作用： 告诉 CPU，“这行代码很关键，别给我乱动位置”。\n例子：\n你写的是：步骤1 -\u0026gt; 步骤2 -\u0026gt; volatile写\nCPU 不允许优化成：volatile写 -\u0026gt; 步骤1 -\u0026gt; 步骤2\n这就是你说的“保证代码执行顺序不改变”。\n2. 它无法改变的“并发”：无法阻止外部线程的“插队” 这正是你后半句说的重点。volatile 不是锁。\n没有排他性： 它不能像 synchronized 那样让线程排队（Serial Execution）。\n现象： 线程 A 和线程 B 可以同时去修改这个 volatile 变量。\n后果： 如果操作不是原子的（比如 i++），大家还是会“撞车”。\n讲解Java的ThreadLocal ThreadLocal 是 Java 中一个非常重要且高频面试的并发工具类。它的核心思想是 “空间换时间”，为每个线程提供独立的变量副本，从而实现线程隔离。\n以下我将从核心概念、应用场景、底层原理（源码级别）、内存泄漏问题以及最佳实践五个维度为你详细讲解。\n1. 核心概念 ThreadLocal（线程局部变量）提供了线程本地变量。当你在代码中创建一个 ThreadLocal 变量时，访问这个变量的每个线程都会拥有一个独立的、自己的本地副本。\n它的作用： 它是为了解决多线程并发访问共享变量时的线程安全问题，但它不是通过加锁（synchronized）来实现的，而是通过让每个线程自己玩自己的，互不干扰。\n比喻：\nsynchronized 就像只有一个厕所，大家需要排队（锁），同一时间只能一个人用。\nThreadLocal 就像给每个人发了一个专用的移动厕所，大家互不影响，不需要排队。\n2. 核心应用场景 ThreadLocal 主要有两个经典的使用场景：\n线程隔离（每个线程需要一个独享的对象）：\n典型案例： SimpleDateFormat。它是线程不安全的，如果把它定义为 static 并在多线程中共用，会报错。\n解法： 使用 ThreadLocal 为每个线程创建一个单独的 SimpleDateFormat 副本。\n案例： 数据库连接（Connection）、Session 管理。\n上下文传递（跨方法传递参数）：\n场景： 在一个 Web 请求中，从 Controller -\u0026gt; Service -\u0026gt; DAO，我们需要传递用户信息（User ID）。\n问题： 如果每个方法都加一个 userId 参数，代码会非常臃肿。\n解法： 在拦截器处将 User ID 存入 ThreadLocal，后续任何地方都可以直接取出来使用，无需层层传参。\n3. 底层原理（重点：ThreadLocalMap） 这是理解 ThreadLocal 的关键。很多人误以为 ThreadLocal 内部维护了一个 Map，Key 是线程，Value 是值。其实恰恰相反。\n3.1 真实的存储结构 Thread 类中： 每个 Thread 对象内部维护了一个成员变量 threadLocals。\nJava\n1 2 // Thread.java 源码片段 ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap： 这是一个类似于 HashMap 的结构，但它是 ThreadLocal 的静态内部类。\nKey 和 Value：\nKey： 是当前的 ThreadLocal 对象实例本身（而且是弱引用，WeakReference）。\nValue： 是我们 set 进去的具体值。\n3.2 引用关系图 1 2 3 4 5 6 Thread (当前线程) └── threadLocals (ThreadLocalMap) └── Entry[] (数组) └── Entry (继承自 WeakReference) ├── Key (弱引用) ──\u0026gt; ThreadLocal 实例 └── Value (强引用) ──\u0026gt; 具体对象 (如 Connection) 结论： 数据其实是存放在线程对象（Thread）自己的堆内存里的，ThreadLocal 仅仅是一个访问入口（Key）。\n3.3 Hash 冲突解决 与 HashMap 使用链表法/红黑树不同，ThreadLocalMap 使用的是 线性探测法 (Linear Probing)。\n如果计算出的槽位（slot）已经被占用了，它就往后找下一个空位存放。\n这也意味着 ThreadLocal 不适合存储极其大量的数据，否则检索效率会下降。\n4. 著名的内存泄漏问题 这是 ThreadLocal 最致命的坑，也是面试必问点。\n4.1 为什么会泄漏？ ThreadLocalMap 的 Entry 对 Key（ThreadLocal） 是弱引用，但对 Value 是强引用。\nKey 被回收： 如果外界没有 ThreadLocal 的强引用了，在下一次 GC 时，Key 会被回收，Entry 中的 Key 变成了 null。\nValue 还在： 但是，Value 是强引用，只要 Current Thread 还在运行（比如线程池中的核心线程，生命周期很长），这个 Value 就会一直存在于内存中，无法被回收。\n结果： 出现了一条 Current Thread -\u0026gt; ThreadLocalMap -\u0026gt; Entry -\u0026gt; Value 的强引用链，导致 Value 占用的内存无法释放，形成内存泄漏。\n4.2 各种补救措施（探测式清理） Java 的设计者也想到了这点。ThreadLocalMap 在调用 set()、get()、remove() 方法时，会顺便检查 Key 为 null 的 Entry，并将对应的 Value 清除。\n4.3 终极解决方案 必须在使用完后，手动调用 remove() 方法。\n5. 最佳实践代码示例 无论是在 Spring 的拦截器中，还是日常开发，请务必遵循 try-finally 模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class UserContext { // 1. 定义 ThreadLocal，通常建议配合 static final 修饰 private static final ThreadLocal\u0026lt;UserInfo\u0026gt; userHolder = new ThreadLocal\u0026lt;\u0026gt;(); // 2. 设置值 public static void setUser(UserInfo user) { userHolder.set(user); } // 3. 获取值 public static UserInfo getUser() { return userHolder.get(); } // 4. 清除值 (至关重要) public static void remove() { userHolder.remove(); } } // 业务使用伪代码 public void doBusiness() { try { UserContext.setUser(new UserInfo(\u0026#34;Gemini\u0026#34;, 1)); // 执行业务逻辑... serviceLayer.process(); } finally { // 5. 必须在 finally 中清除，防止内存泄漏和线程复用导致的数据污染 UserContext.remove(); } } 6. 父子线程传递 (InheritableThreadLocal) 普通的 ThreadLocal 无法在子线程中获取父线程设置的值。如果需要传递，可以使用 InheritableThreadLocal。\n原理： 在创建子线程（Thread 构造函数）时，会自动把父线程的 inheritableThreadLocals Map 中的数据复制一份给子线程。\n注意： 仅限创建时复制，后续父线程修改，子线程不可见（拷贝的是引用）。\n总结 用途： 线程隔离（每个线程一份）和 上下文传递（透传参数）。\n原理： 每个 Thread 内部维护一个 ThreadLocalMap，Key 是 ThreadLocal 实例本身。\n坑：\n内存泄漏： 弱引用 Key 导致 Value 滞留。\n数据污染： 线程池复用线程时，如果没清理，下一个任务会读到上一个任务的数据。\n铁律： 用完必须 remove()。\n如果不主动区remove()，那么这个threadLocal内部的key-value就会在下一次调用这个线程的时候访问到，产生内存泄漏。\nRedo Log是什么 Redo Log（重做日志）是 MySQL 中 InnoDB 存储引擎特有的一种物理日志。\n简单来说，它的核心作用是确保事务的持久性（Durability），即防止数据库在发生故障（如断电、宕机）时丢失数据。它是实现 ACID 中 \u0026ldquo;D\u0026rdquo; 的关键。\n为了帮助你透彻理解（特别是应对面试），我们可以从以下几个维度来解析：\n1. 为什么需要 Redo Log？ 在 MySQL 中，数据是存在磁盘上的，但为了性能，更新操作通常是在内存（Buffer Pool）中完成的。\n问题： 如果每次更新数据都直接写回磁盘的数据页（Page），因为数据页在磁盘上是随机分布的，这会产生大量的随机 I/O，性能非常差。\n解决： 既然直接写数据页太慢，InnoDB 采用了一种策略：当有记录需要更新时，先更新内存，然后把“在某个数据页上做了什么修改”记录到 Redo Log 中。\n优势： 写 Redo Log 是顺序 I/O（追加写入），速度非常快。\n这种技术被称为 WAL (Write-Ahead Logging)，即“先写日志，再写磁盘”。\n核心场景： 如果 MySQL 突然宕机，内存中的脏页（修改过但还没写回磁盘的数据）会丢失。重启时，MySQL 可以利用磁盘上的 Redo Log 把这些丢失的修改“重做”一遍，从而恢复数据。\n2. Redo Log 的工作原理 物理结构 Redo Log 记录的是物理修改。例如：“在第 10 号表空间的第 50 号页面的偏移量 200 处，将值由 A 改为 B”。\n写入流程 (循环写入) Redo Log 的文件大小是固定的（例如配置了 4 个文件，每个 1GB）。InnoDB 使用循环写入（Circular Buffer）的方式来使用这些文件。\n想象一个圆形的缓冲区：\nwrite pos (当前写入点)： 随着事务的执行，不断向前移动，写入新的日志。\ncheckpoint (擦除点/安全点)： 也是向前移动。当数据页被真正刷入磁盘后，对应的 Redo Log 就不需要了，可以被覆盖（擦除）。\n如果 write pos 追上了 checkpoint： 说明 Redo Log 满了。此时 MySQL 必须暂停更新操作，强制把内存中的脏页刷到磁盘中，以推进 checkpoint，腾出空间。 3. 关键参数：innodb_flush_log_at_trx_commit 这是面试中常考的配置项，决定了 Redo Log 何时从内存缓冲区（Redo Log Buffer）刷入磁盘文件。\n值 行为描述 安全性 性能 0 每秒将日志写入磁盘一次。事务提交时不强制刷盘。 低（崩溃可能丢失1秒数据） 最高 1 (默认) 每次事务提交时，都将日志强制写入磁盘。 高（最安全，保证 ACID） 一般 2 每次事务提交时写到操作系统缓存（OS Cache），由 OS 每秒刷盘一次。 中（MySQL挂了没事，OS挂了会丢数据） 高 4. 重点区分：Redo Log vs Binlog 这是面试中最容易混淆的点，必须清晰区分：\n特性 Redo Log (重做日志) Binlog (归档日志) 所属层级 InnoDB 存储引擎层 (特有) MySQL Server 层 (所有引擎通用) 记录内容 物理日志 (在某页做了某修改) 逻辑日志 (SQL 语句或行数据的变更) 写入方式 循环写 (空间固定，会覆盖) 追加写 (写满一个文件切换下一个，不覆盖) 核心作用 崩溃恢复 (Crash-Safe) 主从复制、数据备份/恢复 5. 总结 如果把 MySQL 比如一本账本：\n数据文件 (ibd) 是厚重的总账本，整理起来很慢。\nRedo Log 是手边的粉板（或记事贴）。\nBin Log是什么 Binlog（Binary Log，二进制日志）是 MySQL Server 层（即通用层，不依赖于存储引擎）维护的一种日志文件。\n如果说 Redo Log 是 InnoDB 引擎的“救命稻草”（用于崩溃恢复），那么 Binlog 就是 MySQL 的**“历史档案”**。\n以下是关于 Binlog 的核心知识点，覆盖了原理、用途和常见的面试考点：\n1. 核心作用 Binlog 记录了数据库中所有修改数据的操作（如 INSERT, UPDATE, DELETE, CREATE, DROP 等），不包括查询（SELECT, SHOW）。\n它的主要用途有两个：\n主从复制 (Master-Slave Replication)：\n这是最常见的用途。Master 节点把它的 Binlog 传递给 Slave 节点，Slave 接收并重放这些日志，从而保证主从数据一致。 数据恢复 (Point-in-Time Recovery)：\n如果数据库误删了数据，可以使用最近的一次全量备份（Full Backup）恢复到某个时间点，然后通过重放 Binlog，把数据恢复到误操作的前一秒。 2. 记录格式 (binlog_format) 这是面试中的高频考点。Binlog 有三种记录模式，各有优劣：\n格式 描述 优点 缺点 STATEMENT 记录执行的 SQL 语句原文（如 UPDATE t SET a=1 WHERE id=10）。 日志文件小，网络传输快，IO 压力小。 存在数据不一致风险。如果 SQL 中包含 NOW()、UUID() 等函数，在从库执行时结果可能与主库不同。 ROW 记录每一行数据被修改成的样子（物理变更）。 非常安全，严格保证数据一致性。 日志文件非常大（特别是批量 UPDATE 或 DELETE 时），消耗网络 bandwidth。 MIXED 混合模式。 一般用 Statement，遇到可能导致不一致的 SQL（如用到系统变量）时自动切换为 Row。 试图平衡两者，但有时难以预测 MySQL 的选择。 最佳实践： 目前生产环境（特别是涉及金钱或核心数据时）推荐使用 ROW 格式，虽然空间占用大，但能保证数据的绝对一致性。\n3. 写入机制 (Append Only) 与 Redo Log 的“循环写”（写满覆盖）不同，Binlog 是追加写（Append Only）。\n当一个 Binlog 文件写到一定大小（由 max_binlog_size 控制）后，会切换创建一个新的文件（例如 mysql-bin.000001, mysql-bin.000002）。\n之前的日志不会被覆盖，除非你手动清理或设置了过期时间。\n4. 关键参数：sync_binlog 这个参数控制 Binlog 什么时候刷入磁盘，与性能和安全息息相关：\nsync_binlog = 0：MySQL 每次将 Binlog 写入 OS Cache，由操作系统决定何时刷盘。性能好，但机器宕机可能丢数据。\nsync_binlog = 1：每次事务提交都强制刷盘。最安全，但性能损耗最大。\nsync_binlog = N：每 N 次事务提交刷盘一次。\n双 1 配置： 在要求数据严谨的生产环境，通常建议 sync_binlog = 1 配合 innodb_flush_log_at_trx_commit = 1，这就是常说的“双 1 配置”，能最大程度保证数据不丢失。\n5. 再次对比：Redo Log vs Binlog 为了加深记忆，这里再次从另一个角度对比这两个日志：\n特征 Redo Log (重做日志) Binlog (归档日志) 生动比喻 草稿纸/记事贴 (用完即丢) 历史档案馆/录像带 (永久保存) 产生者 InnoDB 引擎特有 MySQL Server 层 (所有引擎都有) 内容形式 物理日志 (\u0026ldquo;在某页改了某值\u0026rdquo;) 逻辑日志 (\u0026ldquo;执行了某SQL\u0026rdquo; 或 \u0026ldquo;某行变为了X\u0026rdquo;) 主要场景 宕机恢复 (Crash Safe) 主从复制、数据恢复 事务性 事务执行过程中不断写入 事务提交时一次性写入 6. 一个经典问题：为什么需要两份日志？ 你可能会问：既然 Binlog 也有数据记录，为什么 InnoDB 还需要 Redo Log？\n历史原因： MySQL 最早只有 Binlog（Server层），没有 Crash-safe 能力。后来引入 InnoDB 引擎，InnoDB 为了实现 ACID 中的持久性，自己搞了一套 Redo Log。\n效率原因： Binlog 是逻辑日志，恢复速度慢（需要重新执行 SQL 或重放行变更）；Redo Log 是物理日志，直接映射磁盘位置，恢复速度极快。\n介绍一下kafka和RocketMQ的刷盘策略 这是一个非常经典的中间件对比问题。刷盘策略（Flushing Strategy）直接决定了消息队列（MQ）的吞吐量（Performance）和数据可靠性（Reliability）。\nKafka 和 RocketMQ 在这方面的设计理念有明显的区别：\nRocketMQ： 提供了灵活的选择，由用户决定是追求极致性能还是极致数据安全。\nKafka： 倾向于极致的吞吐量，将“数据可靠性”交给多副本复制（Replication）机制，而不是单机的强刷盘。\n以下是详细对比：\n1. RocketMQ 的刷盘策略 RocketMQ 在 Broker 的配置文件中，通过 flushDiskType 参数提供了两种明确的策略。它的设计思路很像 MySQL 的配置，让用户自己权衡。\nA. 异步刷盘 (ASYNC_FLUSH) —— 默认策略 机制： 生产者发送消息后，Broker 只要把消息写入内存（Page Cache / MappedByteBuffer）就立刻返回“发送成功”。\n刷盘时机： 后台有一个线程会定时（通常每隔几毫秒）把内存中的数据刷入磁盘。\n优缺点：\n✅ 吞吐量高，延迟低。\n⚠️ 有数据丢失风险：如果服务器突然断电（宕机），内存中未刷盘的消息会丢失。\nB. 同步刷盘 (SYNC_FLUSH) 机制： 生产者发送消息后，Broker 必须先把消息写入内存，并且强制调用 fsync 刷入磁盘后，才返回“发送成功”。\n优化（Group Commit）： 为了不让性能太差，RocketMQ 实现了**Group Commit（组提交）**机制。它不会每来一条消息就刷一次盘，而是攒一小批消息（微秒级等待），一次性 fsync，类似 MySQL 的机制。\n优缺点：\n✅ 数据绝对安全，断电不丢数据。\n⚠️ 吞吐量下降，延迟变高。\n适用场景： 金融、交易链路等对数据丢失“零容忍”的场景，必须用 SYNC_FLUSH。\n2. Kafka 的刷盘策略 Kafka 的设计哲学完全不同。它官方强烈不推荐用户强制控制刷盘，而是把这个工作完全交给操作系统。\nA. 异步刷盘 (依赖 OS Page Cache) —— 核心策略 机制： Kafka 收到消息后，通过 write() 系统调用把数据写入文件系统的 Page Cache（页缓存），然后立刻返回。\n刷盘时机： Kafka 不主动调用 fsync。它依赖 Linux 系统的后台线程（pdflush/flush）根据系统的脏页策略（vm.dirty_background_ratio 等）自动将数据刷入磁盘。\n为什么这么设计？\nKafka 认为在分布式系统中，单机的持久化并不能保证绝对安全（硬盘坏了照样丢）。\nKafka 的安全性是通过 多副本机制 (Replication) 来保证的。只要消息被写入了多个副本（ISR 集合），即使主节点宕机且数据未刷盘，数据也可以从其他副本恢复。\nB. 同步刷盘 (可配置，但很少用) 虽然 Kafka 提供了 log.flush.interval.messages（每多少条刷一次）和 log.flush.interval.ms（每多少毫秒刷一次）参数，但官方建议保持默认值（即不配置，无限大），交给 OS 管理。\n频繁调用 fsync 会极大地破坏 Kafka 的高吞吐特性。\n3. 横向对比总结 (面试必杀技) 特性 RocketMQ Kafka 主要刷盘方式 支持同步 \u0026amp; 异步 几乎全靠异步 (OS Page Cache) 配置参数 flushDiskType (SYNC_FLUSH / ASYNC_FLUSH) log.flush.interval (建议忽略) 数据安全性保障 单机层面：靠同步刷盘保证。\n集群层面：靠主从复制。 完全依赖集群层面的副本复制机制 (Replication / ISR)。 设计哲学 像传统数据库，提供“金融级”的单机可靠性选项。 追求极致吞吐，相信操作系统和集群副本。 性能 异步刷盘极快；同步刷盘较慢（但有组提交优化）。 极快（因为本质上是写内存）。 4. 深度思考：为什么 Kafka 敢不刷盘？ 这往往是面试官的追问：“Kafka 异步刷盘，万一掉电了怎么办？”\n回答的关键在于 acks 参数：\n如果设置 acks=all (或 -1)：\nKafka 会确保消息不仅写入了 Leader 的内存，还同步到了所有 ISR（In-Sync Replicas）节点的内存中，才会告诉生产者“成功”。\n容灾逻辑： 即使 Leader 突然断电且未刷盘，只要集群中还有一个 ISR 节点活着，数据就不会丢。\n结论：\nRocketMQ 的同步刷盘是物理层面的（写进硬盘才算完）。\nKafka 的安全是逻辑层面的（复制到多台机器的内存才算完）。\nPage Cache是什么？ 简单一句话总结：Page Cache（页缓存）就是操作系统拿出一部分内存（RAM），专门用来给硬盘（Disk）“加速”的。\n我们从“在哪里”和“干什么”两个方面来拆解：\n1. 存储在哪里？ 它就在你的内存条里（RAM）。\nPage Cache 不是什么特殊的硬件，也不是硬盘里的一部分。\n当你买了一台服务器，比如有 32GB 内存。\n你的 Java 程序只用了 4GB。\n剩下的 28GB 内存闲着也是闲着，操作系统（Linux）就会毫不客气地把这些空闲内存征用，当作 Page Cache 使用。\n注意： 它是易失性的。既然是在内存里，一旦断电或者重启，Page Cache 里的东西瞬间就没了。\n2. 它是干啥的？（为什么要用它？） 核心原因只有一个：硬盘太慢了，内存太快了。\n内存（RAM） 的速度像法拉利。\n硬盘（Disk） 的速度像蜗牛。\n如果 CPU 每次读写数据都要等着硬盘（蜗牛）慢慢爬，那 CPU（法拉利）大部分时间都在“发呆”等待。为了解决这个速度不匹配的问题，Linux 引入了 Page Cache 当作“中间商”。\nA. 写操作（Write）的加速： “骗”你写完了 当 Kafka 说“我要把消息写到硬盘”时：\n操作系统直接把数据丢进 Page Cache（内存）。\n操作系统立刻告诉 Kafka：“写完了，你走吧！”（其实还没进硬盘）。\n结果： Kafka 觉得写硬盘飞快（其实是写了内存），吞吐量极高。\n后续： 操作系统会在后台，找个空闲时间，慢慢把 Page Cache 里的数据搬运到硬盘里（这个过程叫 Flush/刷盘）。\n比喻： 你去图书馆还书（写数据）。 如果没有 Page Cache，你得自己跑进库房把书插回架子上（写磁盘），很慢。 有了 Page Cache，前台放了一个还书箱（内存），你把书往箱子里一扔就走了（瞬间完成）。管理员晚点再把箱子里的书摆回架子。\nB. 读操作（Read）的加速： “猜”你会再用 当你要从硬盘读取一个文件时：\n操作系统把文件从硬盘读出来。\n先在 Page Cache（内存） 里留一份备份，然后再给你。\n结果： 下次你（或者别人）再来读同一个文件时，操作系统直接从内存里拿给你，完全不需要动硬盘。速度提升几百倍。\n3. 一个直观的现象（Linux 内存占用） 很多新手在用 Linux 时会发现一个“奇怪”的现象：\n我看机器空闲着，没跑什么程序。\n但用 free 命令一看，内存（Memory）怎么被占用了 90% 以上？\n原因就是 Page Cache。 Linux 的逻辑是：“闲着的内存就是浪费”。与其空着，不如把所有读写过的文件都缓存起来。\n如果你的程序突然需要内存怎么办？ 放心，Linux 会瞬间释放掉一部分 Page Cache 腾出空间给你的程序用。它是“借用”，不是“霸占”。 4. 总结 回到 Kafka 和 MySQL 的场景：\nPage Cache 是谁？ 是 Linux 操作系统利用空闲内存构建的一层缓存。\n在哪里？ 在内存条里（RAM）。\nKafka 为什么快？ 因为 Kafka 写数据实际上是写到了 Page Cache（内存）里，相当于写内存，当然快。\n风险是什么？ 既然在内存里，断电即失。\n这就是为什么 Kafka 叫“异步刷盘”（写完内存就算成功）。\n这也是为什么 MySQL 为了安全要搞“同步刷盘”（必须从 Page Cache 逼到硬盘里才算成功）。\n","date":"2025-11-25T11:43:54+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1/%E5%9C%BA%E6%99%AF2.0/","title":"面试八股/场景2.0"},{"content":"面试题总结 HashMap的底层原理 Hashap 是基于哈希表的数据结构，用于存储键值对(key-value )。其核心是将键的哈希值映射到数组索引位置，通过数组 +链表(在 Java 8 及之后是数组 +链表 +红黑树)来处理哈希冲突。\nHashmap 的默认初始容量为 16，负载因子为 0.75。也就是说，当存储的元素数量超过16x0.75=12个时， Hashmap 会触 发扩容操作，容量x2并重新分配元素位置。这种扩容是比较耗时的操作，频繁扩容会影响性能。\nHashMap 的红黑树优化: 从Java8开始，为了优化当多个元素映射到同一个哈希桶(即发生哈希冲突)时的查找性能，当链表长度超过8时，链表会转变为红黑树。红黑树是一种自平衡二叉搜索树，能够将最坏情况下的査找复杂度从 O(n) 降低到 O(log n)。如果树中元素的数量低于 6，红黑树会转换回链表，以减少不必要的树操作开销。\nhashCode()和 equals()的重要性: HashMp 的键必须实现 hashcode()和 equals()方法。 hashcode()用于计算哈希值，以决定键的存储位置，而 equals()用于比较两个键是否相同。在 put 操作时，如果两个键的 hashcode()相同，但 equals()返回 false，则这两个键会被视为不同的键，存储在同一个桶的不同位置。\n经典的“哈希冲突”案例 在 Java 中，最著名的例子就是字符串 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot;。\nJava\n1 2 3 4 5 6 String s1 = \u0026#34;Aa\u0026#34;; String s2 = \u0026#34;BB\u0026#34;; System.out.println(s1.hashCode()); // 输出 2112 System.out.println(s2.hashCode()); // 输出 2112 System.out.println(s1.equals(s2)); // 输出 false 发生了什么？\nJava 字符串的哈希算法是 s[0]*31 + s[1]：\n'A' 是 65，'a' 是 97 \\rightarrow 65 \\times 31 + 97 = 2112\n'B' 是 66 \\rightarrow 66 \\times 31 + 66 = 2112\n虽然算出来的数字一样，但显然 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot; 是完全不同的字符串。\nHashMap成环 由于线程1已经指向了B和A，线程2却先一步执行了扩容操作，而停止循环的条件就是e.next为null，当执行完扩容后，线程1苏醒，此时e为B，e.next为A，当前e的next指向A，导致A与B之间产生死循环，颠倒后依旧产生连接，就形成了环。\nJDK1.7HashMap多线程死循环问题_哔哩哔哩_bilibili\nSynchronized 和 ReentrantLock有什么区别? 实现层面 synchronized：\n是 Java 的关键字，属于 JVM 层面的实现。 ReentrantLock：\n是 JDK 提供的一个类（java.util.concurrent.locks.ReentrantLock），属于 API 层面的实现。 锁的释放 synchronized：\n自动释放。代码执行完同步代码块，或者抛出异常时，JVM 会自动释放锁，不会导致死锁。 ReentrantLock：\n手动释放。必须手动调用 unlock() 方法。 锁的公平性 synchronized：\n只能是非公平锁。线程获取锁的顺序是不确定的，可能发生“饥饿”现象。 ReentrantLock：\n默认是非公平锁（性能更好）。\n可以通过构造函数 new ReentrantLock(true) 指定为公平锁（遵循先来后到原则），但性能会下降。\n等待可中断 synchronized：\n不可中断。如果一个线程正在等待获取锁，它不能被中断（interrupt），只能一直阻塞等待。 ReentrantLock：\n可中断。通过 lockInterruptibly() 方法，可以让正在等待锁的线程响应中断，放弃等待去处理其他事情。 尝试获取锁 synchronized：\n不行。要么拿到锁，要么阻塞死等。 ReentrantLock：\n提供 tryLock() 方法。可以尝试获取锁，如果锁被占用，可以选择立即返回 false 或者等待一段指定的时间，非常灵活。 特性 synchronized（隐式锁） ReentrantLock（显式锁） 实现方式 关键字 (JVM 层面) 类 (JDK API 层面) 锁的释放 隐式自动释放 显式手动释放 (需在 finally 中 unlock) 公平性 非公平 默认非公平，可设置为公平 响应中断 不支持 支持 (lockInterruptibly) 条件队列 单个 (wait/notify) 多个 (Condition) 尝试获取 不支持 (死等) 支持 (tryLock) 灵活性 低 高 锁升级 锁升级流程图解 锁状态 触发条件 优点 缺点 偏向锁 只有一个线程反复加锁 加锁/解锁几乎零消耗 如果存在线程竞争，撤销偏向锁会有额外开销 轻量级锁 线程交替执行，无同时竞争 不会阻塞线程，利用 CAS 和自旋，响应速度快 如果始终得不到锁，自旋会空耗 CPU 重量级锁 发生长时间或多线程同时竞争 不会空耗 CPU，未获锁线程进入阻塞 线程阻塞/唤醒涉及上下文切换，开销大，较慢 CAS与自旋 什么是CAS（乐观锁） 你看到原句是“Hello”（A）。\n你想改成“Hi”（B）。\n在你提交修改的一瞬间，系统检查文档当前还是不是“Hello”（V）。\n如果是，修改成功。\n如果文档已经被别人改成了“Hello World”，你的预期（A）和实际（V）不符，提交失败，你需要重新读取再尝试。\nCAS 的三大问题 ABA 问题（最著名的坑）：\n虽然 V 还是 A，但不代表它没变过。它可能经历了 A -\u0026gt; B -\u0026gt; A 的过程。\n比喻：桌上有一杯水（A），你离开了一会儿。回来时水还是满的（A），你以为没人动过。实际上可能有人喝光了（B），又给你倒满了（A）。虽然结果一样，但过程可能由于“杯子被用过”而产生副作用。\n解决：加版本号。变成 1A -\u0026gt; 2B -\u0026gt; 3A。Java 中的 AtomicStampedReference 就是干这个的。给提交结果加版本号\n只能保证一个变量的原子性：无法同时操作多个变量。\nCPU 开销大：这通常与“自旋”结合在一起，见下文。\n什么是 自旋 ？ 自旋是一种线程等待的策略。\n当线程抢不到锁（或 CAS 失败）时，它不放弃 CPU，不进入阻塞状态（不睡觉），而是执行一个空循环（Loop），不断地检查“锁释放了吗？”或者“我能重试 CAS 了吗？”。\n为什么要自旋？ 为了避免上下文切换的开销。\n阻塞/唤醒：线程挂起和恢复需要操作系统介入，保存和恢复现场，非常耗时（可能比执行代码本身还慢）。\n自旋：如果锁被占用的时间很短，我在门口转两圈（自旋）锁就释放了，这样比“回家睡觉再被电话叫醒”快得多。\n概念 作用 核心词 优缺点 CAS 实现原子更新 比较并交换 优点：非阻塞，性能好\n缺点：ABA 问题 自旋 等待锁的策略 循环重试 优点：避免上下文切换\n缺点：耗费 CPU SpringBean的生命周期 阶段一：创建与注入 (的基础) 1. 实例化 (Instantiation) 发生了什么： Spring 容器通过反射（Constructor.newInstance()）调用 Bean 的构造函数。\n状态： 此时对象已经在堆内存中存在了，但它只是一个“空壳子”，里面的属性（依赖）全是 null。\n类比： 刚买了一个毛坯房，房子建好了，但里面什么家具都没有。\n2. 属性赋值 (Populate Properties) 发生了什么： Spring 依据配置（XML 或 @Autowired、@Value），将依赖的对象或属性值注入到 Bean 中。\n状态： 对象内部的依赖已经填充完毕。\n类比： 装修工进场，把沙发（Service）、电视（Dao）都搬进了房子里。\n阶段二：容器感知 (Aware 接口回调) 3. Aware 接口回调 (Invoke Aware Interfaces) 发生了什么： 如果 Bean 实现了特定的 Aware 接口，Spring 会把容器内部的一些资源“告诉”这个 Bean。 阶段三：初始化与增强 (最关键的步骤) 所谓的“初始化阶段”，就是 Spring 给你一个机会，在“属性都装好了”之后，但在“给别人使用”之前，让你执行一段自己的业务代码（比如连数据库、加载缓存、校验配置）。\nSpring AOP（默认机制）使用的是 动态代理（Dynamic Proxy）。它的逻辑是委托（Delegation）。\n原本的流程：\n调用者 \\rightarrow 目标对象（Target）\nSpring AOP 的流程：\n调用者 \\rightarrow 代理对象（Proxy） \\rightarrow 执行增强代码（Before） \\rightarrow 调用目标对象 \\rightarrow 执行增强代码（After） \\rightarrow 返回\n特性 Spring AOP AspectJ（静态代理） 原理 动态代理 (Proxy) 字节码织入 (Bytecode Weaving) 修改方式 运行时生成新类包裹目标 编译期/加载期直接修改目标类字节码 是否需要接口 JDK模式需要，CGLIB不需要 不需要 性能 稍慢（有反射和代理调用的开销） 极快（就是普通的方法调用） 能力范围 只能拦截 public 方法 的调用 无所不能：可拦截 private 方法、静态方法、构造函数、字段访问等 内部调用(this) 失效 有效 (完美解决自调用问题) 复杂度 低（Spring Boot 开箱即用） 高（需要配置编译器或 JVM Agent） Redis和Memcached的区别 特性 Memcached Redis 数据结构 单一 (仅支持 String/二进制块) 丰富 (String, List, Hash, Set, ZSet, Bitmap, HyperLogLog, Stream, Geo) 线程模型 多线程 (Multi-threaded) 单线程 (主逻辑) + I/O 多线程 (Redis 6.0+) 持久化 不支持 (重启后数据丢失) 支持 (RDB 快照 \u0026amp; AOF 日志) 分布式支持 客户端实现 (服务端互不通信) 服务端支持 (Redis Cluster, Sentinel) 内存管理 Slab Allocation (预分配，无碎片，但在非均匀大小数据下有浪费) jemalloc/libc (按需分配，利用率高，但可能有内存碎片) 功能丰富度 仅缓存 Lua 脚本、发布/订阅 (Pub/Sub)、事务、Pipeline 最大值限制 Value 最大 1MB Value 最大 512MB A. 数据类型 (Data Types) —— 最大的区别 Memcached: 就像一个巨大的 Map\u0026lt;String, String\u0026gt;。如果你想存一个列表，必须先把列表序列化成 JSON 字符串存进去；取出来时，必须把整个字符串取出来反序列化，修改后再序列化存回去。这非常消耗网络带宽和 CPU。\nRedis: 就像一个瑞士军刀。你可以直接在服务端操作数据结构。\n例子： 你想给一个排行榜加分。\nRedis: ZINCRBY rank_list 10 \u0026quot;user_id\u0026quot; (直接在内存里改数值，极快)。\nMemcached: get -\u0026gt; 反序列化 -\u0026gt; value + 10 -\u0026gt; 序列化 -\u0026gt; set (并发下还需要加锁，否则数据不一致)。\nB. 线程模型 (Threading Model) —— 性能的分水岭 Redis (单线程为主):\nRedis 的核心操作（执行命令）是单线程的。\n优势： 没有线程切换开销，没有锁竞争（Lock-free），代码简单稳定。\n劣势： 无法利用多核 CPU 的优势（但在 6.0 版本引入了多线程 I/O 来处理网络读写，核心计算依然是单线程）。\nMemcached (多线程):\n它使用主线程监听端口，Worker 线程处理读写。\n优势： 可以轻松利用 64 核 CPU 的计算能力，在极高并发（数十万 QPS 以上）且 Value 很小 的场景下，吞吐量可能高于 Redis。\nC. 持久化 (Persistence) —— 数据安全性 Memcached: 把它当作一个易失性缓存。如果服务器断电或重启，所有缓存数据瞬间清空，数据库会瞬间面临巨大的“缓存击穿”压力。\nRedis: 支持持久化。\nRDB: 定期生成快照保存在磁盘。\nAOF: 记录每一条写命令。\n用途： 重启后可以自动恢复数据，甚至可以用来做主数据库使用。\nD. 分布式/集群 (Clustering) Memcached: 服务端是“傻瓜式”的，节点之间互不通信。分布式的逻辑完全由客户端（Client）控制（通常使用一致性哈希算法）。如果你加一台服务器，客户端需要重新计算哈希。\nRedis: 支持原生的 Redis Cluster。服务端之间会通信（Gossip 协议），支持自动分片、故障转移（Failover）。\n内核内存 vs. 用户内存 (The Two Worlds) 操作系统（如 Linux）为了安全和稳定，把内存划分成了两个隔离的区域：\n1. 内核内存 (Kernel Memory / Kernel Space) 权限： 最高权限 (Ring 0)。CPU 可以执行任何指令，访问任何硬件地址。\n居住者： 操作系统内核代码、驱动程序（网卡驱动）、硬件缓冲区。\n特点： 如果这块区域的代码崩溃了，整个操作系统就蓝屏或死机了。它是神圣不可侵犯的。\n2. 用户内存 (User Memory / User Space) 权限： 受限权限 (Ring 3)。只能访问自己的内存空间，严禁直接访问硬件（不能直接读写网卡、硬盘）。\n居住者： 你运行的应用程序（Redis, Java JVM, 浏览器, QQ）。\n特点： 如果你的 Redis 崩了，只是这一个进程死掉，操作系统照样运行。\n核心矛盾： 网卡收到的数据首先必须存放在内核内存（因为它是由驱动程序管理的）。但是，你的 Redis 运行在用户内存。\n代价： 数据必须从“内核态”拷贝 (Copy) 到“用户态”，应用程序才能处理。这就是 Redis 6.0 引入多线程 I/O 想要优化的那个“搬运”过程。###\nSocket 是什么？ (The Abstraction) 很多初学者认为 Socket 就是“插座”或者“连接”。在操作系统层面，Socket 本质上是内核内存中的两个缓冲区（Buffer）。\n当你创建一个 Socket（比如 Java 的 new Socket() 或 Redis 监听的端口），内核会在内核内存里为你申请两块地：\n接收缓冲区 (Recv Buffer): 存放网卡发过来、等待你读取的数据。\n发送缓冲区 (Send Buffer): 存放你写进去、等待网卡发送的数据。\nSocket 就是应用程序（用户态）和网络协议栈（内核态）交互的句柄 (File Descriptor)。\nRedis数据的全生命周期流程 假设外网发来一个 TCP 包给 Redis（端口 6379），流程如下：\n1. 物理层：网卡收货 (NIC) 网线传来电信号，网卡将其转换为二进制数据。\nDMA (Direct Memory Access): 网卡不经过 CPU，直接利用 DMA 技术，把数据包写入到 内核内存 中的一块公用区域（通常叫 Ring Buffer）。\n此时，数据在内核，但还不知道属于哪个 Socket。\n2. 链路层 \u0026amp; 网络层：内核协议栈介入 网卡给 CPU 发送中断 (Interrupt)。\nCPU 停下手中的活，运行网卡驱动程序。\n驱动程序把数据包包装成内核的数据结构（Linux 下叫 sk_buff）。\n操作系统检查 IP 头：是发给本机的吗？是的。\n3. 传输层：分发给 Socket (Demultiplexing) 操作系统检查 TCP 头：目标端口是 6379。\n内核查找：“哪个 Socket 正在监听 6379 端口？” -\u0026gt; 找到了 Redis 的那个 Socket。\n关键动作： 内核把这个数据包（sk_buff）挂到该 Socket 的接收缓冲区 (Recv Buffer) 队列的尾部。\n此时，数据依然在内核内存中，但已经归属到了特定的 Socket 名下。\n4. 应用层：数据搬运 (Copy to User) Redis 主线程（或 I/O 线程）调用系统函数 read(socket_fd)。\nCPU 发生上下文切换： 从用户态切入内核态。\n内存拷贝： CPU 把数据从 内核内存（Socket 的接收缓冲区） 复制到 用户内存（Redis 定义的 buffer）。\nRedis 终于拿到了数据，开始解析处理 set name ...。\n那 Redis 6.0 的 I/O 线程到底解决了什么？ 既然都要经过内核拷贝，那用主线程调 write 和用 I/O 线程调 write 有什么区别？\n区别在于“谁在等”和“谁在分担开销”。\n场景：如果你只有主线程（Redis \u0026lt; 6.0） 主线程：“我要处理 10,000 个客户端的 get 请求。”\n对于每一个请求，主线程都要亲自调用 write。\n每次 write，主线程都要经历：用户态-\u0026gt;内核态切换 (耗时) + CPU 搬运数据 (耗时) + 内核态-\u0026gt;用户态切换 (耗时)。\n结果： 主线程大量时间花在和内核打交道、等待搬运上，导致它处理命令（KV 读写）的时间变少了。\n场景：你有 I/O 线程（Redis 6.0+） 主线程：“我要处理 10,000 个请求。算出结果后，我不亲自发了。”\n主线程把结果扔给 4 个 I/O 线程，说：“你们去调 write 发给客户。”\n主线程立刻转头去处理下一个命令的计算（KV 读写）。\nI/O 线程们 并行地去调用 write，去承担上下文切换和 CPU 搬运数据的开销。\n结果： 主线程被解放了，只专注于纯内存计算，吞吐量大增。\n内核线程，内核级线程，用户级线程 用户级线程是怎么“骗”过内核的？（M:N 模型） 用户级线程通过一个**中间层（Runtime/Scheduler）**来实现。\nM 个用户级线程（比如 1000 个 Goroutine）。\nN 个内核级线程（通常等于 CPU 核数，比如 8 个）。\n映射关系：\n这 8 个内核线程是“干活的苦力”。\n这 1000 个协程是“待办的任务”。\nGo 语言的运行时（Runtime）负责把这 1000 个任务，源源不断地塞给这 8 个苦力去做。\n如果一个任务（协程）卡在 I/O 上了，Runtime 把它拿开，换一个新任务给苦力，苦力（内核线程）永远不休息，也永远不阻塞。\n我们可以把计算机系统看作一家大型工厂（操作系统）：\n内核线程 (Kernel Thread): 工厂的内部设施维护人员（只在核心区工作，不生产对外产品）。\n内核级线程 (Kernel-Level Thread, KLT): 工厂正式聘用的流水线工人（有工牌，受人事部直接管理）。\n用户级线程 (User-Level Thread, ULT): 包工头带来的临时工/外包团队（人事部不知道他们的存在，只知道包工头）。\n一、 详细拆解：三者的定义与区别 1. 内核线程 (Kernel Thread / kthread) 这是最底层的存在，它们完全运行在内核空间（Ring 0）。\n定义： 它是操作系统内核用来执行后台任务的线程。它没有用户地址空间（不映射用户内存），只能访问内核代码和数据。\n谁创建/管理： 操作系统内核。\n能干啥：\n将内存中的脏页刷写到磁盘（如 Linux 的 kflush 或 pdflush）。\n处理软中断和网络包（如 ksoftirqd）。\n执行磁盘 I/O 调度。\n特点： 也就是我们常说的“纯内核线程”。你在 Linux 用 ps -ef 看到的那些名字带中括号 [kthreadd]、[migration] 的进程，就是它们。\n与用户程序的关系： 完全没关系。它们不运行你的 Java 或 Redis 代码，它们只服务于 OS 本身。\n2. 内核级线程 (Kernel-Level Thread, KLT) 这是我们日常开发中最常接触的概念（虽然你可能没意识到）。 在 Linux 中，它们通常被称为 轻量级进程 (LWP, Light Weight Process)。\n定义： 这是一个由内核管理、但用于执行用户态代码的执行实体。它是**“用户进程”在内核眼里的分身**。\n谁创建/管理： 操作系统内核调度器（如 CFS）。\n能干啥： 执行你的 main() 函数，执行 Redis 的主逻辑，执行 Java 的线程。\n特点：\n拥有双重身份： 既有内核栈（陷入内核时用），也有用户栈（运行程序时用）。\n可被独立调度： 操作系统知道它的存在，可以将它分配给任意 CPU 核心。\n高开销： 创建、销毁、切换都需要系统调用，涉及内核态/用户态切换，成本较高（微秒级）。\n代表： Java 的 java.lang.Thread (在 Linux 上)，C++ 的 std::thread，Redis 的主线程和 I/O 线程。\n3. 用户级线程 (User-Level Thread, ULT) 也叫协程、纤程、Green Thread。\n定义： 完全在用户空间实现的线程机制。内核完全不知道它们的存在，内核只看到承载它们的那个 KLT。\n谁创建/管理： 编程语言的运行时（Runtime）或库（如 Go Runtime, JVM）。\n能干啥： 处理高并发逻辑，阻塞式写法的异步执行。\n特点：\n极轻量： 切换只涉及寄存器保存，无需陷入内核，纳秒级。\n不可独立调度： 操作系统无法直接把一个 ULT 分配给 CPU，必须依附于一个 KLT 才能运行。\n代表： Go 的 Goroutine, Python 的 Gevent, Java 21 的 Virtual Thread。\n二、 它们之间的映射模型 (The Mapping Models) 弄清楚关系的关键，在于理解用户级线程 (ULT) 和 内核级线程 (KLT) 是如何搭配工作的。这主要有三种模型：\n1. 多对一模型 (M : 1) —— 上古时代的产物 描述： 多个用户级线程（M）跑在 1 个内核级线程（1）上。\n例子： 老版本的 Python 异步库，某些老旧的 JVM 实现（Green Threads）。\n缺点： 没有并行能力。因为底层只有一个 KLT，所以一次只能用 1 个 CPU 核。如果其中一个 ULT 阻塞了（比如发起系统调用），底层的 KLT 就阻塞了，其他所有 M 个 ULT 全都卡死。\n2. 一对一模型 (1 : 1) —— 现代主流 (Redis, Nginx, Java) 描述： 1 个用户级线程（逻辑上的线程）直接对应 1 个内核级线程。\n机制： 当你在 Java 里 new Thread()，操作系统就在底层真的创建一个 KLT（LWP）。\n优点： 真正的并行。一个线程阻塞，不影响其他线程。实现简单，直接依赖 OS 调度。\n缺点： 线程太贵，开不了一百万个。\n现状： Redis 的主线程和 I/O 线程，Java 目前默认的线程模型，都是 1:1。 所谓的“用户线程”此时只是 KLT 的一个句柄。\n3. 多对多模型 (M : N) —— 高并发的未来 (Go,Java21 Virtual Threads) 描述： M 个用户级线程（协程）动态映射到 N 个内核级线程上。\n机制：\nRuntime 维护一个线程池（N 个 KLT）。\nRuntime 维护一个任务队列（M 个 ULT）。\nRuntime 负责把 ULT 喂给 KLT 执行。如果一个 ULT 阻塞了，Runtime 把它拿下来，换另一个 ULT 上去。\n优点： 既有 ULT 的轻量（可以开百万个），又有 KLT 的并行（利用多核 CPU）。\n现状： Go 语言之所以火，就是因为它的调度器（G-M-P 模型）把这个做到了极致。\n三、 总结与对比表 特性 内核线程 (Kernel Thread) 内核级线程 (KLT / LWP) 用户级线程 (ULT / Coroutine) 可见性 仅内核可见 内核可见，用户可见 仅用户程序可见 (内核不可见) 内存空间 仅内核空间 用户空间 + 内核空间 仅用户空间 调度者 OS 调度器 OS 调度器 语言运行时 (Runtime) 切换开销 小 (无需切换地址空间) 中 (需切入内核态) 极小 (纯用户态操作) 并行性 利用多核 利用多核 依赖于底层的 KLT 阻塞影响 - 线程阻塞，释放 CPU 给别人 协程阻塞，Runtime 切换其他协程 典型例子 ksoftirqd, kworker java.lang.Thread, Redis 线程 Go Goroutine, Java Virtual Thread 一般什么情况下需要陷入内核态？ 简单来说，“陷入内核态”（Trap into Kernel Mode） 也就是 CPU 从 特权级 3 (User Ring 3) 切换到 特权级 0 (Kernel Ring 0) 的过程。\n一般情况下，陷入内核态主要有且仅有三种场景：\n1. 系统调用 (System Call) —— 主动请求 这是最常见的情况。当你的程序需要做一些自己权限不够的事情时，必须主动向操作系统“打报告”。\n因为用户程序不能直接操作硬件（硬盘、网卡、声卡）或管理内存，必须通过特定的接口（System Call Interface）请求内核代劳。\n硬件 I/O 操作：\n读写文件： read(), write(), open()（Redis 写日志、读数据库）。\n网络通信： socket(), connect(), send(), recv()（Redis 处理请求）。\n屏幕输出： printf()（底层调用 write 输出到标准输出）。\n进程控制：\n创建进程： fork(), exec()（Redis 做 RDB 快照时会 fork 子进程）。\n退出程序： exit()。\n内存管理：\n申请内存： malloc() 在堆内存不够时，底层会调用 brk() 或 mmap() 向内核要内存。 比喻： 你要去银行取钱（操作硬件资源），你不能自己冲进金库拿，必须填单子（系统调用），交给柜员（内核），柜员帮你拿出来给你。\n2. 异常 (Exception) —— 内部错误或特殊事件 这是由 CPU 在执行指令时，内部检测到的意外情况。程序“闯祸了”或者遇到了“特殊指令”。\n缺页异常 (Page Fault)：\n当你访问一块内存地址，CPU 发现这块数据不在物理内存里（可能被换到了磁盘 swap 分区，或者刚申请还没分配物理页），CPU 会暂停程序，陷入内核。内核负责把数据从磁盘加载到内存，然后恢复程序运行。 程序错误：\n除以零： 代码里写了 100 / 0。\n非法内存访问 (Segfault)： 试图访问不属于你的内存地址（比如空指针解引用）。\n内核捕获这些错误后，通常会杀死进程（就是你看到的 Segmentation fault）。\n调试断点：\n当你用 GDB 调试代码打断点时，实际上是插入了一条特殊指令（如 x86 的 INT 3）。CPU 执行到这里会自动陷入内核，暂停程序，把控制权交给调试器。 比喻： 你在家里（用户态）做饭，突然锅炸了（除以零）或者你想进邻居家里（非法内存访问），这时候警察（内核）会立刻破门而入处理状况。\n3. 硬件中断 (Hardware Interrupt) —— 被动打断 这是来自 CPU 外部的信号。无论你的程序正在干什么，只要硬件中断来了，CPU 必须无条件停下手头的工作，切到内核态去处理中断。\n时钟中断 (Clock Interrupt)：\n最重要！ 这是多任务操作系统的基石。\n硬件时钟每隔几毫秒就会发一次中断。内核收到中断后，会看：“Redis，你的时间片用完了，该让给 Nginx 跑一会儿了。”\n这就是为什么死循环的程序不会把电脑彻底卡死，因为内核会强行通过时钟中断夺回控制权。\nI/O 完成中断：\n网卡： “新数据包到了！”（内核把数据拷贝到 Socket 缓冲区）。\n硬盘： “刚才你要读的数据我已经读完放到内存了！”\n键盘/鼠标输入：\n你按下一个键，键盘控制器发送中断，CPU 陷入内核读取按键码。 比喻： 你正在家里专心打游戏（用户态运行代码），突然快递员狂按门铃（网卡中断），或者你的闹钟响了（时钟中断），你必须停下游戏去开门或者关闹钟（陷入内核处理）。\n触发方式 来源 例子 主动/被动 系统调用 程序代码 read(), fork(), sleep() 主动 (程序自己写的) 异常 CPU 内部 缺页、除零、Segfault 被动 (通常是闯祸了) 硬件中断 CPU 外部 网卡收包、时钟滴答、键盘 被动 (外部环境强制) Redis单线程避免上下文切换的开销 1. 什么是“昂贵”的上下文切换？ 首先，我们要明确，为什么切换线程很贵？\n当 CPU 从 线程 A 切换到 线程 B 时，不仅仅是“换个人干活”这么简单，它涉及两个巨大的成本：\n直接成本 (CPU 寄存器重置)：\nCPU 需要把线程 A 的“现场”（程序计数器 PC、堆栈指针 SP、通用寄存器等）保存到内存里。\n然后从内存里把线程 B 的“现场”恢复到寄存器里。\n这本身需要花费几微秒 ($\\mu s$)。\n间接成本 (Cache 失效 —— 这才是真正的杀手)：\nCPU 有 L1/L2/L3 高速缓存。线程 A 跑得正欢的时候，缓存Cache里全是线程 A 需要的数据（热数据）。\n突然切到线程 B，线程 B 要用的数据不在缓存里（Cache Miss）。\nCPU 被迫去慢如蜗牛的内存（RAM）里拿数据。\n这会导致 CPU 的执行效率瞬间暴跌。\n2. 多线程模式的痛点 (The \u0026ldquo;Context Switch Storm\u0026rdquo;) 假设 Redis 是传统的多线程模型（比如像早期的 Tomcat 或 MySQL）：\n场景： 来了 1000 个请求。\n处理： 系统开启 1000 个线程（或者用线程池）。\n锁竞争： 线程 A 要修改 Key \u0026ldquo;user:1\u0026rdquo;，线程 B 也要修改。线程 B 抢不到锁，被迫挂起 (Block)。\n自愿切换 (Voluntary Context Switch)：\n因为抢不到锁，或者等待磁盘 I/O，线程 B 主动告诉操作系统：“我干不下去了，把 CPU 让给别人吧。”\n操作系统进行上下文切换。\n结果： 在高并发下，CPU 把大量的时间花在** “保存现场、恢复现场、调度线程、等待锁” **上，真正用来执行 set name gemini 这行代码的时间反而被挤压了。\n3. Redis 的单线程魔法 (The \u0026ldquo;Run-to-Completion\u0026rdquo;) Redis 的主处理逻辑（Command Execution）是单线程的，这意味着：\nA. 彻底消灭“锁竞争” 因为只有我一个人（主线程）在动数据，所以我根本不需要锁（Lock-free）。\n没有锁，就不会出现“因为抢不到锁而挂起”的情况。\n不存在“挂起”，就没有“自愿上下文切换”。\n结果： Redis 主线程是一路狂奔的，它处理完一个请求，马上处理下一个，中间没有任何停顿。\nB. 极致的 Cache 亲和性 (Cache Affinity) 因为始终是这同一个线程在这一颗 CPU 核心上跑。\nRedis 的核心数据结构（dict, ziplist, skiplist）和代码指令，会一直停留在 CPU 的 L1/L2 缓存里。\nCache Hit 率极高。\n这就像一个熟练工人在自己的工位上干活，所有工具都在手边（L1 Cache），闭着眼睛都能拿到。\nC. I/O 多路复用 (Epoll) —— 避免 I/O 阻塞 你可能会问：“那如果读 Socket 数据的时候，数据还没来怎么办？线程不就阻塞了吗？”\nRedis 使用 epoll (Linux)。\n机制： Redis 告诉内核：“这一万个 Socket 你帮我盯着，谁有数据来了你告诉我。”\n非阻塞： Redis 主线程永远不会在某个 Socket 上死等（Block）。它只处理那些“已经准备好数据”的 Socket。\n所以，Redis 永远不会因为 I/O 等待而发生上下文切换。\n4. 总结对比：多线程 vs 单线程 我们可以用去银行办事来比喻：\n模式 场景比喻 上下文切换情况 效率 多线程模型 10 个窗口，10 个柜员。 所有的柜员都要抢同一个账本（锁）来记账。抢不到的柜员就去喝茶（切换）。柜员之间换班还要交接工作（保存现场）。 极高 (锁竞争、线程调度) 低 (大量时间花在抢锁和交接上) Redis 单线程 1 个超级柜员 (Flash)。 只有他一个人，账本就在手边（Cache）。他动作极快，处理完张三马上处理李四，不用跟任何人抢账本，也不用交接班。 极低 (几乎为 0，除非时间片用完) 极高 (CPU 100% 用在干活上) 5. 什么时候 Redis 还是会切换？ 虽然 Redis 尽力避免切换，但被动切换 (Involuntary Context Switch) 是无法避免的，因为操作系统才是老大。\n时间片用完 (Time Slice): 操作系统采用了分时调度。给 Redis 的 10ms 用完了，不管你活干没干完，OS 必须强行把 CPU 抢走给别的进程（比如 SSH、系统日志）用一下。 Redis 单线程避免上下文切换的核心在于：它通过“非阻塞 I/O”和“单线程串行执行”，消灭了代码层面的“锁”和“等待”，从而让 CPU 始终处于全速运算的高效状态。\nRedis写数据全生命周期 假设有一个 Java 客户端，发送了一条命令 SET user:1 \u0026quot;Alice\u0026quot;。\n第一阶段：请求到达与分发 (进 - I/O 阶段) 客户端发送：\n外部的 Java 客户端（用户级线程）发起 TCP 连接，将命令 SET user:1 \u0026quot;Alice\u0026quot; 转换成 Redis 协议（RESP），通过网线发送出去。\n数据到达 Redis 服务器的网卡，进入操作系统的内核 Socket 缓冲区。\n主线程感知 (epoll)：\nRedis 的主线程正在运行事件循环（Event Loop），通过 epoll_wait 监听到这个 Socket 有数据来了（可读事件）。 任务分发 (Distribute)：\n关键点：主线程不亲自去读数据。\n主线程把这个 Socket 连接分配给一组 I/O 线程（IO Thread Pool） 中的某一个。\nI/O 线程并行读取与解析：\n多线程并行：被选中的 I/O 线程（内核级线程）发起系统调用 read()，从内核缓冲区把数据搬运到用户态。\n协议解析：I/O 线程解析数据流，识别出这是一条 SET 命令，参数是 user:1 和 Alice。\n注意：此时主线程会短暂等待，直到所有分配出去的 I/O 任务都完成读取和解析。\n第二阶段：命令执行 (做 - 执行阶段) 主线程串行执行 (Execute)：\n所有 I/O 线程都解析完后，汇报给主线程。\n单线程独占：主线程按照队列顺序，串行地拿到解析好的命令。\n内存操作：主线程在内存的 HashMap 中找到 user:1 这个槽位，填入 \u0026quot;Alice\u0026quot;。\n原子性：因为只有主线程在动这个 Map，所以绝对安全，不需要加锁。\n生成结果：\n执行成功，主线程生成响应结果 +OK。\n主线程把这个结果写入到该客户端的用户态输出缓冲区中。\n第三阶段：响应返回 (出 - I/O 阶段) 任务再次分发：\n主线程依然不亲自把数据发回网卡。\n它再次把“写回数据”的任务分配给 I/O 线程。\nI/O 线程并行回写：\nI/O 线程并行地调用 write() 系统调用，把缓冲区里的 +OK 发送给内核 Socket 缓冲区。\n内核负责通过网卡把数据发回给 Java 客户端。\n第四阶段：持久化 (存 - 后台阶段) 这部分是异步发生的，不影响给客户端返回结果的速度。\n触发持久化：\nAOF：主线程刚才执行完 SET 后，顺手把这条命令写到了内核缓冲区（Page Cache）。\n后台线程 (BIO)：稍后（如每秒）醒来，调用 fsync 把内核缓冲区的数据刷到物理磁盘。 RDB：如果满足了触发条件（如 1 分钟改了 1 万次）。\n主线程：调用 fork 生成子进程。\n子进程：默默地在后台把内存里的 user:1 等所有数据写成 RDB 文件。\nKafka为什么比RocketMQ快 参照物：传统 I/O (Standard I/O) 假设你要把磁盘上的一个文件通过网卡发给消费者（比如读取日志发送）。 代码通常是：read(file, buffer) -\u0026gt; write(socket, buffer)。\n这中间发生了 4 次拷贝 + 4 次上下文切换：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区（Read Buffer）。\nCPU 拷贝：内核缓冲区 -\u0026gt; 用户态缓冲区（数据进来了）。\nCPU 拷贝：用户态缓冲区 -\u0026gt; 内核 Socket 缓冲区（数据又出去了）。\nDMA 拷贝：Socket 缓冲区 -\u0026gt; 网卡。\n痛点：数据在内核和用户态之间反复横跳，CPU 忙着搬运数据，没空干别的。\nKafka 的绝技：sendfile (数据管道) Kafka 在发送消息给消费者时，调用了 Java 的 FileChannel.transferTo()，底层就是 Linux 的 sendfile 系统调用。\n核心机制 sendfile 告诉内核：“把这个文件里的数据，直接发给那个 Socket，不要经过我的手（用户态）。”\n流程（2 次拷贝 + 2 次切换）：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区 (Page Cache)。\nCPU/DMA 拷贝：\n早期 Linux：内核缓冲区 -\u0026gt; Socket 缓冲区。\n现代 Linux (DMA Gather Copy)：内核缓冲区 -\u0026gt; 直接给网卡（只把描述符给 Socket，真正做到了 CPU 0 拷贝）。\n这里的零拷贝指的是零CPU拷贝。\nRocketMQ 的绝技：mmap (内存映射) RocketMQ 选择了 mmap（Memory Mapped Files），在 Java 中对应 MappedByteBuffer。\n核心机制 mmap 告诉内核：“把磁盘上的这个文件，映射到我的虚拟内存地址里来。”\n流程：\n建立映射：用户态的一个虚拟地址指针，直接指向内核的 Page Cache。\n读写数据：\nRocketMQ 读取这个指针，就像读内存数组一样简单。\n操作系统负责在后台利用 DMA 把磁盘数据加载到 Page Cache（缺页中断机制）。\n发送数据：RocketMQ 读取这块“内存”，然后 write 给 Socket。\n这里依然需要一次 CPU 拷贝（从映射内存拷贝到 Socket 缓冲区）。 特性 Kafka (sendfile) RocketMQ (mmap) 数据路径 磁盘 -\u0026gt; 内核 -\u0026gt; 网卡 磁盘 -\u0026gt; 内核 -\u0026gt; 用户态 -\u0026gt; 内核 -\u0026gt; 网卡 CPU 参与度 极低 (几乎不参与拷贝) 中等 (需要一次 CPU 拷贝) 用户态可见性 不可见 (黑盒传输) 可见 (可读、可修改) 适用场景 海量数据流式传输 (只管发，不处理) 复杂业务消息 (需要过滤 Tag、事务回查等) Java API FileChannel.transferTo() MappedByteBuffer 限制 无法对内容进行逻辑处理 文件不能太大 (RocketMQ 限制 1GB) Kafka 之所以吞吐量宇宙第一，是因为它放弃了对消息细节的掌控，直接用 sendfile 当了一个“甩手掌柜”，把数据直接丢给网卡。\nRocketMQ 之所以功能强大（支持 Tag 过滤、复杂的事务状态），是因为它用了 mmap，保留了对数据的访问权，虽然牺牲了一点点传输性能，但换来了业务灵活性。\n一句话概括：Kafka 是为了“运货”而生，RocketMQ 是为了“验货”而生。\nPage Cache 是 Linux 内核为了掩盖磁盘龟速而用闲置内存做的“障眼法”。\n为什么RPC/HTTP2能比HTTP1.1快那么多 简单来说，HTTP/1.1 像是单车道，而 HTTP/2 + RPC 像是多车道高速公路，且路上跑的都是压缩后的跑车而不是臃肿的大卡车。\n以下是具体的技术核心差异：\n1. 多路复用 (Multiplexing) —— 解决核心痛点 这是 HTTP/2 相比 HTTP/1.1 最大的性能提升点，解决了“队头阻塞”（Head-of-Line Blocking）问题。\nHTTP/1.1 的问题：\n在同一个 TCP 连接中，请求是串行的。浏览器/客户端必须等上一个请求响应回来，才能发下一个。如果第一个请求处理很慢（比如数据库卡了），后面的所有请求都会被堵住。\n补救措施： 浏览器通常会针对同一个域名建立 6 个 TCP 连接来并行传输，但这对服务器资源消耗很大。 HTTP/2 (RPC) 的方案：\n它引入了 流 (Stream) 和 帧 (Frame) 的概念。\n所有的请求和响应都共用同一个 TCP 连接。\n不同的请求被拆分成许多小的二进制“帧”，这些帧像洗牌一样混在一起传输，每一帧都有 ID 标识属于哪个请求。\n结果： 请求 A 的数据包不需要等请求 B 处理完就能发送。高并发下，吞吐量极高。\n2. 头部压缩 (HPACK) —— 节省带宽 在微服务架构中，RPC 调用非常频繁，HTTP 头部（Headers）占用的开销比你想象的要大。\nHTTP/1.1 的问题：\nHTTP 是无状态的，每次请求都会携带完整的 Header（如 User-Agent, Cookie, Accept 等）。这些全是纯文本，往往几百字节甚至上 KB。如果你的请求体（Body）只有几十字节，那传输的有效数据比例极低。\nHTTP/2 (RPC) 的方案：\n使用了 HPACK 算法。\n客户端和服务器共同维护一张动态表和静态表。\n如果发送过 User-Agent: Chrome，第二次只需要发送一个索引号（比如 1），服务器查表就知道是 User-Agent: Chrome。\n这使得 Header 的大小几乎可以忽略不计。\n3. 二进制分帧 (Binary Framing) —— 解析更快 计算机处理二进制数据远快于处理文本。\nHTTP/1.1 的问题：\n是文本协议。解析文本需要处理换行符、空格、大小写等，对于高并发服务器来说，解析 JSON 或 HTTP 报文会消耗大量的 CPU 资源。\nHTTP/2 (RPC) 的方案：\n是二进制协议。数据在传输层就已经被分割为更小的消息和帧，并采用二进制编码。机器解析起来非常高效，出错率低，且更紧凑。\n4. 序列化协议 (Serialization) —— RPC 的独门秘籍 这一条主要针对 RPC（如 gRPC 使用的 Protocol Buffers）对比传统的 RESTful (HTTP/1.1 + JSON)。\nHTTP/1.1 + JSON：\nJSON 是基于文本的，冗余度极高。比如 {\u0026ldquo;id\u0026rdquo;: 12345, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;user\u0026rdquo;}，你需要传输字段名 id 和 name。且 JSON 的解析（反序列化）非常耗 CPU。\nRPC (Protobuf)：\n使用 Protocol Buffers (Protobuf) 或 Thrift 等二进制序列化协议。\n体积小： 它是通过 ID 映射字段，不传输字段名，压缩后的体积通常只有 JSON 的 1/3 到 1/10。\n速度快： 二进制流直接映射到内存对象，序列化/反序列化速度比 JSON 快 5-10 倍。\n5. 服务端推送 (Server Push) 虽然在 RPC 场景下用得相对少，但 HTTP/2 允许服务器在客户端请求之前“主动”推送资源，减少了往返延迟（RTT）。\n总结对比 特性 HTTP/1.1 HTTP/2 (及 gRPC) 优势 传输格式 文本 (Text) 二进制 (Binary) 解析更快，体积更小 连接模型 串行 (Keep-Alive) 多路复用 (Multiplexing) 解决队头阻塞，极大提高并发 头部开销 巨大 (纯文本重复发送) HPACK 压缩 节省带宽 负载内容 通常是 JSON (大、慢) 通常是 Protobuf (小、快) 序列化性能提升明显 TCP 连接数 多个 (通常 6 个) 只需 1 个 降低服务器握手和资源开销 HeavyKeeper和LRU，LFU 可以将它们的关系理解为：LRU 和 LFU 是“怎么扔垃圾”，而 HeavyKeeper 是“怎么用极小的代价找出谁是大佬”。\n以下是详细的对比和原理解析：\n1. LRU (Least Recently Used) - 最近最少使用 核心逻辑： “如果数据最近被访问过，那么它将来被访问的几率也很大。”\n关注点： 时间（Recency）。\n工作原理：\n新数据或刚被访问的数据放到队头。\n缓存满时，直接淘汰队尾的数据（最久没被摸过的）。\n优点：\n实现简单（HashMap + 双向链表）。\n适应突发性流量（Burst Traffic），因为热点往往是临近的。\n缺点：\n缓存污染（Cache Pollution）： 如果进行一次全表扫描（读取大量数据但只用一次），会把原本的热点数据全部挤出缓存，导致缓存命中率急剧下降。 2. LFU (Least Frequently Used) - 最不经常使用 核心逻辑： “如果数据过去被访问多次，那么它将来被访问的几率也很大。”\n关注点： 频率（Frequency）。\n工作原理：\n为每个数据维护一个计数器。\n缓存满时，淘汰计数器数值最小的数据。\n优点：\n抗扫描能力强。偶尔的一次性批量读取不会挤掉长期积累的热点数据。\n对于长期稳定的热点数据，命中率极高。\n缺点：\n实现复杂且内存开销大： 需要维护所有数据的计数器，且排序复杂度较高。\n旧数据滞留（Dusty Cache）： 一个以前很热但现在没用的数据（比如上个月的爆款商品），因为计数器很高，会一直霸占缓存，如果不引入衰减机制，很难被淘汰。\n3. HeavyKeeper - 专门抓“大象”的守门员 核心逻辑： “我不追求 100% 精确，但我用极小的内存就能告诉你谁是真正的热点（Top-K）。”\n关注点： 极低内存下的频率预估。\n本质： 它不是一个完整的缓存系统，而是一个算法结构（通常基于 Count-Min Sketch 的改进）。它常被用于 Redis 的热点发现工具或现代缓存系统（如 Caffeine 库）的频率过滤器中。\n工作原理（指纹衰减）：\n它使用类似哈希表的结构，但存储的是指纹（Fingerprint）和计数。\n关键创新： 传统的 Sketch 算法在哈希冲突时会错误地增加计数（导致高估）。HeavyKeeper 引入了衰减机制——当新元素进入并发生哈希冲突时，如果指纹不匹配，它会以一定概率减少（Decay）原有的计数器。\n结果： “小鼠流”（低频数据）的计数会被不断衰减消灭，“大象流”（高频数据）因为访问足够多，能抵抗衰减并幸存下来。\n优点：\n内存占用极小： 相比 LFU 记录所有 key 的完整计数，HeavyKeeper 只需要很少的 bucket 就能大概率找准热点。\n误差可控： 专门为 Top-K 场景设计，对高频数据极其准确。\n总结对比表 特性 LRU (时间) LFU (频率) HeavyKeeper (概率频率) 全称 Least Recently Used Least Frequently Used HeavyKeeper 核心维度 最近访问时间 访问总次数 访问总次数 (概率性) 主要用途 缓存淘汰策略 缓存淘汰策略 热点检测 (Top-K) / 辅助 LFU 抗扫描能力 弱 (容易被冲刷) 强 强 空间开销 中 (存 Key + 链表指针) 大 (存 Key + 计数器) 极小 (哈希桶 + 指纹) 实现复杂度 低 ($O(1)$) 高 (需堆或多级链表) 中 (哈希 + 概率逻辑) 精准度 精确 精确 有误差 (但对热点准确) 典型应用 MySQL Buffer Pool (改进版), 操作系统页置换 传统缓存系统 Redis 热 key 发现, 网络流量分析 LRU代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 package com.lucius.interviewproject.LRU; import java.util.HashMap; public class LRUCache { // 定义双向链表节点 class DLinkedNode { int key; int value; DLinkedNode prev; DLinkedNode next; public DLinkedNode() {} public DLinkedNode(int _key, int _value) {key = _key; value = _value;} } // 核心数据结构 private HashMap\u0026lt;Integer, DLinkedNode\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); private int size; private int capacity; private DLinkedNode head, tail; // 伪头部和伪尾部节点 public LRUCache(int capacity) { this.size = 0; this.capacity = capacity; // 使用伪头部和伪尾部节点，避免处理复杂的 null 边界情况 head = new DLinkedNode(); tail = new DLinkedNode(); head.next = tail; tail.prev = head; } public int get(int key) { DLinkedNode node = cache.get(key); if (node == null) { return -1; } // 如果 key 存在，先通过哈希表定位，然后移动到链表头部 moveToHead(node); return node.value; } public void put(int key, int value) { DLinkedNode node = cache.get(key); if (node == null) { // 如果 key 不存在，创建一个新节点 DLinkedNode newNode = new DLinkedNode(key, value); // 添加进哈希表 cache.put(key, newNode); // 添加至双向链表的头部 addToHead(newNode); size++; // 如果超出容量，删除双向链表的尾部节点 if (size \u0026gt; capacity) { DLinkedNode tail = removeTail(); // 删除哈希表中对应的项 cache.remove(tail.key); size--; } } else { // 如果 key 存在，更新 value，并移动到头部 node.value = value; moveToHead(node); } } // --- 以下是辅助的链表操作方法 --- // 1. 将节点移动到头部 (也就是最近使用的位置) private void moveToHead(DLinkedNode node) { removeNode(node); addToHead(node); } // 2. 将节点插入到伪头部之后 private void addToHead(DLinkedNode node) { node.prev = head; node.next = head.next; head.next.prev = node; head.next = node; } // 3. 删除节点 private void removeNode(DLinkedNode node) { node.prev.next = node.next; node.next.prev = node.prev; } // 4. 删除尾部节点（淘汰最久未使用的） private DLinkedNode removeTail() { DLinkedNode res = tail.prev; removeNode(res); return res; } } Redis的大key的问题怎么解决 由于 Redis 是单线程模型，处理一个巨大的 Key（无论是读取、写入还是删除）都会占用主线程，导致后续请求排队等待，造成 \u0026ldquo;卡顿\u0026rdquo;。\n以下是系统化的解决思路，分为 发现、删除 和 治理（预防） 三个阶段。\n一、 什么是 Big Key？（标准定义） 通常根据 Value 的大小或元素数量来判定：\nString 类型： Value \u0026gt; 10KB（严格标准）或 1MB（宽松标准）。\n集合类型（Hash, List, Set, ZSet）： 元素个数 \u0026gt; 5000 或 10000 个。\n二、 如何发现 Big Key？ 在治理之前，首先要定位它们。\nredis-cli --bigkeys 命令：\nRedis 自带的工具，会扫描整个 Key 空间。\n缺点： 它是阻塞式的扫描（虽然用了 SCAN），在数据量巨大时可能会轻微影响性能，且只能返回每种类型最大的那个 Key，信息不全。\nMEMORY USAGE key 命令：\n如果你怀疑某个 Key 是大 Key，可以用这个命令查询其实际内存占用。 RDB 文件分析（推荐）：\n使用工具（如 rdb-tools 或 redis-rdb-tools）离线分析 RDB 备份文件。\n优点： 完全不影响线上 Redis 性能，生成的报告非常详细（包含 Key 名称、大小、类型）。\n监控告警：\n如果在云服务商（如阿里云、AWS）上，通常控制台会有 \u0026ldquo;大 Key 分析\u0026rdquo; 功能。\n监控网络带宽，如果网络流出流量瞬间飙升，通常是有客户端读取了大 Key。\n三、 如何安全地删除 Big Key？ 绝对禁止直接使用 DEL 命令删除大 Key！\nDEL 是同步阻塞操作，删除一个几百 MB 的 Key 可能会阻塞 Redis 几秒钟，导致故障转移或请求超时。\n1. Redis 4.0 及以上版本（推荐） 使用 UNLINK 命令代替 DEL。\n原理： UNLINK 只是将 Key 从元数据中解绑（逻辑删除），真正的内存回收操作会由后台线程（Lazy Free）异步执行，不会阻塞主线程。 2. Redis 4.0 以下版本（手动渐进式删除） 如果版本较老，必须手动分批删除，避免阻塞：\nHash: 使用 HSCAN 每次扫描一部分字段，然后用 HDEL 删除。\nList: 使用 LPOP/RPOP 或 LTRIM 分批删除。\nSet: 使用 SSCAN 扫描，SREM 删除。\nZSet: 使用 ZREMRANGEBYRANK 分批删除。\n四、 如何彻底解决（设计与预防）？ 删除只是治标，只有修改业务设计才能治本。\n1. 拆分（Split） 将一个大 Key 拆分为多个小 Key。\n场景： 一个 Hash 存储了 100 万个用户对象。\n方案： 使用 Hash 取模设计。例如定义 hash_0 到 hash_99 共100个 Bucket。\n存取时：id % 100 决定存入哪个 Key。\n这样每个 Key 的大小就只有原来的 1/100。\n2. 压缩（Compression） 对于 String 类型的长文本（如 JSON、XML），使用压缩算法。\n方案： 写入 Redis 前使用 Gzip、Snappy 或 Protobuf 进行压缩/序列化。通常能减少 50%-80% 的体积。 3. 剪裁与清洗（Pruning） 不要把 Redis 当数据库用，只存 \u0026ldquo;热点数据\u0026rdquo;。\n场景： 一个 List 存了用户的历史浏览记录，长达几万条。\n方案： 业务上只需要展示最近 100 条。在写入时维持定长队列（LTRIM），或者定期清理过期数据。\n4. 设置过期时间（TTL） 防止 \u0026ldquo;僵尸\u0026rdquo; 大 Key 长期占用内存。给 Key 设置合理的 TTL，让其自动过期删除（注意：Redis 的自动过期在 4.0 之前删除大 Key 也可能阻塞，4.0+ 配置 lazyfree-lazy-expire yes 可解）。 5. 存储转移（Offloading） 如果数据本身就是很大（例如图片二进制、长文章），且必须完整读取，那么它不适合存入 Redis。\n方案： 存入 S3、MongoDB 或 CDN，Redis 只存该数据的 URL 或索引 ID。\n总结对照表 策略 适用场景 关键手段 发现 线上排查 / 离线分析 redis-cli --bigkeys, RDB Tools 应急处理 此时此刻必须删除 UNLINK (异步删除) 架构优化 集合元素过多 拆分 (Sharding/Bucketing) 架构优化 文本 Value 过大 压缩 (Gzip/Snappy) 架构优化 无效数据堆积 定期清理 (LTRIM) / 设置 TTL Redis是怎么找到key存储在哪个节点上？ Redis 在集群模式（Redis Cluster）下，并不是直接把 Key 存到节点上的，而是引入了一个中间层：哈希槽 (Hash Slot)。\n简单来说，Redis 集群预分好了一万多个坑位（Slot），所有的 Key 都要先算一下自己该去哪个坑，而具体的节点（Node）只是负责管理这些坑位。\n以下是具体的寻址过程，分为 理论计算 和 客户端交互 两个层面。\n一、 核心算法：CRC16 + 取模 Redis Cluster 固定的将数据空间划分为 16384 个哈希槽（编号 0 ~ 16383）。\n当你要存储一个 Key（比如 set name lucius）时，Redis 会通过以下两步计算出这个 Key 属于哪个槽：\n计算哈希值：使用 CRC16 算法对 Key 进行计算，得到一个整数。\n取模运算：将得到的整数对 16384 取模。\n公式：\n$$ Slot = CRC16(key) \\pmod{16384} $$计算出 Slot 编号（比如 5000）后，Redis 只需要查看当前集群配置中，编号 5000 的槽是由哪个节点负责的，就能确定数据在哪个节点。\n二、 生动比喻：快递分拣中心 为了方便理解，我们可以把 Redis Cluster 想象成一个巨大的物流分拣系统：\n货物 (Key)：你要存的数据。\n快递筐 (Hash Slot)：系统里一共有 16384 个固定的筐子，编号 0-16383。\n货车 (Node)：实际负责运货的物理服务器（比如有 3 台服务器 A、B、C）。\n流程是这样的：\n分配规则：\n货车 A 负责运送 0 ~ 5500 号筐子。\n货车 B 负责运送 5501 ~ 11000 号筐子。\n货车 C 负责运送 11001 ~ 16383 号筐子。\n存货过程：\n来了一个包裹 name。\n系统算一下（CRC16），发现它应该进 5000 号筐子。\n查表发现 5000 号筐子归 货车 A 管。\n于是包裹被丢进货车 A。\n为什么要这么设计？\n如果因为业务繁忙，你要加一辆货车 D，你不需要把所有包裹重新拆包计算一遍。你只需要把 货车 A 上的一部分筐子（比如 0~1000号）搬到 货车 D 上即可。\n这就是 Redis Cluster 扩容方便的原因：数据迁移的单位是“槽”，而不是单个 Key。\n三、 客户端是怎么知道去哪个节点的？ 虽然服务器知道槽位映射关系，但**客户端（比如你的 Java 代码）**是怎么知道的呢？\n通常有两种情况：\n1. 笨客户端（每次都问，或问错了）—— MOVED 重定向错误 假设客户端不知道 Key name 在哪个节点，它随便连了一个节点（比如节点 B）发送命令：GET name。\n节点 B 收到命令，计算 CRC16('name') % 16384，发现属于 Slot 5000。\n节点 B 查自己的小本本，发现 Slot 5000 归 节点 A 管。\n节点 B 不会帮客户端去取数据（因为那是代理做的事），而是直接返回一个错误：\nMOVED 5000 192.168.1.100:6379\n(翻译：哥们你找错人了，这个 Key 归 5000 号槽管，那个槽在 IP 为 \u0026hellip; 的节点上，你自己去找它吧。)\n客户端收到报错，根据新地址，重新去连接节点 A。\n2. 聪明客户端（Smart Client，如 Jedis, Lettuce）—— 本地缓存 为了性能，现在的客户端（如 Java 的 Jedis、Lettuce）在启动时，会先连接集群，把 Slot -\u0026gt; Node 的映射表 下载下来缓存在本地内存里。\n你要 GET name。\nJava 客户端在本地算一下：Slot = 5000。\n查本地缓存：Slot 5000 -\u0026gt; 节点 A。\n直接连接节点 A 发送请求。\n这避免了额外的网络跳转，效率最高。\n四、 特殊情况：Hash Tag（强制特定 Key 去特定节点） 面试高频考点：\n由于 CRC16 算法是随机的，user:1001 和 order:1001 很大概率会被分到不同的节点上。\n这就导致一个问题：如果你想在一个事务（Multi/Exec）里同时操作这两个 Key，或者用 Lua 脚本同时处理它们，会报错！ 因为 Redis 要求事务或脚本涉及的所有 Key 必须在同一个节点上。\n解决方案：Hash Tag {}\n你可以在 Key 中使用花括号 {}。Redis 计算 Hash 时，如果发现 Key 里有 {}，就只计算 {} 内部字符串的 Hash 值。\nKey 1: user:{1001} -\u0026gt; 计算 CRC16(\u0026quot;1001\u0026quot;)\nKey 2: order:{1001} -\u0026gt; 计算 CRC16(\u0026quot;1001\u0026quot;)\n因为 {} 里的内容一样，算出来的 Slot 肯定一样，它们就一定会落到同一个节点上。\n没有 Hash Tag 之前，Redis 的分拣员（CRC16 算法）是非常老实的，它会把 Key 的每一个字符都算进去。\n1. 没有 Hash Tag（老实模式） 分拣员看到什么就算什么，全名参与计算。\nKey A: user:1001\n算法输入：\u0026quot;user:1001\u0026quot; (9 个字符)\n结果：哈希值 X $\\rightarrow$ 对应 Slot 500\nKey B: order:1001\n算法输入：\u0026quot;order:1001\u0026quot; (10 个字符)\n结果：哈希值 Y $\\rightarrow$ 对应 Slot 8000\n因为 \u0026quot;user:1001\u0026quot; 和 \u0026quot;order:1001\u0026quot; 是完全不同的两个字符串，算出来的结果自然千差万别，所以它们被分到了不同的节点。\n2. 有 Hash Tag（偷懒模式） 分拣员一旦看到 {}，就只算花括号里面的内容，外面的前缀后缀全当看不见。\nKey A: user:{1001}\n算法输入：\u0026quot;1001\u0026quot; (只算这 4 个数字)\n结果：哈希值 Z $\\rightarrow$ 对应 Slot 300\nKey B: order:{1001}\n算法输入：\u0026quot;1001\u0026quot; (还是只算这 4 个数字)\n结果：哈希值 Z $\\rightarrow$ 对应 Slot 300\n因为输入完全一样（都是 \u0026quot;1001\u0026quot;），所以算出来的 Slot 编号绝对一样，这两个 Key 就必定会去同一个节点“团聚”。\n小贴士（Hash Tag使用风险） 虽然 Hash Tag 很好用，但千万不要滥用。\n如果你把几百万个 Key 都加上同一个 Hash Tag（比如 user:{beijing}），那么这几百万个 Key 算出来的 Slot 全都一样，它们会全部挤到同一台机器上。\n后果： 这就导致了数据倾斜（Data Skew）—— 集群里的一台机器忙死（内存爆满、CPU 飙升），而其他机器闲死。\nMySQL三层B+树能存储多少数据? 但在通常的估算标准下（主键为 BigInt，单行数据约 1KB），三层 B+ 树大约能存储 2000 万（2000w）条数据。\n1. 核心预设条件 MySQL 的 InnoDB 存储引擎有以下几个默认属性，这是计算的基础：\n页大小 (Page Size)：默认是 16KB ($16384$ 字节)。\n指针大小：InnoDB 页指针为 6 字节。\n主键类型：通常假设为 BigInt (8 字节)。如果用 Int (4 字节)，存的更多。\n2. B+ 树结构拆解 B+ 树分为非叶子节点（存索引和指针）和叶子节点（存真实数据）。\n第一步：计算非叶子节点能存多少索引？ 非叶子节点不存数据，只存“主键 + 指针”。\n单个索引项大小 = 主键大小 (8B) + 指针大小 (6B) = 14 字节。\n单页可存索引数 = 页大小 / 索引项大小 = $16384 / 14 \\approx 1170$ 个。\n这意味着，一个非叶子节点可以指向 1170 个下级节点。\n第二步：计算叶子节点能存多少数据？ 叶子节点存储真实的行数据。这里变量最大的就是“一行数据的大小”。\n假设 1：一行数据大小为 1KB（比较常见的预设）。\n单页可存行数 = $16384 / 1024 = 16$ 条。\n3. 三层 B+ 树容量计算 结构如下：\n根节点（第1层）：非叶子节点，指向 1170 个第2层节点。\n分支节点（第2层）：非叶子节点，每个节点指向 1170 个叶子节点。总共有 $1170 \\times 1170$ 个叶子节点。\n叶子节点（第3层）：存数据。\n计算公式：\n$\\text{总记录数} = (\\text{根节点指针数}) \\times (\\text{第二层指针数}) \\times (\\text{叶子节点单页行数})$\n代入数值（行数据 1KB）：\n$1170 \\times 1170 \\times 16 \\approx \\mathbf{21,902,400}$\n结论 1： 如果一行数据是 1KB，三层能存约 2190 万 条数据。\n4. 如果数据行很小怎么办？ 有些表可能只有几个字段，一行数据可能只有 100 字节。如果不算页分裂等损耗：\n单页可存行数 = $16384 / 100 \\approx 160$ 条。\n总容量 = $1170 \\times 1170 \\times 160 \\approx \\mathbf{2.19 亿}$。\n结论 2： 数据行越小，三层 B+ 树能存的数据就越多，甚至能过亿。\n5. 现实中的误差（Fill Factor） 上面的计算是理论最大值（所有页都填满 100%）。但在实际运行中：\n页头页尾开销：每个页有 Header、Directory Slot 等元数据，大约占用几十到几百字节，不能全用来存数据。\n页填充率：InnoDB 不会把页填得满满当当，为了减少页分裂，通常填充率在 1/2 到 15/16 之间。如果频繁随机插入，页碎片化会导致填充率下降。\n如果按照 50%-75% 的利用率折算，通常认为三层树的舒适区确实就在 2000万 左右。一旦超过这个数量级，B+ 树可能分裂出第四层，导致磁盘 I/O 增加，查询性能轻微下降。\n事务的四大特性（ACID） 为了保证上述逻辑的严密性，数据库理论规定事务必须满足 ACID 四个特性，这经常在面试中被问到：\nA - 原子性 (Atomicity)：\n核心：要么全做，要么全不做。\n实现靠 Undo Log（回滚日志）。\nC - 一致性 (Consistency)：\n核心：事务前后，数据必须符合逻辑（比如转账前后，两人的钱加起来总数不变）。 I - 隔离性 (Isolation)：\n核心：多个事务并发执行时，互不干扰（这就是我们之前讨论的 RR、RC 隔离级别）。\n实现靠 锁 + MVCC。\nD - 持久性 (Durability)：\n核心：事务一旦提交，数据就是永久的，哪怕下一秒服务器爆炸，重启后数据依然在。\n实现靠 Redo Log（重做日志）。\nMySQL的事务隔离级别 并发事务的三大问题 脏读 (Dirty Read)：事务 A 读到了事务 B 未提交的数据。如果 B 回滚，A 读到的就是脏数据。\n不可重复读 (Non-repeatable Read)：事务 A 在同一个事务中两次读取同一行数据，结果不一样。这是因为在两次读取之间，事务 B 修改或删除了该数据并提交了。\n幻读 (Phantom Read)：事务 A 在同一个事务中两次查询同一个范围，第二次发现多了一些数据。这是因为在两次查询之间，事务 B 插入了新数据并提交了。\n四种隔离级别详解 按照隔离程度从低到高排序：\n1. 读未提交 (Read Uncommitted) 描述：这是最低的隔离级别。一个事务可以读取到另一个事务未提交的修改。\n现象：相当于“裸奔”，没有任何隔离。\n存在问题：脏读、不可重复读、幻读都会发生。\n应用场景：实际开发中极少使用。\n2. 读已提交 (Read Committed - RC) 描述：一个事务只能读取到已经提交的数据。\n实现原理：MVCC（多版本并发控制）。每次执行 SELECT 语句时，都会重新生成一个 Read View（一致性视图）。\n存在问题：解决了“脏读”，但可能发生“不可重复读”（因为每次 Select 都生成新视图，如果中间有人提交修改，你就能看到）。\n备注：这是大多数主流数据库（如 Oracle, PostgreSQL, SQL Server）的默认隔离级别，但不是 MySQL 的默认值。\n3. 可重复读 (Repeatable Read - RR) —— MySQL 默认 描述：确保在同一个事务中，多次读取同样的数据结果是一样的。\n实现原理：MVCC。与 RC 不同的是，RR 级别下，Read View 是在事务启动后的第一次查询时生成的，之后一直复用这个视图。\n存在问题：解决了“脏读”和“不可重复读”。\n关于幻读：在标准 SQL 定义中，RR 是无法解决幻读的。但是，MySQL 的 InnoDB 引擎通过 MVCC + Next-Key Lock 技术，在 RR 级别下很大程度上避免了幻读（正如我上一个回答所解释的）。\n4. 串行化 (Serializable) 描述：最高的隔离级别。它强制事务串行执行，通过强制对读取的数据行加锁（共享锁），避免了并发冲突。\n存在问题：解决了所有问题（脏读、不可重复读、幻读）。\n代价：并发性能极差，容易导致大量的超时和锁竞争。\n应用场景：只有在对数据一致性要求极高且并发量很小的场景下才会使用。\n隔离级别对比总结表 隔离级别 脏读 不可重复读 幻读 性能 备注 Read Uncommitted ✅ 可能 ✅ 可能 ✅ 可能 极高 极少使用 Read Committed (RC) ❌ 无 ✅ 可能 ✅ 可能 高 Oracle/PG 默认 Repeatable Read (RR) ❌ 无 ❌ 无 ❌ (大部分解决) 中 MySQL 默认 Serializable ❌ 无 ❌ 无 ❌ 无 低 强制排队，性能差 为什么可重复读的情况下不能避免幻读 数据在被修改（Update/Delete）的时候，必须基于“最新”的版本进行，而不能基于“历史”版本。\n时间点 事务 A 事务 B 现象/旁白 1 BEGIN; SELECT * FROM users WHERE id = 5; 结果：Empty (空) 事务 A 确认 id=5 还没人用。 2 BEGIN; INSERT INTO users (id, name) VALUES (5, '小明'); COMMIT; 事务 B 抢先插入了 id=5 并提交。 3 SELECT * FROM users WHERE id = 5; 结果：Empty (空) MVCC 生效。事务 A 依然看不到小明。一切看似正常。 4 UPDATE users SET name = '被修改' WHERE id = 5; 结果：Query OK, 1 row affected 关键点来了！ Update 是“当前读”，它能看到最新的提交。它不仅修改成功了，还把这条记录的“版本号”改成了事务 A 自己的。 5 SELECT * FROM users WHERE id = 5; 结果：id=5, name=\u0026lsquo;被修改\u0026rsquo; 【幻读发生】\n事务 A 吓死了：“我刚才查还没有 id=5，怎么我一更新，它就突然冒出来，还被我改了？” 注意，在第二步的时候，事务2已经插入并且提交了，这个时候数据库的内容发生了变化，后续步骤4进行update的时候就得根据最新的数据进行update，然后更新成功，并且，\n假设：\n事务 A 的 ID = 100。\n事务 B 的 ID = 200。\n幻读示例（自己修改或插入的数据，trx_id会变为自己的，可见） 阶段 1：事务 A 开启，生成 ReadView 事务 A 执行第一条 SELECT。\n生成 ReadView，记录当前活跃事务。此时系统里只有 A。\nReadView 只要生成了，在 RR 级别下就永远不会变了。\n阶段 2：事务 B 插入并提交 事务 B 插入 id=5。\n这行数据现在的状态是：{id: 5, name: '小明', trx_id: 200}。\n事务 B 提交。\n阶段 3：事务 A 第一次查询 id=5 事务 A 拿着 ReadView 来看这行数据。\n发现数据的 trx_id 是 200。\nReadView 判断：200 是在我（100）开启之后才进来的“将来的人”。\n结论：不可见。\n阶段 4：事务 A 执行 UPDATE（关键转折点！） 动作：UPDATE users SET name = '被修改' WHERE id = 5;\n当前读：正如之前所说，UPDATE 也是一种读，但它是“当前读”。它不看 ReadView，直接看物理磁盘。它看到了 trx_id=200 的数据（因为 B 已经提交，物理上存在）。\n修改数据：事务 A 把数据改了。\n打标签：这是最重要的一步！事务 A 把这行数据的 trx_id 更新成了自己的 ID（100）。\n现在的行数据变成了：{id: 5, name: '被修改', trx_id: 100}。\n阶段 5：事务 A 第二次查询 id=5 事务 A 再次执行 SELECT。\nReadView 变了吗？ 没有，还是那个旧的 ReadView。\n数据变了吗？ 变了。\n事务 A 再次检查可见性：\n这行数据的 trx_id 是多少？ -\u0026gt; 100。\n当前事务 A 的 ID 是多少？ -\u0026gt; 100。\n触发规则 1：trx_id 等于我自己。\n结论：可见！\n你之所以能看到，是因为你通过 UPDATE 操作，把这行数据的所有权**“抢”**过来了。\n修改前：这行数据属于事务 B（trx_id=200），对你是“未来数据”，不可见。\n修改后：这行数据属于事务 A（trx_id=100），对你是“自家数据”，无条件可见。\nReadView 到底存了什么？ 当你第一次执行 SELECT * FROM user 时，生成的 ReadView 是一张黑名单，长这样：\n1 2 3 4 5 { \u0026#34;m_ids\u0026#34;: [100, 101, 102], // 当前全数据库里，所有还没提交的事务 ID \u0026#34;min_trx_id\u0026#34;: 100, // 最小活跃 ID \u0026#34;max_trx_id\u0026#34;: 103 // 下一个要分配的 ID（水位线） } 请注意： 这个列表里完全没有提 user 表或 student 表的名字。它只规定了谁是老数据（可见），谁是活跃数据（不可见）。\n这个规则对全库所有表通用。\nMVCC简单的流程 事务在第一次select的时候会去检查当前活跃事务，然后会查看下一个要分配的事务id，然后记录下来，后面查询的时候会先去查询当前行数据的trx_id，查看数据的trx_id如果小于当前事务的id就应该直接使用这条数据，如果大于自己的事务id，就去查undo log，顺着undolog版本链找到真正自己能看到的数据，然后修改查询得到的数据。\nMySQL的锁 共享锁 在sql语句末尾加上for share代表共享锁，所有事务都可以读，但是不能修改，直至事务提交\n1 select * from uploaded_file where id = 1981221658045493248 for share; 排他锁 在sql语句末尾加上for update代表排他锁，其他事务不能修改，也不能读。\n1 select * from uploaded_file where id = 1981221658045493248 for update; 表锁 定义：最基本的锁策略，开销最小。它会锁定整张表。\n特点：\n无死锁：因为一次性获取所有需要的锁。\n并发度低：一个用户在写，其他用户都不能读写。\n适用场景：主要由 MyISAM 引擎使用；InnoDB 在特定情况下（如没有索引或手动指定 LOCK TABLES）也会用到，但通常尽量避免。\n意向锁 痛点：假设事务 A 锁住了表中的某一行（行锁），此时事务 B 想申请整个表的写锁（表锁）。事务 B 怎么知道表里有没有人正在改数据？它必须遍历每一行去检查，效率极低。\n定义：意向锁是表级锁。\n当事务 A 想要给某一行加锁时，必须先给表加一个“意向锁”。\n这就像在写字楼门口挂个牌子：“楼里有人（意向锁）”。\n作用：事务 B 看到门口有“意向锁”的牌子，就知道表里有人在忙，直接等待，不用进去逐个房间（行）检查了。它主要用于快速判断表锁和行锁的冲突。\n行锁 定义：InnoDB 的核心特性。只锁定被操作的那一行数据。\n特点：\n并发度高：多个人可以同时修改同一张表的不同行。\n开销大：需要加锁、解锁，且容易发生死锁。\n关键点：InnoDB 的行锁是加在索引上的。如果你查询时没有用到索引，InnoDB 会退化为锁定整张表（虽然实现机制上是把所有行都锁了），导致并发性能大跌。\n间隙锁 含义：只锁住两个记录之间的**“缝隙”**，不包含记录本身。\n锁住范围：(10, 20) —— 指的是大于 10 且小于 20 的范围。\n作用：纯粹是为了防止插入。别人不能在这个范围内 INSERT 任何数据（比如插 15）。但他如果要修改 id=20 这行数据，Gap Lock 是不管的。\nNext-Key Lock 假设数据库表中只有三行数据：id = 10, 20, 30。\n含义：锁住一段间隙 + 锁住间隙右边的那个记录。\n锁住范围：(10, 20] —— 左开右闭区间。\n组成：即锁住了 (10, 20) 这个缝隙，也锁住了 20 这个记录。\n作用：既不准你在缝隙里插数据（防幻读），也不准你修改右边那个记录。\n$Next\\text{-}Key \\ Lock = Gap \\ Lock + Record \\ Lock$\nMDL锁 定义：它不是用来锁数据的，而是用来锁**表结构（Schema）**的。\n触发机制（系统自动控制，用户无需显式调用）：\nMDL 读锁：当你对表进行增删改查（DML）时，自动加 MDL 读锁。\nMDL 写锁：当你对表结构进行修改（DDL，如 ALTER TABLE）时，自动加 MDL 写锁。\n互斥关系：\n读锁和读锁不互斥（大家可以一起查数据）。\n读写互斥、写写互斥。这意味着，如果有长事务正在查询数据（持有 MDL 读锁），你此时想给表加个字段（申请 MDL 写锁），会被阻塞。\n危险场景（MDL 风暴）：\nSession A 开启事务查数据（持有 MDL 读）。\nSession B 想加字段（申请 MDL 写，被阻塞）。\nSession C 及其后的所有查询（申请 MDL 读），因为写锁优先级通常高于读锁，或者写锁在排队，导致后续所有查询全部堵塞。\n结果：数据库线程瞬间爆满，导致宕机。\n索引下推是什么？ MySQL 处理 SQL 语句时，主要分为两层： Server 层（服务器层）： 负责解析 SQL、优化器生成执行计划、调用存储引擎接口、并处理最终的数据过滤（WHERE 条件判断）。\nStorage Engine 层（存储引擎层，如 InnoDB）： 负责真正的数据存储、提取，通过索引在磁盘上找数据。\n“下推”的意思是： 把原本只能在 Server 层做的事情，推给 存储引擎层去做。\n场景复盘 我们使用你的例子：\n表结构： user 表，有列 id (主键), name, age, address 等。\n索引： 联合索引 idx_name_age (name, age)。\nSQL：\nSQL\n1 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; AND age = 20; (注意：这里是 SELECT *，意味着必须回表拿到 address 等其他字段，不能仅靠覆盖索引)\n为什么这个场景特殊？ 根据最左前缀原则：\nname LIKE '王%' 是范围查询。索引能帮我们快速定位到所有姓“王”的人的起始位置。\n但是，一旦使用了范围查询（Range），索引后续的列（这里是 age）就无法用于定位（Seek）了。\n索引里的数据排序是：先按 name 排，name 相同才按 age 排。\n对于 王五 和 王六，他们的 age 是无序的（相对于整个“王%”区间），所以引擎必须扫描所有姓王的数据。\n虽然无法用来定位，但 age 的值确实存在于索引树的叶子节点中。ICP 的核心就在于是否利用了这个已有的数据。\n详细对比：无 ICP vs 有 ICP 假设数据库里有 4 条记录，索引结构 (name, age) 如下：\n(王五, 10) —— 主键 ID: 1\n(王六, 20) —— 主键 ID: 2 \u0026lt;\u0026ndash; 目标数据\n(王七, 30) —— 主键 ID: 3\n(张三, 20) —— 主键 ID: 4\n❌ 阶段一：没有 ICP (MySQL 5.6 之前) 在没有 ICP 的时候，存储引擎认为自己的任务就是找所有 name 以“王”开头的数据。它会忽略 age = 20 这个条件，因为按老规矩，范围查询后的列“失效”了。\n执行流程：\nServer 层告诉 InnoDB：“给我找所有 name LIKE '王%' 的记录。”\nInnoDB 在索引树上找到第一条 (王五, 10)。\nInnoDB 此时无视 age=10 不等于 20 这个事实。\nInnoDB 拿着 ID: 1 去聚簇索引回表，取出整行数据。\nInnoDB 把整行数据返回给 Server 层。\nServer 层拿到数据，进行 WHERE 判断：age 是 20 吗？\n发现是 10，丢弃。 InnoDB 继续找下一条 (王六, 20)。\n回表，取整行，返回给 Server。 Server 层 判断：age 是 20 吗？\n是，保留。 InnoDB 继续找下一条 (王七, 30)。\n回表，取整行，返回给 Server。 Server 层 判断：age 是 20 吗？\n不是，丢弃。 结果： 进行了 3 次回表，Server 层做了 3 次判断，最后只得到了 1 条数据。做了很多无用功（多回了 2 次表）。\n✅ 阶段二：开启 ICP (MySQL 5.6 及以后) MySQL 意识到：“嘿，InnoDB 兄弟，虽然你正在扫描索引，但我需要的 age 其实就在你手里的索引节点上。你能不能顺便帮我看一眼？如果 age 不对，你就别回表了，直接看下一个。”\n这就是 Index Condition Pushdown：把 age = 20 这个条件下推到存储引擎层。\n执行流程：\nServer 层告诉 InnoDB：“给我找 name LIKE '王%' 的记录，同时，如果 age 不等于 20，你就别给我了。”\nInnoDB 在索引树上找到第一条 (王五, 10)。\nInnoDB 直接检查索引上的值：age 是 10。\n不符合 age = 20。\nInnoDB 直接跳过（不回表，不返回给 Server）。\nInnoDB 继续找下一条 (王六, 20)。\n检查索引：age 是 20。\n符合！\nInnoDB 拿着 ID: 2 回表，取出整行数据，返回给 Server。\nServer 层 再次确认（兜底），保留数据。\nInnoDB 继续找下一条 (王七, 30)。\n检查索引：age 是 30。\n不符合，直接跳过。\n结果： 只进行了 1 次回表。I/O 操作大幅减少，性能提升。\n特性 判断 age=20 的位置 处理 (王五, 10) 处理 (王六, 20) 处理 (王七, 30) 总回表次数 无 ICP Server 层 (回表之后) 回表 -\u0026gt; 丢弃 回表 -\u0026gt; 保留 回表 -\u0026gt; 丢弃 3 次 (慢) 有 ICP 存储引擎层 (回表之前) 索引层直接丢弃 回表 -\u0026gt; 保留 索引层直接丢弃 1 次 (快) 怎么看有没有用到 ICP？ 你可以使用 EXPLAIN 命令查看执行计划。\n1 EXPLAIN SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; AND age = 20; 如果输出的 Extra 列中包含：Using index condition\n这就说明 ICP 生效了。\n(注：如果 Extra 是 Using where，说明在 Server 层过滤；如果是 Using index，说明是覆盖索引，不需要回表，性能更好)\n正常的联合索引（完美匹配） 假设索引还是 (name, age)。 SQL: SELECT * FROM user WHERE name = '王五' AND age = 20;\n在这种情况下，都是等值查询，符合最左前缀原则。\n怎么执行？ InnoDB 里的 B+ 树是严格排序的：先按 name 排，name 此时固定是 \u0026lsquo;王五\u0026rsquo;，那么里面的数据就是严格按 age 排序的。 InnoDB 不需要“先找王五，再遍历过滤 age”，而是直接根据 B+ 树的算法，一次性跳（Seek） 到 (王五, 20) 这个节点的位置。\n谁在做？ 存储引擎 (InnoDB)。它利用 B+ 树结构直接定位数据。\nServer 层在干嘛？ Server 层只是给 InnoDB 下达了一个指令：“把 name='王五' AND age=20 的数据给我。” InnoDB 说：“好的，我通过索引直接定位到了，这是数据。” Server 层拿到数据，甚至不需要再判断一次（但在代码实现逻辑上可能会做双重确认），直接发给客户端。\n索引下推 ICP（范围查询导致断档） 这是我们刚才聊的场景。 SQL: SELECT * FROM user WHERE name LIKE '王%' AND age = 20;\n怎么执行？ 因为 name 是范围，B+ 树只能帮你定位到“姓王的开始了”和“姓王的结束了”。在这个范围内，age 是乱序的（相对全局而言）。 InnoDB 不能直接跳到 age=20 的位置，只能从“王”的第一个数据开始扫描。\nICP 的作用： 在扫描过程中，InnoDB 顺便看一眼索引里的 age。如果不符合，就不回表了。\n谁在做？ 还是 存储引擎 (InnoDB)。但是这次它不是“直接定位”，而是“扫描 + 顺便过滤”。\nServer层处理“无法下推”的条件 这是 Server 层更重要的工作。如果 SQL 中包含不在索引里的字段条件，InnoDB 是无能为力的，必须由 Server 层来做。\n举个例子：\n索引： (name, age)\nSQL：\n1 2 3 4 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; -- 索引前缀（用于范围扫描） AND age = 20 -- 索引下推（ICP 在 InnoDB 过滤） AND address = \u0026#39;北京\u0026#39;; -- 索引里没有（Server 层过滤） 详情见下方流程\n索引下推查询的全流程 场景设定 表结构： user (id, name, age, address)\n索引： idx_name_age (name, age) —— 联合二级索引\nSQL 语句：\n1 2 3 4 SELECT * FROM user WHERE name LIKE \u0026#39;王%\u0026#39; -- 索引范围查询 (Range) AND age = 20 -- 索引下推过滤 (ICP) AND address = \u0026#39;北京\u0026#39;; -- 普通条件 (Server 层过滤) 2. 详细执行流程 (Pipeline) 这个流程就像一个漏斗，每经过一层，数据就变少一点，性能就越高。\n第一步：Server 层（准备阶段） 解析与优化： MySQL 优化器分析 SQL，发现可以使用 idx_name_age 索引。\n生成计划： 虽然 name 是范围查询导致 age 无法用于定位，但优化器决定开启 ICP。\n标志： EXPLAIN 中的 Extra 显示 Using index condition。 下发指令： Server 层告诉 InnoDB：“去 idx_name_age 索引里找 name 以 \u0026lsquo;王\u0026rsquo; 开头的数据。同时，把 age = 20 这个条件带上，如果不满足就别给我了。”\n第二步：InnoDB 存储引擎层（ICP 核心阶段） 定位游标： InnoDB 在二级索引 B+ 树上，找到第一个 name 匹配 '王%' 的叶子节点记录（假设是 王五, 10岁, ID:1）。\n索引内过滤 (ICP Check)：\nInnoDB 不急着回表。\n它先看手头索引元组里的 age。\n情况 A（不匹配）： 发现 age 是 10（不等于 20）。\n动作： 直接忽略该条记录，指针移向下一条。（省下一次回表 I/O） 情况 B（匹配）： 指针移向下一条（假设是 王六, 20岁, ID:2）。\n检查 age 是 20。符合条件！准备回表。 第三步：InnoDB 存储引擎层（回表阶段） 读取主键： 拿到符合 ICP 条件的记录的主键 ID:2。\n回表 (Table Lookup)： 拿着 ID:2 去**聚簇索引（主键索引）**树里查找。\n提取行数据： 从聚簇索引叶子节点里读取完整的行数据（包含 name, age, address 等所有列）。\n返回数据： 把这行完整数据返回给 Server 层。\n第四步：Server 层（最终兜底阶段） 接收数据： Server 层拿到 王六 的完整行数据。\n二次确认 (Double Check)： 尽管 InnoDB 过滤过，Server 层依然会校验 name LIKE '王%' 和 age = 20（流程规范）。\n补充过滤： Server 层检查 SQL 中剩下的、没法下推的条件 —— address = '北京'。\n如果 王六 的 address 是 \u0026lsquo;上海\u0026rsquo; -\u0026gt; 丢弃。\n如果 王六 的 address 是 \u0026lsquo;北京\u0026rsquo; -\u0026gt; 放入结果集。\n发送结果： 将最终通过的记录发送给客户端。\n3. 流程总结图解 步骤 所在层级 处理内容 数据状态 (示例) 关键作用 1 Server 生成执行计划 指令：Scan idx, Filter age=20 开启 ICP 2 InnoDB 扫描二级索引 (王五, 10) -\u0026gt; ❌ 直接丢弃\n(王六, 20) -\u0026gt; ✅ 保留 ICP 核心：减少回表 3 InnoDB 回表 (聚簇索引) 拿 ID:2 去找完整行数据 最耗时的 I/O 操作 4 Server 最终过滤 检查 address='北京' 处理非索引列逻辑 PriorityQueue的相关API 操作 复杂度 (Time Complexity) 备注 offer() / add() $O(\\log N)$ 插入操作，需要维护堆的属性。 poll() / remove() $O(\\log N)$ 移除最小/最大元素，需要重新堆化。 peek() / element() $O(1)$ 仅查看堆顶元素。 remove(Object o) $O(N)$ 移除任意元素，需要线性搜索。 方法 签名 描述 int size() public int size() 返回队列中元素的数量。 void clear() public void clear() 移除队列中的所有元素。 boolean isEmpty() public boolean isEmpty() 如果队列不包含任何元素，则返回 true。 Comparator\u0026lt;? super E\u0026gt; comparator() public Comparator\u0026lt;? super E\u0026gt; comparator() 返回用于对此队列中元素进行排序的比较器，或者返回 null（如果使用自然顺序）。 Object[] toArray() public Object[] toArray() 返回包含队列中所有元素的数组。注意：返回的数组不保证是排序的。 ","date":"2025-11-21T21:35:16+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1/%E5%9C%BA%E6%99%AF/","title":"面试八股/场景"}]
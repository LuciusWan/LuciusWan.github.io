[{"content":"Redis学习与实战 缓存穿透 缓存穿透是指客户端请求的数据,Redis和Mysql里面都没有,缓存永远不会生效,如果客户端一直请求相同的id,请求就会一直到达数据库,给数据库上压力了.\n解决方案1:缓存空对象 缓存空对象:如果客户端请求找不到的数据,就把找不到的数据缓存到Redis里,并且设置过期时间,在一定时间内,客户端的空对象请求不会经过Mysql\n缺点:有额外内存消耗,如果管理端新增对象和空对象id相同,可能造成缓存与数据库内容不一致\n解决缓存穿透的业务逻辑: 对应的java逻辑代码: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result getByIdRedis(Long id) { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 解决方案2:布隆过滤 缓存穿透后,穿透的信息进入布隆过滤器,如果再进行查询,先查询布隆过滤器,如果这个id是穿透信息,就直接拒绝查询\n其他解决方案: 做好热点参数的限流\n加强用户权限校验\n缓存雪崩 缓存雪崩是指大量数据同时到期,或者Redis服务直接宕机,大量请求涌入Mysql)\n简单解决办法 把数据存储进Redis的时候直接随机过期时间存储\njava代码如下（其实就是生成随机数) 1 2 3 4 5 private Long cacheAvalanche(){ Random random=new Random(); Long number=random.nextInt(11)+20L; return number; } 其他高级解决方案: Redis集群,分布式部署\n给缓存业务添加降级限流策略,如果redis集体驾崩,就直接拒绝大量请求,防止MySQL数据库压力过大\n给业务添加多级缓存\n缓存击穿 一个热点数据过期,大量线程同时访问,每个线程都选择查询完Redis后查询数据库,导致数据库压力剧增\n解决方案1:互斥锁 使用Redis的setnx作为互斥条件,所有线程同时设置一个键值对,只有一个线程可以设置成功,并且操作数据库,写入缓存,写完后释放锁资源\n1 2 3 4 5 6 7 8 9 10 11 12 13 //设置锁和释放锁的方法 private Boolean setLock(String key){ Boolean flag= stringRedisTemplate.opsForValue().setIfAbsent(key,\u0026#34;1\u0026#34;,10,TimeUnit.SECONDS); if(flag==null){ return false; }else if(flag){ return true; } return false; } private void unLock(String key){ stringRedisTemplate.delete(key); } 互斥锁解决缓存穿透的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result getByIdRedis(Long id) throws InterruptedException { String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ Shop shopRedis= JSONUtil.toBean(shop,Shop.class); return Result.ok(shopRedis); } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } String json= JSON.toJSONString(shop1); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程休眠对应的时间后重新尝试获取资源(递归) }else { Thread.sleep(50); getByIdRedis(id); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 其中为防止获得锁的线程挂了不会释放锁资源,给锁设置过期时间\n解决方案2:逻辑过期时间 在Redis中存储数据时,多存储一条过期时间,如果过期的话,最快发现的线程会主动申请互斥锁,并且查询数据库,查完后设置过期时间并且写回redis,同时返回给客户端,其他的线程请求完锁后,请求不到就直接返回过期的数据,这种方式可以防止死锁的发生,但是牺牲了一部分redis空间 java代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Override public Result redisLogicExpireTime(Long id){ String shop= stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY+id); logger.info(shop); //查询到对应的value,并且这个value不是\u0026#34;\u0026#34;,则店铺存在,直接返回 if(shop!=null\u0026amp;\u0026amp;!\u0026#34;\u0026#34;.equals(shop)){ RedisData redisData=JSONUtil.toBean(shop,RedisData.class); //判断是否过期 if(redisData.getExpireTime().isAfter(LocalDateTime.now())){ Shop shopRedis= redisData.getData(); System.out.println(shopRedis); logger.info(\u0026#34;查询redis直接输出\u0026#34;); return Result.ok(shopRedis); } } //店铺value不等于null,但是为\u0026#34;\u0026#34;，说明缓存和数据库中都没有,直接返回不存在信息 if(shop!=null\u0026amp;\u0026amp;shop.equals(\u0026#34;\u0026#34;)){ return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } //所有线程同时去抢夺互斥锁资源,只会有一个线程抢到 if(setLock(RedisConstants.LOCK_SHOP_KEY+id)){ Shop shop1= getById(id); //数据没查到,说明这个店铺id不存在,这次缓存穿透了,但是可以把空信息写入redis if(shop1==null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,\u0026#34;\u0026#34;,cacheAvalanche(), TimeUnit.MINUTES); return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } RedisData redisData=new RedisData(); redisData.setData(shop1); redisData.setExpireTime(LocalDateTime.now().plusMinutes(cacheAvalanche())); String json= JSON.toJSONString(redisData); //查询到店铺,返回店铺信息,并且把信息写入Redis if(shop1!=null){ stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY+id,json,cacheAvalanche(), TimeUnit.MINUTES); return Result.ok(shop1); } //所有工作做完后释放锁资源 unLock(RedisConstants.LOCK_SHOP_KEY+id); //其他线程直接返回过期的数据 }else { RedisData redisData=new RedisData(); redisData.setData(JSONUtil.toBean(shop,Shop.class)); Shop redis=redisData.getData(); return Result.ok(redis); } return Result.fail(\u0026#34;店铺信息不存在\u0026#34;); } 订单秒杀问题 限量限时商品可能会在短时间内面临大量请求,可能会出现超卖的情况\n如果第一次遇到1的时候没来得及写到数据库里,后面的线程查询的时候遇到的还是1,就可以继续执行扣减的操作,导致超卖的情况发生\nJMeter测试结果 200次线程请求直接超卖了9个商品\n解决方案1:乐观锁 • 假设：乐观锁假设冲突发生的概率很小，允许多个事务同时操作数据，但在提交时检查是否有其他事务修改了数据。\n• 实现：通常通过版本号（version）或时间戳（timestamp）实现。在更新数据时，比较当前版本号与数据库中的版本号，如果一致则更新并增加版本号；如果不一致，则说明数据已被其他事务修改，需要重新获取数据并重试。\n• 适用场景：适用于读多写少的场景，或者数据竞争不激烈的情况下。\nJava实现 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .eq(\u0026#34;stock\u0026#34;, seckillVoucher.getStock()) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } 在写入数据库之前,先查询数据库目前的值和之前查询到的是否一样,是否在写入之前被修改了,如果被修改了就不能写入\nJMeter测试结果 可以发现成功率低的可怜,200次请求只抢到了21张票,原因就是每次写入都要查询到之前是否已经写过,请求频率太高,导致不写入的概率也更高,写入越多的情况越不能用乐观锁\n解决方案2:悲观锁 • 假设：悲观锁假设会发生冲突，即多个事务会同时修改同一数据，因此它在操作开始时就锁定数据，防止其他事务修改。\n• 实现：通常通过数据库的锁机制实现，如行锁、表锁等。\n• 适用场景：适用于写操作频繁的场景，或者数据竞争非常激烈的情况下。\n只要在每次写入更新结果之前先查看一下剩余的量是不是大于0就可以了\nJava代码 1 2 3 4 5 6 7 8 Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;,voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } JMeter测试结果 200次请求,只卖出100张,异常比例正确\n单人订单问题 有些商品给购买者限量,比如买火车票或者限定周边,如果一个黄牛用脚本在短时间大量请求,则有可能会多卖\n简单解决\n1 2 3 4 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } JMeter测试结果显示,200个请求同时下单,一共能购买10张票\n解决方案:共享锁 在 Java 中， synchronized是一个关键字，用于控制对共享资源的访问，确保在同一时刻只有一个线程可以访问特定的代码块或方法。这是实现线程同步的一种方式，主要用于解决多线程环境下的并发问题。\n我们可以把订单秒杀的代码先抽离出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Transactional(rollbackFor = Exception.class) public Result createVoucherOrder(Long voucherId) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherId,UserHolder.getUser().getId()); if(!list.isEmpty()){ return Result.fail(\u0026#34;该用户已下过单\u0026#34;); } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return Result.fail(\u0026#34;库存不足\u0026#34;); } Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); voucherOrderMapper.insert(voucherOrder); return Result.ok(voucherOrder.getVoucherId() + \u0026#34;下单成功\u0026#34;); } 如果是对整个函数加锁,也就是在public后面,那么不是同一个用户也会被锁给拦截,性能不高\n或者可以给锁限定userId,如果同一id就被拦截,串行进行\n1 2 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) 这里intern的作用是,toString会导致产生新的字符串对象,字符串对象虽然值是相同的,但是哈希值不一样,被锁认为是不同的对象,这时用intern可以从字符串池里找相同的串,哈希值相同\n锁应当在事务结束之后再释放才行,否则又会产生冲突,事务还没结束,有个线程又进来了,会引发异常,因此应当把锁放到整个方法外面\n1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } JMeter测试结果 200次买票,只买到1次,解决了单人买票的问题\n上述写法依然有问题\nJava魅力时刻 1 2 3 4 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { return createVoucherOrder(voucherId); } 注意到这里的return createVoucherOrder(voucherId);是目标对象引用的函数，相当于\nreturn this.createVoucherOrder(voucherId);但是只有代理对象才有事务管理的功能,代理对象就是加上@Controller,@Service,@Mapper,@Component,@Bean的对象,这个对象协助目标对象完成工作.\n要想在这个对象里面调用代理对象可以通过如下办法\n1 2 3 4 5 Long userId =UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } AopContext.currentProxy()获取本类的代理对象,然后从Object转成本类的对象,然后调用对应的方法,要在接口里面重新声明这个方法\n同时要引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectjweaver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.22.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在springboot启动类上加注解\n1 @EnableAspectJAutoProxy(exposeProxy = true) 允许SpringIOC容器暴露代理对象,这样我们才能正常获取代理对象\nRedis实现分布式锁 如果现在同时开两个进程,服务器集群部署,由nginx实现负载均衡,实现轮询发送请求,先给8081端口发送,再给8082端口,导致进程内的锁无法和另一个进程的锁联动\n这时可以使用伟大的Redis制作分布式锁来解决这个问题!\n分布式锁的设计 这个锁应当起到互斥作用,很多个线程同时发送过来,只能有一个线程获取锁资源,因此得用setnx.\n在此线程结束运行的时候应当及时释放锁资源,防止服务器资源浪费,及时del key\n如果一个服务器在发送完这个请求后就宕机了,不会执行这个释放锁资源的代码,那么锁资源就不会被释放,导致其他服务器资源浪费.这时候就要给锁设置过期时间,到时间自动释放锁资源\n如果在还没执行expire time的时候服务器就宕机了,那么锁资源一样不会被释放,这时候就得这么写获取锁的语句\n1 set lock thread1 nx ex 10 保持了原子性,让互斥和过期时间一起设置\n同时采用非阻塞的锁,防止很多线程一直等待锁资源释放,尝试一次,如果没获取锁资源就return false,成功就return true\nJava代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { Long threadId = Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId+\u0026#34;\u0026#34;,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } 将分布式锁加入业务逻辑 1 2 3 4 5 6 7 8 9 10 11 12 Long userId =UserHolder.getUser().getId(); SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock=lock.tryLock(1200L); if(!isLock){ return Result.fail(\u0026#34;一人只能买一张票\u0026#34;); } try{ IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); }finally { lock.unlock(); } 分布式锁误删问题: 由于业务阻塞,导致线程1获取锁后没有及时释放锁资源,锁自动释放,线程2请求锁成功,开始执行业务逻辑\n这时候线程1完成业务,执行释放锁的指令,导致业务2的锁被意外删除,以此类推,锁会被意外删除.\n改进办法很简单,只要每次执行删除锁之前先查询锁的线程是否是自己的,是自己的就可以删,不是自己的就跳过.\nJava代码改进 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package com.hmdp.utils; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.UUID; import java.util.concurrent.TimeUnit; public class SimpleRedisLock implements ILock { private StringRedisTemplate stringRedisTemplate; private static final String LOCK_PREFIX = \u0026#34;lock:\u0026#34;; private static final String ID_PREFIX = UUID.randomUUID().toString(); private String lockName; public SimpleRedisLock(String lockName,StringRedisTemplate stringRedisTemplate) { this.lockName = lockName; this.stringRedisTemplate = stringRedisTemplate; } @Override public Boolean tryLock(Long timeoutSec) { String threadId =ID_PREFIX+ Thread.currentThread().getId(); Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(LOCK_PREFIX+lockName,threadId,timeoutSec, TimeUnit.SECONDS); //这样写的话,是true就返回true,如果是false或者null都返回false return Boolean.TRUE.equals(result); } @Override public void unlock() { String UnlockName= stringRedisTemplate.opsForValue().get(LOCK_PREFIX+lockName); String threadId =ID_PREFIX+ Thread.currentThread().getId(); if(threadId.equals(UnlockName)){ stringRedisTemplate.delete(LOCK_PREFIX+lockName); } } } 对程序打断点调试,获取锁后拦截,当我修改这里的ThreadId并且重新放行后,这里的新锁并没有被删掉,解决了误删的问题.\nLua脚本 当我们使用最新的分布式锁的时候,如果在执行finally语句里面的代码时,遭遇JVM进行垃圾回收,这时候会遇到无法战胜的业务阻塞,,代码还是没有做到原子性.如果已经验证完这个线程对应这个锁后突然垃圾回收,那么就会导致del锁这个操作会很危险.\n这时候可以把整个unlock操作用Lua脚本完成\n在Redis客户端使用lua脚本 无参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,\u0026#39;name\u0026#39;,\u0026#39;jack\u0026#39;)\u0026#34; 0 语句的意思是使用脚本,脚本是一个字符串,就是引号里面的,脚本相当于set name jack 0代表没有参数\n有参脚本 1 eval \u0026#34;return redis.call(\u0026#39;set\u0026#39;,KEYS[1],ARGV[1])\u0026#34; 1 dinglz sb 用KEYS[1]和ARGV[1]作为占位符,后面有一对参数\n使用lua脚本解决删除锁问题 1 2 3 4 5 6 7 8 --查询锁的id local id=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(ARGV[1]==id) then --释放锁 return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) end --不是自己的锁,不用释放锁 return 0 Java代码调用Lua脚本 把lua脚本创建在这个目录下,等下方便读取 重写unlock方法 1 2 3 4 5 6 7 8 9 @Override public void unlock() { List list = new ArrayList(); list.add(LOCK_PREFIX+lockName); stringRedisTemplate.execute( UNLOCK_SCRIPT, list, ID_PREFIX+ Thread.currentThread().getId()); } 向redis传输指令,显示脚本,然后是参数,KEYS[1]参数要用集合封装,第二个参数是线程id也就是ARGV[1]\n同时要配置好脚本\n1 2 3 4 5 6 private static DefaultRedisScript\u0026lt;Long\u0026gt; UNLOCK_SCRIPT; static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unLock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 设置文件位置,然后设置返回格式,返回值为0表示删除锁失败,1表示删除锁成功\nRedisson Redisson是一个封装好的分布式锁工具,这里面的锁是已经写好的,并且比前文介绍的锁多一些功能和奇效\n引入依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置Redisson 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.hmdp.config; import org.redisson.Redisson; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RedissonConfig { @Bean public RedissonClient redisson() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://Yourip:Yourport\u0026#34;).setPassword(\u0026#34;Yourpassword\u0026#34;); return Redisson.create(config); } } @Configuration注解 这里顺带提一嘴Springboot框架面试高频考点,@Configuration是什么,和@Component有啥区别. @Configuration是配置类要添加的注解,它的构成是\n1 2 3 4 5 6 7 8 9 10 11 12 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Component public @interface Configuration { @AliasFor( annotation = Component.class ) String value() default \u0026#34;\u0026#34;; boolean proxyBeanMethods() default true; } 这里面也有@Component,但是它比前者多实现单例模式\n如果你在创建Bean对象的时候一次性创建多个,Spring容器并不会去对象池去找是否有已经创建过的对象,而是直接再创建,这样无法保证单例性\n而如果用@Configuration就可以只创建一次Bean对象\n使用Redisson制作分布式锁 1 2 3 //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); 中间那一行代码就等价于之前写的SimpleRedisLock\nRedisson解决不可重入 不可重入导致死锁 如果一个线程请求锁资源,然后又请求了一次锁资源,第二次请求会失败,因为已经有线程获取过锁,并且就是自身,这导致了这个线程请求不到锁,也释放不了锁,导致了死锁.\n解决方案 于是Redisson改变了锁的结构,让锁的数据结构变为Hash,key存储锁的名称,field存储线程名称,value存储该锁被同一个线程调用了几次,每次调用会给value自增,如果释放锁资源就value自减一次,如果value==0,那么就删除这个锁资源.\nRedisson解决不可重试 不可重试导致大量请求失败 正常线程如果获取锁失败就直接返回false了,或者说一直循环递归等待下去,导致了大量请求无法返回客户需要的内容\n解决方案 1 Boolean isLock1=redissonClient.getLock(\u0026#34;order\u0026#34;+userId).tryLock(1L, TimeUnit.SECONDS); 注意到我们之前在设置tryLock的时候设置了尝试时间1L,单位是秒.这个意思是我可以总共等待1秒,如果这1秒内获取到锁资源,就返回true,如果没请求到就返回false,当然这个1L可以改为任何数值.\nRedisson的tryLock原码 1 2 3 4 5 6 7 long time = unit.toMillis(waitTime); long current = System.currentTimeMillis(); long threadId = Thread.currentThread().getId(); Long ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { return true; } ttl是剩余等待时间,后面的tryAcquire是看是否获取锁成功,如果获取锁成功就返回null,如果获取成功就返回剩余等待时间.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 else { current = System.currentTimeMillis(); RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } else { boolean var16; try { time -= System.currentTimeMillis() - current; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); boolean var20 = false; return var20; } do { long currentTime = System.currentTimeMillis(); ttl = this.tryAcquire(waitTime, leaseTime, unit, threadId); if (ttl == null) { var16 = true; return var16; } time -= System.currentTimeMillis() - currentTime; if (time \u0026lt;= 0L) { this.acquireFailed(waitTime, unit, threadId); var16 = false; return var16; } currentTime = System.currentTimeMillis(); if (ttl \u0026gt;= 0L \u0026amp;\u0026amp; ttl \u0026lt; time) { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); } else { ((RedissonLockEntry)subscribeFuture.getNow()).getLatch().tryAcquire(time, TimeUnit.MILLISECONDS); } time -= System.currentTimeMillis() - currentTime; } while(time \u0026gt; 0L); this.acquireFailed(waitTime, unit, threadId); var16 = false; } finally { this.unsubscribe(subscribeFuture, threadId); } return var16; } } 主要看else中的原码,如果获取锁失败,并且要进入等待,RFuture subscribeFuture = this.subscribe(threadId）指的是这个线程订阅了请求的锁的信息,如果锁被释放了,这个线程就会收到信息,这正是观察者模式.但是这个等待并不是无限制的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 RFuture\u0026lt;RedissonLockEntry\u0026gt; subscribeFuture = this.subscribe(threadId); if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { if (!subscribeFuture.cancel(false)) { subscribeFuture.onComplete((res, e) -\u0026gt; { if (e == null) { this.unsubscribe(subscribeFuture, threadId); } }); } this.acquireFailed(waitTime, unit, threadId); return false; } 如果时间到达上限了,直接返回false,并且取消订阅.\n如果时间没到上限,就再尝试获取锁,没获取到就继续订阅,因为很多线程同时请求过来,得按顺序获取锁.直到获取到锁或者直接到时间才结束这个循环.\nRedis本地集群部署 只要改一下端口号就能实现本地的Redis集群\n在config文件下修改端口号\n用记事本或者vscode打开都可以,然后按下Ctrl+F搜索6379,下面的端口号改成没设置过的端口号,但也不要跟其他进程冲突了,我这里改为了6381\n然后分别启动Redis就实现Redis集群了\nRedisson实现分布式联锁 1 2 3 4 RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); 使用随机一个redisson客户端来调用它的.getMultiLock方法就可以制作出联锁\n联锁就可以在Redis集群的情况下,所有Redis共有一把锁,以免出现重复申请锁资源的情况\ngetMultiLock会尝试同时获取所有指定的锁，只有当所有锁都成功获取时，才算加锁成功。如果任何一个锁获取失败，它会回滚已经获取的锁，确保加锁操作的原子性。\n通过将多个锁的获取和释放封装在一起，getMultiLock简化了在复杂业务场景下的并发控制逻辑，减少了开发人员在处理多个锁时的错误风险。\n其中redisson.getMultilock使用任意一个对象都可以的原因是,这里是统一新创建\n1 2 3 public RLock getMultiLock(RLock... locks) { return new RedissonMultiLock(locks); } 通过这样制作联锁,可以让每一个Redis都有lock\n异步秒杀问题 将超卖和判重用Redis解决 把卖票过程比喻成厨子做饭,如果饭店只有一个人,那么他自己得招待顾客,还得自己下厨,但是这时候多来了个服务员,服务员负责招待顾客下单,厨子只是来做菜,卖票过程就是用Redis作为先手,把订单都收到手了,交给后端再交给数据库来异步处理这些订单.\nJMeter测试数据时,随着时间请求量会增长,因此可能会面对短时间超高并发,并且现有的代码还有很多查询MySQL的操作,比如:\n查询优惠券剩余数量,查询stock\n顾客是否已经买过一张票,查询是否有这个订单\n于是我们可以通过改变订单流程来解决\n在商家添加优惠券信息的时候就把优惠券的信息和数量同步到Redis\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+voucher.getId()+\u0026#34;:stock\u0026#34;,voucher.getStock().toString()); } 然后在请求到达后端时,先查询Redis,判断优惠券数量是否够,这个用户是否下过单了\nlua脚本 由于一次性操作Redis次数过多,直接使用多条java语句没有原子性,因此要用lua脚本 1 2 3 4 5 6 7 8 9 10 local stock=redis.call(\u0026#39;get\u0026#39;,KEYS[1]) if(tonumber(stock)\u0026lt;1) then return 1 end local success = redis.call(\u0026#39;SADD\u0026#39;, KEYS[2], ARGV[1]) if(success==0) then return 2 end redis.call(\u0026#39;decr\u0026#39;,KEYS[1]) return 0 由于KEYS传过来时必须得是String类型,而只有number才能比较大小,因此先转化为数字,如果票没了就返回1.\nRedis的set集合 Redis的set集合在插入的时候,要判重,如果重复就不能插入,返回0,如果插入成功就返回1,故可以作为锁.\n多人秒杀的存储效果是这样的\n然后就可以写代码调用脚本了\n1 2 3 4 5 6 7 8 9 10 11 //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } 后端接受到可以下单的信息后制作订单\n1 2 3 4 5 6 7 8 9 Long id= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(id); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(redisId.nextId(\u0026#34;order\u0026#34;)); 然后把订单数据交给阻塞队列来异步执行,这里要用java自带的阻塞队列,然后多创建一个线程来解决这些下单问题\n1 2 3 4 5 6 7 8 9 //创建阻塞队列 private BlockingQueue\u0026lt;VoucherOrder\u0026gt; queue=new ArrayBlockingQueue\u0026lt;VoucherOrder\u0026gt;(1024*1024); //创建线程池 private static final ExecutorService SECKILL_ORDER_EXECUTOR= Executors.newSingleThreadExecutor( ); //在启动类初始化完就马上把 @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); }着重讲一下\n@PostConstruct 注解：\n当类的实例被创建后，Spring容器会自动调用这个方法。\n通常用于执行一些初始化操作，比如启动线程、加载配置等。\nSECKILL_ORDER_EXECUTOR：\n它的作用是管理线程的生命周期，避免频繁创建和销毁线程的开销。 submit(new VoucherOrderHandler())：\nsubmit方法将一个任务提交到线程池中执行。\nVoucherOrderHandler实现了Runnable接口的类\n这里创建了一个VoucherOrderHandler实例，并将其提交到线程池中，线程池会选择一个空闲线程来执行这个任务。\n这是线程池的任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //给线程池分配任务 private class VoucherOrderHandler implements Runnable{ @Override public void run() { while(true){ try{ VoucherOrder voucherOrder=queue.take(); voucherHandler(voucherOrder); }catch (Exception e){ System.out.println(\u0026#34;订单处理异常\u0026#34;+e.getMessage()); } } } } 在队列中有元素的时候,子线程取出voucherOrder对象,然后解决下单问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private void voucherHandler(VoucherOrder voucherOrder) throws InterruptedException { Long userId=voucherOrder.getUserId(); //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+userId); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ proxy.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;id为\u0026#34;+userId+\u0026#34;的顾客买到票了\u0026#34;); lock.unlock(); } } 注意到这是个子线程的任务,子线程的任务无法获得代理对象,也就是SpringBoot的IOC容器管理的对象,但是我们需要事务回滚,所以还是得用代理对象,所以只能把代理对象作为私有变量,然后在类的方法中对这个私有代理对象进行赋值\n1 2 3 4 5 6 7 8 private IVoucherOrderService proxy; @Override public Result order(Long voucherId) { ... //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); ... } 然后改进createVoucherOrde方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Transactional(rollbackFor = Exception.class) public void createVoucherOrder(VoucherOrder voucherOrder) { //开始的话看库存够不够,够就库存减一,并且创建订单 List\u0026lt;VoucherOrder\u0026gt; list=voucherOrderMapper.selectByUserId(voucherOrder.getVoucherId(),voucherOrder.getUserId()); if(!list.isEmpty()){ return ; } Boolean success=seckillVoucherServiceImpl.update() .setSql(\u0026#34;stock=stock-1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherOrder.getVoucherId()) .gt(\u0026#34;stock\u0026#34;, 0) .update(); if(!success){ return ; } voucherOrderMapper.insert(voucherOrder); } 至此,异步下单已经初步完成了.\nJMeter测试 由于要实现多人秒杀,所以就得用多个账户登录来抢票,但是找不到1000个真人来测试,总不能一个一个敲登录来获取token吧,所以可以写一个自动登录1000个账户的测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.hmdp; import com.hmdp.utils.RedisConstants; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; import java.util.HashMap; import java.util.Map; import java.util.UUID; import java.util.concurrent.TimeUnit; @SpringBootTest public class TokenTest { private static final Integer NUMBER_OF_TOKEN = 1000; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN+1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token= UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY+token,map); System.out.println(token); stringRedisTemplate.expire(token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); } } } 在 Redis里存一份即可,然后把所有的token输出出来,后面拿来给JMeter,这样绕过了拦截器\n把tokens存到txt文件中\n在JMeter里面这样设置一下\n注意那个路径就是txt文件存储位置\n然后改一下登录状态头\n然后就可以开始测试了!\n测试结果:\n1000人抢200张票,只有20%成功率,80%的异常率,测试成功\nRedis实现消息队列 认识消息队列 消息队列（Message Queue，简称MQ）是一种在软件架构中用于实现应用程序之间异步通信的中间件。它允许一个或多个生产者（消息的发送者）将消息发送到队列中，然后由一个或多个消费者（消息的接收者）从队列中读取消息。消息队列的主要作用是解耦、缓冲、异步通信和负载均衡等,可以用来削峰填谷,减轻服务器和数据库的处理压力。 之前有用到spring的阻塞队列,但是这个阻塞队列效果不是很好,如果中途服务挂机了,或者说停机后JVM会强制删除所有内存数据,那么后续请求就无法完成,并且不保留记录.这时候就需要外部的消息队列了,这里先用Redis实现,后面还可以用实现好的消息队列,kafka,RocketMQ\nRedis要求: redis必须达到5版本及其以上,这里使用的是stream数据结构来制作消息队列\nRedis单消费模式 我们可以使用XADD来向消息队列里面加入元素,用XREAD来读取消息队列的元素\n1 XADD users * k2 v2 第一次redis会去查存储空间里面有没有users这个消息队列如果没有就创建\n这个语句的意思是添加名称为users的消息队列,然后*为自动生成id,k2 v2为一个键值对\n添加成功后会返回一个数据\u0026quot;1743079174227-0\u0026quot;这是一个时间戳,用来唯一标识这个队列\n同样的我们可以用XREAD来读取消息队列中的数据\n1 XREAD count 1 streams users 0 这个语句的意思是读消息,一次读一条,读取消息队列users的消息,并且从0开始读\n1 XREAD count 1 block 0 streams users $ 这个语句的意思是读取users的消息,($)读取最新的消息,然后无限阻塞,直到有消息进入队列就读取一条消息.\n这样看上去一个消息队列建好了,但是有bug,如果存储数据时间较长,存储数据没来得及存储完,又传来了一堆新的消息,$只能读取最新的消息,导致中间有很多消息都漏掉了\nRedis消费者组模式 省流版: 消费者组里面有很多消费者,它们是竞争关系,都来争着处理消息,可以解决消息漏处理的问题\n消息表示指的是最后被处理的消息会被打上标签,就像看书有个书签,看完后下次再看就立马知道在哪了\n消息确认就跟TCP三次握手相似,只是没有最后一段客户端向服务端的确认信息,每次处理完信息都会确认一下,并且有个pending-list,如果没处理这个消息就根据这个list继续处理\n创建消费者组 1 XGROUP CREATE users group1 0 这个语句的意思是在users这个消息队列中创建消费者组,如果没有users这个消息队列就会创建失败,这个消费者组的名称为group1,每次从id=0开始读\n通过消费者组读消息队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743074094428-0\u0026#34; 2) 1) \u0026#34;k1\u0026#34; 2) \u0026#34;v1\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743079174227-0\u0026#34; 2) 1) \u0026#34;k2\u0026#34; 2) \u0026#34;v2\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082841091-0\u0026#34; 2) 1) \u0026#34;k3\u0026#34; 2) \u0026#34;v3\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082847320-0\u0026#34; 2) 1) \u0026#34;k4\u0026#34; 2) \u0026#34;v4\u0026#34; localhost:6379\u0026gt; XREADGROUP group group1 c1 count 1 block 2000 streams users \u0026gt; 1) 1) \u0026#34;users\u0026#34; 2) 1) 1) \u0026#34;1743082852967-0\u0026#34; 2) 1) \u0026#34;k5\u0026#34; 2) \u0026#34;v5\u0026#34; 这个语句的含义是通过消费者组进行读取,group的名称是group1(刚刚创建的),消费者名称叫c1(随便取的名字,没有的话会自动创建),每次消费一条信息,阻塞2秒,消息队列名称为users,选择从最早发过来的未读消息开始读,\u0026gt;换成0可以使因为之前处理消息的时候,服务器炸了,重新处理的时候读取pending-list,直接从未处理完成的消息继续处理\n确认信息方法XACK 1 2 XACK users group1 1743074094428-0 1743079320687-0 1743082841091-0 1743082847320-0 (integer) 4 前面是消息队列名称和消费者组名,后面是消息被消费后发出的时间戳\n通过如下语句查询pending-list\n1 2 3 4 5 6 xpending users group1 1) (integer) 1 2) \u0026#34;1743079174227-0\u0026#34; 3) \u0026#34;1743079174227-0\u0026#34; 4) 1) 1) \u0026#34;c1\u0026#34; 2) \u0026#34;1\u0026#34; 通过Redis实现消息队列替代阻塞队列 其实没必要这么实现(绝对不是因为我这边IDEA无法识别我写的函数才不实现的)\n我们可以直接上正经的消息队列\n通过RabbitMQ替代阻塞队列 RabbitMQ是个消息队列,文档非常完整好懂,可以通过文档学习.要使用RabbitMQ要先下载,这里我在ubuntu虚拟机上下载并使用这个消息队列\n在 Ubuntu 上安装 RabbitMQ 通常需要以下步骤：\n1. 更新系统包列表 在安装任何软件之前，建议先更新系统的包列表，以确保安装的软件是最新的版本。运行以下命令：\n1 sudo apt update 2. 安装 Erlang RabbitMQ 是基于 Erlang 编程语言开发的，因此需要先安装 Erlang。可以使用以下命令安装 Erlang：\n1 sudo apt install erlang 3. 添加 RabbitMQ 的官方仓库 为了获取最新版本的 RabbitMQ，建议添加 RabbitMQ 的官方仓库。运行以下命令：\n1 2 3 sudo apt install apt-transport-https wget -O- https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add - echo \u0026#34;deb https://dl.bintray.com/rabbitmq/debian $(lsb_release -sc) main\u0026#34; | sudo tee /etc/apt/sources.list.d/rabbitmq.list 4. 更新包列表 添加完官方仓库后，需要再次更新包列表：\n1 sudo apt update 5. 安装 RabbitMQ Server 现在可以安装 RabbitMQ 了。运行以下命令：\n1 sudo apt install rabbitmq-server 6. 启动和启用 RabbitMQ 服务 安装完成后，RabbitMQ 服务应该会自动启动。可以通过以下命令检查服务状态：\n1 sudo systemctl status rabbitmq-server 如果服务未启动，可以手动启动并设置开机自启：\n1 2 sudo systemctl start rabbitmq-server sudo systemctl enable rabbitmq-server 7. 配置 RabbitMQ（可选） 如果需要进行额外配置，例如设置用户、权限等，可以使用以下命令：\n添加用户：\n1 sudo rabbitmqctl add_user myuser mypassword 设置用户权限：\n1 2 sudo rabbitmqctl set_user_tags myuser administrator sudo rabbitmqctl set_permissions -p / myuser \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; 启用管理插件（用于访问 Web 管理界面，默认端口为 15672）：\n1 sudo rabbitmq-plugins enable rabbitmq_management 正式使用RabbitMQ 按照以上步骤下载完rabbitmq后,我们可以打开网址馆里rabbitmq\nhttp://虚拟机的ip地址:15672\n注! 如果你用的不是docker下载的rabbitmq,那么你虚拟机的ip地址会改变,下次连不上rabbitmq有可能是因为ip地址变了 rabbitmq管理界面长这样\n你可以在主机上打开,也可以在虚拟机上打开,第一次登录只能在虚拟机上打开,因为有默认账号密码.输入账号:guest,密码:guest.然后进去后可以给自己之前用命令行创建的用户改权限\n点击创建的用户,这样修改权限\n这样你就可以用后端语言操控rabbitmq了!\n然后我们就可以打开心爱的IDEA\n引入maven坐标 先引入几个maven坐标\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--rabbitMQ的maven坐标--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.18.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 注意:springboot2.0版本只能用这套maven坐标,要用3.0版本maven坐标的话会出bug\n配置rabbitmq 先写好yaml\n然后这样写配置类,把rabbitmq交给IOC容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package com.hmdp.config; import com.hmdp.properties.RabbitMQProperties; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.connection.ConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitMQConfig { @Autowired private RabbitMQProperties rabbitMQProperties; @Bean public ConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(rabbitMQProperties.getHost()); connectionFactory.setUsername(rabbitMQProperties.getUsername()); connectionFactory.setPassword(rabbitMQProperties.getPassword()); connectionFactory.setVirtualHost(rabbitMQProperties.getVirtualHost()); connectionFactory.setPort(rabbitMQProperties.getPort()); return connectionFactory; } @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { return new RabbitTemplate(connectionFactory); } @Bean public Queue voucherOrderQueue() { return new Queue(\u0026#34;voucher_order_queue\u0026#34;, true); } } 之前我们用的是阻塞队列,单独为消费者new了个线程来处理消息,现在我们可以创建一个消费者类,并且把对象交给IOC容器,让这个消费者持续处理信息\n消费者类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package com.hmdp.Consumer; import com.hmdp.entity.VoucherOrder; import com.hmdp.service.IVoucherOrderService; import org.redisson.api.RLock; import org.redisson.api.RedissonClient; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import org.springframework.transaction.annotation.Transactional; import javax.annotation.Resource; import java.util.concurrent.TimeUnit; @Component public class VoucherOrderConsumer { @Autowired private IVoucherOrderService voucherOrderService; @Resource private RedissonClient redisson6379; @Resource private RedissonClient redisson6380; @Resource private RedissonClient redisson6381; @Transactional @RabbitListener(queues = \u0026#34;voucher_order_queue\u0026#34;) public void handle(VoucherOrder voucherOrder) throws InterruptedException { //SimpleRedisLock lock=new SimpleRedisLock(\u0026#34;order:\u0026#34;+userId,stringRedisTemplate); RLock lock1=redisson6379.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock2=redisson6380.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock3=redisson6381.getLock(\u0026#34;lock:order:\u0026#34;+voucherOrder.getUserId()); RLock lock=redisson6380.getMultiLock(lock1,lock2,lock3); Boolean isLock1=lock.tryLock(1L, TimeUnit.SECONDS); //Boolean isLock=lock.tryLock(1200L); if(!isLock1){ return ; } try{ voucherOrderService.createVoucherOrder(voucherOrder); }finally { System.out.println(\u0026#34;订单处理成功：\u0026#34; + voucherOrder.getId()); lock.unlock(); } } } 然后ServiceImpl类就成为了生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override public Result order(Long voucherId) { //查询优惠券信息 SeckillVoucher seckillVoucher = seckillVoucherMapper.selectById(voucherId); //判断秒杀是否开始 LocalDateTime timeEnd = seckillVoucher.getEndTime(); LocalDateTime timeBegin=seckillVoucher.getBeginTime(); if(timeBegin.isAfter(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动暂未开始\u0026#34;); }else if (timeEnd.isBefore(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀活动现已结束\u0026#34;); } //前期判断 List\u0026lt;String\u0026gt; KEYS = new ArrayList\u0026lt;\u0026gt;(); //List\u0026lt;String\u0026gt; ARGS = new ArrayList\u0026lt;\u0026gt;(); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:stock\u0026#34;); KEYS.add(\u0026#34;Inventory\u0026#34;+voucherId+\u0026#34;:set\u0026#34;); Long id=redisId.nextId(\u0026#34;order\u0026#34;); Long result = stringRedisTemplate.execute(TICKET_SNATCHING_SCRIPT, KEYS, UserHolder.getUser().getId()+\u0026#34;\u0026#34;); if(result==1){ return Result.fail(\u0026#34;没票了\u0026#34;); }else if (result==2){ return Result.fail(\u0026#34;一个人不能抢多张票\u0026#34;); } Long userId= UserHolder.getUser().getId(); VoucherOrder voucherOrder=new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); voucherOrder.setCreateTime(LocalDateTime.now()); voucherOrder.setUpdateTime(LocalDateTime.now()); voucherOrder.setPayTime(LocalDateTime.now()); voucherOrder.setStatus(1); voucherOrder.setId(id); // 使用 RabbitMQ 发送消息 rabbitTemplate.convertAndSend(\u0026#34;voucher_order_queue\u0026#34;, voucherOrder); //queue.add(voucherOrder); //获取代理对象 proxy=(IVoucherOrderService) AopContext.currentProxy(); return Result.ok(\u0026#34;下单成功\u0026#34;+id); } 这样我们就使用了rabbitmq作为消息队列完成了异步秒杀.这只是rabbitmq的一点实力,后面我可能会专开一个坑来学rabbitmq\n测试类更新 简单更新了一下测试类 把token一键写入.txt文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Test public void test1() { // 指定文件路径 String filePath = \u0026#34;C:\\\\Users\\\\86180\\\\Desktop\\\\Test\\\\秒杀订单TOKEN数据.txt\u0026#34;; File file = new File(filePath); // 如果文件不存在则创建文件夹和文件 if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } // 如果文件存在，先清空文件内容 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file))) { writer.write(\u0026#34;\u0026#34;); // 清空文件内容 } catch (IOException e) { e.printStackTrace(); } // 写入新的 token 数据 try (BufferedWriter writer = new BufferedWriter(new FileWriter(file, true))) { for (Integer i = 1; i \u0026lt; NUMBER_OF_TOKEN + 1; i++) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;nickName\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;icon\u0026#34;, \u0026#34;\u0026#34;); map.put(\u0026#34;id\u0026#34;, i.toString()); String token = UUID.randomUUID().toString(); stringRedisTemplate.opsForHash().putAll(RedisConstants.LOGIN_USER_KEY + token, map); stringRedisTemplate.expire(RedisConstants.LOGIN_USER_KEY + token, RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); // 将 token 写入文件 writer.write(token); writer.newLine(); // 换行 } } catch (IOException e) { e.printStackTrace(); } } 一键刷新测试数据,让我们和JMETER再抢一千次优惠券吧!!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.hmdp; import com.hmdp.mapper.SeckillVoucherMapper; import com.hmdp.service.impl.VoucherOrderServiceImpl; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.StringRedisTemplate; @SpringBootTest public class RefreshData { private static final Long VOUCHER_ID=16L; private static final Long STOCK=1000L; @Autowired private VoucherOrderServiceImpl voucherOrderService; @Autowired private SeckillVoucherMapper seckillVoucherMapper; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() { //删除所有订单 voucherOrderService.deleteByVoucherId(VOUCHER_ID); //将剩余票数刷新为指定数值 seckillVoucherMapper.updateByVoucherId(VOUCHER_ID,STOCK); //同步修改redis的剩余票数 stringRedisTemplate.opsForValue().set(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:stock\u0026#34;,STOCK+\u0026#34;\u0026#34;); //删除redis的set stringRedisTemplate.delete(\u0026#34;Inventory\u0026#34;+VOUCHER_ID+\u0026#34;:set\u0026#34;); } } 点赞功能 问题分析 点赞要求我们第一次点上去是点赞数+1,再点一次是点赞数-1,这完全可以交给数据库去解决,然后就是点赞前五名的人要展示在页面上,这时候可以用到redis的ZSET,排序集合\n业务逻辑: 点赞后,java代码查看是否点赞过,没点赞就点赞数+1,同时记录这个人点赞的时间戳,作为ZSET的排序依据,越早点赞的人越靠前,所有人都加入这个集合,点过赞再点就取消之前点赞,并且从这个集合中remove.查看点赞前五的代码就只用根据时间戳选择前五个用户就好,下面是代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Override //更新点赞 public void updateLike(Long id) { Long userId= UserHolder.getUser().getId(); //获取时间戳 long timestamp = System.currentTimeMillis(); //向ZSET中插入,看是否点过赞了 Boolean success = stringRedisTemplate.opsForZSet().add(RedisConstants.BLOG_LIKED_KEY + id, userId.toString(), timestamp); if(!Boolean.TRUE.equals(success)){ //点过了赞就无法插入,就取消点赞,点赞数减一,从点赞集合中移除用户 boolean success1 =update().setSql(\u0026#34;liked = liked - 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); if(success1) { stringRedisTemplate.opsForZSet().remove(RedisConstants.BLOG_LIKED_KEY + id, userId.toString()); } }else{ //没点过赞就可以插入,点赞数量加一 update().setSql(\u0026#34;liked = liked + 1\u0026#34;).eq(\u0026#34;id\u0026#34;, id).update(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public Result selectLike(Long id) { //从ZSET中取最早点赞的5个人 Set\u0026lt;String\u0026gt; ids = stringRedisTemplate.opsForZSet().range(RedisConstants.BLOG_LIKED_KEY + id, 0, 4); if(ids==null||ids.size()==0){ return Result.ok(); } //获取点赞人的Id,然后查表,查到人后返回icon和username List\u0026lt;Long\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); for (String userId : ids) { list.add(Long.parseLong(userId)); } String strId= StrUtil.join(\u0026#34;,\u0026#34;,ids); List\u0026lt;User\u0026gt; users = userService.query() .in(\u0026#34;id\u0026#34;, ids) .last(\u0026#34;order by field(id,\u0026#34;+strId+\u0026#34;)\u0026#34;) .list(); List\u0026lt;UserDTO\u0026gt; userDTOS = new ArrayList\u0026lt;\u0026gt;(); for (User user : users) { UserDTO userDTO = new UserDTO(); //只返回icon,userId和userName,其实userName都可以不传 BeanUtils.copyProperties(user, userDTO); userDTOS.add(userDTO); } return Result.ok(userDTOS); } 关注与互关 关注 关注很好办,只用在数据库的follow表中插入一条数据,谁关注了谁,业务逻辑非常EZ\n查看互关 现在有用户A,B,C.A关注了C,B也关注了C,这时候我们如果是A,我们盒B的账号的时候就能发现,我们共同关注了C,实现这个功能需要两个关注列表取交集,这就可以用到Redis的SET集合了\n在关注好友的时候同时创建集合,集合名就是被关注用户的ID,集合内容就是关注者的ID\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public Result followServer(Long bloggerId, Boolean isFollow) { Long userId= UserHolder.getUser().getId(); if(isFollow){ Follow follow=new Follow(); follow.setUserId(userId); follow.setFollowUserId(bloggerId); follow.setCreateTime(LocalDateTime.now()); followMapper.insert(follow); stringRedisTemplate.opsForSet().add(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;的用户关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); }else if(!isFollow){ followMapper.deleteByUserId(userId,bloggerId); logger.info(\u0026#34;id为\u0026#34;+userId+\u0026#34;取消关注了id为\u0026#34;+bloggerId+\u0026#34;的用户\u0026#34;); stringRedisTemplate.opsForSet().remove(RedisConstants.FOLLOW+userId.toString(),bloggerId+\u0026#34;\u0026#34;); } return Result.ok(); } 然后我们写查询共同关注者的时候就可以用set的\n下面是redis里实现set的取交集\n1 2 3 4 5 6 7 8 127.0.0.1:6379\u0026gt; SADD key1 a b c d (integer) 4 127.0.0.1:6379\u0026gt; SADD key2 c d e f (integer) 4 127.0.0.1:6379\u0026gt; SADD key3 a c e (integer) 3 127.0.0.1:6379\u0026gt; SINTER key1 key2 key3 1) \u0026#34;c\u0026#34; 在java代码中我们可以这么写,用java中的Set集合接收共同关注者的id\n1 Set\u0026lt;String\u0026gt; intersect = stringRedisTemplate.opsForSet().intersect(RedisConstants.FOLLOW + userId.toString() , RedisConstants.FOLLOW+id.toString()); 然后共同关注就做好了\nfeed流\u0026amp;滚动分页查询 Feed流是一种常见的信息展示方式\nfeed流定义 Feed流是一种基于用户社交关系或兴趣偏好的信息分发机制。它通过动态地向用户推送个性化的内容，让用户在浏览过程中能够快速获取到自己感兴趣的信息。\n核心特点 个性化推荐：Feed流会根据用户的浏览历史、兴趣标签、社交关系等多维度数据，为每个用户量身定制内容。例如，抖音会根据用户点赞、关注、评论等行为，推荐相关的短视频；微博会根据用户的关注列表和兴趣偏好，推送微博动态。\n动态更新：内容会实时更新，用户每次刷新页面或打开应用时，都能看到最新的信息。这种动态性让用户能够及时获取到新鲜的内容，增强了用户的粘性和活跃度。\n分析B站的推送机制 当你特别关注了一个up主,那个up主每次发视频就会私信发送给你,这叫推模式,直接推送给个人\n如果你直接去查看up主的主页,你就能看到他所有的内容,这种叫拉模式,拉取up主的所有内容\n上述两种模式,推模式不适合大V,如果不特别关注就推送,那么网络资源消耗过大.\n这次我要用Redis实现推模式,写一个feed流\n设计思路 我们要实现推流,就要在博主发送blog的时候把信息发到关注他的粉丝账号上,我们先查数据库,找到粉丝id,然后选取Redis数据结构来存储推流信息.\nList和SortedSet都可以来记录有序集合,但是要实现分页滚动查询,还是用ZSET好 我们可以这样写保存blog的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Override public Result saveBlog(Blog blog) { // 获取登录用户 UserDTO user = UserHolder.getUser(); blog.setUserId(user.getId()); // 保存探店博文 boolean saveSuccess = blogService.save(blog); if(!saveSuccess){ return Result.fail(\u0026#34;发布笔记失败\u0026#34;); } List\u0026lt;Long\u0026gt; idList=userMapper.selectByFollower(user.getId()); if(idList!=null\u0026amp;\u0026amp;!idList.isEmpty()){ for(Long id:idList){ stringRedisTemplate.opsForZSet().add(RedisConstants.FEED_KEY + id, blog.getId().toString(), System.currentTimeMillis()); } } // 返回id return Result.ok(blog.getId()); } 存储结果是这样的\n我们以时间戳作为分数,越靠前的blog时间戳大,到时候用户最先看到的就是最新消息\n滚动分页查询 用户每次查询2条记录,记录按照时间戳来排序,第一次查询的最大时间戳为当前时间,要找到最新的消息,后面再查就是上一次查到的最小的时间戳,然后偏移量加一,因为要查询后面两条,偏移量是通过之前重复时间戳数量计算出来的,当很多人同时建立blog时,时间戳可能会一样,这时候就得去重,加上偏移量\n附Java代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Override public Result queryBlogByUserId(Long time, Long offset) { Long userId=UserHolder.getUser().getId(); Set\u0026lt;ZSetOperations.TypedTuple\u0026lt;String\u0026gt;\u0026gt; typedTuples; if(offset==0){ typedTuples= stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, System.currentTimeMillis(), offset, 2); }else{ typedTuples = stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(RedisConstants.FEED_KEY + userId, 0, time, offset, 2); } if(typedTuples==null|| typedTuples.isEmpty()){ return Result.fail(\u0026#34;没有文章可以看了捏\u0026#34;); } List\u0026lt;Blog\u0026gt; blogs = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Long\u0026gt; score=new ArrayList\u0026lt;\u0026gt;(); for (ZSetOperations.TypedTuple\u0026lt;String\u0026gt; object : typedTuples) { score.add(Objects.requireNonNull(object.getScore()).longValue()); Blog blog = blogMapper.selectById(Long.parseLong(Objects.requireNonNull(object.getValue()))); blogs.add(blog); } int count=1; Long lastScore=score.get(0); for (int i = 1; i \u0026lt; score.size(); i++) { if(score.get(i)!=lastScore){ count=1; lastScore=score.get(i); }else{ count++; } } ScrollResult scrollResult = new ScrollResult(); scrollResult.setList(blogs); scrollResult.setMinTime(score.get(score.size()-1)); scrollResult.setOffset(count); return Result.ok(scrollResult); } 注意reverseRangeByScoreWithScores函数参数顺序,集合名称,分数最小值,分数最大值,偏移量,查询信息数,这个函数可以同时返回score和value\n最后的效果: Redis-Geo实现搜索附近商户 Redis-Geo可以实现两个经纬度之间的距离测算\n比如我给出一个店铺的经纬度是87.588076 43.841359\n我的坐标是87.5795849 43.81927399\n那我们可以通过redis计算出这两地之间的距离\n1 2 3 4 5 6 7 8 localhost:6379\u0026gt; geoadd g1 87.529252 43.841359 urmuqizhan (integer) 1 localhost:6379\u0026gt; geoadd g1 87.588076 43.8242569 ShenZhenCheng (integer) 1 localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng \u0026#34;5088.3803\u0026#34; localhost:6379\u0026gt; geodist g1 urmuqizhan ShenZhenCheng km \u0026#34;5.0884\u0026#34; 这里我们通过geoadd语句添加了两地坐标,然后通过geodist计算出了两地之间的距离,如果限定输出格式的话,默认是米,可以限制输出为千米\n软件设计思路 用户要查看周围店铺的时候,我们就要按照距离顺序来给用户推荐,比如美团外卖的最近店铺,用户会给我们自己的坐标,也就是经纬度,我们要做的就是按照他传过来的位置和店铺位置算一个距离数据,然后排序查询后的搜索结果,返回给前端.\n注意到这里面有typeId,表示店铺的类型,比如美食,娱乐等等\n我们要在redis上存储这些店铺的信息,先把经纬度存进去,还有店铺的ID,还有typeId,我们这样可以设计\nshop:geo表示redis数据类型,1表示typeId\n具体实现 当我们把查询到的typeId用来查询所有相关的店铺\n1 2 3 4 5 6 7 GeoResults\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; result = stringRedisTemplate.opsForGeo().search( key, GeoReference.fromCoordinate(x, y), //默认米为单位,5公里 new Distance(5000), RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end) ); 这个函数的参数为,key,用户坐标,查询附近5km的所有店铺,查询到分页表的最后一个下标,因为redis没有设置from 到end的查询方式,所以只能全查了,这样查出来的就按照距离顺序\n这里同时查询出来了距离和店铺的id,我们可以这样取出所有值\n1 2 3 4 5 6 7 8 9 10 11 List\u0026lt;Long\u0026gt; ids=new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Distance\u0026gt; distances=new ArrayList\u0026lt;\u0026gt;(); for (GeoResult\u0026lt;RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt;\u0026gt; r : result) { if (sum\u0026lt;from) { sum++; continue; } RedisGeoCommands.GeoLocation\u0026lt;String\u0026gt; location = r.getContent(); ids.add(Long.valueOf(location.getName())); distances.add(r.getDistance()); } 然后查询数据库,把店铺所有信息和距离返回给前端\n1 2 3 4 5 6 7 for (int i =0;i\u0026lt;ids.size();i++) { Shop shop= shopMapper.selectById(ids.get(i)); shop.setDistance(Double.valueOf(distances.get(i).toString().replaceAll(\u0026#34;[^\\\\d.]\u0026#34;, \u0026#34;\u0026#34;))); if(shop!=null){ shops.add(shop); } } 最后结果就是这样了\n查询的时候是按照距离来搜的,并且附带距离\n","date":"2025-03-16T20:30:40+08:00","permalink":"https://LuciusWan.github.io/p/redis%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E6%88%98/","title":"Redis学习与实战"},{"content":"面试题总结 HashMap的底层原理 Hashap 是基于哈希表的数据结构，用于存储键值对(key-value )。其核心是将键的哈希值映射到数组索引位置，通过数组 +链表(在 Java 8 及之后是数组 +链表 +红黑树)来处理哈希冲突。\nHashmap 的默认初始容量为 16，负载因子为 0.75。也就是说，当存储的元素数量超过16x0.75=12个时， Hashmap 会触 发扩容操作，容量x2并重新分配元素位置。这种扩容是比较耗时的操作，频繁扩容会影响性能。\nHashMap 的红黑树优化: 从Java8开始，为了优化当多个元素映射到同一个哈希桶(即发生哈希冲突)时的查找性能，当链表长度超过8时，链表会转变为红黑树。红黑树是一种自平衡二叉搜索树，能够将最坏情况下的査找复杂度从 O(n) 降低到 O(log n)。如果树中元素的数量低于 6，红黑树会转换回链表，以减少不必要的树操作开销。\nhashCode()和 equals()的重要性: HashMp 的键必须实现 hashcode()和 equals()方法。 hashcode()用于计算哈希值，以决定键的存储位置，而 equals()用于比较两个键是否相同。在 put 操作时，如果两个键的 hashcode()相同，但 equals()返回 false，则这两个键会被视为不同的键，存储在同一个桶的不同位置。\n经典的“哈希冲突”案例 在 Java 中，最著名的例子就是字符串 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot;。\nJava\n1 2 3 4 5 6 String s1 = \u0026#34;Aa\u0026#34;; String s2 = \u0026#34;BB\u0026#34;; System.out.println(s1.hashCode()); // 输出 2112 System.out.println(s2.hashCode()); // 输出 2112 System.out.println(s1.equals(s2)); // 输出 false 发生了什么？\nJava 字符串的哈希算法是 s[0]*31 + s[1]：\n'A' 是 65，'a' 是 97 \\rightarrow 65 \\times 31 + 97 = 2112\n'B' 是 66 \\rightarrow 66 \\times 31 + 66 = 2112\n虽然算出来的数字一样，但显然 \u0026quot;Aa\u0026quot; 和 \u0026quot;BB\u0026quot; 是完全不同的字符串。\nHashMap成环 由于线程1已经指向了B和A，线程2却先一步执行了扩容操作，而停止循环的条件就是e.next为null，当执行完扩容后，线程1苏醒，此时e为B，e.next为A，当前e的next指向A，导致A与B之间产生死循环，颠倒后依旧产生连接，就形成了环。\nJDK1.7HashMap多线程死循环问题_哔哩哔哩_bilibili\nSynchronized 和 ReentrantLock有什么区别? 实现层面 synchronized：\n是 Java 的关键字，属于 JVM 层面的实现。 ReentrantLock：\n是 JDK 提供的一个类（java.util.concurrent.locks.ReentrantLock），属于 API 层面的实现。 锁的释放 synchronized：\n自动释放。代码执行完同步代码块，或者抛出异常时，JVM 会自动释放锁，不会导致死锁。 ReentrantLock：\n手动释放。必须手动调用 unlock() 方法。 锁的公平性 synchronized：\n只能是非公平锁。线程获取锁的顺序是不确定的，可能发生“饥饿”现象。 ReentrantLock：\n默认是非公平锁（性能更好）。\n可以通过构造函数 new ReentrantLock(true) 指定为公平锁（遵循先来后到原则），但性能会下降。\n等待可中断 synchronized：\n不可中断。如果一个线程正在等待获取锁，它不能被中断（interrupt），只能一直阻塞等待。 ReentrantLock：\n可中断。通过 lockInterruptibly() 方法，可以让正在等待锁的线程响应中断，放弃等待去处理其他事情。 尝试获取锁 synchronized：\n不行。要么拿到锁，要么阻塞死等。 ReentrantLock：\n提供 tryLock() 方法。可以尝试获取锁，如果锁被占用，可以选择立即返回 false 或者等待一段指定的时间，非常灵活。 特性 synchronized（隐式锁） ReentrantLock（显式锁） 实现方式 关键字 (JVM 层面) 类 (JDK API 层面) 锁的释放 隐式自动释放 显式手动释放 (需在 finally 中 unlock) 公平性 非公平 默认非公平，可设置为公平 响应中断 不支持 支持 (lockInterruptibly) 条件队列 单个 (wait/notify) 多个 (Condition) 尝试获取 不支持 (死等) 支持 (tryLock) 灵活性 低 高 锁升级 锁升级流程图解 锁状态 触发条件 优点 缺点 偏向锁 只有一个线程反复加锁 加锁/解锁几乎零消耗 如果存在线程竞争，撤销偏向锁会有额外开销 轻量级锁 线程交替执行，无同时竞争 不会阻塞线程，利用 CAS 和自旋，响应速度快 如果始终得不到锁，自旋会空耗 CPU 重量级锁 发生长时间或多线程同时竞争 不会空耗 CPU，未获锁线程进入阻塞 线程阻塞/唤醒涉及上下文切换，开销大，较慢 CAS与自旋 什么是CAS（乐观锁） 你看到原句是“Hello”（A）。\n你想改成“Hi”（B）。\n在你提交修改的一瞬间，系统检查文档当前还是不是“Hello”（V）。\n如果是，修改成功。\n如果文档已经被别人改成了“Hello World”，你的预期（A）和实际（V）不符，提交失败，你需要重新读取再尝试。\nCAS 的三大问题 ABA 问题（最著名的坑）：\n虽然 V 还是 A，但不代表它没变过。它可能经历了 A -\u0026gt; B -\u0026gt; A 的过程。\n比喻：桌上有一杯水（A），你离开了一会儿。回来时水还是满的（A），你以为没人动过。实际上可能有人喝光了（B），又给你倒满了（A）。虽然结果一样，但过程可能由于“杯子被用过”而产生副作用。\n解决：加版本号。变成 1A -\u0026gt; 2B -\u0026gt; 3A。Java 中的 AtomicStampedReference 就是干这个的。给提交结果加版本号\n只能保证一个变量的原子性：无法同时操作多个变量。\nCPU 开销大：这通常与“自旋”结合在一起，见下文。\n什么是 自旋 ？ 自旋是一种线程等待的策略。\n当线程抢不到锁（或 CAS 失败）时，它不放弃 CPU，不进入阻塞状态（不睡觉），而是执行一个空循环（Loop），不断地检查“锁释放了吗？”或者“我能重试 CAS 了吗？”。\n为什么要自旋？ 为了避免上下文切换的开销。\n阻塞/唤醒：线程挂起和恢复需要操作系统介入，保存和恢复现场，非常耗时（可能比执行代码本身还慢）。\n自旋：如果锁被占用的时间很短，我在门口转两圈（自旋）锁就释放了，这样比“回家睡觉再被电话叫醒”快得多。\n概念 作用 核心词 优缺点 CAS 实现原子更新 比较并交换 优点：非阻塞，性能好\n缺点：ABA 问题 自旋 等待锁的策略 循环重试 优点：避免上下文切换\n缺点：耗费 CPU SpringBean的生命周期 阶段一：创建与注入 (的基础) 1. 实例化 (Instantiation) 发生了什么： Spring 容器通过反射（Constructor.newInstance()）调用 Bean 的构造函数。\n状态： 此时对象已经在堆内存中存在了，但它只是一个“空壳子”，里面的属性（依赖）全是 null。\n类比： 刚买了一个毛坯房，房子建好了，但里面什么家具都没有。\n2. 属性赋值 (Populate Properties) 发生了什么： Spring 依据配置（XML 或 @Autowired、@Value），将依赖的对象或属性值注入到 Bean 中。\n状态： 对象内部的依赖已经填充完毕。\n类比： 装修工进场，把沙发（Service）、电视（Dao）都搬进了房子里。\n阶段二：容器感知 (Aware 接口回调) 3. Aware 接口回调 (Invoke Aware Interfaces) 发生了什么： 如果 Bean 实现了特定的 Aware 接口，Spring 会把容器内部的一些资源“告诉”这个 Bean。 阶段三：初始化与增强 (最关键的步骤) 所谓的“初始化阶段”，就是 Spring 给你一个机会，在“属性都装好了”之后，但在“给别人使用”之前，让你执行一段自己的业务代码（比如连数据库、加载缓存、校验配置）。\nSpring AOP（默认机制）使用的是 动态代理（Dynamic Proxy）。它的逻辑是委托（Delegation）。\n原本的流程：\n调用者 \\rightarrow 目标对象（Target）\nSpring AOP 的流程：\n调用者 \\rightarrow 代理对象（Proxy） \\rightarrow 执行增强代码（Before） \\rightarrow 调用目标对象 \\rightarrow 执行增强代码（After） \\rightarrow 返回\n特性 Spring AOP AspectJ（静态代理） 原理 动态代理 (Proxy) 字节码织入 (Bytecode Weaving) 修改方式 运行时生成新类包裹目标 编译期/加载期直接修改目标类字节码 是否需要接口 JDK模式需要，CGLIB不需要 不需要 性能 稍慢（有反射和代理调用的开销） 极快（就是普通的方法调用） 能力范围 只能拦截 public 方法 的调用 无所不能：可拦截 private 方法、静态方法、构造函数、字段访问等 内部调用(this) 失效 有效 (完美解决自调用问题) 复杂度 低（Spring Boot 开箱即用） 高（需要配置编译器或 JVM Agent） Redis和Memcached的区别 特性 Memcached Redis 数据结构 单一 (仅支持 String/二进制块) 丰富 (String, List, Hash, Set, ZSet, Bitmap, HyperLogLog, Stream, Geo) 线程模型 多线程 (Multi-threaded) 单线程 (主逻辑) + I/O 多线程 (Redis 6.0+) 持久化 不支持 (重启后数据丢失) 支持 (RDB 快照 \u0026amp; AOF 日志) 分布式支持 客户端实现 (服务端互不通信) 服务端支持 (Redis Cluster, Sentinel) 内存管理 Slab Allocation (预分配，无碎片，但在非均匀大小数据下有浪费) jemalloc/libc (按需分配，利用率高，但可能有内存碎片) 功能丰富度 仅缓存 Lua 脚本、发布/订阅 (Pub/Sub)、事务、Pipeline 最大值限制 Value 最大 1MB Value 最大 512MB A. 数据类型 (Data Types) —— 最大的区别 Memcached: 就像一个巨大的 Map\u0026lt;String, String\u0026gt;。如果你想存一个列表，必须先把列表序列化成 JSON 字符串存进去；取出来时，必须把整个字符串取出来反序列化，修改后再序列化存回去。这非常消耗网络带宽和 CPU。\nRedis: 就像一个瑞士军刀。你可以直接在服务端操作数据结构。\n例子： 你想给一个排行榜加分。\nRedis: ZINCRBY rank_list 10 \u0026quot;user_id\u0026quot; (直接在内存里改数值，极快)。\nMemcached: get -\u0026gt; 反序列化 -\u0026gt; value + 10 -\u0026gt; 序列化 -\u0026gt; set (并发下还需要加锁，否则数据不一致)。\nB. 线程模型 (Threading Model) —— 性能的分水岭 Redis (单线程为主):\nRedis 的核心操作（执行命令）是单线程的。\n优势： 没有线程切换开销，没有锁竞争（Lock-free），代码简单稳定。\n劣势： 无法利用多核 CPU 的优势（但在 6.0 版本引入了多线程 I/O 来处理网络读写，核心计算依然是单线程）。\nMemcached (多线程):\n它使用主线程监听端口，Worker 线程处理读写。\n优势： 可以轻松利用 64 核 CPU 的计算能力，在极高并发（数十万 QPS 以上）且 Value 很小 的场景下，吞吐量可能高于 Redis。\nC. 持久化 (Persistence) —— 数据安全性 Memcached: 把它当作一个易失性缓存。如果服务器断电或重启，所有缓存数据瞬间清空，数据库会瞬间面临巨大的“缓存击穿”压力。\nRedis: 支持持久化。\nRDB: 定期生成快照保存在磁盘。\nAOF: 记录每一条写命令。\n用途： 重启后可以自动恢复数据，甚至可以用来做主数据库使用。\nD. 分布式/集群 (Clustering) Memcached: 服务端是“傻瓜式”的，节点之间互不通信。分布式的逻辑完全由客户端（Client）控制（通常使用一致性哈希算法）。如果你加一台服务器，客户端需要重新计算哈希。\nRedis: 支持原生的 Redis Cluster。服务端之间会通信（Gossip 协议），支持自动分片、故障转移（Failover）。\n内核内存 vs. 用户内存 (The Two Worlds) 操作系统（如 Linux）为了安全和稳定，把内存划分成了两个隔离的区域：\n1. 内核内存 (Kernel Memory / Kernel Space) 权限： 最高权限 (Ring 0)。CPU 可以执行任何指令，访问任何硬件地址。\n居住者： 操作系统内核代码、驱动程序（网卡驱动）、硬件缓冲区。\n特点： 如果这块区域的代码崩溃了，整个操作系统就蓝屏或死机了。它是神圣不可侵犯的。\n2. 用户内存 (User Memory / User Space) 权限： 受限权限 (Ring 3)。只能访问自己的内存空间，严禁直接访问硬件（不能直接读写网卡、硬盘）。\n居住者： 你运行的应用程序（Redis, Java JVM, 浏览器, QQ）。\n特点： 如果你的 Redis 崩了，只是这一个进程死掉，操作系统照样运行。\n核心矛盾： 网卡收到的数据首先必须存放在内核内存（因为它是由驱动程序管理的）。但是，你的 Redis 运行在用户内存。\n代价： 数据必须从“内核态”拷贝 (Copy) 到“用户态”，应用程序才能处理。这就是 Redis 6.0 引入多线程 I/O 想要优化的那个“搬运”过程。###\nSocket 是什么？ (The Abstraction) 很多初学者认为 Socket 就是“插座”或者“连接”。在操作系统层面，Socket 本质上是内核内存中的两个缓冲区（Buffer）。\n当你创建一个 Socket（比如 Java 的 new Socket() 或 Redis 监听的端口），内核会在内核内存里为你申请两块地：\n接收缓冲区 (Recv Buffer): 存放网卡发过来、等待你读取的数据。\n发送缓冲区 (Send Buffer): 存放你写进去、等待网卡发送的数据。\nSocket 就是应用程序（用户态）和网络协议栈（内核态）交互的句柄 (File Descriptor)。\nRedis数据的全生命周期流程 假设外网发来一个 TCP 包给 Redis（端口 6379），流程如下：\n1. 物理层：网卡收货 (NIC) 网线传来电信号，网卡将其转换为二进制数据。\nDMA (Direct Memory Access): 网卡不经过 CPU，直接利用 DMA 技术，把数据包写入到 内核内存 中的一块公用区域（通常叫 Ring Buffer）。\n此时，数据在内核，但还不知道属于哪个 Socket。\n2. 链路层 \u0026amp; 网络层：内核协议栈介入 网卡给 CPU 发送中断 (Interrupt)。\nCPU 停下手中的活，运行网卡驱动程序。\n驱动程序把数据包包装成内核的数据结构（Linux 下叫 sk_buff）。\n操作系统检查 IP 头：是发给本机的吗？是的。\n3. 传输层：分发给 Socket (Demultiplexing) 操作系统检查 TCP 头：目标端口是 6379。\n内核查找：“哪个 Socket 正在监听 6379 端口？” -\u0026gt; 找到了 Redis 的那个 Socket。\n关键动作： 内核把这个数据包（sk_buff）挂到该 Socket 的接收缓冲区 (Recv Buffer) 队列的尾部。\n此时，数据依然在内核内存中，但已经归属到了特定的 Socket 名下。\n4. 应用层：数据搬运 (Copy to User) Redis 主线程（或 I/O 线程）调用系统函数 read(socket_fd)。\nCPU 发生上下文切换： 从用户态切入内核态。\n内存拷贝： CPU 把数据从 内核内存（Socket 的接收缓冲区） 复制到 用户内存（Redis 定义的 buffer）。\nRedis 终于拿到了数据，开始解析处理 set name ...。\n那 Redis 6.0 的 I/O 线程到底解决了什么？ 既然都要经过内核拷贝，那用主线程调 write 和用 I/O 线程调 write 有什么区别？\n区别在于“谁在等”和“谁在分担开销”。\n场景：如果你只有主线程（Redis \u0026lt; 6.0） 主线程：“我要处理 10,000 个客户端的 get 请求。”\n对于每一个请求，主线程都要亲自调用 write。\n每次 write，主线程都要经历：用户态-\u0026gt;内核态切换 (耗时) + CPU 搬运数据 (耗时) + 内核态-\u0026gt;用户态切换 (耗时)。\n结果： 主线程大量时间花在和内核打交道、等待搬运上，导致它处理命令（KV 读写）的时间变少了。\n场景：你有 I/O 线程（Redis 6.0+） 主线程：“我要处理 10,000 个请求。算出结果后，我不亲自发了。”\n主线程把结果扔给 4 个 I/O 线程，说：“你们去调 write 发给客户。”\n主线程立刻转头去处理下一个命令的计算（KV 读写）。\nI/O 线程们 并行地去调用 write，去承担上下文切换和 CPU 搬运数据的开销。\n结果： 主线程被解放了，只专注于纯内存计算，吞吐量大增。\n内核线程，内核级线程，用户级线程 用户级线程是怎么“骗”过内核的？（M:N 模型） 用户级线程通过一个**中间层（Runtime/Scheduler）**来实现。\nM 个用户级线程（比如 1000 个 Goroutine）。\nN 个内核级线程（通常等于 CPU 核数，比如 8 个）。\n映射关系：\n这 8 个内核线程是“干活的苦力”。\n这 1000 个协程是“待办的任务”。\nGo 语言的运行时（Runtime）负责把这 1000 个任务，源源不断地塞给这 8 个苦力去做。\n如果一个任务（协程）卡在 I/O 上了，Runtime 把它拿开，换一个新任务给苦力，苦力（内核线程）永远不休息，也永远不阻塞。\n我们可以把计算机系统看作一家大型工厂（操作系统）：\n内核线程 (Kernel Thread): 工厂的内部设施维护人员（只在核心区工作，不生产对外产品）。\n内核级线程 (Kernel-Level Thread, KLT): 工厂正式聘用的流水线工人（有工牌，受人事部直接管理）。\n用户级线程 (User-Level Thread, ULT): 包工头带来的临时工/外包团队（人事部不知道他们的存在，只知道包工头）。\n一、 详细拆解：三者的定义与区别 1. 内核线程 (Kernel Thread / kthread) 这是最底层的存在，它们完全运行在内核空间（Ring 0）。\n定义： 它是操作系统内核用来执行后台任务的线程。它没有用户地址空间（不映射用户内存），只能访问内核代码和数据。\n谁创建/管理： 操作系统内核。\n能干啥：\n将内存中的脏页刷写到磁盘（如 Linux 的 kflush 或 pdflush）。\n处理软中断和网络包（如 ksoftirqd）。\n执行磁盘 I/O 调度。\n特点： 也就是我们常说的“纯内核线程”。你在 Linux 用 ps -ef 看到的那些名字带中括号 [kthreadd]、[migration] 的进程，就是它们。\n与用户程序的关系： 完全没关系。它们不运行你的 Java 或 Redis 代码，它们只服务于 OS 本身。\n2. 内核级线程 (Kernel-Level Thread, KLT) 这是我们日常开发中最常接触的概念（虽然你可能没意识到）。 在 Linux 中，它们通常被称为 轻量级进程 (LWP, Light Weight Process)。\n定义： 这是一个由内核管理、但用于执行用户态代码的执行实体。它是**“用户进程”在内核眼里的分身**。\n谁创建/管理： 操作系统内核调度器（如 CFS）。\n能干啥： 执行你的 main() 函数，执行 Redis 的主逻辑，执行 Java 的线程。\n特点：\n拥有双重身份： 既有内核栈（陷入内核时用），也有用户栈（运行程序时用）。\n可被独立调度： 操作系统知道它的存在，可以将它分配给任意 CPU 核心。\n高开销： 创建、销毁、切换都需要系统调用，涉及内核态/用户态切换，成本较高（微秒级）。\n代表： Java 的 java.lang.Thread (在 Linux 上)，C++ 的 std::thread，Redis 的主线程和 I/O 线程。\n3. 用户级线程 (User-Level Thread, ULT) 也叫协程、纤程、Green Thread。\n定义： 完全在用户空间实现的线程机制。内核完全不知道它们的存在，内核只看到承载它们的那个 KLT。\n谁创建/管理： 编程语言的运行时（Runtime）或库（如 Go Runtime, JVM）。\n能干啥： 处理高并发逻辑，阻塞式写法的异步执行。\n特点：\n极轻量： 切换只涉及寄存器保存，无需陷入内核，纳秒级。\n不可独立调度： 操作系统无法直接把一个 ULT 分配给 CPU，必须依附于一个 KLT 才能运行。\n代表： Go 的 Goroutine, Python 的 Gevent, Java 21 的 Virtual Thread。\n二、 它们之间的映射模型 (The Mapping Models) 弄清楚关系的关键，在于理解用户级线程 (ULT) 和 内核级线程 (KLT) 是如何搭配工作的。这主要有三种模型：\n1. 多对一模型 (M : 1) —— 上古时代的产物 描述： 多个用户级线程（M）跑在 1 个内核级线程（1）上。\n例子： 老版本的 Python 异步库，某些老旧的 JVM 实现（Green Threads）。\n缺点： 没有并行能力。因为底层只有一个 KLT，所以一次只能用 1 个 CPU 核。如果其中一个 ULT 阻塞了（比如发起系统调用），底层的 KLT 就阻塞了，其他所有 M 个 ULT 全都卡死。\n2. 一对一模型 (1 : 1) —— 现代主流 (Redis, Nginx, Java) 描述： 1 个用户级线程（逻辑上的线程）直接对应 1 个内核级线程。\n机制： 当你在 Java 里 new Thread()，操作系统就在底层真的创建一个 KLT（LWP）。\n优点： 真正的并行。一个线程阻塞，不影响其他线程。实现简单，直接依赖 OS 调度。\n缺点： 线程太贵，开不了一百万个。\n现状： Redis 的主线程和 I/O 线程，Java 目前默认的线程模型，都是 1:1。 所谓的“用户线程”此时只是 KLT 的一个句柄。\n3. 多对多模型 (M : N) —— 高并发的未来 (Go,Java21 Virtual Threads) 描述： M 个用户级线程（协程）动态映射到 N 个内核级线程上。\n机制：\nRuntime 维护一个线程池（N 个 KLT）。\nRuntime 维护一个任务队列（M 个 ULT）。\nRuntime 负责把 ULT 喂给 KLT 执行。如果一个 ULT 阻塞了，Runtime 把它拿下来，换另一个 ULT 上去。\n优点： 既有 ULT 的轻量（可以开百万个），又有 KLT 的并行（利用多核 CPU）。\n现状： Go 语言之所以火，就是因为它的调度器（G-M-P 模型）把这个做到了极致。\n三、 总结与对比表 特性 内核线程 (Kernel Thread) 内核级线程 (KLT / LWP) 用户级线程 (ULT / Coroutine) 可见性 仅内核可见 内核可见，用户可见 仅用户程序可见 (内核不可见) 内存空间 仅内核空间 用户空间 + 内核空间 仅用户空间 调度者 OS 调度器 OS 调度器 语言运行时 (Runtime) 切换开销 小 (无需切换地址空间) 中 (需切入内核态) 极小 (纯用户态操作) 并行性 利用多核 利用多核 依赖于底层的 KLT 阻塞影响 - 线程阻塞，释放 CPU 给别人 协程阻塞，Runtime 切换其他协程 典型例子 ksoftirqd, kworker java.lang.Thread, Redis 线程 Go Goroutine, Java Virtual Thread 一般什么情况下需要陷入内核态？ 简单来说，“陷入内核态”（Trap into Kernel Mode） 也就是 CPU 从 特权级 3 (User Ring 3) 切换到 特权级 0 (Kernel Ring 0) 的过程。\n一般情况下，陷入内核态主要有且仅有三种场景：\n1. 系统调用 (System Call) —— 主动请求 这是最常见的情况。当你的程序需要做一些自己权限不够的事情时，必须主动向操作系统“打报告”。\n因为用户程序不能直接操作硬件（硬盘、网卡、声卡）或管理内存，必须通过特定的接口（System Call Interface）请求内核代劳。\n硬件 I/O 操作：\n读写文件： read(), write(), open()（Redis 写日志、读数据库）。\n网络通信： socket(), connect(), send(), recv()（Redis 处理请求）。\n屏幕输出： printf()（底层调用 write 输出到标准输出）。\n进程控制：\n创建进程： fork(), exec()（Redis 做 RDB 快照时会 fork 子进程）。\n退出程序： exit()。\n内存管理：\n申请内存： malloc() 在堆内存不够时，底层会调用 brk() 或 mmap() 向内核要内存。 比喻： 你要去银行取钱（操作硬件资源），你不能自己冲进金库拿，必须填单子（系统调用），交给柜员（内核），柜员帮你拿出来给你。\n2. 异常 (Exception) —— 内部错误或特殊事件 这是由 CPU 在执行指令时，内部检测到的意外情况。程序“闯祸了”或者遇到了“特殊指令”。\n缺页异常 (Page Fault)：\n当你访问一块内存地址，CPU 发现这块数据不在物理内存里（可能被换到了磁盘 swap 分区，或者刚申请还没分配物理页），CPU 会暂停程序，陷入内核。内核负责把数据从磁盘加载到内存，然后恢复程序运行。 程序错误：\n除以零： 代码里写了 100 / 0。\n非法内存访问 (Segfault)： 试图访问不属于你的内存地址（比如空指针解引用）。\n内核捕获这些错误后，通常会杀死进程（就是你看到的 Segmentation fault）。\n调试断点：\n当你用 GDB 调试代码打断点时，实际上是插入了一条特殊指令（如 x86 的 INT 3）。CPU 执行到这里会自动陷入内核，暂停程序，把控制权交给调试器。 比喻： 你在家里（用户态）做饭，突然锅炸了（除以零）或者你想进邻居家里（非法内存访问），这时候警察（内核）会立刻破门而入处理状况。\n3. 硬件中断 (Hardware Interrupt) —— 被动打断 这是来自 CPU 外部的信号。无论你的程序正在干什么，只要硬件中断来了，CPU 必须无条件停下手头的工作，切到内核态去处理中断。\n时钟中断 (Clock Interrupt)：\n最重要！ 这是多任务操作系统的基石。\n硬件时钟每隔几毫秒就会发一次中断。内核收到中断后，会看：“Redis，你的时间片用完了，该让给 Nginx 跑一会儿了。”\n这就是为什么死循环的程序不会把电脑彻底卡死，因为内核会强行通过时钟中断夺回控制权。\nI/O 完成中断：\n网卡： “新数据包到了！”（内核把数据拷贝到 Socket 缓冲区）。\n硬盘： “刚才你要读的数据我已经读完放到内存了！”\n键盘/鼠标输入：\n你按下一个键，键盘控制器发送中断，CPU 陷入内核读取按键码。 比喻： 你正在家里专心打游戏（用户态运行代码），突然快递员狂按门铃（网卡中断），或者你的闹钟响了（时钟中断），你必须停下游戏去开门或者关闹钟（陷入内核处理）。\n触发方式 来源 例子 主动/被动 系统调用 程序代码 read(), fork(), sleep() 主动 (程序自己写的) 异常 CPU 内部 缺页、除零、Segfault 被动 (通常是闯祸了) 硬件中断 CPU 外部 网卡收包、时钟滴答、键盘 被动 (外部环境强制) Redis单线程避免上下文切换的开销 1. 什么是“昂贵”的上下文切换？ 首先，我们要明确，为什么切换线程很贵？\n当 CPU 从 线程 A 切换到 线程 B 时，不仅仅是“换个人干活”这么简单，它涉及两个巨大的成本：\n直接成本 (CPU 寄存器重置)：\nCPU 需要把线程 A 的“现场”（程序计数器 PC、堆栈指针 SP、通用寄存器等）保存到内存里。\n然后从内存里把线程 B 的“现场”恢复到寄存器里。\n这本身需要花费几微秒 ($\\mu s$)。\n间接成本 (Cache 失效 —— 这才是真正的杀手)：\nCPU 有 L1/L2/L3 高速缓存。线程 A 跑得正欢的时候，缓存Cache里全是线程 A 需要的数据（热数据）。\n突然切到线程 B，线程 B 要用的数据不在缓存里（Cache Miss）。\nCPU 被迫去慢如蜗牛的内存（RAM）里拿数据。\n这会导致 CPU 的执行效率瞬间暴跌。\n2. 多线程模式的痛点 (The \u0026ldquo;Context Switch Storm\u0026rdquo;) 假设 Redis 是传统的多线程模型（比如像早期的 Tomcat 或 MySQL）：\n场景： 来了 1000 个请求。\n处理： 系统开启 1000 个线程（或者用线程池）。\n锁竞争： 线程 A 要修改 Key \u0026ldquo;user:1\u0026rdquo;，线程 B 也要修改。线程 B 抢不到锁，被迫挂起 (Block)。\n自愿切换 (Voluntary Context Switch)：\n因为抢不到锁，或者等待磁盘 I/O，线程 B 主动告诉操作系统：“我干不下去了，把 CPU 让给别人吧。”\n操作系统进行上下文切换。\n结果： 在高并发下，CPU 把大量的时间花在** “保存现场、恢复现场、调度线程、等待锁” **上，真正用来执行 set name gemini 这行代码的时间反而被挤压了。\n3. Redis 的单线程魔法 (The \u0026ldquo;Run-to-Completion\u0026rdquo;) Redis 的主处理逻辑（Command Execution）是单线程的，这意味着：\nA. 彻底消灭“锁竞争” 因为只有我一个人（主线程）在动数据，所以我根本不需要锁（Lock-free）。\n没有锁，就不会出现“因为抢不到锁而挂起”的情况。\n不存在“挂起”，就没有“自愿上下文切换”。\n结果： Redis 主线程是一路狂奔的，它处理完一个请求，马上处理下一个，中间没有任何停顿。\nB. 极致的 Cache 亲和性 (Cache Affinity) 因为始终是这同一个线程在这一颗 CPU 核心上跑。\nRedis 的核心数据结构（dict, ziplist, skiplist）和代码指令，会一直停留在 CPU 的 L1/L2 缓存里。\nCache Hit 率极高。\n这就像一个熟练工人在自己的工位上干活，所有工具都在手边（L1 Cache），闭着眼睛都能拿到。\nC. I/O 多路复用 (Epoll) —— 避免 I/O 阻塞 你可能会问：“那如果读 Socket 数据的时候，数据还没来怎么办？线程不就阻塞了吗？”\nRedis 使用 epoll (Linux)。\n机制： Redis 告诉内核：“这一万个 Socket 你帮我盯着，谁有数据来了你告诉我。”\n非阻塞： Redis 主线程永远不会在某个 Socket 上死等（Block）。它只处理那些“已经准备好数据”的 Socket。\n所以，Redis 永远不会因为 I/O 等待而发生上下文切换。\n4. 总结对比：多线程 vs 单线程 我们可以用去银行办事来比喻：\n模式 场景比喻 上下文切换情况 效率 多线程模型 10 个窗口，10 个柜员。 所有的柜员都要抢同一个账本（锁）来记账。抢不到的柜员就去喝茶（切换）。柜员之间换班还要交接工作（保存现场）。 极高 (锁竞争、线程调度) 低 (大量时间花在抢锁和交接上) Redis 单线程 1 个超级柜员 (Flash)。 只有他一个人，账本就在手边（Cache）。他动作极快，处理完张三马上处理李四，不用跟任何人抢账本，也不用交接班。 极低 (几乎为 0，除非时间片用完) 极高 (CPU 100% 用在干活上) 5. 什么时候 Redis 还是会切换？ 虽然 Redis 尽力避免切换，但被动切换 (Involuntary Context Switch) 是无法避免的，因为操作系统才是老大。\n时间片用完 (Time Slice): 操作系统采用了分时调度。给 Redis 的 10ms 用完了，不管你活干没干完，OS 必须强行把 CPU 抢走给别的进程（比如 SSH、系统日志）用一下。 Redis 单线程避免上下文切换的核心在于：它通过“非阻塞 I/O”和“单线程串行执行”，消灭了代码层面的“锁”和“等待”，从而让 CPU 始终处于全速运算的高效状态。\nRedis写数据全生命周期 假设有一个 Java 客户端，发送了一条命令 SET user:1 \u0026quot;Alice\u0026quot;。\n第一阶段：请求到达与分发 (进 - I/O 阶段) 客户端发送：\n外部的 Java 客户端（用户级线程）发起 TCP 连接，将命令 SET user:1 \u0026quot;Alice\u0026quot; 转换成 Redis 协议（RESP），通过网线发送出去。\n数据到达 Redis 服务器的网卡，进入操作系统的内核 Socket 缓冲区。\n主线程感知 (epoll)：\nRedis 的主线程正在运行事件循环（Event Loop），通过 epoll_wait 监听到这个 Socket 有数据来了（可读事件）。 任务分发 (Distribute)：\n关键点：主线程不亲自去读数据。\n主线程把这个 Socket 连接分配给一组 I/O 线程（IO Thread Pool） 中的某一个。\nI/O 线程并行读取与解析：\n多线程并行：被选中的 I/O 线程（内核级线程）发起系统调用 read()，从内核缓冲区把数据搬运到用户态。\n协议解析：I/O 线程解析数据流，识别出这是一条 SET 命令，参数是 user:1 和 Alice。\n注意：此时主线程会短暂等待，直到所有分配出去的 I/O 任务都完成读取和解析。\n第二阶段：命令执行 (做 - 执行阶段) 主线程串行执行 (Execute)：\n所有 I/O 线程都解析完后，汇报给主线程。\n单线程独占：主线程按照队列顺序，串行地拿到解析好的命令。\n内存操作：主线程在内存的 HashMap 中找到 user:1 这个槽位，填入 \u0026quot;Alice\u0026quot;。\n原子性：因为只有主线程在动这个 Map，所以绝对安全，不需要加锁。\n生成结果：\n执行成功，主线程生成响应结果 +OK。\n主线程把这个结果写入到该客户端的用户态输出缓冲区中。\n第三阶段：响应返回 (出 - I/O 阶段) 任务再次分发：\n主线程依然不亲自把数据发回网卡。\n它再次把“写回数据”的任务分配给 I/O 线程。\nI/O 线程并行回写：\nI/O 线程并行地调用 write() 系统调用，把缓冲区里的 +OK 发送给内核 Socket 缓冲区。\n内核负责通过网卡把数据发回给 Java 客户端。\n第四阶段：持久化 (存 - 后台阶段) 这部分是异步发生的，不影响给客户端返回结果的速度。\n触发持久化：\nAOF：主线程刚才执行完 SET 后，顺手把这条命令写到了内核缓冲区（Page Cache）。\n后台线程 (BIO)：稍后（如每秒）醒来，调用 fsync 把内核缓冲区的数据刷到物理磁盘。 RDB：如果满足了触发条件（如 1 分钟改了 1 万次）。\n主线程：调用 fork 生成子进程。\n子进程：默默地在后台把内存里的 user:1 等所有数据写成 RDB 文件。\nKafka为什么比RocketMQ快 参照物：传统 I/O (Standard I/O) 假设你要把磁盘上的一个文件通过网卡发给消费者（比如读取日志发送）。 代码通常是：read(file, buffer) -\u0026gt; write(socket, buffer)。\n这中间发生了 4 次拷贝 + 4 次上下文切换：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区（Read Buffer）。\nCPU 拷贝：内核缓冲区 -\u0026gt; 用户态缓冲区（数据进来了）。\nCPU 拷贝：用户态缓冲区 -\u0026gt; 内核 Socket 缓冲区（数据又出去了）。\nDMA 拷贝：Socket 缓冲区 -\u0026gt; 网卡。\n痛点：数据在内核和用户态之间反复横跳，CPU 忙着搬运数据，没空干别的。\nKafka 的绝技：sendfile (数据管道) Kafka 在发送消息给消费者时，调用了 Java 的 FileChannel.transferTo()，底层就是 Linux 的 sendfile 系统调用。\n核心机制 sendfile 告诉内核：“把这个文件里的数据，直接发给那个 Socket，不要经过我的手（用户态）。”\n流程（2 次拷贝 + 2 次切换）：\nDMA 拷贝：磁盘 -\u0026gt; 内核缓冲区 (Page Cache)。\nCPU/DMA 拷贝：\n早期 Linux：内核缓冲区 -\u0026gt; Socket 缓冲区。\n现代 Linux (DMA Gather Copy)：内核缓冲区 -\u0026gt; 直接给网卡（只把描述符给 Socket，真正做到了 CPU 0 拷贝）。\n这里的零拷贝指的是零CPU拷贝。\nRocketMQ 的绝技：mmap (内存映射) RocketMQ 选择了 mmap（Memory Mapped Files），在 Java 中对应 MappedByteBuffer。\n核心机制 mmap 告诉内核：“把磁盘上的这个文件，映射到我的虚拟内存地址里来。”\n流程：\n建立映射：用户态的一个虚拟地址指针，直接指向内核的 Page Cache。\n读写数据：\nRocketMQ 读取这个指针，就像读内存数组一样简单。\n操作系统负责在后台利用 DMA 把磁盘数据加载到 Page Cache（缺页中断机制）。\n发送数据：RocketMQ 读取这块“内存”，然后 write 给 Socket。\n这里依然需要一次 CPU 拷贝（从映射内存拷贝到 Socket 缓冲区）。 特性 Kafka (sendfile) RocketMQ (mmap) 数据路径 磁盘 -\u0026gt; 内核 -\u0026gt; 网卡 磁盘 -\u0026gt; 内核 -\u0026gt; 用户态 -\u0026gt; 内核 -\u0026gt; 网卡 CPU 参与度 极低 (几乎不参与拷贝) 中等 (需要一次 CPU 拷贝) 用户态可见性 不可见 (黑盒传输) 可见 (可读、可修改) 适用场景 海量数据流式传输 (只管发，不处理) 复杂业务消息 (需要过滤 Tag、事务回查等) Java API FileChannel.transferTo() MappedByteBuffer 限制 无法对内容进行逻辑处理 文件不能太大 (RocketMQ 限制 1GB) Kafka 之所以吞吐量宇宙第一，是因为它放弃了对消息细节的掌控，直接用 sendfile 当了一个“甩手掌柜”，把数据直接丢给网卡。\nRocketMQ 之所以功能强大（支持 Tag 过滤、复杂的事务状态），是因为它用了 mmap，保留了对数据的访问权，虽然牺牲了一点点传输性能，但换来了业务灵活性。\n一句话概括：Kafka 是为了“运货”而生，RocketMQ 是为了“验货”而生。\nPage Cache 是 Linux 内核为了掩盖磁盘龟速而用闲置内存做的“障眼法”。\n为什么RPC/HTTP2能比HTTP1.1快那么多 简单来说，HTTP/1.1 像是单车道，而 HTTP/2 + RPC 像是多车道高速公路，且路上跑的都是压缩后的跑车而不是臃肿的大卡车。\n以下是具体的技术核心差异：\n1. 多路复用 (Multiplexing) —— 解决核心痛点 这是 HTTP/2 相比 HTTP/1.1 最大的性能提升点，解决了“队头阻塞”（Head-of-Line Blocking）问题。\nHTTP/1.1 的问题：\n在同一个 TCP 连接中，请求是串行的。浏览器/客户端必须等上一个请求响应回来，才能发下一个。如果第一个请求处理很慢（比如数据库卡了），后面的所有请求都会被堵住。\n补救措施： 浏览器通常会针对同一个域名建立 6 个 TCP 连接来并行传输，但这对服务器资源消耗很大。 HTTP/2 (RPC) 的方案：\n它引入了 流 (Stream) 和 帧 (Frame) 的概念。\n所有的请求和响应都共用同一个 TCP 连接。\n不同的请求被拆分成许多小的二进制“帧”，这些帧像洗牌一样混在一起传输，每一帧都有 ID 标识属于哪个请求。\n结果： 请求 A 的数据包不需要等请求 B 处理完就能发送。高并发下，吞吐量极高。\n2. 头部压缩 (HPACK) —— 节省带宽 在微服务架构中，RPC 调用非常频繁，HTTP 头部（Headers）占用的开销比你想象的要大。\nHTTP/1.1 的问题：\nHTTP 是无状态的，每次请求都会携带完整的 Header（如 User-Agent, Cookie, Accept 等）。这些全是纯文本，往往几百字节甚至上 KB。如果你的请求体（Body）只有几十字节，那传输的有效数据比例极低。\nHTTP/2 (RPC) 的方案：\n使用了 HPACK 算法。\n客户端和服务器共同维护一张动态表和静态表。\n如果发送过 User-Agent: Chrome，第二次只需要发送一个索引号（比如 1），服务器查表就知道是 User-Agent: Chrome。\n这使得 Header 的大小几乎可以忽略不计。\n3. 二进制分帧 (Binary Framing) —— 解析更快 计算机处理二进制数据远快于处理文本。\nHTTP/1.1 的问题：\n是文本协议。解析文本需要处理换行符、空格、大小写等，对于高并发服务器来说，解析 JSON 或 HTTP 报文会消耗大量的 CPU 资源。\nHTTP/2 (RPC) 的方案：\n是二进制协议。数据在传输层就已经被分割为更小的消息和帧，并采用二进制编码。机器解析起来非常高效，出错率低，且更紧凑。\n4. 序列化协议 (Serialization) —— RPC 的独门秘籍 这一条主要针对 RPC（如 gRPC 使用的 Protocol Buffers）对比传统的 RESTful (HTTP/1.1 + JSON)。\nHTTP/1.1 + JSON：\nJSON 是基于文本的，冗余度极高。比如 {\u0026ldquo;id\u0026rdquo;: 12345, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;user\u0026rdquo;}，你需要传输字段名 id 和 name。且 JSON 的解析（反序列化）非常耗 CPU。\nRPC (Protobuf)：\n使用 Protocol Buffers (Protobuf) 或 Thrift 等二进制序列化协议。\n体积小： 它是通过 ID 映射字段，不传输字段名，压缩后的体积通常只有 JSON 的 1/3 到 1/10。\n速度快： 二进制流直接映射到内存对象，序列化/反序列化速度比 JSON 快 5-10 倍。\n5. 服务端推送 (Server Push) 虽然在 RPC 场景下用得相对少，但 HTTP/2 允许服务器在客户端请求之前“主动”推送资源，减少了往返延迟（RTT）。\n总结对比 特性 HTTP/1.1 HTTP/2 (及 gRPC) 优势 传输格式 文本 (Text) 二进制 (Binary) 解析更快，体积更小 连接模型 串行 (Keep-Alive) 多路复用 (Multiplexing) 解决队头阻塞，极大提高并发 头部开销 巨大 (纯文本重复发送) HPACK 压缩 节省带宽 负载内容 通常是 JSON (大、慢) 通常是 Protobuf (小、快) 序列化性能提升明显 TCP 连接数 多个 (通常 6 个) 只需 1 个 降低服务器握手和资源开销 HeavyKeeper和LRU，LFU 可以将它们的关系理解为：LRU 和 LFU 是“怎么扔垃圾”，而 HeavyKeeper 是“怎么用极小的代价找出谁是大佬”。\n以下是详细的对比和原理解析：\n1. LRU (Least Recently Used) - 最近最少使用 核心逻辑： “如果数据最近被访问过，那么它将来被访问的几率也很大。”\n关注点： 时间（Recency）。\n工作原理：\n新数据或刚被访问的数据放到队头。\n缓存满时，直接淘汰队尾的数据（最久没被摸过的）。\n优点：\n实现简单（HashMap + 双向链表）。\n适应突发性流量（Burst Traffic），因为热点往往是临近的。\n缺点：\n缓存污染（Cache Pollution）： 如果进行一次全表扫描（读取大量数据但只用一次），会把原本的热点数据全部挤出缓存，导致缓存命中率急剧下降。 2. LFU (Least Frequently Used) - 最不经常使用 核心逻辑： “如果数据过去被访问多次，那么它将来被访问的几率也很大。”\n关注点： 频率（Frequency）。\n工作原理：\n为每个数据维护一个计数器。\n缓存满时，淘汰计数器数值最小的数据。\n优点：\n抗扫描能力强。偶尔的一次性批量读取不会挤掉长期积累的热点数据。\n对于长期稳定的热点数据，命中率极高。\n缺点：\n实现复杂且内存开销大： 需要维护所有数据的计数器，且排序复杂度较高。\n旧数据滞留（Dusty Cache）： 一个以前很热但现在没用的数据（比如上个月的爆款商品），因为计数器很高，会一直霸占缓存，如果不引入衰减机制，很难被淘汰。\n3. HeavyKeeper - 专门抓“大象”的守门员 核心逻辑： “我不追求 100% 精确，但我用极小的内存就能告诉你谁是真正的热点（Top-K）。”\n关注点： 极低内存下的频率预估。\n本质： 它不是一个完整的缓存系统，而是一个算法结构（通常基于 Count-Min Sketch 的改进）。它常被用于 Redis 的热点发现工具或现代缓存系统（如 Caffeine 库）的频率过滤器中。\n工作原理（指纹衰减）：\n它使用类似哈希表的结构，但存储的是指纹（Fingerprint）和计数。\n关键创新： 传统的 Sketch 算法在哈希冲突时会错误地增加计数（导致高估）。HeavyKeeper 引入了衰减机制——当新元素进入并发生哈希冲突时，如果指纹不匹配，它会以一定概率减少（Decay）原有的计数器。\n结果： “小鼠流”（低频数据）的计数会被不断衰减消灭，“大象流”（高频数据）因为访问足够多，能抵抗衰减并幸存下来。\n优点：\n内存占用极小： 相比 LFU 记录所有 key 的完整计数，HeavyKeeper 只需要很少的 bucket 就能大概率找准热点。\n误差可控： 专门为 Top-K 场景设计，对高频数据极其准确。\n总结对比表 特性 LRU (时间) LFU (频率) HeavyKeeper (概率频率) 全称 Least Recently Used Least Frequently Used HeavyKeeper 核心维度 最近访问时间 访问总次数 访问总次数 (概率性) 主要用途 缓存淘汰策略 缓存淘汰策略 热点检测 (Top-K) / 辅助 LFU 抗扫描能力 弱 (容易被冲刷) 强 强 空间开销 中 (存 Key + 链表指针) 大 (存 Key + 计数器) 极小 (哈希桶 + 指纹) 实现复杂度 低 ($O(1)$) 高 (需堆或多级链表) 中 (哈希 + 概率逻辑) 精准度 精确 精确 有误差 (但对热点准确) 典型应用 MySQL Buffer Pool (改进版), 操作系统页置换 传统缓存系统 Redis 热 key 发现, 网络流量分析 LRU代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 package com.lucius.interviewproject.LRU; import java.util.HashMap; public class LRUCache { // 定义双向链表节点 class DLinkedNode { int key; int value; DLinkedNode prev; DLinkedNode next; public DLinkedNode() {} public DLinkedNode(int _key, int _value) {key = _key; value = _value;} } // 核心数据结构 private HashMap\u0026lt;Integer, DLinkedNode\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); private int size; private int capacity; private DLinkedNode head, tail; // 伪头部和伪尾部节点 public LRUCache(int capacity) { this.size = 0; this.capacity = capacity; // 使用伪头部和伪尾部节点，避免处理复杂的 null 边界情况 head = new DLinkedNode(); tail = new DLinkedNode(); head.next = tail; tail.prev = head; } public int get(int key) { DLinkedNode node = cache.get(key); if (node == null) { return -1; } // 如果 key 存在，先通过哈希表定位，然后移动到链表头部 moveToHead(node); return node.value; } public void put(int key, int value) { DLinkedNode node = cache.get(key); if (node == null) { // 如果 key 不存在，创建一个新节点 DLinkedNode newNode = new DLinkedNode(key, value); // 添加进哈希表 cache.put(key, newNode); // 添加至双向链表的头部 addToHead(newNode); size++; // 如果超出容量，删除双向链表的尾部节点 if (size \u0026gt; capacity) { DLinkedNode tail = removeTail(); // 删除哈希表中对应的项 cache.remove(tail.key); size--; } } else { // 如果 key 存在，更新 value，并移动到头部 node.value = value; moveToHead(node); } } // --- 以下是辅助的链表操作方法 --- // 1. 将节点移动到头部 (也就是最近使用的位置) private void moveToHead(DLinkedNode node) { removeNode(node); addToHead(node); } // 2. 将节点插入到伪头部之后 private void addToHead(DLinkedNode node) { node.prev = head; node.next = head.next; head.next.prev = node; head.next = node; } // 3. 删除节点 private void removeNode(DLinkedNode node) { node.prev.next = node.next; node.next.prev = node.prev; } // 4. 删除尾部节点（淘汰最久未使用的） private DLinkedNode removeTail() { DLinkedNode res = tail.prev; removeNode(res); return res; } } ","date":"2025-11-21T21:35:16+08:00","permalink":"https://LuciusWan.github.io/p/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1/%E5%9C%BA%E6%99%AF/","title":"面试八股/场景"},{"content":"刷! 字母异位词分组 题目 给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。\n字母异位词 是由重新排列源单词的所有字母得到的一个新单词。\n示例 1:\n输入: strs = [\u0026quot;eat\u0026quot;, \u0026quot;tea\u0026quot;, \u0026quot;tan\u0026quot;, \u0026quot;ate\u0026quot;, \u0026quot;nat\u0026quot;, \u0026quot;bat\u0026quot;] 输出: [[\u0026ldquo;bat\u0026rdquo;],[\u0026ldquo;nat\u0026rdquo;,\u0026ldquo;tan\u0026rdquo;],[\u0026ldquo;ate\u0026rdquo;,\u0026ldquo;eat\u0026rdquo;,\u0026ldquo;tea\u0026rdquo;]]\n示例 2:\n输入: strs = [\u0026quot;\u0026quot;] 输出: [[\u0026quot;\u0026quot;]]\n示例 3:\n输入: strs = [\u0026quot;a\u0026quot;] 输出: [[\u0026ldquo;a\u0026rdquo;]]\n题意就是一个单词里面所有字母都相同的就是字母异位词\n解法: 题目要求返回格式是List\u0026lt;List\u0026gt;,那么每个字母异位词都要放入List里面\n可以通过给字符串排序,然后判断这个字符串是否和其他字符串相等来判断字母异位词\n可以使用Char[] arr=string.toCharArray();函数来将String转为Char[]类型,然后用Arrays.sort()进行排序.\n互相比较很麻烦,所以我们使用HashMap数据结构\nMap\u0026lt;String,List\u0026gt;\n其中String是排完序后的Char[]转为的String,用String str=new String(arr);来获取\n如果有这个key,就直接在map.get(key)里面add(str)\n如果没有这个key,就新建一个List,一定要加入排序好的str\n最后return的时候要遍历map获取所有List\n使用for-each\n1 2 3 4 5 List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(List\u0026lt;String\u0026gt; list:map.values()){ ans.add(list); } return ans; 完整版代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Solution { public List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; groupAnagrams(String[] strs) { Map\u0026lt;String,List\u0026lt;String\u0026gt;\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;strs.length;i++){ String string=strs[i]; char[] arr=string.toCharArray(); Arrays.sort(arr); String str=new String(arr); if(map.containsKey(str)){ map.get(str).add(string); }else{ List\u0026lt;String\u0026gt; list=new ArrayList\u0026lt;\u0026gt;(); list.add(string); map.put(str,list); } } List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (List\u0026lt;String\u0026gt; list : map.values()) { result.add(list); } return result; } } ","date":"2025-06-06T10:06:50+08:00","permalink":"https://LuciusWan.github.io/p/leetcode%E5%88%B7%E9%A2%98/","title":"Leetcode刷题"},{"content":"设计模式 OOP七大原则 单一职责原则 每个类最好只有一个任务或职责比如Controller类就负责接收前端请求,然后向Service层请求结果,而不是直接请求Mapper层或者直接处理数据返回.\n开闭原则 对扩展开放，对修改关闭，具体来说是写程序的时候可以多实现接口,让这个接口对应的类有更多功能,而不是删去以前的代码去修改功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 抽象支付接口 interface Payment { void pay(BigDecimal amount); } // 实现类（扩展时新增类即可） @Service class Alipay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;支付宝支付：\u0026#34; + amount); } } @Service class WechatPay implements Payment { @Override public void pay(BigDecimal amount) { System.out.println(\u0026#34;微信支付：\u0026#34; + amount); } } // 控制器（对修改关闭） @RestController class PaymentController { @Autowired private List\u0026lt;Payment\u0026gt; payments; // Spring自动注入所有实现 @PostMapping(\u0026#34;/pay\u0026#34;) public String pay(@RequestParam String type, @RequestParam BigDecimal amount) { payments.stream() .filter(p -\u0026gt; p.getClass().getSimpleName() .equalsIgnoreCase(type + \u0026#34;Pay\u0026#34;)) .findFirst() .ifPresent(p -\u0026gt; p.pay(amount)); return \u0026#34;success\u0026#34;; } } 依赖倒置原则 依赖抽象而非实现，多定义很多层接口,最后再对接口进行实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 抽象层 interface UserRepository { User findById(Long id); } // 高层模块 @Service class UserService { private final UserRepository repository; // 依赖抽象 @Autowired public UserService(UserRepository repository) { this.repository = repository; } public User getUser(Long id) { return repository.findById(id); } } // 低层实现（可以是MySQL/MongoDB等） @Repository class JpaUserRepository implements UserRepository { @Override public User findById(Long id) { // 实际数据库操作 } } 它不关心具体的数据来源是 MySQL、MongoDB 还是其他方式，只依赖于接口，上层接口只关心数据。 合成复用原则 类最好要组合使用,而不是继承添加特性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 错误示范：用继承获取日志能力 class OrderService extends LoggingUtil { ... } // 正确示范：通过组合引入能力 @Service class OrderService { private final LoggingUtil logger; // 组合 @Autowired public OrderService(LoggingUtil logger) { this.logger = logger; } public void createOrder() { logger.log(\u0026#34;创建订单\u0026#34;); // 业务逻辑 } } SpringBoot项目中,多使用@Autowired,组合不同的类,让类之间共享方法\n口隔离原则 不应强迫客户端依赖于它们不使用的接口。换句话说，一个类应该只提供给其他类它实际需要的方法，而不是所有可能的方法。\n迪米特法则 也被称为最少知识原则，表明一个对象应该尽可能少地了解其他对象。每个单元对于其他的单元只能拥有最少的知识，并且仅仅与那些与之紧密相关的单元进行交互。\n比如有Mapper,Service,Controller三层架构,此时我们最好让他们之间一层一层通信,而不是Controller直接去找Mapper层找数据输出.\n里氏替换原则 在继承父类的时候最好不要修改父类的方法,可以扩展方法,这样在要使用父类的时候,可以用子类替代.\n单例模式 饿汉式单例模式 在项目启动的时候创建出的单例对象的行为就是饿汉式单例模式,比如下列代码\n1 2 3 4 5 6 7 8 9 public class Singleton { private static final Singleton INSTANCE = new Singleton(); private Singleton() {} public static Singleton getInstance() { return INSTANCE; } } static表示是静态资源,存在与静态资源池里面,final表示这个对象不会再被改变了,因此对象在启动的时候就创建好了.\nSpring容器创建的Bean对象默认就是饿汉式单例模式,通过@Autowired实现控制反转与依赖注入.\n优点：\n实现简单，代码清晰。 线程安全。 缺点：\n无论是否使用，都会在类加载时创建实例，可能浪费资源。\n懒汉式单例模式 懒汉式单例模式是指单例对象在需要使用的时候才会创建,样例代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 这种情况下可能导致线程安全问题,高并发的时候并不能保证单例,因此要在创建对象的时候加上锁\n1 2 3 4 5 6 7 8 9 10 11 12 public class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 工厂模式 简单工厂 简单工厂创建对象的时候要考虑对象的类型,然后用if-else语句来判断是要创建哪个对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 工厂类 public class ShapeFactory { // 根据传入的类型创建对应的对象 public Shape getShape(String shapeType) { if (shapeType == null || shapeType.isEmpty()) { return null; } if (shapeType.equalsIgnoreCase(\u0026#34;CIRCLE\u0026#34;)) { return new Circle(); } else if (shapeType.equalsIgnoreCase(\u0026#34;SQUARE\u0026#34;)) { return new Square(); } else if (shapeType.equalsIgnoreCase(\u0026#34;RECTANGLE\u0026#34;)) { return new Rectangle(); } return null; } } 这样局限性还是很高,判断很多if else语句也会导致代码效率不高\n工厂方法模式 一个类只负责创建一种产品，通过继承和多态性，可以方便地扩展新的产品类型。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // 定义产品接口 public interface Product { void use(); } // 具体产品A public class ConcreteProductA implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品A\u0026#34;); } } // 具体产品B public class ConcreteProductB implements Product { @Override public void use() { System.out.println(\u0026#34;使用产品B\u0026#34;); } } // 抽象工厂接口 public abstract class Creator { // 工厂方法，由子类实现 public abstract Product factoryMethod(); } // 具体工厂A public class ConcreteCreatorA extends Creator { @Override public Product factoryMethod() { return new ConcreteProductA(); } } // 具体工厂B public class ConcreteCreatorB extends Creator { @Override public Product factoryMethod() { return new ConcreteProductB(); } } // 测试类 public class FactoryMethodTest { public static void main(String[] args) { // 使用具体工厂A创建产品A Creator creatorA = new ConcreteCreatorA(); Product productA = creatorA.factoryMethod(); productA.use(); // 使用具体工厂B创建产品B Creator creatorB = new ConcreteCreatorB(); Product productB = creatorB.factoryMethod(); productB.use(); } } 一个工厂只负责创建一种对象\n抽象工厂 抽象工厂模式提供了一组用于创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。能够创建一系列相关的对象，而不是单一的产品。\n代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 // 定义产品族接口 public interface AbstractProductA { void useA(); } public interface AbstractProductB { void useB(); } // 具体产品A1 public class ConcreteProductA1 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A1\u0026#34;); } } // 具体产品A2 public class ConcreteProductA2 implements AbstractProductA { @Override public void useA() { System.out.println(\u0026#34;使用产品A2\u0026#34;); } } // 具体产品B1 public class ConcreteProductB1 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B1\u0026#34;); } } // 具体产品B2 public class ConcreteProductB2 implements AbstractProductB { @Override public void useB() { System.out.println(\u0026#34;使用产品B2\u0026#34;); } } // 抽象工厂接口 public interface AbstractFactory { AbstractProductA createProductA(); AbstractProductB createProductB(); } // 具体工厂1 public class ConcreteFactory1 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA1(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB1(); } } // 具体工厂2 public class ConcreteFactory2 implements AbstractFactory { @Override public AbstractProductA createProductA() { return new ConcreteProductA2(); } @Override public AbstractProductB createProductB() { return new ConcreteProductB2(); } } // 测试类 public class AbstractFactoryTest { public static void main(String[] args) { // 使用具体工厂1创建产品族1 AbstractFactory factory1 = new ConcreteFactory1(); AbstractProductA productA1 = factory1.createProductA(); AbstractProductB productB1 = factory1.createProductB(); productA1.useA(); productB1.useB(); // 使用具体工厂2创建产品族2 AbstractFactory factory2 = new ConcreteFactory2(); AbstractProductA productA2 = factory2.createProductA(); AbstractProductB productB2 = factory2.createProductB(); productA2.useA(); productB2.useB(); } } 每个具体工厂可以创建不同的对象\n在Spring中,配置类就使用了工厂模式\n1 2 3 4 5 6 7 8 9 @Bean public ChatClient DesignPattern(OpenAiChatModel model, ChatMemory chatMemory) { return ChatClient.builder(model) .defaultSystem(AIConstant.DESIGN_PATTERN) .defaultAdvisors( new MessageChatMemoryAdvisor(chatMemory), new SimpleLoggerAdvisor()) .build(); } 而一个配置类里面有多个@Bean注解下的工厂方法,可以实现抽象工厂和工厂方法模式\n","date":"2025-05-16T20:56:35+08:00","permalink":"https://LuciusWan.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"设计模式"},{"content":"Redis高级篇 Redis持久化 RDB(RedisDatabase) RDB 会在指定的时间间隔（比如每 5 分钟）对 Redis 的内存数据进行一次“拍照”，生成一个二进制文件（dump.rdb）。这个文件可以自己设置名称,默认为dump.rdb.这个文件包含了当时的所有数据状态。\n如果 Redis 崩溃了，重启时会加载最近的dump.rdb来恢复数据。\n如果使用命令save可以直接保存rdb文件\n每次启动Redis的时候Redis就会访问这个rdb文件来获取以前的数据\n每次关闭Redis服务端的时候都会生成一个新的dump.rdb\n文件就在这里\n如果只是关机的时候使用,万一什么时候Redis宕机了,就无法恢复数据了,这时候得用间隔保存了,这时候只需要打开Redis配置文件,修改如下字段\n# save \u0026quot;\u0026quot;表示注释掉了 Redis 的默认 RDB 持久化策略（即禁用默认的自动快照生成）。\n下面的意思是900秒内有1次操作就保存一次,300秒内10次操作就自动保存一次,60秒内有10000次操作就保存一次.\nfork 子进程：Redis 调用 fork() 创建一个子进程，子进程与主进程共享内存数据。\nCOW（Copy-On-Write）：\n子进程开始快照操作时，主进程仍可处理客户端请求并修改数据。 当主进程修改某个数据页时，操作系统会将该页复制一份（写时复制），子进程看到的仍是修改前的数据。 子进程将所有数据页写入磁盘生成 .rdb 文件，而主进程不影响快照的一致性。 COW有缺点就是,如果我的Redis已经占用了很高的内存,此时我要修改的数据也很多,复制的数据非常多会导致内存溢出\n并且修改次数多,导致复制次数也多,开销也很大\n修改次数少的时候如果宕机就会导致大部分数据丢失\nAOF（Append-Only File） AOF则是记录每一次操作Redis的命令,把命令记录在磁盘中,如果后面需要恢复就再执行一次所有Redis命令,下面的就是AOF文件\n只有修改了redis.conf中的如下文件后才能使用\n有如下三种记录频率\n第一个是每写一次命令,执行完后就写入磁盘,然后返回信息,这样就很慢了,和直接操作数据库没有区别,第二个方法是隔了一秒后进行,实现了异步处理,顶多丢失1秒的数据,最后一种由操作系统判断什么时候写回磁盘,推荐使用第二种.\n下面是AOF文件中的内容\n如果我写三个如下命令\n1 2 3 4 5 6 127.0.0.1:6379\u0026gt; set name111 dinglz OK 127.0.0.1:6379\u0026gt; set name111 wfg OK 127.0.0.1:6379\u0026gt; set name111 666 OK 这样直接写入aof文件会比较占内存,可以使用如下命令来重写AOF文件\n1 BGREWRITEAOF 重写后的文件如下\n直接就看不懂了,但是这样确实简化了AOF文件,不用连续设置三次才得到最终数据.\n1 2 3 127.0.0.1:6379\u0026gt; bgrewriteaof Background append only file rewriting started 127.0.0.1:6379\u0026gt; 可以看到这个命令甚至是在后台执行的\n通常情况下是两种持久化机制一起使用,可以保证数据的稳定性\nRedis主从同步 主从同步示例要三个Redis,我们可以使用windows本地复制三个Redis文件,然后修改配置文件,端口号6379,6380,6381,或者直接用docker,pull下redis的最新版本,然后创建三个实例.\n分别启动三个Redis的服务端,然后再Redis-cli的6380上输入如下名令\n1 slaveof 127.0.0.1 6379 意思是Redis6380要成为6379的从节点\n也可以使用如下命令\n1 replicaof 127.0.0.1 6379 这时候6380就是6379的从节点了\n当我们在6379上使用set命令\n1 2 3 127.0.0.1:6379\u0026gt; set number 111 OK 127.0.0.1:6379\u0026gt; 那么从节点上也可以看到被修改了\n1 2 3 4 5 6 ~ .\\redis-cli.exe -p 6381 -h localhost localhost:6381\u0026gt; replicaof localhost 6379 OK localhost:6381\u0026gt; get number \u0026#34;111\u0026#34; localhost:6381\u0026gt; 这就实现了主从同步\n全量同步 在我们输入slaveof host port之后,slave向master发送了自己的replid和offset,id和master肯定不一样,这时候就告知master这时候得做全量同步,清空slave本地缓存,把master生成的RDB发给slave进行数据同步.\n并且在建立主从关系后,master会把自己的命令都交给slave去做数据同步,增量同步.\n增量同步 repl_baklog是记录了RDB期间的所有命令的一个文件,是环状读写的,每次做增量同步的时候slave都会发送自己的offset,master在自己的repl_baklog表中查找offset,如果找到的话就把offset后面的数据交给master.下图红绿交接就是offset\n如果slave宕机了,而且时间还挺长,master写repl_baklog文件已经覆盖了offset,那此时只能做一个全量同步.\n可以从以下几个方面来优化Redis主从就集群:\n在master中配置repl-diskless-syncyes启用无磁盘复制，避免全量同步时的磁盘IO。\nRedis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO\n适当提高repl baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力,可以直接从其他slave上直接读取数据,而不是都找master\n哨兵模式 哨兵的工作原理 Redis的哨兵（Sentinel）是一个监控和故障转移系统，用于管理Redis主从复制架构中的高可用性。它在Redis 2.8版本中被引入，主要目的是解决当主节点出现故障时，如何自动完成故障发现和故障转移的问题。以下是关于Redis哨兵的一些\n哨兵每一秒广播发送一次ping命令,告诉所有节点,自己没有宕机\n如果某个节点在指定时间内没有响应，则会被标记为“主观下线”。如果主节点被标记为主观下线，哨兵会询问其他哨兵实例，根据多数哨兵的意见决定是否将其标记为“客观下线”。\n客观下线后就会触发主从交换,选出一个offset最大的slave,向其发送slaveof no one,让其成为master节点,然后强制修改原主节点的配置文件,让那个redis slave of新的master,然后让所有节点都执行slaveof新master.\n","date":"2025-05-13T20:22:24+08:00","permalink":"https://LuciusWan.github.io/p/redis%E9%AB%98%E7%BA%A7%E7%AF%87/","title":"Redis高级篇"},{"content":"Docker初体验 Docker 是什么 Docker 是一个应用打包、分发、部署的工具\n你也可以把它理解为一个轻量的虚拟机，它只虚拟你软件需要的运行环境，多余的一点都不要，\n而普通虚拟机则是一个完整而庞大的系统，包含各种不管你要不要的软件。\n跟普通虚拟机的对比 特性 普通虚拟机 Docker 跨平台 通常只能在桌面级系统运行，例如 Windows/Mac，无法在不带图形界面的服务器上运行 支持的系统非常多，各类 windows 和 Linux 都支持 性能 性能损耗大，内存占用高，因为是把整个完整系统都虚拟出来了 性能好，只虚拟软件所需运行环境，最大化减少没用的配置 自动化 需要手动安装所有东西 一个命令就可以自动部署好所需环境 稳定性 稳定性不高，不同系统差异大 稳定性好，不同系统都一样部署方式 打包、分发、部署 打包：就是把你软件运行所需的依赖、第三方库、软件打包到一起，变成一个安装包\n分发：你可以把你打包好的“安装包”上传到一个镜像仓库，其他人可以非常方便的获取和安装\n部署：拿着“安装包”就可以一个命令运行起来你的应用，自动模拟出一模一样的运行环境，不管是在 Windows/Mac/Linux。\n下载\u0026amp;安装docker 下面是桌面版链接,点击下载\nhttps://www.docker.com/products/docker-desktop\n推荐下载这个\n下载完后是个exe文件,点开后开始安装\n我们在安装完成后可能会遇到这个报错\n这是因为我们没开启虚拟化,如果你下载过Linux虚拟机应该就不会有这个错误,同时我们还要下载Linux子系统,跟着引导来就好\n解决方法：\n控制面板-\u0026gt;程序-\u0026gt;启用或关闭 windows 功能，开启 Windows 虚拟化和 Linux 子系统（WSL2)\n要确定BIOS支持虚拟化\n添加镜像源 我们如果每次都到docker官方去获取镜像,那么没有魔法就会非常慢,所以我们可以添加镜像源\n可用的国内镜像源如下.可以添加多个镜像源\n镜像加速器 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://ud6340vz.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 用docker安装软件 我们可以下载个redis玩玩\n下载Redis镜像 打开命令提示符（CMD）或PowerShell，然后使用以下命令从Docker Hub下载官方的Redis镜像：\n1 docker pull redis 这将下载最新版本的Redis镜像。你也可以指定版本号来下载特定版本的Redis镜像，例如：\n1 docker pull redis:latest 运行Redis容器 下载完成后，你可以使用以下命令来启动一个Redis容器：\n1 docker run --name my-redis -d -p 6379:6379 redis 这里的参数解释如下：\n--name my-redis：为容器指定一个名称，这里是my-redis。 -d：表示以分离模式运行容器,在后台运行。 -p 6379:6379：将容器的6379端口映射到宿主机的6379端口，这样你就可以通过宿主机的6379端口访问Redis服务。 验证Redis服务 为了验证Redis服务是否正常运行，你可以使用以下命令连接到Redis容器：\n1 docker exec -it my-redis redis-cli 这将打开一个Redis命令行接口。你可以在这里输入Redis命令来测试服务，例如：\n1 ping 如果服务正常运行，你应该看到输出PONG。\n我们可以在docker的终端上打开redis并使用 停止和删除容器 当你完成测试并想要停止Redis容器时，可以使用以下命令：\n1 docker stop my-redis 要删除容器，可以使用：\n1 docker rm my-redis 如果你想要强制删除正在运行的容器，可以添加-f参数：\n1 docker rm -f my-redis 配置Redis密码（可选） 如果你需要为Redis设置密码，可以在运行容器时通过环境变量REDIS_PASSWORD来设置。例如：\n1 docker run --name my-redis -d -p 6379:6379 -e REDIS_PASSWORD=mypassword redis redis-server --requirepass mypassword 这将设置Redis的密码为mypassword。之后，你需要使用这个密码来连接到Redis服务。\n制作自己的镜像 我们可以把自己的项目打包成一个镜像,让这个镜像在别的电脑上不配环境就能跑起来\n下面是springboot项目的制作镜像案例\n在制作镜像的时候,我们要先写一个dockerfile,这个dockerfile怎么写可以直接问AI\nSpringBoot的dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 使用官方的 OpenJDK 作为基础镜像,写清楚你的jdk版本 FROM openjdk:17-jdk-alpine # 设置工作目录 WORKDIR /app # 将构建好的 JAR 文件复制到镜像中 COPY target/你的jar包的名字.jar /app/app.jar # 暴露应用运行的端口（例如 Spring Boot 默认的 8080 端口） EXPOSE 8083 # 设置容器启动时运行的命令 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;] 这个文件就跟src和pom.xml坐一桌(放一块)就行了\n然后我们就可以通过下面的命令来制作这个docker镜像\n1 docker build -t test:v1 . test是镜像的名称,v1是版本号\n然后我们可以在本地跑一下这个镜像\n1 docker run -p 8083:8083 --name test-hello test:v1 \u0026ndash;name test-hello指的是容器的名称是test-hello,后面跟的是要跑的是什么镜像的什么版本\n多容器通信 多容器通信的意义 在Docker中，多容器通信是指多个容器之间能够相互发现并进行数据交换的能力。\n这种通信机制在构建微服务架构和分布式应用时尤为重要，因为它允许不同服务之间高效地协作。\nDocker提供了多种网络模式来实现容器间的通信，包括桥接网络（Bridge）、主机网络（Host）、覆盖网络（Overlay）以及Macvlan网络等。\n在本地,我们通过本地回环的测试网络localhost127.0.0.1来相互通信,前端代码,后端代码,中间件,数据库等都通过127.0.0.1通信,而我们在docker部署多个容器并没有这样一个网络实现容器间通信,这时候就要用这样个网络.\n上面三种网络形式挺麻烦的,我们直接用docker-compose.yml,当容器多了,这种方法的好处就体现出来了. 举个例子 我的这个项目要用到3个redis,还有rabbitmq,下面这个是我的docker-compose.yml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 services: springboot-app: image: test:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: YourUserName RABBITMQ_DEFAULT_PASS: YourPassword #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network networks: my-network: 我们的这个网络就叫my-network,然后所有的容器都配置在这一个文件中,我们只需要在项目目录里面加上这个yml文件就可以准备启动整个项目了\n在这里打开终端,然后输入如下命令\n1 docker-compose up -d 然后项目就启动了\n这样可以方便快捷的实现容器间的通信互联\n容器的通信路由 我们的容器现在都在一个网络下了,我们要通过域名来访问对应的容器\n比如我这个java代码,这是Redisson的配置代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package com.hmdp.config; import ... @Configuration public class RedissonConfig { @Autowired private RedisProperties redisProperties; @Bean public RedissonClient redisson6379() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis1:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6380() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis2:6379\u0026#34;); return Redisson.create(config); } @Bean public RedissonClient redisson6381() { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://redis3:6379\u0026#34;); return Redisson.create(config); } } ip地址localhost改写为容器的名称,也就是容器的域名\n后面的端口一定要是镜像暴露出来的端口,redis暴露出来的就是6379端口\nrabbitmq的配置也要改\n1 2 3 4 5 6 rabbitmq: host: rabbitmq port: 5672 username: YourUserName password: YourPassword virtual-host: / host要改为容器名称.\nDocker部署MySQL 修改docker-compose.yml 想要在docker上部署MySQL,先要关掉MySQL的本地服务,可以直接在任务管理器里找mysql,然后关闭这个任务即可.\n然后修改docker-compose.yml，加上这个即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: YourDataBaseName #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network 1 2 volumes: - ./mysql/data:/var/lib/mysql 这个语句的意思是挂载目录\n挂载目录 在使用 Docker 部署 MySQL 时，挂载目录（通常使用 Docker 的 volume 功能）主要有以下几个目的：\n1. 数据持久化 背景：Docker 容器是无状态的，当容器被删除或重新启动时，容器内部的数据（如 MySQL 数据库文件）会丢失。\n解决方案：通过挂载宿主机的目录到容器内部，可以将 MySQL 的数据文件存储在宿主机上。这样，即使容器被删除或重新启动，数据仍然可以被保留。\n2 . 方便数据迁移 背景：当需要将数据库从一个环境迁移到另一个环境时，数据的迁移是一个关键步骤。\n解决方案：通过挂载目录，可以直接将宿主机上的数据目录复制到新的宿主机上，然后启动新的 MySQL 容器，从而实现数据的迁移。\n示例：\n1 2 # 将数据目录从旧宿主机复制到新宿主机 scp -r /path/to/mysql-data user@new-host:/path/to/mysql-data 具体就是这个语句让我本地建了个文件夹，实现了持久化存储\n然后我们在终端上登录mysql,使用对应的数据库,然后把表数据填进去就可以再次启动容器了\n实现多端负载均衡 我的这个项目是开了8083和8084端口同时接受前端请求,用nginx实现负载均衡,目前只开放了8083端口,修改docker-compose.yml即可\n修改docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network 加入这个语句即可,启动后就实现了多端口接收数据\n发布Docker镜像 镜像仓库介绍 镜像仓库用来存储我们 build 出来的“安装包”，Docker 官方提供了一个 镜像库，里面包含了大量镜像，基本各种软件所需依赖都有，要什么直接上去搜索。\n我们也可以把自己 build 出来的镜像上传到 docker 提供的镜像库中，方便传播。\n当然你也可以搭建自己的私有镜像库，或者使用国内各种大厂提供的镜像托管服务，例如：阿里云、腾讯云\n上传镜像 首先要 注册一个账号 创建一个镜像库 然后在命令行中登录一下\n注意:这里登录只能是小写字母,之前写的大写字母username也得转为小写\n新建一个tag，名字必须跟你注册账号一样 1 docker tag test:v1 username/test:v1 推上去 1 docker push username/test:v1 然后我们可以随便新建一个文件夹,修改一下docker-compose.yml文件,然后粘过来\n修改docker-compose.yml文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: luciuswan/hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8084:8083\u0026#34; # 映射 8084 端口到容器的 8083 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP 协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ networks: - my-network mysql: image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: driver: bridge 主要是修改这个image\n1 image: luciuswan/hmdp:v1 docker,启动! 然后在这里启动powershell,输入命令即可运行项目\n1 docker-compose -p hmdp up -d 如果直接输入docker-compose -d,会提示你没有容器名称\n正常输入的话,我们的项目就跑起来了\n这时候还跑不了,因为数据没有迁移\nDocker数据迁移 部署的时候每次都得重新建数据库,建表,这样并没有提现到docker的方便部署,我们可以通过docker指令来复制docker中的mysql数据库,然后复制到宿主机,也就是windows本地,然后把这个文件送到别的宿主机\n1. 备份旧容器的数据 在旧容器中，使用mysqldump工具备份数据库。\n步骤： 进入旧MySQL容器：\n1 docker exec -it \u0026lt;旧容器名称或ID\u0026gt; bash 备份所有数据库：\n1 mysqldump -u root -p --all-databases \u0026gt; /backup_all_databases.sql 如果只需要备份特定数据库，可以指定数据库名称：\n1 mysqldump -u root -p your_database_name \u0026gt; /backup_your_database.sql 将备份文件从旧容器复制到宿主机：\n1 docker cp \u0026lt;旧容器名称或ID\u0026gt;:/backup_all_databases.sql ./backup_all_databases.sql 效果如下图\n2. 将备份文件上传到新机器 将备份文件（如backup_all_databases.sql）上传到目标机器上。可以使用文件传输工具（如SCP、FTP、WinSCP等）。\n我是直接上传到云服务器了\n3. 在新机器上使用docker-compose部署MySQL 确保你的docker-compose.yml文件正确配置，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 services: springboot-app: image: hmdp:v1 # 替换为你的 Spring Boot 应用镜像 ports: - \u0026#34;8083:8083\u0026#34; # 假设 Spring Boot 应用运行在 8080 端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network springboot-app-2: image: hmdp:v1 ports: - \u0026#34;8084:8083\u0026#34; # 映射8084端口到容器的8080端口 depends_on: - redis1 - redis2 - redis3 - rabbitmq - mysql networks: - my-network redis1: image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; # 映射 6379 端口 networks: - my-network redis2: image: redis:latest ports: - \u0026#34;6380:6379\u0026#34; # 映射 6380 端口 networks: - my-network redis3: image: redis:latest ports: - \u0026#34;6381:6379\u0026#34; # 映射 6381 端口 networks: - my-network rabbitmq: image: rabbitmq:3.12-management ports: - \u0026#34;5672:5672\u0026#34; # AMQP协议端口 - \u0026#34;15672:15672\u0026#34; # 管理界面端口 environment: RABBITMQ_DEFAULT_USER: LuciusWan RABBITMQ_DEFAULT_PASS: Wwwaxk12345@ #volumes: # - ./rabbitmq/data:/var/lib/rabbitmq networks: - my-network mysql: image: mysql:8.0 container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: hmdp #MYSQL_USER: your_username #MYSQL_PASSWORD: your_password volumes: - ./mysql/data:/var/lib/mysql networks: - my-network networks: my-network: 运行以下命令启动服务：\n1 docker-compose -p hmdp up -d 在宝塔面板里面进入包含这个yml文件的文件夹中\n1 2 3 4 cd /www cd wwwroot cd hmdp docker-compose -p hmdp up -d 这样,容器就在新的宿主机启动了\n4. 将备份数据恢复到新容器 将备份文件复制到新容器：\n1 docker cp ./backup_all_databases.sql mysql-container:/backup_all_databases.sql 进入新容器并恢复数据：\n1 docker exec -it mysql-container bash 在容器内部，运行以下命令恢复数据：\n1 mysql -u root -p \u0026lt; /backup_all_databases.sql 输入root用户的密码后，数据将被恢复到新容器中。\n然后我们的数据就同步在新的宿主机了\n5. 验证数据 在新容器中登录MySQL，检查数据是否正确恢复：\n1 docker exec -it mysql-container mysql -u root -p 输入密码后，执行以下命令查看数据库列表：\n1 SHOW DATABASES; 确保你的数据库和数据已经正确恢复。\n然后项目就可以正常跑起来了,如果遇到java代码无法连接MySQL,并且原因是MySQL不支持publicKey,可以在配置MySQL连接方式处这么修改\n然后我们这个项目在哪里跑都一样了\n","date":"2025-04-08T14:25:17+08:00","permalink":"https://LuciusWan.github.io/p/docker%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"Docker初体验"},{"content":"Linux实战 OpenEuler安装 可以参考这个up主的视频 B站视频链接 下载VirtualBox虚拟机 在浏览器官网搜索virtualBox官网Oracle VirtualBox然后直接下载即可\n打开VirtualBox后发现并没有操作系统(),那么我们就再去浏览器下载openEuler操作系统\n下载OpenEuler操作系统 在浏览器上搜索OpenEuler社区openEuler | 开源社区 | openEuler社区官网\n点开后找到Offline Everything ISO，下载就好了\n事实上并没有删除()\n在VirtualBox中加载OpenEuler 点击注册,然后按照下图配置\n然后新建虚拟电脑的时候配置一下\n全都配置好就可以使用了\n注意!!!一定要记住自己的root密码 OpenEuler实践报告 一、实验环境 操作系统：OpenEuler（通过VirtualBox虚拟机运行） 编译器：GCC 二、作业要求的代码 例1：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { fork(); fork(); fork(); printf(\u0026#34;hello\\n\u0026#34;); return 0; } 例2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { int x = 1; pid_t p = fork(); if(p \u0026lt; 0){ perror(\u0026#34;fork fail\u0026#34;); exit(1); } else if (p == 0) printf(\u0026#34;Child has x = %d\\n\u0026#34;, ++x); else printf(\u0026#34;Parent has x = %d\\n\u0026#34;, --x); return 0; } 例题一操作 创建文件并输入代码：\n1 vim example1.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example1.c -o example1 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example1 观察输出结果。\n运行结果及分析 例1运行结果：\n1 2 3 4 5 6 7 8 hello hello hello hello hello hello hello hello 例一分析： 每次fork()调用都会创建一个新的进程，三次fork()会创建8个进程（2^3），每个进程都会执行printf(\u0026quot;hello\\n\u0026quot;);，所以输出8次\u0026quot;hello\u0026quot;。\n例题二操作 创建文件并输入代码：\n1 vim example2.c 将例1的代码复制到文件中，保存并退出。\n编译代码：\n1 gcc example2.c -o example2 如果没有错误，将生成可执行文件example1。\n运行程序：\n1 ./example2 观察输出结果。\n运行结果及分析 例2运行结果：\n例二分析：\n父进程和子进程各自拥有变量x的独立副本。 子进程中x的值被递增（++x），所以输出2。 父进程中x的值被递减（--x），所以输出0。 五、总结 通过本次实践，我掌握了在Linux环境下使用GCC编译C代码的基本流程，理解了fork()系统调用的原理和用法，以及进程控制的基本概念。同时，也熟悉了在OpenEuler操作系统下的开发环境和工具的使用。\nHW3-多线程-git 1. 编写和编译多线程代码 1.1 创建代码文件 在Linux命令行中，使用vi或nano编辑器创建一个名为pthread_hello.c的文件：\n1 vi pthread_hello.c 编写如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; /* Thread function that prints \u0026#34;Hello World\u0026#34; */ void *worker(void *arg) { printf(\u0026#34;Hello World!\\n\u0026#34;); return NULL; /* Thread exits (dies) */ } int main() { pthread_t thread; int ret; /* Create a new thread */ ret = pthread_create(\u0026amp;thread, NULL, worker, NULL); if (ret != 0) { perror(\u0026#34;pthread_create failed\u0026#34;); return 1; } /* Wait for the thread to finish */ pthread_join(thread, NULL); return 0; } 1.2 编译代码 使用gcc编译代码，并链接pthread库：\n1 gcc pthread_hello.c -o pthread_hello -lpthread 1.3 运行程序 运行编译后的程序：\n1 ./pthread_hello 输出结果为：\nHello World!\n2. 使用Git管理项目 2.1 创建项目目录 在主目录下创建一个名为os_practice的项目目录：\n1 2 mkdir os_practice cd os_practice 2.2 初始化Git仓库 初始化Git仓库：\n1 git init 2.3 创建子目录 为每次的实践创建单独的子目录，例如：\n1 2 mkdir hw1 cd hw1 将pthread_hello.c文件复制到该目录下：\n1 cp ~/pthread_hello.c . 2.4 添加文件到Git 将文件添加到Git仓库：\n1 git add pthread_hello.c 2.5 提交更改 提交更改并添加描述信息：\n1 git commit -m \u0026#34;Added pthread Hello World example\u0026#34; 2.6 检查Git状态 检查当前Git仓库的状态：\n1 git status 提交代码至github 在github中注册好之后,创建代码仓库 创建好之后,使用github给的bash代码 1 2 3 4 5 6 7 echo \u0026#34;# OS-HomeWork\u0026#34; \u0026gt;\u0026gt; README.md git init git add README.md git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/LuciusWan/OS-HomeWork.git git push -u origin main 然后本地仓库就和github连上了.\n我们可以在本地编译,提交代码至github仓库\n分别使用下面bash语句\n1 2 3 git add . git commit -m \u0026#34;update\u0026#34; git push git add .\n将当前工作区中的所有更改（包括新文件、修改的文件和删除的文件）添加到 Git 的暂存区\ngit commit -m \u0026ldquo;update\u0026rdquo;\n将暂存区中的更改正式提交到本地仓库，并添加一条提交信息。\n提交（commit）是 Git 的一个快照，记录了当前暂存区中的所有更改。\n-m \u0026quot;update\u0026quot; 是提交信息，用来描述这次提交的内容或目的。\n提交信息是可选的，但强烈建议添加，以便以后能够清楚地了解每次提交的更改内容。\ngit push\n很好理解,把本地仓库修改内容和修改信息一并推送到远程仓库\n提交后,我们的仓库就会发生变化 OS第一次上机课 作业内容如下\n任务二 编写nosync-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) sum += 1; } int main(void) { pthread_t tid1, tid2; pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下不上锁,线程之间互相抢资源,导致线程错误,最终结果错误\n结果如下:\n1 2 3 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim nosync-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc nosync-ex.c -o nosync-exadmin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./nosync-ex 1000000 + 1000000 = 1172208 编写mutex-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int sum = 0; pthread_mutex_t mutex; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { pthread_mutex_lock(\u0026amp;mutex); sum += 1; pthread_mutex_unlock(\u0026amp;mutex); } } int main(void) { pthread_t tid1, tid2; pthread_mutex_init(\u0026amp;mutex, NULL); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 这种情况下可以上锁,线程之间只能有一个能使用锁资源,保证了线程安全,结果正确\n结果如下\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim mutex-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc mutex-ex.c -o mutex-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./mutex-ex 1000000 + 1000000 = 2000000 编写sem-ex.c文件 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; int sum = 0; sem_t sem; void *thread(void*) { int i; for (i = 0; i \u0026lt; 1000000; i++) { sem_wait(\u0026amp;sem); sum += 1; sem_post(\u0026amp;sem); } } int main(void) { pthread_t tid1, tid2; sem_init(\u0026amp;sem, 0, 1); pthread_create(\u0026amp;tid1, NULL, thread, NULL); pthread_create(\u0026amp;tid2, NULL, thread, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(\u0026#34;1000000 + 1000000 = %d\\n\u0026#34;, sum); return (0); } 信号量可以通过其操作原语（如 sem_wait() 和 sem_post()）实现互斥访问,这里使用了信号量保证了线程安全,结果正确\n1 2 3 4 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ vim sem-ex.c admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc sem-ex.c -o sem-ex admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./sem-ex 1000000 + 1000000 = 2000000 任务三 编写生产者消费者问题 生产者消费者问题是一个消息队列,实现了异步处理,可以达到削峰填谷的作用\n代码实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define BUFFER_SIZE 5 #define NUM_ITEMS 10 int buffer[BUFFER_SIZE]; int count = 0; // 当前缓冲区中的元素数量 int in = 0, out = 0; pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t full = PTHREAD_COND_INITIALIZER; pthread_cond_t empty = PTHREAD_COND_INITIALIZER; void* producer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == BUFFER_SIZE) { pthread_cond_wait(\u0026amp;full, \u0026amp;mutex); // 等待缓冲区不满 } buffer[in] = i; printf(\u0026#34;Produced: %d at position %d\\n\u0026#34;, i, in); in = (in + 1) % BUFFER_SIZE; count++; pthread_cond_signal(\u0026amp;empty); // 通知消费者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } void* consumer(void* arg) { for (int i = 0; i \u0026lt; NUM_ITEMS; i++) { pthread_mutex_lock(\u0026amp;mutex); while (count == 0) { pthread_cond_wait(\u0026amp;empty, \u0026amp;mutex); // 等待缓冲区不空 } int item = buffer[out]; printf(\u0026#34;Consumed: %d from position %d\\n\u0026#34;, item, out); out = (out + 1) % BUFFER_SIZE; count--; pthread_cond_signal(\u0026amp;full); // 通知生产者 pthread_mutex_unlock(\u0026amp;mutex); } return NULL; } int main() { pthread_t prod, cons; pthread_create(\u0026amp;prod, NULL, producer, NULL); pthread_create(\u0026amp;cons, NULL, consumer, NULL); pthread_join(prod, NULL); pthread_join(cons, NULL); return 0; } 运行结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ gcc MesssageQueue.c -o MessageQueue admin01@admin01-VirtualBox:~/文档/OS-ClassHomework$ ./MessageQueue Produced: 0 at position 0 Produced: 1 at position 1 Produced: 2 at position 2 Produced: 3 at position 3 Produced: 4 at position 4 Consumed: 0 from position 0 Consumed: 1 from position 1 Consumed: 2 from position 2 Consumed: 3 from position 3 Consumed: 4 from position 4 Produced: 5 at position 0 Produced: 6 at position 1 Produced: 7 at position 2 Produced: 8 at position 3 Produced: 9 at position 4 Consumed: 5 from position 0 Consumed: 6 from position 1 Consumed: 7 from position 2 Consumed: 8 from position 3 Consumed: 9 from position 4 消息队列的容量上限为5个item,因此当生产者获取消息队列资源后给这个资源上锁,只有生产者可以向里面写入数据,可以看到从0-4一共五个数被填入消息队列,然后由于队列已满,通知消费者读取数据,消费者读取了0-4的数据后由于消息队列中没有元素,消费者释放锁资源,并且通知生产者可以生产数据,生产者继续生产5-9的数据,队列又满,通知消费者读取,最后完成所有数据的生产消费,进程结束.\nGit提交代码 使用命令,把所有文件提交到工作区\n1 git add . 然后使用命令提交代码\n1 git commit -m \u0026#34;update\u0026#34; 查看提交记录\n1 git log 结果如下\n提交成功\n","date":"2025-03-21T14:01:52+08:00","permalink":"https://LuciusWan.github.io/p/linux%E5%AE%9E%E6%88%98/","title":"Linux实战"},{"content":"JavaWeb 三层解耦 这里会用到面向对象七大原则中的单一职责原则，即每个程序有自己的任务，而不是有很多任务导致单一程序复杂，耦合度高，复用性差\n我们可以将后端划分为三个部分，MVC框架是Controller，View，Model\n而springboot可以划分为Controller，Service，Dao三层，分别为监听层，逻辑处理层，数据管理层，原来复杂的Controller层是这样的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @RestController public class EmpController { String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } });); List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 现在可以使用三层架构来分别放置 Controller，Service，Dao三层\nDao层的接口及实现如下 1 2 3 public interface EmpDao { public List\u0026lt;Emp\u0026gt; listEmp(); } 1 2 3 4 5 6 7 8 9 10 11 public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } Service层的接口及实现如下 1 2 3 public interface EmpService { public List\u0026lt;Emp\u0026gt; list(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.util.List; public class EmpServiceA implements EmpService { private EmpDao empDao=new EmpDaoA(); @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 这里通过创建Dao层对象然后调用其方法来获取数据，但这会让Dao层和Service层紧耦合\nController代码如下 1 2 3 4 5 6 7 8 9 10 @RestController public class EmpController { private EmpServiceA empServiceA =new EmpServiceA(); @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empServiceA.list(); System.out.println(empList); return Result.success(empList); } } 同样的，这里的创建对象也会让Service层和Controller层紧耦合\n我们可以考虑使用设计模式中的工厂模式来解决这个紧耦合办法，但是springboot已经想好了解决对策，那就是\n控制反转与依赖注入 控制反转:Inversion Of control，简称IOC。对象的创建控制权由程序自身转移到外部(容器)，这种思想称为控制反转\n依赖注入: Dependency Injection，简称DI。容器为应用程序提供运行时所依赖的资源，称之为依赖注入。\nBean对象:IOC容器中创建、管理的对象，称之为Bean\n解耦之后的代码演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 //Dao层 @Component public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //加载并解析XML文件 String file= this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; EmpList= XmlParserUtils.parse(file, Emp.class); return EmpList; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //Service层 @Component public class EmpServiceA implements EmpService { @Autowired private EmpDao empDao; @Override public List\u0026lt;Emp\u0026gt; list() { //对数据进行转化处理 List\u0026lt;Emp\u0026gt; empList=empDao.listEmp(); empList.stream().forEach(emp -\u0026gt; { String gender = emp.getGender(); String job = emp.getJob(); if(gender.equals(\u0026#34;1\u0026#34;)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(gender.equals(\u0026#34;2\u0026#34;)){ emp.setGender(\u0026#34;女\u0026#34;); } if(job.equals(\u0026#34;1\u0026#34;)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(job.equals(\u0026#34;2\u0026#34;)){ emp.setJob(\u0026#34;班主任\u0026#34;); } else if (job.equals(\u0026#34;3\u0026#34;)) { emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } 1 2 3 4 5 6 7 8 9 10 11 12 //Controller层 @RestController public class EmpController { @Autowired private EmpService empService; @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list() { List\u0026lt;Emp\u0026gt; empList=empService.list(); System.out.println(empList); return Result.success(empList); } } 如果我此时要加入EmpDaoB（通过MySQL等数据库传送数据），那就吧EmpDaoA的@Component注释了\nspringboot给三层架构分别出了三个衍生注解@Repository，@Service，@Controller\n后续基本上都用数据库传输，并且springboot继承了Mybatis，Mybatis可以使用注解@Mapper来替代@Repository，而Controller层自带@RestController注解，因此可以不用@Controller\n@Component注解可以在不属于这三层，但是很有用的工具类上加这个注解\nPojo文件 pojo文件中存放各种JavaBean\nSpringboot特有的JavaBean写法，使用前要引入Lombok依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package com.test.springboottest03_crud.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.time.LocalDate; import java.time.LocalDateTime; @Data @NoArgsConstructor @AllArgsConstructor public class Emp { private Integer id; private String username; private String password; private String name; private Short gender; private String image; private Short job; private LocalDate entryDate; private Integer deptId; private LocalDateTime createTime;//创建时间 private LocalDateTime updateTime;//修改时间 } 这里用到了三个注解 @Data 同时包含了toString方法，HashCode，所有get，set方法\n@NoArgsConstructor 是无参构造\n@AllArgsConstructor 是全参构造\nMybatis的增删改查(注解写法) 在文件中创建mapper文件夹，创建对应的Mapper接口\n使用注解@Mapper\n1 2 3 4 5 6 7 8 9 @Mapper//程序开始时会自动创建代理对象 public interface EmpMapper { @Delete(\u0026#34;delete from emp where id=#{id}\u0026#34;) public int delete(Integer id); @Options(useGeneratedKeys = true,keyProperty = \u0026#34;id\u0026#34;) @Insert(\u0026#34;insert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time)\u0026#34; + \u0026#34; values (#{username},#{name},#{gender},#{image},#{job},#{entryDate},#{deptId},#{createTime},#{updateTime})\u0026#34;) public void insert(Emp emp); } 第一个是删除操作，@Delete里面写SQL语句，d=#{id}是Mybatis的占位符 使用Integer是因为int不支持不输入就是null，与SQL语句不吻合\n该删除操作删除的是指定id对象\n第二个是插入操作 写正常的insert语句，然后每个占位符都是JavaBean里面的，注意驼峰命名法\n插入操作的形参是JavaBean对象\nTest类的写法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class SpringBootTest03CrudApplicationTests { @Autowired EmpMapper empMapper; @Test public void testDelete() { int a = empMapper.delete(17); System.out.println(a); } public void testInsert() { //构造员工对象 Emp emp = new Emp(); emp.setUsername(\u0026#34;Tom7\u0026#34;); emp.setName(\u0026#34;汤姆3\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setCreateTime(LocalDateTime.now()); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); //执行新增员工信息操作 empMapper.insert(emp); System.out.println(emp.getId()); } } 在测试类中，先用抽象父类创建对象，然后使用依赖注入@Autowire，等价于EmpMapper empMapp=new EmpMapperA()，把和数据库连接好的bean对象传过来，这样就可以对数据库或者xml等数据载体进行操作了。\n删除操作 前面定义了delete接口是int返回值，这里a返回为删除多少个对象\n1 2 3 public void testDelete() { int a = empMapper.delete(17); System.out.println(a); 插入操作 insert方法要将创建好的对象初始化后使用empMapper.insert(emp)来插入\n如果直接输出emp.getId()是没有结果的，在定义接口的时候使用注解@Options\n1 @Options(useGeneratedKeys = true,keyProperty = \u0026#34; 这样就可以返回Id了\n使用LocalDateTime.now()这个方法最后的返回值符合MySQL的date格式\n修改操作 mapper中的代码\n1 2 3 @Update(\u0026#34;update emp set username =#{username},name=#{name},gender=#{gender},image=#{image},\u0026#34; + \u0026#34;job=#{job},entrydate=#{entryDate},dept_id=#{deptId},update_time=#{updateTime} where id=#{id}\u0026#34;) public void update(Emp emp); Test中的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 public void testUpdate() { Emp emp = new Emp(); emp.setId(1); emp.setUsername(\u0026#34;Tom12\u0026#34;); emp.setName(\u0026#34;汤姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setGender((short)1); emp.setJob((short)1); emp.setEntryDate(LocalDate.of(2000,1,1)); emp.setUpdateTime(LocalDateTime.now()); emp.setDeptId(1); empMapper.update(emp); } 查询操作 mapper中的代码\n1 2 @Select(\u0026#34;select * from emp where id=#{id}\u0026#34;) public Emp selectById(Integer id); Test中的代码\n1 2 3 4 5 6 public void testSelect() { Integer id=12; Emp emp= new Emp(); emp=empMapper.selectById(id); System.out.println(emp); } 这里是根据id来对数据查询，但是在注入对象empMapper对应的代理对象赋值的时候，数据库中的下划线命名法和java中的驼峰命名法冲突，导致后面使用驼峰命名法的字段赋值失败\n这时候可以在application.properties中输入camel+Tab 1 2 #Mybatis的驼峰命名法映射开关打开 mybatis.configuration.map-underscore-to-camel-case=true 这时候所有输出就对味了\n查询操作ProMax：模糊查询 对员工姓名进行模糊查询，对应的SQL语句是\n1 select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc 其中‘%张%’的意思是其中有一个字是张就行了，前面和后面都有字也在查询范围里面，张无忌，我是张三等名字都可以被查询到，模糊查询要用关键词like，时间范围可以用between\n但是在@Select注解中不能直接这么写，‘%#{name}%’，其中#{name}不能放到引号里面，因为#{name}会在预编译期间变为？，如果是%?%那么任何一个索引都可以被查询到\n1 2 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by updateTime desc\u0026#34;) 可以调用函数concat(\u0026rsquo;%\u0026rsquo;,#{name},\u0026rsquo;%')\nTest代码为\n1 2 3 4 public void testSelectPlus() { List\u0026lt;Emp\u0026gt; empList=empMapper.selectAll(\u0026#34;张\u0026#34;,(short)1,LocalDate.of(2010,01,01),LocalDate.of(2020,01,01)); System.out.println(empList); } LocalDate.of(2010,01,01)可以输入时间\nMybatis的XML写法 要想使用XML映射来实现增删改查需要在resources中添加一致包名和xml文件\n注：在resources里面创建的不是软件包，是资源包，分隔符不是\u0026rsquo;.\u0026lsquo;而是\u0026rsquo;/\u0026rsquo;，之后会自动转化为\u0026rsquo;.\u0026rsquo;,并且之后创建的xml文件要和接口文档命名一致\n两种方法对比：\n1 2 3 4 //条件查询注解法 @Select(\u0026#34;select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and \u0026#34; + \u0026#34;entrydate between #{begin} and #{end} order by update_time desc\u0026#34;) public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 //xml法 public List\u0026lt;Emp\u0026gt; selectAll(String name, Short gender, LocalDate begin, LocalDate end); 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp where name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) and gender=#{gender} and entrydate between #{begin} and #{end} order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; XML法的前面部分是固定语句，可以直接从官网复制\n创建一个接口的xml语句可以先创建好接口，然后按下Alt+Enter点击最上面的选项\n然后就可以在xml文件里编辑了\n想通过这种方式创建得按照下面方式下载MybatisX插件\n在XML文件中，SQL语句很长，可以选中所有SQL语句然后按下Ctrl+Alt+L格式化\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp set username =#{username}, name=#{name}, gender=#{gender}, image=#{image}, job=#{job}, entrydate=#{entryDate}, dept_id=#{deptId}, update_time=#{updateTime} where id = #{id} \u0026lt;/update\u0026gt; 注：Ctrl+Alt+L可能被网易云音乐或者QQ占用，需要去对应的软件中关闭此快捷键\n不管哪一种方法，都要有方法体，只是说把SQL语句移到了xml文件中\n可以在IDEA中下载MybatisX插件，跳转非常方便\n官方提示 使用注解来映射简单语句会使代码显得更加简洁，但对于稍微复杂一点的语句，Java 注解不仅力不从心，还会让你本就复杂的 SQL 语句更加混乱不堪。 因此，如果你需要做一些很复杂的操作，最好用 XML 来映射语句。\n动态SQL语句 实际业务需求:\n所有搜索条件都是null，此时服务器发送数据为查找所有。\n当有搜索条件的时候，也有条件为null\n若直接写刚才的select语句很容易就搜索不到数据，因为搜索对应的值为null和无搜索条件逻辑不符，此时可以引入动态SQL语句\nSelect动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.test.springboottest03_crud.mapper.EmpMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; select * from emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;, #{name}, \u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender = #{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by update_time desc \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 其中语句可以判断是否有这个条件，如果没有则跳过这条语句。\n可以动态判断是否该加and，如果搜索条件为后面两个条件，那么SQL语句开头就是and导致语法错误，但是where可以解决这个问题\nUpdate的动态SQL语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;update id=\u0026#34;update2\u0026#34;\u0026gt; update emp \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;username!=null\u0026#34;\u0026gt;username =#{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt;name=#{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt;gender=#{gender},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;image!=null\u0026#34;\u0026gt;image=#{image},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;job!=null\u0026#34;\u0026gt;job=#{job},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;entryDate!=null\u0026#34;\u0026gt;entrydate=#{entryDate},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;deptId!=null\u0026#34;\u0026gt;dept_id=#{deptId},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime!=null\u0026#34;\u0026gt;update_time=#{updateTime}\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 这里同样用到了if来设置默认搜索条件，并且引入来判断逗号是否多余导致的SQL语句错误，与的用法一致\n在上述xml写好后，修改条件就可以如下\n1 2 3 4 5 6 7 8 9 public void testUpdate() { Emp emp = new Emp(); emp.setId(12); emp.setUsername(\u0026#34;Sam54235\u0026#34;); /*emp.setName(\u0026#34;萨姆1\u0026#34;); emp.setImage(\u0026#34;1.jpg\u0026#34;); emp.setUpdateTime(LocalDateTime.now());*/ empMapper.update2(emp); } 动态SQL\u0026mdash;批量删除操作 一次性删除多个对象可以这样写SQL语句\n1 delete from emp where id in(18,21); 1 2 3 4 5 6 7 //接口部分这么写 public void deleteById(List\u0026lt;Integer\u0026gt; list); //Test类中这样写 public void deleteTest() { List\u0026lt;Integer\u0026gt; list = Arrays.asList(10, 11); empMapper.deleteById(list); } 因为要删除多个，所以此时传参以集合的方式传递，并且后面集合的名称要和xml中的一致\n在xml中需要这么写\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;deleteById\u0026#34;\u0026gt; delete from emp where id in \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 其中foreach操作可以遍历传递过来的集合list，然后拼凑出所要的sql语句\n其中collection是集合的名称，item是告诉sql语句这时候要按照什么进行删除，separator是SQL语句的分隔符，open和close分别是开始和结尾的字符#{id}通过占位符来加入数据，最后就可以形成(10,11)这样的语句，和之前的delete from emp where id in结合起来就是完整的SQL语句\nSQL代码复用 在企业中直接使用select * from emp速度没有全参访问速度快\n1 2 select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp 1 2 3 4 \u0026lt;sql id=\u0026#34;commonSelect\u0026#34;\u0026gt; select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp \u0026lt;/sql\u0026gt; 这时候可以使用动态SQL语句sql来封装SQL代码\nid就是以后调用的时候的名称\n要调用的时候就这样写\n1 2 3 4 \u0026lt;select id=\u0026#34;selectAll\u0026#34; resultType=\u0026#34;com.test.springboottest03_crud.pojo.Emp\u0026#34;\u0026gt; \u0026lt;include refid=\u0026#34;commonSelect\u0026#34;/\u0026gt; /**/ \u0026lt;/select\u0026gt; 简易Web网站开发 前端部分已经写好，我们只用对照产品经理写的API文档接口来写后端程序即可\n创建springboot项目，勾选springweb依赖，lombok依赖，mybaties和MySQL依赖\n在application.properties中配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spring.application.name=SpringBootProject01 #????? spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver #??????url spring.datasource.url=jdbc:mysql://localhost:3306/springboottest #????????? spring.datasource.username=root #???????? spring.datasource.password=123456 #??mybatis???, ???????? mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl #??mybatis??????????? a_column ------\u0026gt; aCloumn mybatis.configuration.map-underscore-to-camel-case=true----\u0026gt; aCloumn 配置MySQL信息，MySQL用户名，密码，还有Mybatis的驼峰命名法转蛇形命名法\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping 使用三层架构，分别是DeptController，DeptService，DeptMapper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Slf4j @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { Dept dp=new Dept(); @Autowired private DeptService deptService; /*@RequestMapping(value = \u0026#34;/depts\u0026#34;,method = RequestMethod.GET)*/ @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public Result delete(@PathVariable Integer id){ log.info(\u0026#34;删除所选部门数据\u0026#34;); deptService.delete(id); return Result.success(); } @PostMapping() public Result save(@RequestBody Dept dept){ log.info(\u0026#34;添加部门{}\u0026#34;, dept); deptService.save(dept); return Result.success(); } @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable Integer id){ log.info(\u0026#34;根据ID{}查询部门\u0026#34;, id); dp=deptService.select(id); return Result.success(dp); } @PutMapping() public Result update(@RequestBody Dept dept){ log.info(\u0026#34;修改部门{}\u0026#34;, dept); deptService.update(dept); return Result.success(); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/depts)后可以在后面定义类似GetMapping(\u0026quot;/depts/{id}\u0026quot;)时直接省略前面的/depts\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } public void delete(Integer id){ deptMapper.delete(id); } public void save(Dept dept){ dept.setCreateTime(LocalDateTime.now()); dept.setUpdateTime(LocalDateTime.now()); deptMapper.save(dept); } @Override public void update(Dept dept) { dept.setUpdateTime(LocalDateTime.now()); deptMapper.update(dept); } @Override public Dept select(Integer id) { return deptMapper.list1(id); } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示全用xml格式\n1 2 3 4 5 6 7 8 9 @Mapper public interface DeptMapper { /* @Select(\u0026#34;select * from springboottest.dept\u0026#34;)*/ public List\u0026lt;Dept\u0026gt; list(); public void delete(Integer id); public void save(Dept dept); public void update(Dept dept); public Dept list1(Integer id); } xml文件如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;insert id=\u0026#34;save\u0026#34;\u0026gt; insert into springboottest.dept(springboottest.dept.name,springboottest.dept.create_time,springboottest.dept.update_time) values(#{name},#{createTime},#{updateTime}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34;\u0026gt; update springboottest.dept set springboottest.dept.name=#{name},springboottest.dept.update_time=#{updateTime} where springboottest.dept.id=#{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.dept where id=#{id} \u0026lt;/delete\u0026gt; \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;list1\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept where id=#{id} \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n注意到这里update接口应当先根据ID查询到对应的数据，然后再将更改后的数据发送给服务端存储\n点击编辑按钮后，前端发送get请求，将查询到的数据发送到这个窗口页面上\n然后我们可以对其进行修改，然后将改正后的数据通过post请求发送给后端，然后后端对这个数据进行存储，完成了一次更新操作\n@PathVariable注解的使用 当前端发送数据且根据id给后端时，前端的id和后端的id不一定相同\n但是数据库中的内容并不是如此\n所以这里可以通过@PathVariable注解来寻找到之前数据库传过来的正确的id，格式如下\n1 2 3 4 5 6 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result select(@PathVariable(\u0026#34;id\u0026#34;) Integer id) { log.info(\u0026#34;根据id{}查询数据\u0026#34;,id); Emp emp1=empService.selectId(id); return Result.success(emp1); } @RequestBody注解的使用 前端此时传回来的数据是JSON格式，并不能直接把这个数据转化为对象传给数据库做select或者存储，此时可以通过注解@RequestBody来转化为Java对象,格式如下\n1 2 3 4 5 6 @PutMapping public Result update(@RequestBody Emp emp){ log.info(\u0026#34;{}修改数据\u0026#34;,emp.getUsername()); empService.update(emp); return Result.success(); } 查询emp部分稍有麻烦\n分页查询员工 根据API接口文档\n前端返回的数据为当前页数和每页有多少个数据\n此时后端应当给前端返回的是当前页所查询到的数据和总共数据库中有多少条数据\n后面的查询很简单，可以直接用个select语句来完成\n1 select count(*) from springboottest.emp 前面的数据得用到分页查询，条件为limit #{page},#{pageSize}，\n此时EmpService得设置page和pageSize\n1 2 3 4 5 6 7 8 9 @Override public PojoBean select(String name, Short gender, LocalDate begin, LocalDate end, Integer page, Integer pageSize) { PojoBean pojoBean = new PojoBean(); pojoBean.setTotal(empMapper.count()); pojoBean.setRows(empMapper.list(name,gender,begin,end,(page-1)*pageSize,pageSize)); System.out.println((page-1)*pageSize); System.out.println(pageSize); return pojoBean; } 在数据库中limit 0,5代表第0索引开始，且每页有5个元素，前端应该是第1页，每页有5个元素，因此索引数和前端页码对上的话，索引为(page-1)*pageSize\n分页条件查询员工 此时前端可能会给出查询条件，姓名name，性别gender，入职时间，entryDate\n这些条件可能给，也可能全给，也可能给部分，也可能一个都不给，可以用之前提到的动态SQL语句来解决这个问题，这种复杂的sql语句不能用注解来写，只能通过XML文件配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Emp\u0026#34;\u0026gt; select * from springboottest.emp \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;name!=null\u0026#34;\u0026gt; name like concat(\u0026#39;%\u0026#39;,#{name},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;gender!=null\u0026#34;\u0026gt; and gender=#{gender} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;begin!=null and end!=null\u0026#34;\u0026gt; and entrydate between #{begin} and #{end} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; limit #{page},#{pageSize} \u0026lt;/select\u0026gt; 前端总共返回的数据如下\n1 2 3 4 5 6 7 @GetMapping public Result emp(String name, Short gender, LocalDate begin, LocalDate end, @RequestParam(defaultValue = \u0026#34;1\u0026#34;) Integer page, @RequestParam(defaultValue = \u0026#34;10\u0026#34;) Integer pageSize) { PojoBean pb=empService.select(name,gender,begin,end,page,pageSize); return Result.success(pb); } @RequestParam 注解的使用 @RequestParam注解可以让参数有默认值，这样用户不使用任何条件查询就可以查询到默认的10条记录\n最终给前端因为要返回两种数据，一个是总页数，一个是查询到的员工的list集合\n因此这时候创建一个PojoBean类\n最后把数据封装好后以Result的标准JSON格式返回给前端\n批量删除员工 前端返回的删除指令可能有多条，这时候返回来的是个数组\n1 2 3 4 5 6 @DeleteMapping(\u0026#34;/{ids}\u0026#34;) public Result delete(@PathVariable(\u0026#34;ids\u0026#34;) Integer [] ids) { log.info(\u0026#34;删除所选员工数据\u0026#34;); empService.delete(ids); return Result.success(); } 接受到前端的数据后可以去service层,然后再把数组交给Mapper层\n最后的xml语句为\n1 2 3 4 5 6 \u0026lt;delete id=\u0026#34;delete\u0026#34;\u0026gt; delete from springboottest.emp where springboottest.emp.id in \u0026lt;foreach collection=\u0026#34;ids\u0026#34; item=\u0026#34;id\u0026#34; separator=\u0026#34;,\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{id} \u0026lt;/foreach\u0026gt; \u0026lt;/delete\u0026gt; 安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入jwt的依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package com.test.springbootproject01.interceptor; import ... @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package com.test.springbootproject01.config; import ... @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package com.test.springbootproject01.Controller; import ... @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } AOP 面向切面/方法编程 要在使用AOP之前先引入依赖\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 一个简单的AOP入门示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.test.springbootproject01.AOP; import ... @Slf4j @Component @Aspect public class TimeAspect { @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) public Object recordTime(ProceedingJoinPoint joinPoint) throws Throwable { //方法启动时间 long startTime = System.currentTimeMillis(); //执行方法 Object result = joinPoint.proceed(); //方法结束时间 long endTime = System.currentTimeMillis(); log.info(joinPoint.getSignature()+\u0026#34;方法执行时间为\u0026#34;+(endTime - startTime) + \u0026#34;ms\u0026#34;); return result; } } 1 @Around(\u0026#34;execution(* com.test.springbootproject01.Service.*.*(..))\u0026#34;) execution是用来提示后面是切入点，第一个*指的是返回值为任意类型，com.test.springbootproject01.Service第二个是指任何类，第三个是任何方法，(..)表示匹配任何数量和类型的参数\nNginx的反向代理 后端部署在服务器上默认占用8080端口，前端若也要在服务器上部署，最好不要也选择8080，此时就要用到反向代理。\n打开\nnginx配置界面、\n然后修改这里的代码\nlisten代表前端服务器占用的端口\nlocation /api/ 块说明 1 2 3 location /api/ { proxy_pass http://localhost:8080/emprequest/; } location 指令（/api/ 路径情况）： 这里的 location /api/ 表示匹配所有以 /api/ 开头的客户端请求 URI。例如，像 http://localhost:100/api/user、http://localhost:100/api/order 这样的请求都会进入到这个 location 块中进行后续处理。 proxy_pass 指令： 用于设置反向代理，即将匹配到 /api/ 开头的请求转发到指定的后端服务器地址及路径上。在这里，它会把请求转发到 http://localhost:8080/emprequest/。具体来说，比如前端页面发起了一个 http://localhost:100/api/some-api 的请求，Nginx 会把这个请求去掉 /api/ 这部分前缀后，转发到 http://localhost:8080/emprequest/some-api 这个路径上，让运行在 8080 端口的后端服务器去处理对应的请求，然后后端服务器返回的响应结果又会通过 Nginx 再传递回发起请求的客户端（比如浏览器）。 总体来讲，这段 Nginx 配置定义了一个监听在 100 端口的服务器，针对根路径请求会查找并返回 html 目录下的相关文件，而针对以 /api/ 开头的请求则会将其代理转发到本地 8080 端口下的特定路径上让后端服务进行处理。 此时前端的代码为\n以后设计接口最好这样搞\nTODO标签代表还没做完的事，后面可以查看TODO标签对没写完的代码进行完善\n","date":"2025-03-16T15:38:21+08:00","permalink":"https://LuciusWan.github.io/p/javaweb%E9%83%A8%E5%88%86%E7%AC%94%E8%AE%B0/","title":"JavaWeb部分笔记"},{"content":"API接口文档 1. 文档概述 产品经理的任务 产品经理定义每个版本需要实现的具体功能和细节，通常通过撰写产品需求文档来明确需求。并且撰写API接口文档告诉前后端工程师，怎样开发才能在双方完成任务后，前后端能够完美对接。\n文档目的 API接口文档旨在帮助开发人员了解如何调用和使用本系统提供的API。文档包括了接口的定义、请求与响应格式、错误处理机制等内容。\n系统架构 前端：原生JS 或 Vue.js 后端：Java原生 或 SpringBoot框架 API接口文档示例 部门管理 1.1 部门列表查询 1.1.1 基本信息 请求路径：/depts\n请求方式：GET\n接口描述：该接口用于部门列表数据查询\n1.1.2 请求参数 无\n1.1.3 响应数据 参数格式：application/json\n参数说明：\n参数名 类型 是否必须 备注 code number 必须 响应码，1 代表成功，0 代表失败 msg string 非必须 提示信息 data object[ ] 非必须 返回的数据 \\ - id number 非必须 \\ - name string 非必须 \\ - createTime string 非必须 \\ - updateTime string 非必须 响应数据样例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;学工部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;教研部\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;2022-09-01T23:06:29\u0026#34; } ] } 2. 前端使用说明 前端框架选择 1. JS原生代码（使用fetch） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fetch(\u0026#39;/depts\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; { if (data.code === 1) { console.log(\u0026#34;部门列表:\u0026#34;, data.data); } else { console.log(\u0026#34;请求失败:\u0026#34;, data.msg); } }) .catch(error =\u0026gt; { console.error(\u0026#39;Error:\u0026#39;, error); }); Vue.js 在Vue组件中，可以使用Axios来简化API调用。\n示例代码（使用Axios发送GET请求）：\n错误处理 前端应对API请求中的常见错误进行处理，如404（未找到），500（服务器错误）等。\n错误处理示例：\n1 2 3 4 5 6 7 8 9 10 fetch(\u0026#39;https://api.example.com/data\u0026#39;) .then(response =\u0026gt; { if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return response.json(); }) .catch(error =\u0026gt; { console.error(\u0026#39;API call failed:\u0026#39;, error); }); 3. 后端实现说明 后端语言/框架选择 Java原生 使用Java原生编写API接口，通常通过HttpServlet处理请求。\n示例代码（Java原生实现GET请求）：\n1 2 3 4 5 6 7 8 9 10 11 import javax.servlet.*; import javax.servlet.http.*; import java.io.*; public class DataServlet extends HttpServlet { protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(\u0026#34;application/json\u0026#34;); PrintWriter out = response.getWriter(); out.println(\u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Hello, World!\\\u0026#34;}\u0026#34;); } } SpringBoot 使用SpringBoot框架，MySQL数据库，Mybatis框架来实现后端数据的提供\n示例代码（SpringBoot实现前端Get的请求）：\n内容是查询所有部门，要求这里是Get请求，可以使用@GetMapping\n使用三层架构，DeptController，DeptService，DeptMapper,响应，处理数据，调取数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //日志输出的注解 @Slf4j //controller层必带的注解 @RestController @RequestMapping(\u0026#34;/dept\u0026#34;) public class DeptController { Dept dp=new Dept(); //依赖注入 @Autowired private DeptService deptService; @GetMapping() public Result list(){ log.info(\u0026#34;查询所有部门数据\u0026#34;); List\u0026lt;Dept\u0026gt; depts= deptService.list(); return Result.success(depts); } } 这是DeptController的代码有@RequestMapping(\u0026quot;/dept\u0026quot;)后可以在后面定义类似GetMapping(\u0026quot;/dept\u0026quot;)时直接省略前面的/dept\nResult类可以以统一格式把数据上传到前端，并且是JSON格式(这是个工具类，直接导入pojo包下即可)\n统一返回格式大致如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package com.test.springbootproject01.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应信息 描述字符串 private Object data; //返回的数据 //增删改 成功响应 public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应 public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } Service层用来处理数据，需要用到注解@Service\n1 2 3 4 5 6 7 8 9 @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; public List\u0026lt;Dept\u0026gt; list(){ List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } } 最后到Mapper层用来和数据库对接，Mapper可以用XML来和数据库对接，也可以使用注解的方式，这里演示Mapper层配合xml格式调用数据\n1 2 3 4 @Mapper public interface DeptMapper { public List\u0026lt;Dept\u0026gt; list(); } xml文件如下\n1 2 3 \u0026lt;select id=\u0026#34;list\u0026#34; resultType=\u0026#34;com.test.springbootproject01.pojo.Dept\u0026#34;\u0026gt; select * from springboottest.dept \u0026lt;/select\u0026gt; 这样Get请求从前端发送过来后，由后端Controller层接受请求，然后调用service层处理数据，然后service层再调用mapper层获取数据，最终处理完数据后返回给前端\n安全性与认证 API接口使用JWT（JSON Web Token）进行认证，确保请求的安全性。如果登录成功就获得一个令牌，每次访问网站都会检查jwt令牌是否有效，同时可以给jwt令牌设置有效时限。\nJWT认证示例（Spring Security集成JWT）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; public class JwtTokenFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (token != null \u0026amp;\u0026amp; token.startsWith(\u0026#34;Bearer \u0026#34;)) { // Validate and parse JWT token here UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(user, null, authorities); SecurityContextHolder.getContext().setAuthentication(authentication); } chain.doFilter(request, response); } } SpringBoot手搓jwt令牌认证 在使用前要在pom.xml中引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这是jwt令牌的工具类直接CV到pojo包下即可,key是秘钥，Time是令牌有效期，过期自动登出网站\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package com.test.springbootproject01.pojo; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; public class JwtHelper { private String key = \u0026#34;Lucius\u0026#34;; private Integer Time=3600*1000; public String getJwt(Claims claims){ String jwt= Jwts.builder() .setClaims(claims) .signWith(SignatureAlgorithm.HS256,key) .setExpiration(new Date(System.currentTimeMillis()+Time)) .compact(); return jwt; } public Claims parseJwt(String jwt){ Claims claims=Jwts.parser() //输入秘钥 .setSigningKey(key) //给jwt令牌解码 .parseClaimsJws(jwt) //获取claims对象 .getBody(); return claims; } } 为了让没有jwt令牌的用户无法访问网站，我们得使用拦截器，下面是springboot中的拦截器\n我们要先配置这个拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package com.test.springbootproject01.interceptor; import com.alibaba.fastjson.JSONObject; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import jakarta.servlet.http.HttpServletRequest; import jakarta.servlet.http.HttpServletResponse; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; @Component @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { @Override//目标方法运行前执行 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //1获取请求路径 String url = request.getRequestURI(); log.info(\u0026#34;拦截到请求：{}\u0026#34;,url); //如果是登录请求，放行 if(url.equals(\u0026#34;/login\u0026#34;)){ log.info(\u0026#34;登录放行\u0026#34;); return true; } //2判断是否登录 String jwt=request.getHeader(\u0026#34;token\u0026#34;); if(jwt==null){ log.info(\u0026#34;未登录，拦截\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin= JSONObject.toJSONString(error); response.getWriter().write(notlogin); //返回false不放行 return false; } JwtHelper jwtHelper=new JwtHelper(); //3判断jwt是否合法 //解析jwt令牌时，如果解析失败，抛出异常，捕获异常，返回错误信息，如果解析成功，就可以放行 try { jwtHelper.parseJwt(jwt); } catch (Exception e) { log.info(\u0026#34;jwt无效\u0026#34;); Result error=Result.error(\u0026#34;NOT_LOGIN\u0026#34;); String notlogin=JSONObject.toJSONString(error); response.getWriter().write(notlogin); return false; } log.info(\u0026#34;jwt有效\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } } 正常写的话需要实现HandlerInterceptor接口中的preHandle方法，这个方法是在调用controller方法前执行的，在后端未向前端发送数据时拦截检查jwt令牌，jwt令牌的逻辑请看注释\n写一个类名为WebConfig,然后配置拦截器的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.test.springbootproject01.config; import com.test.springbootproject01.interceptor.LoginCheckInterceptor; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.InterceptorRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @Configuration//@Configuration注解表示当前类是一个配置类 public class WebConfig implements WebMvcConfigurer { @Autowired //注入拦截器对象 private LoginCheckInterceptor loginCheckInterceptor; @Override //注册/添加拦截器 public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(loginCheckInterceptor) //添加拦截器拦截路径 .addPathPatterns(\u0026#34;/**\u0026#34;) //除了/login以外的路径都要被拦截 .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 然后回到登录的controller层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.test.springbootproject01.Controller; import com.test.springbootproject01.Service.EmpService; import com.test.springbootproject01.pojo.Emp; import com.test.springbootproject01.pojo.JwtHelper; import com.test.springbootproject01.pojo.Result; import io.jsonwebtoken.Claims; import io.jsonwebtoken.impl.DefaultClaims; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @Slf4j @RestController @RequestMapping(\u0026#34;/login\u0026#34;) public class LoginController { @Autowired private EmpService empService; @PostMapping public Result Login(@RequestBody Emp emp){ log.info(\u0026#34;{}请求登录\u0026#34;,emp); Emp emp1=empService.login(emp); //如果查有此人就开始准备制作令牌 if(emp1!=null){ JwtHelper jh=new JwtHelper(); Claims claims=new DefaultClaims(); claims.put(\u0026#34;id\u0026#34;,emp1.getId()); claims.put(\u0026#34;username\u0026#34;,emp1.getUsername()); claims.put(\u0026#34;password\u0026#34;,emp1.getPassword()); log.info(\u0026#34;请求人用户名：{}\u0026#34;,emp.getUsername()); log.info(\u0026#34;请求人密码{}\u0026#34;,emp.getPassword()); String jwt=jh.getJwt(claims); return Result.success(jwt); } return Result.error(\u0026#34;NOT_LOGIN\u0026#34;); } } java代码是这样的(\n","date":"2025-03-16T15:29:26+08:00","permalink":"https://LuciusWan.github.io/p/api%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"API接口文档使用教程"}]